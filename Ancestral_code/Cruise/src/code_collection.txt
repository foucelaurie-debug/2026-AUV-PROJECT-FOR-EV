AUV Cruise 代码汇总（源路径: Ancestral_code/Cruise/src）
- 基于根目录 README.md: AGX 运行 ROS2 节点（uv_ai、uv_hm、uv_vision、uv_control_py、uv_launch_pkg、utils、models），串口连接 STM32H743 运动控制与 STM32F407 设备管理。
- 下方按文件列出路径、功能简述，并附完整代码，便于交给其他 AI 解读单片机与 ROS 集成工程。
- 节点与话题：uv_hmu 串口桥接 MCU；uv_capture/uv_depthimg 等发布相机流；uv_detect_demo/uv_automaton 系列做视觉/自动化；uv_launch_pkg/launch.py 作为启动入口；uv_control_py 管理 PID/推力曲线与坐标；uv_msgs 定义消息；utils/models 为 YOLO 推理与模型定义。

===== ..\..\..\README.md =====
功能: 根目录 README：硬件分层与 ROS2 节点说明
# AUV Cruise ��Ŀ˵��

## 1. ����ܹ�����
- AGX ��λ�������� Linux �ϵ� ROS 2 ������ Ancestral_code/Cruise/src, �����Ӿ���֪, �������, ��ͨ�����������鵥Ƭ��ͨ�š�
- �˶����ư� STM32H743 ����λ�� MCU_PROJECT/MotionControl-CSnew, ������̬��λ�ñջ�����, ���������ƽ������������ PWM��
- �豸����� STM32F407 ����λ�� MCU_PROJECT/DeviceManager, �����ص�ѹ����ڻ������, �Լ����, �����, DVL ��Դ��������ơ�
- ���Դ������Ϊ: AGX �Ǵ��Ժ��۾�, H743 ������ļ����ǰͥ, F407 ������֧��ϵͳ��

## 2. �� AGX �ϵ�ʵ����������
1) ׼������Ȩ��: �� Ancestral_code/Cruise/scripts/run/permissions.sh �����ò�ִ��, ȷ�� /dev/ttyUSB0 �� /dev/ttyUSB1 �ɷ��ʡ�
2) ���Ӳ���Žӽڵ� uv_hmu.py (��λ���͵�Ƭ��֮�����): �� uv_hm/uv_hm/uv_hmu.py �ڲ�ʹ�� uv_control_py/Serial.py ����·����, ������ PID ���������ߡ�
   ʾ������ (·������ʵ�ʻ�������): ros2 run uv_hm uv_hmu.py --h750-path /dev/ttyUSB1 --f407-path /dev/ttyUSB0 --pid-path datas/pid_parameters.json --curve-path datas/thrust_cureves.json
3) �� rqt ���е���: �ص��ע motion_controller ���� (���� H743 ����̬, Ŀ��, ������) �� device_manager ���� (���� F407 �ĵ�ѹ, ©ˮ, ����͵����״̬��)��
4) ����������: ���� uv_vision/uv_capture.py ��ȡǰ�Ӻ���������ͷͼ��, ������ uv_ai/uv_detect_demo.py �� YOLO Ŀ����, ��������������� ROS ���⡣

===== .\models\models\__init__.py =====
功能: 代码摘录

===== .\models\models\2042.yaml =====
功能: 代码摘录
# create by pogg
# parameters
nc: 1  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 10,13, 16,30, 33,23 ]  # P3/8
  - [ 30,61, 62,45, 59,119 ]  # P4/16
  - [ 116,90, 156,198, 373,326 ]  # P5/32

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, conv_bn_relu_maxpool, [ 32 ] ],    # 0-P2/4
    [ -1, 1, Shuffle_Block, [ 116, 2 ] ], # 1-P3/8
    [ -1, 3, Shuffle_Block, [ 116, 1 ] ], # 2
    [ -1, 1, Shuffle_Block, [ 232, 2 ] ], # 3-P4/16
    [ -1, 7, Shuffle_Block, [ 232, 1 ] ], # 4
    [ -1, 1, Shuffle_Block, [ 464, 2 ] ], # 5-P5/32
    [ -1, 3, Shuffle_Block, [ 464, 1 ] ], # 6
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 128, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, C3, [ 128, False ] ],  # 10

    [ -1, 1, Conv, [ 64, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, C3, [ 64, False ] ],  # 14 (P3/8-small)

    [ -1, 1, Conv, [ 64, 3, 2 ] ],
    [ [ -1, 11 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, C3, [ 128, False ] ],  # 17 (P4/16-medium)

    [ -1, 1, Conv, [ 128, 3, 2 ] ],
    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, C3, [ 256, False ] ],  # 20 (P5/32-large)

    [ [ 14, 17, 20 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\aimlab.yaml =====
功能: 代码摘录
# create by pogg
# parameters
nc: 1  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 10,13, 16,30, 33,23 ]  # P3/8
  - [ 30,61, 62,45, 59,119 ]  # P4/16
  - [ 116,90, 156,198, 373,326 ]  # P5/32

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, conv_bn_relu_maxpool, [ 32 ] ],    # 0-P2/4
    [ -1, 1, Shuffle_Block, [ 116, 2 ] ], # 1-P3/8
    [ -1, 3, Shuffle_Block, [ 116, 1 ] ], # 2
    [ -1, 1, Shuffle_Block, [ 232, 2 ] ], # 3-P4/16
    [ -1, 7, Shuffle_Block, [ 232, 1 ] ], # 4
    [ -1, 1, Shuffle_Block, [ 464, 2 ] ], # 5-P5/32
    [ -1, 3, Shuffle_Block, [ 464, 1 ] ], # 6
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 128, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, C3, [ 128, False ] ],  # 10

    [ -1, 1, Conv, [ 64, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, C3, [ 64, False ] ],  # 14 (P3/8-small)

    [ -1, 1, Conv, [ 64, 3, 2 ] ],
    [ [ -1, 11 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, C3, [ 128, False ] ],  # 17 (P4/16-medium)

    [ -1, 1, Conv, [ 128, 3, 2 ] ],
    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, C3, [ 256, False ] ],  # 20 (P5/32-large)

    [ [ 14, 17, 20 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\apex.yaml =====
功能: 代码摘录
# create by pogg
# parameters
nc: 1  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 10,13, 16,30, 33,23 ]  # P3/8
  - [ 30,61, 62,45, 59,119 ]  # P4/16
  - [ 116,90, 156,198, 373,326 ]  # P5/32

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, conv_bn_relu_maxpool, [ 32 ] ],    # 0-P2/4
    [ -1, 1, Shuffle_Block, [ 116, 2 ] ], # 1-P3/8
    [ -1, 3, Shuffle_Block, [ 116, 1 ] ], # 2
    [ -1, 1, Shuffle_Block, [ 232, 2 ] ], # 3-P4/16
    [ -1, 7, Shuffle_Block, [ 232, 1 ] ], # 4
    [ -1, 1, Shuffle_Block, [ 464, 2 ] ], # 5-P5/32
    [ -1, 3, Shuffle_Block, [ 464, 1 ] ], # 6
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 128, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, C3, [ 128, False ] ],  # 10

    [ -1, 1, Conv, [ 64, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, C3, [ 64, False ] ],  # 14 (P3/8-small)

    [ -1, 1, Conv, [ 64, 3, 2 ] ],
    [ [ -1, 11 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, C3, [ 128, False ] ],  # 17 (P4/16-medium)

    [ -1, 1, Conv, [ 128, 3, 2 ] ],
    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, C3, [ 256, False ] ],  # 20 (P5/32-large)

    [ [ 14, 17, 20 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\BFV.yaml =====
功能: 代码摘录
# create by pogg
# parameters
nc: 1  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 10,13, 16,30, 33,23 ]  # P3/8
  - [ 30,61, 62,45, 59,119 ]  # P4/16
  - [ 116,90, 156,198, 373,326 ]  # P5/32

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, conv_bn_relu_maxpool, [ 32 ] ],    # 0-P2/4
    [ -1, 1, Shuffle_Block, [ 116, 2 ] ], # 1-P3/8
    [ -1, 3, Shuffle_Block, [ 116, 1 ] ], # 2
    [ -1, 1, Shuffle_Block, [ 232, 2 ] ], # 3-P4/16
    [ -1, 7, Shuffle_Block, [ 232, 1 ] ], # 4
    [ -1, 1, Shuffle_Block, [ 464, 2 ] ], # 5-P5/32
    [ -1, 3, Shuffle_Block, [ 464, 1 ] ], # 6
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 128, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, C3, [ 128, False ] ],  # 10

    [ -1, 1, Conv, [ 64, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, C3, [ 64, False ] ],  # 14 (P3/8-small)

    [ -1, 1, Conv, [ 64, 3, 2 ] ],
    [ [ -1, 11 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, C3, [ 128, False ] ],  # 17 (P4/16-medium)

    [ -1, 1, Conv, [ 128, 3, 2 ] ],
    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, C3, [ 256, False ] ],  # 20 (P5/32-large)

    [ [ 14, 17, 20 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\common.py =====
功能: 代码摘录
# YOLOv5 common modules

import math
import warnings
from copy import copy
from pathlib import Path

import numpy as np
import pandas as pd
import requests
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from torch.cuda import amp

from utils.datasets import letterbox
from utils.general import non_max_suppression, make_divisible, scale_coords, increment_path, xyxy2xywh
from utils.plots import color_list, plot_one_box
from utils.torch_utils import time_synchronized


def autopad(k, p=None):  # kernel, padding
    # Pad to 'same'
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p

def constant_init(module, val, bias=0):
    if hasattr(module, 'weight') and module.weight is not None:
        nn.init.constant_(module.weight, val)
    if hasattr(module, 'bias') and module.bias is not None:
        nn.init.constant_(module.bias, bias)

def kaiming_init(module,
                 a=0,
                 mode='fan_out',
                 nonlinearity='relu',
                 bias=0,
                 distribution='normal'):
    assert distribution in ['uniform', 'normal']
    if hasattr(module, 'weight') and module.weight is not None:
        if distribution == 'uniform':
            nn.init.kaiming_uniform_(
                module.weight, a=a, mode=mode, nonlinearity=nonlinearity)
        else:
            nn.init.kaiming_normal_(
                module.weight, a=a, mode=mode, nonlinearity=nonlinearity)
    if hasattr(module, 'bias') and module.bias is not None:
        nn.init.constant_(module.bias, bias)

def last_zero_init(m):
    if isinstance(m, nn.Sequential):
        constant_init(m[-1], val=0)
        m[-1].inited = True
    else:
        constant_init(m, val=0)
        m.inited = True

class ContextBlock2d(nn.Module):
    """ContextBlock2d

    Parameters
    ----------
    inplanes : int
        Number of in_channels.
    pool : string
        spatial att or global pooling (default:'att').
    fusions : list

    Reference:
        Yue Cao, et al. "GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond."
    """
    def __init__(self, inplanes, pool='att', fusions=['channel_add', 'channel_mul']):
        super(ContextBlock2d, self).__init__()
        assert pool in ['avg', 'att']
        assert all([f in ['channel_add', 'channel_mul'] for f in fusions])
        assert len(fusions) > 0, 'at least one fusion should be used'
        self.inplanes = inplanes
        self.planes = inplanes // 4
        self.pool = pool
        self.fusions = fusions
        if 'att' in pool:
            self.conv_mask = nn.Conv2d(inplanes, 1, kernel_size=1)
            self.softmax = nn.Softmax(dim=2)
        else:
            self.avg_pool = nn.AdaptiveAvgPool2d(1)
        if 'channel_add' in fusions:
            self.channel_add_conv = nn.Sequential(
                nn.Conv2d(self.inplanes, self.planes, kernel_size=1),
                nn.LayerNorm([self.planes, 1, 1]),
                nn.ReLU(inplace=True),
                nn.Conv2d(self.planes, self.inplanes, kernel_size=1)
            )
        else:
            self.channel_add_conv = None
        if 'channel_mul' in fusions:
            self.channel_mul_conv = nn.Sequential(
                nn.Conv2d(self.inplanes, self.planes, kernel_size=1),
                nn.LayerNorm([self.planes, 1, 1]),
                nn.ReLU(inplace=True),
                nn.Conv2d(self.planes, self.inplanes, kernel_size=1)
            )
        else:
            self.channel_mul_conv = None
        self.reset_parameters()

    def reset_parameters(self):
        if self.pool == 'att':
            kaiming_init(self.conv_mask, mode='fan_in')
            self.conv_mask.inited = True

        if self.channel_add_conv is not None:
            last_zero_init(self.channel_add_conv)
        if self.channel_mul_conv is not None:
            last_zero_init(self.channel_mul_conv)

    def spatial_pool(self, x):
        batch, channel, height, width = x.size()
        if self.pool == 'att':
            input_x = x
            # [N, C, H * W]
            input_x = input_x.view(batch, channel, height * width)
            # [N, 1, C, H * W]
            input_x = input_x.unsqueeze(1)
            # [N, 1, H, W]
            context_mask = self.conv_mask(x)
            # [N, 1, H * W]
            context_mask = context_mask.view(batch, 1, height * width)
            # [N, 1, H * W]
            context_mask = self.softmax(context_mask)
            # [N, 1, H * W, 1]
            context_mask = context_mask.unsqueeze(3)
            # [N, 1, C, 1]
            context = torch.matmul(input_x, context_mask)
            # [N, C, 1, 1]
            context = context.view(batch, channel, 1, 1)
        else:
            # [N, C, 1, 1]
            context = self.avg_pool(x)

        return context

    def forward(self, x):
        # [N, C, 1, 1]
        context = self.spatial_pool(x)

        if self.channel_mul_conv is not None:
            # [N, C, 1, 1]
            channel_mul_term = torch.sigmoid(self.channel_mul_conv(context))
            out = x * channel_mul_term
        else:
            out = x
        if self.channel_add_conv is not None:
            # [N, C, 1, 1]
            channel_add_term = self.channel_add_conv(context)
            out = out + channel_add_term
        return out

class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Conv, self).__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())
        # self.act = nn.ReLU(inplace=True)
        # self.act = nn.LeakyReLU(0.1, inplace=True) if act else nn.Identity()

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def fuseforward(self, x):
        return self.act(self.conv(x))


class TransformerLayer(nn.Module):
    # Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)
    def __init__(self, c, num_heads):
        super().__init__()
        self.q = nn.Linear(c, c, bias=False)
        self.k = nn.Linear(c, c, bias=False)
        self.v = nn.Linear(c, c, bias=False)
        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)
        self.fc1 = nn.Linear(c, c, bias=False)
        self.fc2 = nn.Linear(c, c, bias=False)

    def forward(self, x):
        x = self.ma(self.q(x), self.k(x), self.v(x))[0] + x
        x = self.fc2(self.fc1(x)) + x
        return x


class TransformerBlock(nn.Module):
    # Vision Transformer https://arxiv.org/abs/2010.11929
    def __init__(self, c1, c2, num_heads, num_layers):
        super().__init__()
        self.conv = None
        if c1 != c2:
            self.conv = Conv(c1, c2)
        self.linear = nn.Linear(c2, c2)  # learnable position embedding
        self.tr = nn.Sequential(*[TransformerLayer(c2, num_heads) for _ in range(num_layers)])
        self.c2 = c2

    def forward(self, x):
        if self.conv is not None:
            x = self.conv(x)
        b, _, w, h = x.shape
        p = x.flatten(2)
        p = p.unsqueeze(0)
        p = p.transpose(0, 3)
        p = p.squeeze(3)
        e = self.linear(p)
        x = p + e

        x = self.tr(x)
        x = x.unsqueeze(3)
        x = x.transpose(0, 3)
        x = x.reshape(b, self.c2, w, h)
        return x


class Bottleneck(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super(Bottleneck, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))


class BottleneckCSP(nn.Module):
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(BottleneckCSP, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)
        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)
        self.cv4 = Conv(2 * c_, c2, 1, 1)
        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)
        self.act = nn.LeakyReLU(0.1, inplace=True)
        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])

    def forward(self, x):
        y1 = self.cv3(self.m(self.cv1(x)))
        y2 = self.cv2(x)
        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))


class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(C3, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))

class C3_GC(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(C3_GC, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.gc = ContextBlock2d(c1)
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        out = torch.cat((self.m(self.cv1(x)), self.cv2(self.gc(x))), dim=1)
        out = self.cv3(out)
        return out

class C3TR(C3):
    # C3 module with TransformerBlock()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = TransformerBlock(c_, c_, 4, n)


class SPP(nn.Module):
    # Spatial pyramid pooling layer used in YOLOv3-SPP
    def __init__(self, c1, c2, k=(5, 9, 13)):
        super(SPP, self).__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])

    def forward(self, x):
        x = self.cv1(x)
        return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))


class SPPF(nn.Module):
    # Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher
    def __init__(self, c1, c2, k=5):  # equivalent to SPP(k=(5, 9, 13))
        super().__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * 4, c2, 1, 1)
        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)

    def forward(self, x):
        x = self.cv1(x)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # suppress torch 1.9.0 max_pool2d() warning
            y1 = self.m(x)
            y2 = self.m(y1)
            return self.cv2(torch.cat([x, y1, y2, self.m(y2)], 1))

class Focus(nn.Module):
    # Focus wh information into c-space
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Focus, self).__init__()
        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)
        # self.contract = Contract(gain=2)

    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)
        return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))
        # return self.conv(self.contract(x))


class Contract(nn.Module):
    # Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        N, C, H, W = x.size()  # assert (H / s == 0) and (W / s == 0), 'Indivisible gain'
        s = self.gain
        x = x.view(N, C, H // s, s, W // s, s)  # x(1,64,40,2,40,2)
        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # x(1,2,2,64,40,40)
        return x.view(N, C * s * s, H // s, W // s)  # x(1,256,40,40)


class Expand(nn.Module):
    # Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        N, C, H, W = x.size()  # assert C / s ** 2 == 0, 'Indivisible gain'
        s = self.gain
        x = x.view(N, s, s, C // s ** 2, H, W)  # x(1,2,2,16,80,80)
        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # x(1,16,80,2,80,2)
        return x.view(N, C // s ** 2, H * s, W * s)  # x(1,16,160,160)


class Concat(nn.Module):
    # Concatenate a list of tensors along dimension
    def __init__(self, dimension=1):
        super(Concat, self).__init__()
        self.d = dimension

    def forward(self, x):
        return torch.cat(x, self.d)


class NMS(nn.Module):
    # Non-Maximum Suppression (NMS) module
    conf = 0.25  # confidence threshold
    iou = 0.45  # IoU threshold
    classes = None  # (optional list) filter by class

    def __init__(self):
        super(NMS, self).__init__()

    def forward(self, x):
        return non_max_suppression(x[0], conf_thres=self.conf, iou_thres=self.iou, classes=self.classes)


class autoShape(nn.Module):
    # input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS
    conf = 0.25  # NMS confidence threshold
    iou = 0.45  # NMS IoU threshold
    classes = None  # (optional list) filter by class

    def __init__(self, model):
        super(autoShape, self).__init__()
        self.model = model.eval()

    def autoshape(self):
        print('autoShape already enabled, skipping... ')  # model already converted to model.autoshape()
        return self

    @torch.no_grad()
    def forward(self, imgs, size=640, augment=False, profile=False):
        # Inference from various sources. For height=640, width=1280, RGB images example inputs are:
        #   filename:   imgs = 'data/samples/zidane.jpg'
        #   URI:             = 'https://github.com/ultralytics/yolov5/releases/download/v1.0/zidane.jpg'
        #   OpenCV:          = cv2.imread('image.jpg')[:,:,::-1]  # HWC BGR to RGB x(640,1280,3)
        #   PIL:             = Image.open('image.jpg')  # HWC x(640,1280,3)
        #   numpy:           = np.zeros((640,1280,3))  # HWC
        #   torch:           = torch.zeros(16,3,320,640)  # BCHW (scaled to size=640, 0-1 values)
        #   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images

        t = [time_synchronized()]
        p = next(self.model.parameters())  # for device and type
        if isinstance(imgs, torch.Tensor):  # torch
            with amp.autocast(enabled=p.device.type != 'cpu'):
                return self.model(imgs.to(p.device).type_as(p), augment, profile)  # inference

        # Pre-process
        n, imgs = (len(imgs), imgs) if isinstance(imgs, list) else (1, [imgs])  # number of images, list of images
        shape0, shape1, files = [], [], []  # image and inference shapes, filenames
        for i, im in enumerate(imgs):
            f = f'image{i}'  # filename
            if isinstance(im, str):  # filename or uri
                im, f = np.asarray(Image.open(requests.get(im, stream=True).raw if im.startswith('http') else im)), im
            elif isinstance(im, Image.Image):  # PIL Image
                im, f = np.asarray(im), getattr(im, 'filename', f) or f
            files.append(Path(f).with_suffix('.jpg').name)
            if im.shape[0] < 5:  # image in CHW
                im = im.transpose((1, 2, 0))  # reverse dataloader .transpose(2, 0, 1)
            im = im[:, :, :3] if im.ndim == 3 else np.tile(im[:, :, None], 3)  # enforce 3ch input
            s = im.shape[:2]  # HWC
            shape0.append(s)  # image shape
            g = (size / max(s))  # gain
            shape1.append([y * g for y in s])
            imgs[i] = im  # update
        shape1 = [make_divisible(x, int(self.stride.max())) for x in np.stack(shape1, 0).max(0)]  # inference shape
        x = [letterbox(im, new_shape=shape1, auto=False)[0] for im in imgs]  # pad
        x = np.stack(x, 0) if n > 1 else x[0][None]  # stack
        x = np.ascontiguousarray(x.transpose((0, 3, 1, 2)))  # BHWC to BCHW
        x = torch.from_numpy(x).to(p.device).type_as(p) / 255.  # uint8 to fp16/32
        t.append(time_synchronized())

        with amp.autocast(enabled=p.device.type != 'cpu'):
            # Inference
            y = self.model(x, augment, profile)[0]  # forward
            t.append(time_synchronized())

            # Post-process
            y = non_max_suppression(y, conf_thres=self.conf, iou_thres=self.iou, classes=self.classes)  # NMS
            for i in range(n):
                scale_coords(shape1, y[i][:, :4], shape0[i])

            t.append(time_synchronized())
            return Detections(imgs, y, files, t, self.names, x.shape)


class Detections:
    # detections class for YOLOv5 inference results
    def __init__(self, imgs, pred, files, times=None, names=None, shape=None):
        super(Detections, self).__init__()
        d = pred[0].device  # device
        gn = [torch.tensor([*[im.shape[i] for i in [1, 0, 1, 0]], 1., 1.], device=d) for im in imgs]  # normalizations
        self.imgs = imgs  # list of images as numpy arrays
        self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)
        self.names = names  # class names
        self.files = files  # image filenames
        self.xyxy = pred  # xyxy pixels
        self.xywh = [xyxy2xywh(x) for x in pred]  # xywh pixels
        self.xyxyn = [x / g for x, g in zip(self.xyxy, gn)]  # xyxy normalized
        self.xywhn = [x / g for x, g in zip(self.xywh, gn)]  # xywh normalized
        self.n = len(self.pred)  # number of images (batch size)
        self.t = tuple((times[i + 1] - times[i]) * 1000 / self.n for i in range(3))  # timestamps (ms)
        self.s = shape  # inference BCHW shape

    def display(self, pprint=False, show=False, save=False, render=False, save_dir=''):
        colors = color_list()
        for i, (img, pred) in enumerate(zip(self.imgs, self.pred)):
            str = f'image {i + 1}/{len(self.pred)}: {img.shape[0]}x{img.shape[1]} '
            if pred is not None:
                for c in pred[:, -1].unique():
                    n = (pred[:, -1] == c).sum()  # detections per class
                    str += f"{n} {self.names[int(c)]}{'s' * (n > 1)}, "  # add to string
                if show or save or render:
                    for *box, conf, cls in pred:  # xyxy, confidence, class
                        label = f'{self.names[int(cls)]} {conf:.2f}'
                        plot_one_box(box, img, label=label, color=colors[int(cls) % 10])
            img = Image.fromarray(img.astype(np.uint8)) if isinstance(img, np.ndarray) else img  # from np
            if pprint:
                print(str.rstrip(', '))
            if show:
                img.show(self.files[i])  # show
            if save:
                f = self.files[i]
                img.save(Path(save_dir) / f)  # save
                print(f"{'Saved' * (i == 0)} {f}", end=',' if i < self.n - 1 else f' to {save_dir}\n')
            if render:
                self.imgs[i] = np.asarray(img)

    def print(self):
        self.display(pprint=True)  # print results
        print(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {tuple(self.s)}' % self.t)

    def show(self):
        self.display(show=True)  # show results

    def save(self, save_dir='runs/hub/exp'):
        save_dir = increment_path(save_dir, exist_ok=save_dir != 'runs/hub/exp')  # increment save_dir
        Path(save_dir).mkdir(parents=True, exist_ok=True)
        self.display(save=True, save_dir=save_dir)  # save results

    def render(self):
        self.display(render=True)  # render results
        return self.imgs

    def pandas(self):
        # return detections as pandas DataFrames, i.e. print(results.pandas().xyxy[0])
        new = copy(self)  # return copy
        ca = 'xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class', 'name'  # xyxy columns
        cb = 'xcenter', 'ycenter', 'width', 'height', 'confidence', 'class', 'name'  # xywh columns
        for k, c in zip(['xyxy', 'xyxyn', 'xywh', 'xywhn'], [ca, ca, cb, cb]):
            a = [[x[:5] + [int(x[5]), self.names[int(x[5])]] for x in x.tolist()] for x in getattr(self, k)]  # update
            setattr(new, k, [pd.DataFrame(x, columns=c) for x in a])
        return new

    def tolist(self):
        # return a list of Detections objects, i.e. 'for result in results.tolist():'
        x = [Detections([self.imgs[i]], [self.pred[i]], self.names, self.s) for i in range(self.n)]
        for d in x:
            for k in ['imgs', 'pred', 'xyxy', 'xyxyn', 'xywh', 'xywhn']:
                setattr(d, k, getattr(d, k)[0])  # pop out of list
        return x

    def __len__(self):
        return self.n

class Classify(nn.Module):
    # Classification head, i.e. x(b,c1,20,20) to x(b,c2)
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Classify, self).__init__()
        self.aap = nn.AdaptiveAvgPool2d(1)  # to x(b,c1,1,1)
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g)  # to x(b,c2,1,1)
        self.flat = nn.Flatten()

    def forward(self, x):
        z = torch.cat([self.aap(y) for y in (x if isinstance(x, list) else [x])], 1)  # cat if list
        return self.flat(self.conv(z))  # flatten to x(b,c2)


# build attention module
# -------------------------------------------------------------------------
class Hswish(nn.Module):
    def __init__(self, inplace=True):
        super(Hswish, self).__init__()
        self.relu = nn.ReLU6(inplace=inplace)

    def forward(self, x):
        return self.relu(x + 3) / 6


class SELayer(nn.Module):
    def __init__(self, channel, reduction=4):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel),
            Hswish())

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x)
        y = y.view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y


# build shuffle block
# -------------------------------------------------------------------------

def channel_shuffle(x, groups):
    batchsize, num_channels, height, width = x.data.size()
    channels_per_group = num_channels // groups

    # reshape
    x = x.view(batchsize, groups,
               channels_per_group, height, width)

    x = torch.transpose(x, 1, 2).contiguous()

    # flatten
    x = x.view(batchsize, -1, height, width)

    return x


class conv_bn_relu_maxpool(nn.Module):
    def __init__(self, c1, c2):  # ch_in, ch_out
        super(conv_bn_relu_maxpool, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(c1, c2, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(c2),
            nn.ReLU(inplace=True),
        )
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)

    def forward(self, x):
        return self.maxpool(self.conv(x))


class Shuffle_Block(nn.Module):
    def __init__(self, inp, oup, stride):
        super(Shuffle_Block, self).__init__()

        if not (1 <= stride <= 3):
            raise ValueError('illegal stride value')
        self.stride = stride

        branch_features = oup // 2
        assert (self.stride != 1) or (inp == branch_features << 1)

        if self.stride > 1:
            self.branch1 = nn.Sequential(
                self.depthwise_conv(inp, inp, kernel_size=3, stride=self.stride, padding=1),
                nn.BatchNorm2d(inp),
                nn.Conv2d(inp, branch_features, kernel_size=1, stride=1, padding=0, bias=False),
                nn.BatchNorm2d(branch_features),
                nn.ReLU(inplace=True),
            )

        self.branch2 = nn.Sequential(
            nn.Conv2d(inp if (self.stride > 1) else branch_features,
                      branch_features, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(branch_features),
            nn.ReLU(inplace=True),
            self.depthwise_conv(branch_features, branch_features, kernel_size=3, stride=self.stride, padding=1),
            nn.BatchNorm2d(branch_features),
            nn.Conv2d(branch_features, branch_features, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(branch_features),
            nn.ReLU(inplace=True),
        )

    @staticmethod
    def depthwise_conv(i, o, kernel_size, stride=1, padding=0, bias=False):
        return nn.Conv2d(i, o, kernel_size, stride, padding, bias=bias, groups=i)

    def forward(self, x):
        if self.stride == 1:
            x1, x2 = x.chunk(2, dim=1)
            out = torch.cat((x1, self.branch2(x2)), dim=1)
        else:
            out = torch.cat((self.branch1(x), self.branch2(x)), dim=1)

        out = channel_shuffle(out, 2)

        return out


# shuffle block end
# -------------------------------------------------------------------------

# build DWConvblock
# -------------------------------------------------------------------------
class DWConvblock(nn.Module):
    "Depthwise conv + Pointwise conv"

    def __init__(self, in_channels, out_channels, k, s):
        super(DWConvblock, self).__init__()
        self.p = k // 2
        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=k, stride=s, padding=self.p, groups=in_channels,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(in_channels)
        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = F.relu(x)
        return x

# DWConvblock end
# -------------------------------------------------------------------------

# build Efficient-lite
# -------------------------------------------------------------------------
class stem(nn.Module):
    def __init__(self, c1, c2):  # ch_in, ch_out
        super(stem, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, c2, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_features=c2, momentum=0.01, eps=1e-3),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.conv(x)


def round_filters(filters, multiplier, divisor=8, min_width=None):
    """Calculate and round number of filters based on width multiplier."""
    if not multiplier:
        return filters
    filters *= multiplier
    min_width = min_width or divisor
    new_filters = max(min_width, int(filters + divisor / 2) // divisor * divisor)
    # Make sure that round down does not go down by more than 10%.
    if new_filters < 0.9 * filters:
        new_filters += divisor
    return int(new_filters)


def round_repeats(repeats, multiplier):
    """Round number of filters based on depth multiplier."""
    if not multiplier:
        return repeats
    return int(math.ceil(multiplier * repeats))


def drop_connect(x, drop_connect_rate, training):
    if not training:
        return x
    keep_prob = 1.0 - drop_connect_rate
    batch_size = x.shape[0]
    random_tensor = keep_prob
    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=x.dtype, device=x.device)
    binary_mask = torch.floor(random_tensor)
    x = (x / keep_prob) * binary_mask
    return x


class MBConvBlock(nn.Module):
    def __init__(self, inp, oup, k, s):
        super(MBConvBlock, self).__init__()

        self._momentum = 0.01
        self._epsilon = 1e-3
        self.input_filters = inp
        self.output_filters = oup
        self.stride = s
        self.id_skip = True  # skip connection and drop connect

        # Depthwise convolution phase
        self._depthwise_conv = nn.Conv2d(
            in_channels=oup,
            out_channels=oup,
            groups=oup,  # groups makes it depthwise
            kernel_size=k,
            padding=(k - 1) // 2,
            stride=s,
            bias=False,
        )

        self._bn1 = nn.BatchNorm2d(
            num_features=oup, momentum=self._momentum, eps=self._epsilon
        )

        # Output phase
        self._project_conv = nn.Conv2d(
            in_channels=oup, out_channels=oup, kernel_size=1, bias=False
        )
        self._bn2 = nn.BatchNorm2d(
            num_features=oup, momentum=self._momentum, eps=self._epsilon
        )
        self._relu = nn.ReLU(inplace=True)

    def forward(self, x, drop_connect_rate=None):
        """
        :param x: input tensor
        :param drop_connect_rate: drop connect rate (float, between 0 and 1)
        :return: output of block
        """

        # Expansion and Depthwise Convolution
        identity = x

        x = self._relu(self._bn1(self._depthwise_conv(x)))

        x = self._bn2(self._project_conv(x))

        # Skip connection and drop connect
        if (
                self.id_skip
                and self.stride == 1
                and self.input_filters == self.output_filters
        ):
            if drop_connect_rate:
                x = drop_connect(x, drop_connect_rate, training=self.training)
            x += identity  # skip connection
        return x


# Efficient-lite end
# -------------------------------------------------------------------------
class LC3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(LC3, self).__init__()
        # 这里使用轻量化的C3 Block模块,使用add操作替换cat
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)])
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        return self.cv3(torch.add(self.m(self.cv1(x)), self.cv2(x)))


class ADD(nn.Module):
    # Stortcut a list of tensors along dimension
    def __init__(self, alpha=0.5):
        super(ADD, self).__init__()
        self.a = alpha

    def forward(self, x):
        x1, x2 = x[0], x[1]
        return torch.add(x1, x2, alpha=self.a)

# build repvgg block
# -----------------------------
def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):
    result = nn.Sequential()
    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,
                                        kernel_size=kernel_size, stride=stride, padding=padding, groups=groups,
                                        bias=False))
    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))

    return result


class SEBlock(nn.Module):

    def __init__(self, input_channels, internal_neurons):
        super(SEBlock, self).__init__()
        self.down = nn.Conv2d(in_channels=input_channels, out_channels=internal_neurons, kernel_size=1, stride=1,
                              bias=True)
        self.up = nn.Conv2d(in_channels=internal_neurons, out_channels=input_channels, kernel_size=1, stride=1,
                            bias=True)
        self.input_channels = input_channels

    def forward(self, inputs):
        x = F.avg_pool2d(inputs, kernel_size=inputs.size(3))
        x = self.down(x)
        x = F.relu(x)
        x = self.up(x)
        x = torch.sigmoid(x)
        x = x.view(-1, self.input_channels, 1, 1)
        return inputs * x


class RepVGGBlock(nn.Module):

    def __init__(self, in_channels, out_channels, kernel_size=3,
                 stride=1, padding=1, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False):
        super(RepVGGBlock, self).__init__()
        self.deploy = deploy
        self.groups = groups
        self.in_channels = in_channels

        padding_11 = padding - kernel_size // 2

        self.nonlinearity = nn.SiLU()

        # self.nonlinearity = nn.ReLU()

        if use_se:
            self.se = SEBlock(out_channels, internal_neurons=out_channels // 16)
        else:
            self.se = nn.Identity()

        if deploy:
            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,
                                         stride=stride,
                                         padding=padding, dilation=dilation, groups=groups, bias=True,
                                         padding_mode=padding_mode)

        else:
            self.rbr_identity = nn.BatchNorm2d(
                num_features=in_channels) if out_channels == in_channels and stride == 1 else None
            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,
                                     stride=stride, padding=padding, groups=groups)
            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride,
                                   padding=padding_11, groups=groups)
            # print('RepVGG Block, identity = ', self.rbr_identity)

    def get_equivalent_kernel_bias(self):
        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)
        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)
        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)
        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid

    def _pad_1x1_to_3x3_tensor(self, kernel1x1):
        if kernel1x1 is None:
            return 0
        else:
            return torch.nn.functional.pad(kernel1x1, [1, 1, 1, 1])

    def _fuse_bn_tensor(self, branch):
        if branch is None:
            return 0, 0
        if isinstance(branch, nn.Sequential):
            kernel = branch.conv.weight
            running_mean = branch.bn.running_mean
            running_var = branch.bn.running_var
            gamma = branch.bn.weight
            beta = branch.bn.bias
            eps = branch.bn.eps
        else:
            assert isinstance(branch, nn.BatchNorm2d)
            if not hasattr(self, 'id_tensor'):
                input_dim = self.in_channels // self.groups
                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)
                for i in range(self.in_channels):
                    kernel_value[i, i % input_dim, 1, 1] = 1
                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)
            kernel = self.id_tensor
            running_mean = branch.running_mean
            running_var = branch.running_var
            gamma = branch.weight
            beta = branch.bias
            eps = branch.eps
        std = (running_var + eps).sqrt()
        t = (gamma / std).reshape(-1, 1, 1, 1)
        return kernel * t, beta - running_mean * gamma / std

    def forward(self, inputs):
        if hasattr(self, 'rbr_reparam'):
            return self.nonlinearity(self.se(self.rbr_reparam(inputs)))

        if self.rbr_identity is None:
            id_out = 0
        else:
            id_out = self.rbr_identity(inputs)

        return self.nonlinearity(self.se(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out))

    def fusevggforward(self, x):
        return self.nonlinearity(self.rbr_dense(x))


# repvgg block end
# -----------------------------

# build mbv3 block
# -----------------------------
class mobilev3_bneck(nn.Module):
    def __init__(self, inp, oup, hidden_dim, kernel_size, stride, use_se, use_hs):
        super(mobilev3_bneck, self).__init__()
        assert stride in [1, 2]

        self.identity = stride == 1 and inp == oup

        if inp == hidden_dim:
            self.conv = nn.Sequential(
                # dw
                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim,
                          bias=False),
                nn.BatchNorm2d(hidden_dim),
                Hswish() if use_hs else nn.ReLU(inplace=True),
                # Squeeze-and-Excite
                SELayer(hidden_dim) if use_se else nn.Sequential(),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )
        else:
            self.conv = nn.Sequential(
                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),
                nn.BatchNorm2d(hidden_dim),
                Hswish() if use_hs else nn.ReLU(inplace=True),
                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim,
                          bias=False),
                nn.BatchNorm2d(hidden_dim),
                # Squeeze-and-Excite
                SELayer(hidden_dim) if use_se else nn.Sequential(),
                Hswish() if use_hs else nn.ReLU(inplace=True),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )

    def forward(self, x):
        y = self.conv(x)
        if self.identity:
            return x + y
        else:
            return y


# mbv3 block end
# -----------------------------

# build Lcnet
# -----------------------------
class CBH(nn.Module):
    def __init__(self, num_channels, num_filters, filter_size, stride, num_groups=1):
        super().__init__()
        self.conv = nn.Conv2d(
            num_channels,
            num_filters,
            filter_size,
            stride,
            padding=(filter_size - 1) // 2,
            groups=num_groups,
            bias=False)
        self.bn = nn.BatchNorm2d(num_filters)
        self.hardswish = nn.Hardswish()

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        x = self.hardswish(x)
        return x

    def fuseforward(self, x):
        return self.hardswish(self.conv(x))

# class Hardsigmoid(nn.Module):
#     def forward(self, x):
#         out = F.relu6(x + 3, inplace=True) / 6
#         return out


class LC_SEModule(nn.Module):
    def __init__(self, channel, reduction=4):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.conv1 = nn.Conv2d(
            in_channels=channel,
            out_channels=channel // reduction,
            kernel_size=1,
            stride=1,
            padding=0)
        self.relu = nn.ReLU()
        self.conv2 = nn.Conv2d(
            in_channels=channel // reduction,
            out_channels=channel,
            kernel_size=1,
            stride=1,
            padding=0)
        self.SiLU = nn.SiLU()
        # self.hardsigmoid = nn.Hardsigmoid()

    def forward(self, x):
        identity = x
        x = self.avg_pool(x)
        x = self.conv1(x)
        x = self.relu(x)
        x = self.conv2(x)
        # x = self.hardsigmoid(x)
        x = self.SiLU(x)
        out = identity * x
        return out


class LC_Block(nn.Module):
    def __init__(self, num_channels, num_filters, stride, dw_size, use_se=False):
        super().__init__()
        self.use_se = use_se
        self.dw_conv = CBH(
            num_channels=num_channels,
            num_filters=num_channels,
            filter_size=dw_size,
            stride=stride,
            num_groups=num_channels)
        if use_se:
            self.se = LC_SEModule(num_channels)
        self.pw_conv = CBH(
            num_channels=num_channels,
            filter_size=1,
            num_filters=num_filters,
            stride=1)

    def forward(self, x):
        x = self.dw_conv(x)
        if self.use_se:
            x = self.se(x)
        x = self.pw_conv(x)
        return x


class Dense(nn.Module):
    def __init__(self, num_channels, num_filters, filter_size, dropout_prob):
        super().__init__()
        # self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.dense_conv = nn.Conv2d(
            in_channels=num_channels,
            out_channels=num_filters,
            kernel_size=filter_size,
            stride=1,
            padding=0,
            bias=False)
        self.hardswish = nn.Hardswish()
        self.dropout = nn.Dropout(p=dropout_prob)
        # self.flatten = nn.Flatten(start_dim=1, end_dim=-1)
        # self.fc = nn.Linear(num_filters, num_filters)

    def forward(self, x):
        # x = self.avg_pool(x)
        # b, _, w, h = x.shape
        x = self.dense_conv(x)
        # b, _, w, h = x.shape
        x = self.hardswish(x)
        x = self.dropout(x)
        # x = self.flatten(x)
        # x = self.fc(x)
        # x = x.reshape(b, self.c2, w, h)
        return x

    
# build enhance shuffle block
# -------------------------------------------------------------------------

class GhostConv(nn.Module):
    # Ghost Convolution https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=3, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups
        super().__init__()
        c_ = c2 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, s, None, g, act)
        self.cv2 = Conv(c_, c_, k, s, None, c_, act)

    def forward(self, x):
        y = self.cv1(x)
        return torch.cat((y, self.cv2(y)), dim=1)

class ES_SEModule(nn.Module):
    def __init__(self, channel, reduction=4):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.conv1 = nn.Conv2d(
            in_channels=channel,
            out_channels=channel // reduction,
            kernel_size=1,
            stride=1,
            padding=0)
        self.relu = nn.ReLU()
        self.conv2 = nn.Conv2d(
            in_channels=channel // reduction,
            out_channels=channel,
            kernel_size=1,
            stride=1,
            padding=0)
        self.hardsigmoid = nn.Hardsigmoid()

    def forward(self, x):
        identity = x
        x = self.avg_pool(x)
        x = self.conv1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.hardsigmoid(x)
        out = identity * x
        return out

class ES_Bottleneck(nn.Module):
    def __init__(self, inp, oup, stride):
        super(ES_Bottleneck, self).__init__()

        if not (1 <= stride <= 3):
            raise ValueError('illegal stride value')
        self.stride = stride

        branch_features = oup // 2
        # assert (self.stride != 1) or (inp == branch_features << 1)

        if self.stride > 1:
            self.branch1 = nn.Sequential(
                self.depthwise_conv(inp, inp, kernel_size=3, stride=self.stride, padding=1),
                nn.BatchNorm2d(inp),
                nn.Conv2d(inp, branch_features, kernel_size=1, stride=1, padding=0, bias=False),
                nn.BatchNorm2d(branch_features),
                nn.Hardswish(inplace=True),
            )

        self.branch2 = nn.Sequential(
            nn.Conv2d(inp if (self.stride > 1) else branch_features,
                      branch_features, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(branch_features),
            nn.Hardswish(inplace=True),
            self.depthwise_conv(branch_features, branch_features, kernel_size=3, stride=self.stride, padding=1),
            nn.BatchNorm2d(branch_features),
            ES_SEModule(branch_features),
            nn.Conv2d(branch_features, branch_features, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(branch_features),
            nn.Hardswish(inplace=True),
        )

        self.branch3 = nn.Sequential(
            GhostConv(branch_features, branch_features, 3, 1),
            ES_SEModule(branch_features),
            nn.Conv2d(branch_features, branch_features, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(branch_features),
            nn.Hardswish(inplace=True),
        )

        self.branch4 = nn.Sequential(
            self.depthwise_conv(oup, oup, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(oup),
            nn.Conv2d(oup, oup, kernel_size=1, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(oup),
            nn.Hardswish(inplace=True),
        )


    @staticmethod
    def depthwise_conv(i, o, kernel_size=3, stride=1, padding=0, bias=False):
        return nn.Conv2d(i, o, kernel_size, stride, padding, bias=bias, groups=i)

    @staticmethod
    def conv1x1(i, o, kernel_size=1, stride=1, padding=0, bias=False):
        return nn.Conv2d(i, o, kernel_size, stride, padding, bias=bias)

    def forward(self, x):
        if self.stride == 1:
            x1, x2 = x.chunk(2, dim=1)
            x3 = torch.cat((x1, self.branch3(x2)), dim=1)
            out = channel_shuffle(x3, 2)
        elif self.stride == 2:
            x1 = torch.cat((self.branch1(x), self.branch2(x)), dim=1)
            out = self.branch4(x1)

        return out

# enhance shuffle block end
# -------------------------------------------------------------------------

===== .\models\models\empty.py =====
功能: 代码摘录
def main(args=None):
    print()

===== .\models\models\experimental.py =====
功能: 代码摘录
# YOLOv5 experimental modules

import numpy as np
import torch
import torch.nn as nn

from models.common import Conv
from utils.google_utils import attempt_download


class CrossConv(nn.Module):
    # Cross Convolution Downsample
    def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False):
        # ch_in, ch_out, kernel, stride, groups, expansion, shortcut
        super(CrossConv, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, (1, k), (1, s))
        self.cv2 = Conv(c_, c2, (k, 1), (s, 1), g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))


class Sum(nn.Module):
    # Weighted sum of 2 or more layers https://arxiv.org/abs/1911.09070
    def __init__(self, n, weight=False):  # n: number of inputs
        super(Sum, self).__init__()
        self.weight = weight  # apply weights boolean
        self.iter = range(n - 1)  # iter object
        if weight:
            self.w = nn.Parameter(-torch.arange(1., n) / 2, requires_grad=True)  # layer weights

    def forward(self, x):
        y = x[0]  # no weight
        if self.weight:
            w = torch.sigmoid(self.w) * 2
            for i in self.iter:
                y = y + x[i + 1] * w[i]
        else:
            for i in self.iter:
                y = y + x[i + 1]
        return y


class GhostConv(nn.Module):
    # Ghost Convolution https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups
        super(GhostConv, self).__init__()
        c_ = c2 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, k, s, None, g, act)
        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act)

    def forward(self, x):
        y = self.cv1(x)
        return torch.cat([y, self.cv2(y)], 1)


class GhostBottleneck(nn.Module):
    # Ghost Bottleneck https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, kernel, stride
        super(GhostBottleneck, self).__init__()
        c_ = c2 // 2
        self.conv = nn.Sequential(GhostConv(c1, c_, 1, 1),  # pw
                                  DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw
                                  GhostConv(c_, c2, 1, 1, act=False))  # pw-linear
        self.shortcut = nn.Sequential(DWConv(c1, c1, k, s, act=False),
                                      Conv(c1, c2, 1, 1, act=False)) if s == 2 else nn.Identity()

    def forward(self, x):
        return self.conv(x) + self.shortcut(x)


class MixConv2d(nn.Module):
    # Mixed Depthwise Conv https://arxiv.org/abs/1907.09595
    def __init__(self, c1, c2, k=(1, 3), s=1, equal_ch=True):
        super(MixConv2d, self).__init__()
        groups = len(k)
        if equal_ch:  # equal c_ per group
            i = torch.linspace(0, groups - 1E-6, c2).floor()  # c2 indices
            c_ = [(i == g).sum() for g in range(groups)]  # intermediate channels
        else:  # equal weight.numel() per group
            b = [c2] + [0] * groups
            a = np.eye(groups + 1, groups, k=-1)
            a -= np.roll(a, 1, axis=1)
            a *= np.array(k) ** 2
            a[0] = 1
            c_ = np.linalg.lstsq(a, b, rcond=None)[0].round()  # solve for equal weight indices, ax = b

        self.m = nn.ModuleList([nn.Conv2d(c1, int(c_[g]), k[g], s, k[g] // 2, bias=False) for g in range(groups)])
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.LeakyReLU(0.1, inplace=True)

    def forward(self, x):
        return x + self.act(self.bn(torch.cat([m(x) for m in self.m], 1)))


class Ensemble(nn.ModuleList):
    # Ensemble of models
    def __init__(self):
        super(Ensemble, self).__init__()

    def forward(self, x, augment=False):
        y = []
        for module in self:
            y.append(module(x, augment)[0])
        # y = torch.stack(y).max(0)[0]  # max ensemble
        # y = torch.stack(y).mean(0)  # mean ensemble
        y = torch.cat(y, 1)  # nms ensemble
        return y, None  # inference, train output


def attempt_load(weights, map_location=None):
    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a
    model = Ensemble()
    for w in weights if isinstance(weights, list) else [weights]:
        # attempt_download(w)
        ckpt = torch.load(w, map_location=map_location)  # load
        model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval())  # FP32 model

    # Compatibility updates
    for m in model.modules():
        if type(m) in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU]:
            m.inplace = True  # pytorch 1.7.0 compatibility
        elif type(m) is Conv:
            m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatibility

    if len(model) == 1:
        # torch.save(ckpt, 'v5-vgg.pt')
        return model[-1]  # return model
    else:
        print('Ensemble created with %s\n' % weights)
        for k in ['names', 'stride']:
            setattr(model, k, getattr(model[-1], k))
        return model  # return ensemble

===== .\models\models\hub\anchors.yaml =====
功能: 代码摘录
# Default YOLOv5 anchors for COCO data


# P5 -------------------------------------------------------------------------------------------------------------------
# P5-640:
anchors_p5_640:
  - [ 10,13, 16,30, 33,23 ]  # P3/8
  - [ 30,61, 62,45, 59,119 ]  # P4/16
  - [ 116,90, 156,198, 373,326 ]  # P5/32


# P6 -------------------------------------------------------------------------------------------------------------------
# P6-640:  thr=0.25: 0.9964 BPR, 5.54 anchors past thr, n=12, img_size=640, metric_all=0.281/0.716-mean/best, past_thr=0.469-mean: 9,11,  21,19,  17,41,  43,32,  39,70,  86,64,  65,131,  134,130,  120,265,  282,180,  247,354,  512,387
anchors_p6_640:
  - [ 9,11,  21,19,  17,41 ]  # P3/8
  - [ 43,32,  39,70,  86,64 ]  # P4/16
  - [ 65,131,  134,130,  120,265 ]  # P5/32
  - [ 282,180,  247,354,  512,387 ]  # P6/64

# P6-1280:  thr=0.25: 0.9950 BPR, 5.55 anchors past thr, n=12, img_size=1280, metric_all=0.281/0.714-mean/best, past_thr=0.468-mean: 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792
anchors_p6_1280:
  - [ 19,27,  44,40,  38,94 ]  # P3/8
  - [ 96,68,  86,152,  180,137 ]  # P4/16
  - [ 140,301,  303,264,  238,542 ]  # P5/32
  - [ 436,615,  739,380,  925,792 ]  # P6/64

# P6-1920:  thr=0.25: 0.9950 BPR, 5.55 anchors past thr, n=12, img_size=1920, metric_all=0.281/0.714-mean/best, past_thr=0.468-mean: 28,41,  67,59,  57,141,  144,103,  129,227,  270,205,  209,452,  455,396,  358,812,  653,922,  1109,570,  1387,1187
anchors_p6_1920:
  - [ 28,41,  67,59,  57,141 ]  # P3/8
  - [ 144,103,  129,227,  270,205 ]  # P4/16
  - [ 209,452,  455,396,  358,812 ]  # P5/32
  - [ 653,922,  1109,570,  1387,1187 ]  # P6/64


# P7 -------------------------------------------------------------------------------------------------------------------
# P7-640:  thr=0.25: 0.9962 BPR, 6.76 anchors past thr, n=15, img_size=640, metric_all=0.275/0.733-mean/best, past_thr=0.466-mean: 11,11,  13,30,  29,20,  30,46,  61,38,  39,92,  78,80,  146,66,  79,163,  149,150,  321,143,  157,303,  257,402,  359,290,  524,372
anchors_p7_640:
  - [ 11,11,  13,30,  29,20 ]  # P3/8
  - [ 30,46,  61,38,  39,92 ]  # P4/16
  - [ 78,80,  146,66,  79,163 ]  # P5/32
  - [ 149,150,  321,143,  157,303 ]  # P6/64
  - [ 257,402,  359,290,  524,372 ]  # P7/128

# P7-1280:  thr=0.25: 0.9968 BPR, 6.71 anchors past thr, n=15, img_size=1280, metric_all=0.273/0.732-mean/best, past_thr=0.463-mean: 19,22,  54,36,  32,77,  70,83,  138,71,  75,173,  165,159,  148,334,  375,151,  334,317,  251,626,  499,474,  750,326,  534,814,  1079,818
anchors_p7_1280:
  - [ 19,22,  54,36,  32,77 ]  # P3/8
  - [ 70,83,  138,71,  75,173 ]  # P4/16
  - [ 165,159,  148,334,  375,151 ]  # P5/32
  - [ 334,317,  251,626,  499,474 ]  # P6/64
  - [ 750,326,  534,814,  1079,818 ]  # P7/128

# P7-1920:  thr=0.25: 0.9968 BPR, 6.71 anchors past thr, n=15, img_size=1920, metric_all=0.273/0.732-mean/best, past_thr=0.463-mean: 29,34,  81,55,  47,115,  105,124,  207,107,  113,259,  247,238,  222,500,  563,227,  501,476,  376,939,  749,711,  1126,489,  801,1222,  1618,1227
anchors_p7_1920:
  - [ 29,34,  81,55,  47,115 ]  # P3/8
  - [ 105,124,  207,107,  113,259 ]  # P4/16
  - [ 247,238,  222,500,  563,227 ]  # P5/32
  - [ 501,476,  376,939,  749,711 ]  # P6/64
  - [ 1126,489,  801,1222,  1618,1227 ]  # P7/128

===== .\models\models\hub\gcnet.yaml =====
功能: 代码摘录
# YOLOv5 🚀 by Ultralytics, GPL-3.0 license

# Parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3_GC, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3_GC, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3_GC, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]

# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\PicoDet-l.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 0.67  # model depth multiple
width_multiple: 1.00  # layer channel multiple

# anchors
anchors: 4 # auto-anchor 4 anchors per P output layer

# ESNet
backbone:
  # [from, number, module, args]
  [ [ -1, 1, CBH, [ 48, 3, 2 ] ],    # 0-P2/4
    [ -1, 1, ES_Bottleneck, [ 96, 2 ] ], # 1-P3/8
    [ -1, 3, ES_Bottleneck, [ 96, 1 ] ], # 2
    [ -1, 1, ES_Bottleneck, [ 192, 2 ] ], # 3-P5/16
    [ -1, 7, ES_Bottleneck, [ 192, 1 ] ], # 4
    [ -1, 1, ES_Bottleneck, [ 384, 2 ] ], # 5-P7/32
    [ -1, 3, ES_Bottleneck, [ 384, 1 ] ], # 6
  ]

#  CSP-PAN
head:
  [ [ -1, 1, Conv, [ 192, 1, 1 ] ], # 7
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 9 (P3/8-small)

    [ -1, 1, Conv, [ 192, 1, 1 ] ], # 10
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 13

    [ -1, 1, Conv, [ 192, 1, 1 ] ], # 14
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 17 (P3/8-small)

    [-1, 1, DWConvblock, [ 192, 5, 2 ]], # 18
    [ [ -1, 14 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 20 (P4/16-medium)

    [ -1, 1, DWConvblock, [ 192, 5, 2 ] ],
    [ [ -1, 10 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 23 (P5/32-large)

    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P6
    [ -1, 1, DWConvblock, [ 192, 5, 2 ] ],  # 26 (P5/32-large)

    [ [ 17, 20, 23, 25 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\hub\PicoDet-m.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 0.67  # model depth multiple
width_multiple: 0.75  # layer channel multiple

# anchors
anchors: 4 # auto-anchor 4 anchors per P output layer

# ESNet
backbone:
  # [from, number, module, args]
  [ [ -1, 1, CBH, [ 48, 3, 2 ] ],    # 0-P2/4
    [ -1, 1, ES_Bottleneck, [ 96, 2 ] ], # 1-P3/8
    [ -1, 3, ES_Bottleneck, [ 96, 1 ] ], # 2
    [ -1, 1, ES_Bottleneck, [ 192, 2 ] ], # 3-P5/16
    [ -1, 7, ES_Bottleneck, [ 192, 1 ] ], # 4
    [ -1, 1, ES_Bottleneck, [ 384, 2 ] ], # 5-P7/32
    [ -1, 3, ES_Bottleneck, [ 384, 1 ] ], # 6
  ]

#  CSP-PAN
head:
  [ [ -1, 1, Conv, [ 192, 1, 1 ] ], # 7
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 9 (P3/8-small)

    [ -1, 1, Conv, [ 192, 1, 1 ] ], # 10
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 13

    [ -1, 1, Conv, [ 192, 1, 1 ] ], # 14
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 17 (P3/8-small)

    [-1, 1, DWConvblock, [ 192, 5, 2 ]], # 18
    [ [ -1, 14 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 20 (P4/16-medium)

    [ -1, 1, DWConvblock, [ 192, 5, 2 ] ],
    [ [ -1, 10 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 23 (P5/32-large)

    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P6
    [ -1, 1, DWConvblock, [ 192, 5, 2 ] ],  # 26 (P5/32-large)

    [ [ 17, 20, 23, 25 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\hub\PicoDet-s.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 0.67  # model depth multiple
width_multiple: 0.50  # layer channel multiple

# anchors
anchors: 4 # auto-anchor 4 anchors per P output layer

# ESNet
backbone:
  # [from, number, module, args]
  [ [ -1, 1, CBH, [ 48, 3, 2 ] ],    # 0-P2/4
    [ -1, 1, ES_Bottleneck, [ 96, 2 ] ], # 1-P3/8
    [ -1, 3, ES_Bottleneck, [ 96, 1 ] ], # 2
    [ -1, 1, ES_Bottleneck, [ 192, 2 ] ], # 3-P5/16
    [ -1, 7, ES_Bottleneck, [ 192, 1 ] ], # 4
    [ -1, 1, ES_Bottleneck, [ 384, 2 ] ], # 5-P7/32
    [ -1, 3, ES_Bottleneck, [ 384, 1 ] ], # 6
  ]

#  CSP-PAN
head:
  [ [ -1, 1, Conv, [ 192, 1, 1 ] ], # 7
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 9 (P3/8-small)

    [ -1, 1, Conv, [ 192, 1, 1 ] ], # 10
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 13

    [ -1, 1, Conv, [ 192, 1, 1 ] ], # 14
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 17 (P3/8-small)

    [-1, 1, DWConvblock, [ 192, 5, 2 ]], # 18
    [ [ -1, 14 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 20 (P4/16-medium)

    [ -1, 1, DWConvblock, [ 192, 5, 2 ] ],
    [ [ -1, 10 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 23 (P5/32-large)

    [ [ -1, 7 ], 1, ADD, [ 1 ] ],  # cat head P6
    [ -1, 1, DWConvblock, [ 192, 5, 2 ] ],  # 26 (P5/32-large)

    [ [ 17, 20, 23, 25 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\hub\PicoDet-x.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.00  # model depth multiple
width_multiple: 1.00  # layer channel multiple

# anchors
anchors: 4 # auto-anchor 4 anchors per P output layer

# ESNet
backbone:
  # [from, number, module, args]
  [ [ -1, 1, CBH, [ 48, 3, 2 ] ],    # 0-P2/4
    [ -1, 1, ES_Bottleneck, [ 96, 2 ] ], # 1-P3/8
    [ -1, 3, ES_Bottleneck, [ 96, 1 ] ], # 2
    [ -1, 1, ES_Bottleneck, [ 192, 2 ] ], # 3-P5/16
    [ -1, 7, ES_Bottleneck, [ 192, 1 ] ], # 4
    [ -1, 1, ES_Bottleneck, [ 384, 2 ] ], # 5-P7/32
    [ -1, 3, ES_Bottleneck, [ 384, 1 ] ], # 6
  ]

#  CSP-PAN
head:
  [ [ -1, 1, Conv, [ 192, 1, 1 ] ], # 7
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 9 (P3/8-small)

    [ -1, 1, Conv, [ 192, 1, 1 ] ], # 10
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 13

    [ -1, 1, Conv, [ 192, 1, 1 ] ], # 14
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 17 (P3/8-small)

    [-1, 1, DWConvblock, [ 192, 5, 2 ]], # 18
    [ [ -1, 14 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 20 (P4/16-medium)

    [ -1, 1, DWConvblock, [ 192, 5, 2 ] ],
    [ [ -1, 10 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, BottleneckCSP, [ 192, False ] ],  # 23 (P5/32-large)

    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P6
    [ -1, 1, DWConvblock, [ 192, 5, 2 ] ],  # 26 (P5/32-large)

    [ [ 17, 20, 23, 25 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\hub\repyolov5s.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1  # model depth multiple
width_multiple: 1  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [32, 3]],  # 0-P1/2
   [-1, 1, RepVGGBlock, [64, 3, 2]], # 1-P2/4
   [-1, 1, C3, [64]],
   [-1, 1, RepVGGBlock, [128, 3, 2]], # 3-P3/8
   [-1, 3, C3, [128]],
   [-1, 1, RepVGGBlock, [256, 3, 2]], # 5-P4/16
   [-1, 3, C3, [256]],
   [-1, 1, RepVGGBlock, [512, 3, 2]], # 7-P4/16
   [-1, 1, SPP, [512, [5, 9, 13]]],
   [-1, 1, C3, [512, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 1, C3, [256, False]],  # 13

   [-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 1, C3, [128, False]],  # 17 (P3/8-small)

   [-1, 1, RepVGGBlock, [128, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 1, C3, [256, False]],  # 20 (P4/16-medium)

   [-1, 1, RepVGGBlock, [256, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 1, C3, [512, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\TPH-YOLOv5.yaml =====
功能: 代码摘录
# YOLOv5 🚀 by Ultralytics, GPL-3.0 license

# Parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [19,27,  44,40,  38,94]  # P3/8
  - [96,68,  86,152,  180,137]  # P4/16
  - [140,301,  303,264,  238,542]  # P5/32
  - [436,615,  739,380,  925,792]  # P6/64

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [768, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [768]],
   [-1, 1, Conv, [1024, 3, 2]],  # 9-P6/64
   [-1, 1, SPP, [1024, [3, 5, 7]]],
   [-1, 3, C3TR, [1024, False]],  # 11
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [768, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 8], 1, Concat, [1]],  # cat backbone P5
   [-1, 3, C3, [768, False]],  # 15

   [-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 19

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3TR, [256, False]],  # 23 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 20], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3TR, [512, False]],  # 26 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 16], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3TR, [768, False]],  # 29 (P5/32-large)

   [-1, 1, Conv, [768, 3, 2]],
   [[-1, 12], 1, Concat, [1]],  # cat head P6
   [-1, 3, C3TR, [1024, False]],  # 32 (P6/64-xlarge)

   [[23, 26, 29, 32], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\hub\yolov3.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# darknet53 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [32, 3, 1]],  # 0
   [-1, 1, Conv, [64, 3, 2]],  # 1-P1/2
   [-1, 1, Bottleneck, [64]],
   [-1, 1, Conv, [128, 3, 2]],  # 3-P2/4
   [-1, 2, Bottleneck, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 5-P3/8
   [-1, 8, Bottleneck, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 7-P4/16
   [-1, 8, Bottleneck, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 9-P5/32
   [-1, 4, Bottleneck, [1024]],  # 10
  ]

# YOLOv3 head
head:
  [[-1, 1, Bottleneck, [1024, False]],
   [-1, 1, Conv, [512, [1, 1]]],
   [-1, 1, Conv, [1024, 3, 1]],
   [-1, 1, Conv, [512, 1, 1]],
   [-1, 1, Conv, [1024, 3, 1]],  # 15 (P5/32-large)

   [-2, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 8], 1, Concat, [1]],  # cat backbone P4
   [-1, 1, Bottleneck, [512, False]],
   [-1, 1, Bottleneck, [512, False]],
   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, Conv, [512, 3, 1]],  # 22 (P4/16-medium)

   [-2, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P3
   [-1, 1, Bottleneck, [256, False]],
   [-1, 2, Bottleneck, [256, False]],  # 27 (P3/8-small)

   [[27, 22, 15], 1, Detect, [nc, anchors]],   # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov3-spp.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# darknet53 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [32, 3, 1]],  # 0
   [-1, 1, Conv, [64, 3, 2]],  # 1-P1/2
   [-1, 1, Bottleneck, [64]],
   [-1, 1, Conv, [128, 3, 2]],  # 3-P2/4
   [-1, 2, Bottleneck, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 5-P3/8
   [-1, 8, Bottleneck, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 7-P4/16
   [-1, 8, Bottleneck, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 9-P5/32
   [-1, 4, Bottleneck, [1024]],  # 10
  ]

# YOLOv3-SPP head
head:
  [[-1, 1, Bottleneck, [1024, False]],
   [-1, 1, SPP, [512, [5, 9, 13]]],
   [-1, 1, Conv, [1024, 3, 1]],
   [-1, 1, Conv, [512, 1, 1]],
   [-1, 1, Conv, [1024, 3, 1]],  # 15 (P5/32-large)

   [-2, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 8], 1, Concat, [1]],  # cat backbone P4
   [-1, 1, Bottleneck, [512, False]],
   [-1, 1, Bottleneck, [512, False]],
   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, Conv, [512, 3, 1]],  # 22 (P4/16-medium)

   [-2, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P3
   [-1, 1, Bottleneck, [256, False]],
   [-1, 2, Bottleneck, [256, False]],  # 27 (P3/8-small)

   [[27, 22, 15], 1, Detect, [nc, anchors]],   # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov3-tiny.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,14, 23,27, 37,58]  # P4/16
  - [81,82, 135,169, 344,319]  # P5/32

# YOLOv3-tiny backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [16, 3, 1]],  # 0
   [-1, 1, nn.MaxPool2d, [2, 2, 0]],  # 1-P1/2
   [-1, 1, Conv, [32, 3, 1]],
   [-1, 1, nn.MaxPool2d, [2, 2, 0]],  # 3-P2/4
   [-1, 1, Conv, [64, 3, 1]],
   [-1, 1, nn.MaxPool2d, [2, 2, 0]],  # 5-P3/8
   [-1, 1, Conv, [128, 3, 1]],
   [-1, 1, nn.MaxPool2d, [2, 2, 0]],  # 7-P4/16
   [-1, 1, Conv, [256, 3, 1]],
   [-1, 1, nn.MaxPool2d, [2, 2, 0]],  # 9-P5/32
   [-1, 1, Conv, [512, 3, 1]],
   [-1, 1, nn.ZeroPad2d, [[0, 1, 0, 1]]],  # 11
   [-1, 1, nn.MaxPool2d, [2, 1, 0]],  # 12
  ]

# YOLOv3-tiny head
head:
  [[-1, 1, Conv, [1024, 3, 1]],
   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, Conv, [512, 3, 1]],  # 15 (P5/32-large)

   [-2, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 8], 1, Concat, [1]],  # cat backbone P4
   [-1, 1, Conv, [256, 3, 1]],  # 19 (P4/16-medium)

   [[19, 15], 1, Detect, [nc, anchors]],  # Detect(P4, P5)
  ]

===== .\models\models\hub\yolov5_repvgg_prune.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# repvgg backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, RepVGGBlock, [40, 3, 2]],  # 0-P1/2
   [-1, 1, RepVGGBlock, [48, 3, 2]], # 1-P2/4
   [-1, 1, RepVGGBlock, [40, 3, 1]], # 2-P2/4
   [-1, 1, RepVGGBlock, [96, 3, 2]], # 3-P3/8
   [-1, 1, RepVGGBlock, [80, 3, 1]],
   [-1, 1, RepVGGBlock, [80, 3, 1]],
   [-1, 1, RepVGGBlock, [80, 3, 1]], # cat 4
   [-1, 1, RepVGGBlock, [192, 3, 2]], # 5-P4/16
   [-1, 1, RepVGGBlock, [176, 3, 1]],
   [-1, 1, RepVGGBlock, [176, 3, 1]],
   [-1, 1, RepVGGBlock, [176, 3, 1]], # CAT 6
   [-1, 1, RepVGGBlock, [512, 3, 2]], # 7-P4/16
  ]
# YOLOv5 head
head:
  [[-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 10], 1, Concat, [1]],  # cat backbone P4
   [-1, 2, C3, [256, False]],  # 11

   [-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P3
   [-1, 2, C3, [128, False]],  # 15 (P3/8-small)

   [-1, 1, Conv, [128, 3, 2]],
   [[-1, 16], 1, Concat, [1]],  # cat head P4
   [-1, 2, C3, [128, False]],  # 18 (P4/16-medium)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 12], 1, Concat, [1]],  # cat head P5
   [-1, 2, C3, [512, False]],  # 21 (P5/32-large)

   [[19, 22, 25], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5-efficient-lite0.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, stem, [ 16 ] ],    # 0-P2/4
    [ -1, 1, MBConvBlock, [ 16, 32, 3, 1 ] ], # 1-P3/8
    [ -1, 3, MBConvBlock, [ 16, 24, 3, 2 ] ], # 2
    [ -1, 1, MBConvBlock, [ 24, 40, 3, 2 ] ], # 3-P4/16
    [ -1, 7, MBConvBlock, [ 40, 80, 3, 2 ] ], # 4
    [ -1, 1, MBConvBlock, [ 80, 112, 3, 1 ] ], # 5-P5/32
    [ -1, 3, MBConvBlock, [ 112, 192, 3, 2 ] ], # 6
    [ -1, 3, MBConvBlock, [ 192, 320, 3, 1 ] ], # 7
  ]

# v5Lite-s head
head:
  [[-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 5], 1, Concat, [1]],  # cat backbone P4
   [-1, 1, C3, [256, False]],  # 11

   [-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 3], 1, Concat, [1]],  # cat backbone P3
   [-1, 1, C3, [128, False]],  # 15 (P3/8-small)

   [-1, 1, Conv, [128, 3, 2]],
   [[-1, 12], 1, Concat, [1]],  # cat head P4
   [-1, 1, C3, [256, False]],  # 18 (P4/16-medium)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 8], 1, Concat, [1]],  # cat head P5
   [-1, 1, C3, [512, False]],  # 21 (P5/32-large)

   [[15, 18, 21], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5-fpn.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, Bottleneck, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, BottleneckCSP, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, BottleneckCSP, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 6, BottleneckCSP, [1024]],  # 9
  ]

# YOLOv5 FPN head
head:
  [[-1, 3, BottleneckCSP, [1024, False]],  # 10 (P5/32-large)

   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 1, Conv, [512, 1, 1]],
   [-1, 3, BottleneckCSP, [512, False]],  # 14 (P4/16-medium)

   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 1, Conv, [256, 1, 1]],
   [-1, 3, BottleneckCSP, [256, False]],  # 18 (P3/8-small)

   [[18, 14, 10], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5l.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, C3, [256]],
   [-1, 1, Conv, [256, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [512, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [512, [5, 9, 13]]],
   [-1, 3, C3, [1024, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5l6.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 19,27,  44,40,  38,94 ]  # P3/8
  - [ 96,68,  86,152,  180,137 ]  # P4/16
  - [ 140,301,  303,264,  238,542 ]  # P5/32
  - [ 436,615,  739,380,  925,792 ]  # P6/64

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, Focus, [ 64, 3 ] ],  # 0-P1/2
    [ -1, 1, Conv, [ 128, 3, 2 ] ],  # 1-P2/4
    [ -1, 3, C3, [ 128 ] ],
    [ -1, 1, Conv, [ 256, 3, 2 ] ],  # 3-P3/8
    [ -1, 9, C3, [ 256 ] ],
    [ -1, 1, Conv, [ 512, 3, 2 ] ],  # 5-P4/16
    [ -1, 9, C3, [ 512 ] ],
    [ -1, 1, Conv, [ 768, 3, 2 ] ],  # 7-P5/32
    [ -1, 3, C3, [ 768 ] ],
    [ -1, 1, Conv, [ 1024, 3, 2 ] ],  # 9-P6/64
    [ -1, 1, SPP, [ 1024, [ 3, 5, 7 ] ] ],
    [ -1, 3, C3, [ 1024, False ] ],  # 11
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 768, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 8 ], 1, Concat, [ 1 ] ],  # cat backbone P5
    [ -1, 3, C3, [ 768, False ] ],  # 15

    [ -1, 1, Conv, [ 512, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 3, C3, [ 512, False ] ],  # 19

    [ -1, 1, Conv, [ 256, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 3, C3, [ 256, False ] ],  # 23 (P3/8-small)

    [ -1, 1, Conv, [ 256, 3, 2 ] ],
    [ [ -1, 20 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 3, C3, [ 512, False ] ],  # 26 (P4/16-medium)

    [ -1, 1, Conv, [ 512, 3, 2 ] ],
    [ [ -1, 16 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 3, C3, [ 768, False ] ],  # 29 (P5/32-large)

    [ -1, 1, Conv, [ 768, 3, 2 ] ],
    [ [ -1, 12 ], 1, Concat, [ 1 ] ],  # cat head P6
    [ -1, 3, C3, [ 1024, False ] ],  # 32 (P6/64-xlarge)

    [ [ 23, 26, 29, 32 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\hub\yolov5m.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 0.67  # model depth multiple
width_multiple: 0.75  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, C3, [1024, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5m6.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 0.67  # model depth multiple
width_multiple: 0.75  # layer channel multiple

# anchors
anchors:
  - [ 19,27,  44,40,  38,94 ]  # P3/8
  - [ 96,68,  86,152,  180,137 ]  # P4/16
  - [ 140,301,  303,264,  238,542 ]  # P5/32
  - [ 436,615,  739,380,  925,792 ]  # P6/64

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, Focus, [ 64, 3 ] ],  # 0-P1/2
    [ -1, 1, Conv, [ 128, 3, 2 ] ],  # 1-P2/4
    [ -1, 3, C3, [ 128 ] ],
    [ -1, 1, Conv, [ 256, 3, 2 ] ],  # 3-P3/8
    [ -1, 9, C3, [ 256 ] ],
    [ -1, 1, Conv, [ 512, 3, 2 ] ],  # 5-P4/16
    [ -1, 9, C3, [ 512 ] ],
    [ -1, 1, Conv, [ 768, 3, 2 ] ],  # 7-P5/32
    [ -1, 3, C3, [ 768 ] ],
    [ -1, 1, Conv, [ 1024, 3, 2 ] ],  # 9-P6/64
    [ -1, 1, SPP, [ 1024, [ 3, 5, 7 ] ] ],
    [ -1, 3, C3, [ 1024, False ] ],  # 11
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 768, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 8 ], 1, Concat, [ 1 ] ],  # cat backbone P5
    [ -1, 3, C3, [ 768, False ] ],  # 15

    [ -1, 1, Conv, [ 512, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 3, C3, [ 512, False ] ],  # 19

    [ -1, 1, Conv, [ 256, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 3, C3, [ 256, False ] ],  # 23 (P3/8-small)

    [ -1, 1, Conv, [ 256, 3, 2 ] ],
    [ [ -1, 20 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 3, C3, [ 512, False ] ],  # 26 (P4/16-medium)

    [ -1, 1, Conv, [ 512, 3, 2 ] ],
    [ [ -1, 16 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 3, C3, [ 768, False ] ],  # 29 (P5/32-large)

    [ -1, 1, Conv, [ 768, 3, 2 ] ],
    [ [ -1, 12 ], 1, Concat, [ 1 ] ],  # cat head P6
    [ -1, 3, C3, [ 1024, False ] ],  # 32 (P6/64-xlarge)

    [ [ 23, 26, 29, 32 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\hub\yolov5-mbv3l.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # dont change this otherwise InvertedResidual will be affected
width_multiple: 1.0  # dont change this otherwise InvertedResidual will be affected

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # MobileNetV3-large
  # [from, number, InvertedResidual module, [in, out, filter, hidden, stride, use_se, use_hs]]
  [[-1, 1, Conv, [16, 3, 2]],                          # 0-p1/2
   [-1, 1, mobilev3_bneck, [ 16,  16, 3, 1, 0, 0]],  # 1-p1/2
   [-1, 1, mobilev3_bneck, [ 24,  64, 3, 2, 0, 0]],  # 2-p2/4
   [-1, 1, mobilev3_bneck, [ 24,  72, 3, 1, 0, 0]],  # 3-p2/4
   [-1, 1, mobilev3_bneck, [ 40,  72, 5, 2, 1, 0]],  # 4-p3/8
   [-1, 1, mobilev3_bneck, [ 40, 120, 5, 1, 1, 0]],  # 5-p3/8
   [-1, 1, mobilev3_bneck, [ 40, 120, 5, 1, 1, 0]],  # 6-p3/8
   [-1, 1, mobilev3_bneck, [ 80, 240, 3, 2, 0, 1]],  # 7-p4/16
   [-1, 1, mobilev3_bneck, [ 80, 200, 3, 1, 0, 1]],  # 8-p4/16
   [-1, 1, mobilev3_bneck, [ 80, 184, 3, 1, 0, 1]],  # 9-p4/16
   [-1, 1, mobilev3_bneck, [ 80, 184, 3, 1, 0, 1]],  # 10-p4/16
   [-1, 1, mobilev3_bneck, [112, 480, 3, 1, 1, 1]],  # 11-p4/16
   [-1, 1, mobilev3_bneck, [112, 672, 3, 1, 1, 1]],  # 12-p4/16
   [-1, 1, mobilev3_bneck, [160, 672, 5, 1, 1, 1]],  # 13-p4/16
   [-1, 1, mobilev3_bneck, [160, 672, 5, 2, 1, 1]],  # 14-p5/32
   [-1, 1, mobilev3_bneck, [160, 960, 5, 1, 1, 1]],  # 15-p5/32
  ]

# v5Lite-s head
head:
  [[-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 13], 1, Concat, [1]],  # cat backbone P4
   [-1, 1, C3, [256, False]],  # 15

   [-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P3
   [-1, 1, C3, [128, False]],  # 19 (P3/8-small)

   [-1, 1, Conv, [128, 3, 2]],
   [[-1, 20], 1, Concat, [1]],  # cat head P4
   [-1, 1, C3, [256, False]],  # 22 (P4/16-medium)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 16], 1, Concat, [1]],  # cat head P5
   [-1, 1, C3, [512, False]],  # 25 (P5/32-large)

   [[23, 26, 29], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5-mbv3s.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # dont change this otherwise InvertedResidual will be affected
width_multiple: 1.0  # dont change this otherwise InvertedResidual will be affected

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # MobileNetV3-small
  # [from, number, mobilev3_bneck module, [in, out, filter, hidden, stride, use_se, use_hs]]
  # [from, number, module, args]
  [[-1, 1, Conv, [16, 3, 2]],  # 0-P1/2
   [-1, 1, mobilev3_bneck, [16,  16, 3, 2, 1, 0]],  # 1-p2/4
   [-1, 1, mobilev3_bneck, [24,  72, 3, 2, 0, 0]],  # 2-p3/8
   [-1, 1, mobilev3_bneck, [24,  88, 3, 1, 0, 0]],  # 3-p3/8
   [-1, 1, mobilev3_bneck, [40,  96, 5, 2, 1, 1]],  # 4-p4/16
   [-1, 1, mobilev3_bneck, [40, 240, 5, 1, 1, 1]],  # 5-p4/16
   [-1, 1, mobilev3_bneck, [40, 240, 5, 1, 1, 1]],  # 6-p4/16
   [-1, 1, mobilev3_bneck, [48, 120, 5, 1, 1, 1]],  # 7-p4/16
   [-1, 1, mobilev3_bneck, [48, 144, 5, 1, 1, 1]],  # 8-p4/16
   [-1, 1, mobilev3_bneck, [96, 288, 5, 2, 1, 1]],  # 9-p5/32
   [-1, 1, mobilev3_bneck, [96, 576, 5, 1, 1, 1]],  # 10-p5/32
   [-1, 1, mobilev3_bneck, [96, 576, 5, 1, 1, 1]],  # 11-p5/32
  ]

# v5Lite-s head
head:
  [[-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 8], 1, Concat, [1]],  # cat backbone P4
   [-1, 1, C3, [256, False]],  # 15

   [-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 3], 1, Concat, [1]],  # cat backbone P3
   [-1, 1, C3, [128, False]],  # 19 (P3/8-small)

   [-1, 1, Conv, [128, 3, 2]],
   [[-1, 16], 1, Concat, [1]],  # cat head P4
   [-1, 1, C3, [256, False]],  # 22 (P4/16-medium)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 12], 1, Concat, [1]],  # cat head P5
   [-1, 1, C3, [512, False]],  # 25 (P5/32-large)

   [[19, 22, 25], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5-p2.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors: 3

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, Focus, [ 64, 3 ] ],  # 0-P1/2
    [ -1, 1, Conv, [ 128, 3, 2 ] ],  # 1-P2/4
    [ -1, 3, C3, [ 128 ] ],
    [ -1, 1, Conv, [ 256, 3, 2 ] ],  # 3-P3/8
    [ -1, 9, C3, [ 256 ] ],
    [ -1, 1, Conv, [ 512, 3, 2 ] ],  # 5-P4/16
    [ -1, 9, C3, [ 512 ] ],
    [ -1, 1, Conv, [ 1024, 3, 2 ] ],  # 7-P5/32
    [ -1, 1, SPP, [ 1024, [ 5, 9, 13 ] ] ],
    [ -1, 3, C3, [ 1024, False ] ],  # 9
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 512, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 3, C3, [ 512, False ] ],  # 13

    [ -1, 1, Conv, [ 256, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 3, C3, [ 256, False ] ],  # 17 (P3/8-small)

    [ -1, 1, Conv, [ 128, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P2
    [ -1, 1, C3, [ 128, False ] ],  # 21 (P2/4-xsmall)

    [ -1, 1, Conv, [ 128, 3, 2 ] ],
    [ [ -1, 18 ], 1, Concat, [ 1 ] ],  # cat head P3
    [ -1, 3, C3, [ 256, False ] ],  # 24 (P3/8-small)

    [ -1, 1, Conv, [ 256, 3, 2 ] ],
    [ [ -1, 14 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 3, C3, [ 512, False ] ],  # 27 (P4/16-medium)

    [ -1, 1, Conv, [ 512, 3, 2 ] ],
    [ [ -1, 10 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 3, C3, [ 1024, False ] ],  # 30 (P5/32-large)

    [ [ 24, 27, 30 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5-p6.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors: 3

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, Focus, [ 64, 3 ] ],  # 0-P1/2
    [ -1, 1, Conv, [ 128, 3, 2 ] ],  # 1-P2/4
    [ -1, 3, C3, [ 128 ] ],
    [ -1, 1, Conv, [ 256, 3, 2 ] ],  # 3-P3/8
    [ -1, 9, C3, [ 256 ] ],
    [ -1, 1, Conv, [ 512, 3, 2 ] ],  # 5-P4/16
    [ -1, 9, C3, [ 512 ] ],
    [ -1, 1, Conv, [ 768, 3, 2 ] ],  # 7-P5/32
    [ -1, 3, C3, [ 768 ] ],
    [ -1, 1, Conv, [ 1024, 3, 2 ] ],  # 9-P6/64
    [ -1, 1, SPP, [ 1024, [ 3, 5, 7 ] ] ],
    [ -1, 3, C3, [ 1024, False ] ],  # 11
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 768, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 8 ], 1, Concat, [ 1 ] ],  # cat backbone P5
    [ -1, 3, C3, [ 768, False ] ],  # 15

    [ -1, 1, Conv, [ 512, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 3, C3, [ 512, False ] ],  # 19

    [ -1, 1, Conv, [ 256, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 3, C3, [ 256, False ] ],  # 23 (P3/8-small)

    [ -1, 1, Conv, [ 256, 3, 2 ] ],
    [ [ -1, 20 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 3, C3, [ 512, False ] ],  # 26 (P4/16-medium)

    [ -1, 1, Conv, [ 512, 3, 2 ] ],
    [ [ -1, 16 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 3, C3, [ 768, False ] ],  # 29 (P5/32-large)

    [ -1, 1, Conv, [ 768, 3, 2 ] ],
    [ [ -1, 12 ], 1, Concat, [ 1 ] ],  # cat head P6
    [ -1, 3, C3, [ 1024, False ] ],  # 32 (P5/64-xlarge)

    [ [ 23, 26, 29, 32 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\hub\yolov5-p7.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors: 3

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, Focus, [ 64, 3 ] ],  # 0-P1/2
    [ -1, 1, Conv, [ 128, 3, 2 ] ],  # 1-P2/4
    [ -1, 3, C3, [ 128 ] ],
    [ -1, 1, Conv, [ 256, 3, 2 ] ],  # 3-P3/8
    [ -1, 9, C3, [ 256 ] ],
    [ -1, 1, Conv, [ 512, 3, 2 ] ],  # 5-P4/16
    [ -1, 9, C3, [ 512 ] ],
    [ -1, 1, Conv, [ 768, 3, 2 ] ],  # 7-P5/32
    [ -1, 3, C3, [ 768 ] ],
    [ -1, 1, Conv, [ 1024, 3, 2 ] ],  # 9-P6/64
    [ -1, 3, C3, [ 1024 ] ],
    [ -1, 1, Conv, [ 1280, 3, 2 ] ],  # 11-P7/128
    [ -1, 1, SPP, [ 1280, [ 3, 5 ] ] ],
    [ -1, 3, C3, [ 1280, False ] ],  # 13
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 1024, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 10 ], 1, Concat, [ 1 ] ],  # cat backbone P6
    [ -1, 3, C3, [ 1024, False ] ],  # 17

    [ -1, 1, Conv, [ 768, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 8 ], 1, Concat, [ 1 ] ],  # cat backbone P5
    [ -1, 3, C3, [ 768, False ] ],  # 21

    [ -1, 1, Conv, [ 512, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 3, C3, [ 512, False ] ],  # 25

    [ -1, 1, Conv, [ 256, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 3, C3, [ 256, False ] ],  # 29 (P3/8-small)

    [ -1, 1, Conv, [ 256, 3, 2 ] ],
    [ [ -1, 26 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 3, C3, [ 512, False ] ],  # 32 (P4/16-medium)

    [ -1, 1, Conv, [ 512, 3, 2 ] ],
    [ [ -1, 22 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 3, C3, [ 768, False ] ],  # 35 (P5/32-large)

    [ -1, 1, Conv, [ 768, 3, 2 ] ],
    [ [ -1, 18 ], 1, Concat, [ 1 ] ],  # cat head P6
    [ -1, 3, C3, [ 1024, False ] ],  # 38 (P6/64-xlarge)

    [ -1, 1, Conv, [ 1024, 3, 2 ] ],
    [ [ -1, 14 ], 1, Concat, [ 1 ] ],  # cat head P7
    [ -1, 3, C3, [ 1280, False ] ],  # 41 (P7/128-xxlarge)

    [ [ 29, 32, 35, 38, 41 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6, P7)
  ]

===== .\models\models\hub\yolov5-panet.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, BottleneckCSP, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, BottleneckCSP, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, BottleneckCSP, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, BottleneckCSP, [1024, False]],  # 9
  ]

# YOLOv5 PANet head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, BottleneckCSP, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5-repvgg_A1.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# repvgg backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, RepVGGBlock, [64, 3, 2]],  # 0-P1/2
   [-1, 1, RepVGGBlock, [64, 3, 2]], # 1-P2/4
   [-1, 1, RepVGGBlock, [64, 3, 1]], # 2-P2/4
   [-1, 1, RepVGGBlock, [128, 3, 2]], # 3-P3/8
   [-1, 3, RepVGGBlock, [128, 3, 1]],
   [-1, 1, RepVGGBlock, [256, 3, 2]], # 5-P4/16
   [-1, 13, RepVGGBlock, [256, 3, 1]],
   [-1, 1, RepVGGBlock, [512, 3, 2]], # 7-P4/16
  ]
# YOLOv5 head
head:
  [[-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 1, C3, [256, False]],  # 11

   [-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 1, C3, [128, False]],  # 15 (P3/8-small)

   [-1, 1, Conv, [128, 3, 2]],
   [[-1, 12], 1, Concat, [1]],  # cat head P4
   [-1, 1, C3, [256, False]],  # 18 (P4/16-medium)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 8], 1, Concat, [1]],  # cat head P5
   [-1, 1, C3, [512, False]],  # 21 (P5/32-large)

   [[15, 18, 21], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5s6.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple

# anchors
anchors:
  - [ 19,27,  44,40,  38,94 ]  # P3/8
  - [ 96,68,  86,152,  180,137 ]  # P4/16
  - [ 140,301,  303,264,  238,542 ]  # P5/32
  - [ 436,615,  739,380,  925,792 ]  # P6/64

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, Focus, [ 64, 3 ] ],  # 0-P1/2
    [ -1, 1, Conv, [ 128, 3, 2 ] ],  # 1-P2/4
    [ -1, 3, C3, [ 128 ] ],
    [ -1, 1, Conv, [ 256, 3, 2 ] ],  # 3-P3/8
    [ -1, 9, C3, [ 256 ] ],
    [ -1, 1, Conv, [ 512, 3, 2 ] ],  # 5-P4/16
    [ -1, 9, C3, [ 512 ] ],
    [ -1, 1, Conv, [ 768, 3, 2 ] ],  # 7-P5/32
    [ -1, 3, C3, [ 768 ] ],
    [ -1, 1, Conv, [ 1024, 3, 2 ] ],  # 9-P6/64
    [ -1, 1, SPP, [ 1024, [ 3, 5, 7 ] ] ],
    [ -1, 3, C3, [ 1024, False ] ],  # 11
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 768, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 8 ], 1, Concat, [ 1 ] ],  # cat backbone P5
    [ -1, 3, C3, [ 768, False ] ],  # 15

    [ -1, 1, Conv, [ 512, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 3, C3, [ 512, False ] ],  # 19

    [ -1, 1, Conv, [ 256, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 3, C3, [ 256, False ] ],  # 23 (P3/8-small)

    [ -1, 1, Conv, [ 256, 3, 2 ] ],
    [ [ -1, 20 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 3, C3, [ 512, False ] ],  # 26 (P4/16-medium)

    [ -1, 1, Conv, [ 512, 3, 2 ] ],
    [ [ -1, 16 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 3, C3, [ 768, False ] ],  # 29 (P5/32-large)

    [ -1, 1, Conv, [ 768, 3, 2 ] ],
    [ [ -1, 12 ], 1, Concat, [ 1 ] ],  # cat head P6
    [ -1, 3, C3, [ 1024, False ] ],  # 32 (P6/64-xlarge)

    [ [ 23, 26, 29, 32 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\hub\yolov5ss-0.5.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [11,16,  28,27,  33,74,  ]  # P3/8
  - [ 83,61,  107,162,  297,278 ]  # P4/16

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, conv_bn_relu_maxpool, [ 24 ] ],    # 0-P2/4
    [ -1, 1, Shuffle_Block, [ 48, 2 ] ], # 1-P3/8
    [ -1, 3, Shuffle_Block, [ 48, 1 ] ], # 2
    [ -1, 1, Shuffle_Block, [ 96, 2 ] ], # 3-P4/16
    [ -1, 7, Shuffle_Block, [ 96, 1 ] ], # 4
    [ -1, 1, Shuffle_Block, [ 192, 2 ] ], # 5-P5/32
    [ -1, 3, Shuffle_Block, [ 192, 1 ] ], # 6
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 128, 1, 1 ] ],  # 7
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],  # 8
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4  9
    [ -1, 1, Light_C3, [ 128, False ] ],  # 10

    [ -1, 1, Conv, [ 128, 1, 1 ] ],   # 11
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],  # 12
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3  # 13
    [ -1, 1, Light_C3, [ 128, False ] ],  # 14 (P3/8-small)

    [ [ 14, 10 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5ss-0.5-p4.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 4,5,  8,10,  13,16 ]  # P3/8
  - [ 23,29,  43,55,  73,105 ]  # P4/16
  - [ 146,217,  231,300,  335,433 ]  # P5/32

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, conv_bn_relu_maxpool, [ 24 ] ],    # 0-P2/4
    [ -1, 1, Shuffle_Block, [ 48, 2 ] ], # 1-P3/8
    [ -1, 3, Shuffle_Block, [ 48, 1 ] ], # 2
    [ -1, 1, Shuffle_Block, [ 96, 2 ] ], # 3-P4/16
    [ -1, 7, Shuffle_Block, [ 96, 1 ] ], # 4
    [ -1, 1, Shuffle_Block, [ 192, 2 ] ], # 5-P5/32
    [ -1, 3, Shuffle_Block, [ 192, 1 ] ], # 6
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 64, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, C3, [ 64, False ] ],  # 10

    [ -1, 1, Conv, [ 64, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, C3, [ 64, False ] ],  # 14 (P3/8-small)

    [ -1, 1, Conv, [ 64, 3, 2 ] ],
    [ [ -1, 11 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, C3, [ 64, False ] ],  # 17 (P4/16-medium)

    [ -1, 1, Conv, [ 64, 3, 2 ] ],
    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, C3, [ 64, False ] ],  # 20 (P5/32-large)

    [ [ 14, 17, 20 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5ss-dw.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 4,5,  8,10,  13,16 ]  # P3/8
  - [ 23,29,  43,55,  73,105 ]  # P4/16


# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, conv_bn_relu_maxpool, [ 24 ] ],    # 0-P2/4
    [ -1, 1, Shuffle_Block, [ 48, 2 ] ], # 1-P3/8
    [ -1, 3, Shuffle_Block, [ 48, 1 ] ], # 2
    [ -1, 1, Shuffle_Block, [ 96, 2 ] ], # 3-P4/16
    [ -1, 7, Shuffle_Block, [ 96, 1 ] ], # 4
    [ -1, 1, Shuffle_Block, [ 192, 2 ] ], # 5-P5/32
    [ -1, 3, Shuffle_Block, [ 192, 1 ] ], # 6
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 192, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, ADD, [ 1 ] ],  # cat backbone P4
    [ -1, 1, DWConvblock, [ 192 ] ],  # 10

    [ -1, 1, Conv, [ 96, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, ADD, [ 1 ] ],  # cat backbone P3
    [ -1, 1, DWConvblock, [ 96 ] ],  # 14

    [ [ 14, 10 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5s-transformer.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, C3TR, [1024, False]],  # 9  <-------- C3TR() Transformer module
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5x.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.33  # model depth multiple
width_multiple: 1.25  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, C3, [1024, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\hub\yolov5x6.yaml =====
功能: 代码摘录
# parameters
nc: 80  # number of classes
depth_multiple: 1.33  # model depth multiple
width_multiple: 1.25  # layer channel multiple

# anchors
anchors:
  - [ 19,27,  44,40,  38,94 ]  # P3/8
  - [ 96,68,  86,152,  180,137 ]  # P4/16
  - [ 140,301,  303,264,  238,542 ]  # P5/32
  - [ 436,615,  739,380,  925,792 ]  # P6/64

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, Focus, [ 64, 3 ] ],  # 0-P1/2
    [ -1, 1, Conv, [ 128, 3, 2 ] ],  # 1-P2/4
    [ -1, 3, C3, [ 128 ] ],
    [ -1, 1, Conv, [ 256, 3, 2 ] ],  # 3-P3/8
    [ -1, 9, C3, [ 256 ] ],
    [ -1, 1, Conv, [ 512, 3, 2 ] ],  # 5-P4/16
    [ -1, 9, C3, [ 512 ] ],
    [ -1, 1, Conv, [ 768, 3, 2 ] ],  # 7-P5/32
    [ -1, 3, C3, [ 768 ] ],
    [ -1, 1, Conv, [ 1024, 3, 2 ] ],  # 9-P6/64
    [ -1, 1, SPP, [ 1024, [ 3, 5, 7 ] ] ],
    [ -1, 3, C3, [ 1024, False ] ],  # 11
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 768, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 8 ], 1, Concat, [ 1 ] ],  # cat backbone P5
    [ -1, 3, C3, [ 768, False ] ],  # 15

    [ -1, 1, Conv, [ 512, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 3, C3, [ 512, False ] ],  # 19

    [ -1, 1, Conv, [ 256, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 3, C3, [ 256, False ] ],  # 23 (P3/8-small)

    [ -1, 1, Conv, [ 256, 3, 2 ] ],
    [ [ -1, 20 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 3, C3, [ 512, False ] ],  # 26 (P4/16-medium)

    [ -1, 1, Conv, [ 512, 3, 2 ] ],
    [ [ -1, 16 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 3, C3, [ 768, False ] ],  # 29 (P5/32-large)

    [ -1, 1, Conv, [ 768, 3, 2 ] ],
    [ [ -1, 12 ], 1, Concat, [ 1 ] ],  # cat head P6
    [ -1, 3, C3, [ 1024, False ] ],  # 32 (P6/64-xlarge)

    [ [ 23, 26, 29, 32 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)
  ]

===== .\models\models\v5Lite-c.yaml =====
功能: 代码摘录
# create by pogg
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 10,13, 16,30, 33,23 ]  # P3/8
  - [ 30,61, 62,45, 59,119 ]  # P4/16
  - [ 116,90, 156,198, 373,326 ]  # P5/32

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, CBH, [ 32, 3, 2 ] ],    # 0-P2/4
    [ -1, 1, LC_Block, [ 64, 2, 3, False ] ], # 1-P3/8
    [ -1, 1, LC_Block, [ 64, 1, 3, False ] ], # 2-P4/16
    [ -1, 1, LC_Block, [ 128, 2, 3, False ] ], # 3
    [ -1, 1, LC_Block, [ 128, 1, 3, False ] ], # 4-P5/32
    [ -1, 1, LC_Block, [ 128, 1, 3, False ] ], # 5
    [ -1, 1, LC_Block, [ 128, 1, 3, False ] ], # 6
    [ -1, 1, LC_Block, [ 256, 2, 3, False ] ], # 7-P5/32
    [ -1, 1, LC_Block, [ 256, 1, 5, False ] ],
    [ -1, 1, LC_Block, [ 256, 1, 5, False ] ],
    [ -1, 1, LC_Block, [ 256, 1, 5, False ] ], # 10-P5/32
    [ -1, 1, LC_Block, [ 256, 1, 5, False ] ],
    [ -1, 1, LC_Block, [ 256, 1, 5, False ] ], # 12-P5/32
    [ -1, 1, LC_Block, [ 512, 2, 5, True ] ],
    [ -1, 1, LC_Block, [ 512, 1, 5, True ] ], # 14-P5/32
    [ -1, 1, LC_Block, [ 512, 1, 5, True ] ], # 15
    [ -1, 1, LC_Block, [ 512, 1, 5, True ] ], # 16
    [ -1, 1, Dense, [ 512, 1, 0.2 ] ],
  ]

# v5Lite-c head
head:
  [ [-1, 1, Conv, [256, 1, 1]], # 18
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 12 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [-1, 1, C3, [256, False]],  # 21

    [-1, 1, Conv, [128, 1, 1]], # 22
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [-1, 1, C3, [128, False]],  # 25 (P3/8-small)

    [ -1, 1, LC_Block, [ 128, 2, 5, True ] ],  # 26
    [ [ -1, 22 ], 1, Concat, [ 1 ] ],  # cat head P4
    [-1, 1, C3, [256, False]],  # 28 (P4/16-medium)

    [ -1, 1, LC_Block, [ 256, 2, 5, True ] ], # 29
    [ [ -1, 18 ], 1, Concat, [ 1 ] ],  # cat head P5
    [-1, 1, C3, [512, False]],  # 31 (P5/32-large)

    [ [ 25, 28, 31 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\v5Lite-e.yaml =====
功能: 代码摘录
# create by pogg
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 10,13, 16,30, 33,23 ]  # P3/8
  - [ 30,61, 62,45, 59,119 ]  # P4/16
  - [ 116,90, 156,198, 373,326 ]  # P5/32

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, conv_bn_relu_maxpool, [ 32 ] ],    # 0-P2/4
    [ -1, 1, Shuffle_Block, [ 116, 2 ] ], # 1-P3/8
    [ -1, 3, Shuffle_Block, [ 116, 1 ] ], # 2
    [ -1, 1, Shuffle_Block, [ 232, 2 ] ], # 3-P4/16
    [ -1, 7, Shuffle_Block, [ 232, 1 ] ], # 4
    [ -1, 1, Shuffle_Block, [ 464, 2 ] ], # 5-P5/32
    [ -1, 1, Shuffle_Block, [ 464, 1 ] ], # 6
  ]

# v5lite-e head
head:
  [ [ -1, 1, Conv, [ 96, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, DWConvblock, [96, 3, 1] ],  # 10

    [ -1, 1, Conv, [ 96, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, DWConvblock, [96, 3, 1] ],  # 14 (P3/8-small)

    [-1, 1, DWConvblock, [96, 3, 2]],
    [ [ -1, 11 ], 1, ADD, [ 1 ] ],  # cat head P4
    [ -1, 1, DWConvblock, [96, 3, 1] ],  # 17 (P4/16-medium)

    [ -1, 1, DWConvblock, [ 96, 3, 2 ] ],
    [ [ -1, 7 ], 1, ADD, [ 1 ] ],  # cat head P5
    [ -1, 1, DWConvblock, [96, 3, 1] ],  # 20 (P5/32-large)

    [ [ 14, 17, 20 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\v5Lite-g.yaml =====
功能: 代码摘录
# create by pogg
# parameters
nc: 80  # number of classes
depth_multiple: 1  # model depth multiple
width_multiple: 1  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5-repvgg backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [32, 3]],  # 0-P1/2
   [-1, 1, RepVGGBlock, [64, 3, 2]], # 1-P2/4
   [-1, 1, C3, [64]],
   [-1, 1, RepVGGBlock, [128, 3, 2]], # 3-P3/8
   [-1, 3, C3, [128]],
   [-1, 1, RepVGGBlock, [256, 3, 2]], # 5-P4/16
   [-1, 3, C3, [256]],
   [-1, 1, RepVGGBlock, [512, 3, 2]], # 7-P4/16
   [-1, 1, SPP, [512, [5, 9, 13]]],
   [-1, 1, C3, [512, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [128, False]],  # 13

   [-1, 1, Conv, [128, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [128, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [128, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [128, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [128, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [128, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

===== .\models\models\v5Lite-s.yaml =====
功能: 代码摘录
# create by pogg
# parameters
nc: 80  # number of classes
depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple

# anchors
anchors:
  - [ 10,13, 16,30, 33,23 ]  # P3/8
  - [ 30,61, 62,45, 59,119 ]  # P4/16
  - [ 116,90, 156,198, 373,326 ]  # P5/32

# custom backbone
backbone:
  # [from, number, module, args]
  [ [ -1, 1, conv_bn_relu_maxpool, [ 32 ] ],    # 0-P2/4
    [ -1, 1, Shuffle_Block, [ 116, 2 ] ], # 1-P3/8
    [ -1, 3, Shuffle_Block, [ 116, 1 ] ], # 2
    [ -1, 1, Shuffle_Block, [ 232, 2 ] ], # 3-P4/16
    [ -1, 7, Shuffle_Block, [ 232, 1 ] ], # 4
    [ -1, 1, Shuffle_Block, [ 464, 2 ] ], # 5-P5/32
    [ -1, 3, Shuffle_Block, [ 464, 1 ] ], # 6
  ]

# YOLOv5 head
head:
  [ [ -1, 1, Conv, [ 128, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P4
    [ -1, 1, C3, [ 128, False ] ],  # 10

    [ -1, 1, Conv, [ 64, 1, 1 ] ],
    [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],
    [ [ -1, 2 ], 1, Concat, [ 1 ] ],  # cat backbone P3
    [ -1, 1, C3, [ 64, False ] ],  # 14 (P3/8-small)

    [ -1, 1, Conv, [ 64, 3, 2 ] ],
    [ [ -1, 11 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, C3, [ 128, False ] ],  # 17 (P4/16-medium)

    [ -1, 1, Conv, [ 128, 3, 2 ] ],
    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, C3, [ 256, False ] ],  # 20 (P5/32-large)

    [ [ 14, 17, 20 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5)
  ]

===== .\models\models\yolo.py =====
功能: 代码摘录
# YOLOv5 YOLO-specific modules

import argparse
import logging
import sys
from copy import deepcopy

sys.path.append('./')  # to run '$ python *.py' files in subdirectories
logger = logging.getLogger(__name__)

from models.common import *
from models.experimental import *
from utils.autoanchor import check_anchor_order
from utils.general import make_divisible, check_file, set_logging
from utils.torch_utils import time_synchronized, fuse_conv_and_bn, model_info, scale_img, initialize_weights, \
    select_device, copy_attr

try:
    import thop  # for FLOPS computation
except ImportError:
    thop = None


class Detect(nn.Module):
    stride = None  # strides computed during build
    export = False  # onnx export

    def __init__(self, nc=80, anchors=(), ch=()):  # detection layer
        super(Detect, self).__init__()
        self.nc = nc  # number of classes
        self.no = nc + 5  # number of outputs per anchor
        self.nl = len(anchors)  # number of detection layers
        self.na = len(anchors[0]) // 2  # number of anchors
        self.grid = [torch.zeros(1)] * self.nl  # init grid
        a = torch.tensor(anchors).float().view(self.nl, -1, 2)
        self.register_buffer('anchors', a)  # shape(nl,na,2)
        self.register_buffer('anchor_grid', a.clone().view(self.nl, 1, -1, 1, 1, 2))  # shape(nl,1,na,1,1,2)
        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv

    def forward(self, x):
        # x = x.copy()  # for profiling
        z = []  # inference output
        logits_ = []
        self.training |= self.export
        for i in range(self.nl):
            x[i] = self.m[i](x[i])  # conv
            bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()

            if not self.training:  # inference
                if torch.onnx.is_in_onnx_export():
                    self.grid[i] = self._make_grid(nx, ny).to(x[i].device)
                elif self.grid[i].shape[2:4] != x[i].shape[2:4]:
                    self.grid[i] = self._make_grid(nx, ny).to(x[i].device)
                logits = x[i][..., 5:]

                y = x[i].sigmoid()
                if not torch.onnx.is_in_onnx_export():
                    y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + self.grid[i]) * self.stride[i]  # xy
                    y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
                else:
                    xy = (y[..., 0:2] * 2. - 0.5 + self.grid[i]) * self.stride[i]  # xy
                    wh = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i].data  # wh
                    y = torch.cat((xy, wh, y[..., 4:]), -1)
                z.append(y.view(bs, -1, self.no))
                logits_.append(logits.view(bs, -1, self.no - 5))

        return x if self.training else (torch.cat(z, 1), torch.cat(logits_, 1), x)

    def cat_forward(self, x):
        z = []  # inference output
        for i in range(self.nl):
            x[i] = self.m[i](x[i])  # conv
            bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()

            if self.grid[i].shape[2:4] != x[i].shape[2:4]:
                self.grid[i] = self._make_grid(nx, ny).to(x[i].device)

            y = x[i].sigmoid()
            z.append(y.view(bs, -1, self.no))

        return torch.cat(z, 1)

    @staticmethod
    def _make_grid(nx=20, ny=20):
        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])
        return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()

class Model(nn.Module):
    def __init__(self, cfg='yolov5s.yaml', ch=3, nc=None, anchors=None):  # model, input channels, number of classes
        super(Model, self).__init__()
        if isinstance(cfg, dict):
            self.yaml = cfg  # model dict
        else:  # is *.yaml
            import yaml  # for torch hub
            self.yaml_file = Path(cfg).name
            with open(cfg) as f:
                self.yaml = yaml.load(f, Loader=yaml.SafeLoader)  # model dict

        # Define model
        ch = self.yaml['ch'] = self.yaml.get('ch', ch)  # input channels
        if nc and nc != self.yaml['nc']:
            logger.info(f"Overriding model.yaml nc={self.yaml['nc']} with nc={nc}")
            self.yaml['nc'] = nc  # override yaml value
        if anchors:
            logger.info(f'Overriding model.yaml anchors with anchors={anchors}')
            self.yaml['anchors'] = round(anchors)  # override yaml value
        self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])  # model, savelist
        self.names = [str(i) for i in range(self.yaml['nc'])]  # default names
        # print([x.shape for x in self.forward(torch.zeros(1, ch, 64, 64))])

        # Build strides, anchors
        m = self.model[-1]  # Detect()
        if isinstance(m, Detect):
            s = 256  # 2x min stride
            m.stride = torch.tensor([s / x.shape[-2] for x in self.forward(torch.zeros(1, ch, s, s))])  # forward
            m.anchors /= m.stride.view(-1, 1, 1)
            check_anchor_order(m)
            self.stride = m.stride
            self._initialize_biases()  # only run once
            # print('Strides: %s' % m.stride.tolist())

        # Init weights, biases
        initialize_weights(self)
        self.info()
        logger.info('')

    def forward(self, x, augment=False, profile=False):
        if augment:
            img_size = x.shape[-2:]  # height, width
            s = [1, 0.83, 0.67]  # scales
            f = [None, 3, None]  # flips (2-ud, 3-lr)
            y = []  # outputs
            for si, fi in zip(s, f):
                xi = scale_img(x.flip(fi) if fi else x, si, gs=int(self.stride.max()))
                yi = self.forward_once(xi)[0]  # forward
                # cv2.imwrite(f'img_{si}.jpg', 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1])  # save
                yi[..., :4] /= si  # de-scale
                if fi == 2:
                    yi[..., 1] = img_size[0] - yi[..., 1]  # de-flip ud
                elif fi == 3:
                    yi[..., 0] = img_size[1] - yi[..., 0]  # de-flip lr
                y.append(yi)
            return torch.cat(y, 1), None  # augmented inference, train
        else:
            return self.forward_once(x, profile)  # single-scale inference, train

    def forward_once(self, x, profile=True):
        y, dt = [], []  # outputs
        for m in self.model:
            if m.f != -1:  # if not from previous layer
                x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers

            if profile:
                o = thop.profile(m, inputs=(x,))[0] / 1E9 * 2 if thop else 0  # FLOPS
                t = time_synchronized()
                for _ in range(10):
                    _ = m(x)
                dt.append((time_synchronized() - t) * 100)
                print('%10.1f%10.0f%10.1fms %-40s' % (o, m.np, dt[-1], m.type))

            x = m(x)  # run
            y.append(x if m.i in self.save else None)  # save output

        if profile:
            print('%.1fms total' % sum(dt))
        return x

    def _initialize_biases(self, cf=None):  # initialize biases into Detect(), cf is class frequency
        # https://arxiv.org/abs/1708.02002 section 3.3
        # cf = torch.bincount(torch.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1.
        m = self.model[-1]  # Detect() module
        for mi, s in zip(m.m, m.stride):  # from
            b = mi.bias.view(m.na, -1)  # conv.bias(255) to (3,85)
            b.data[:, 4] += math.log(8 / (640 / s) ** 2)  # obj (8 objects per 640 image)
            b.data[:, 5:] += math.log(0.6 / (m.nc - 0.99)) if cf is None else torch.log(cf / cf.sum())  # cls
            mi.bias = torch.nn.Parameter(b.view(-1), requires_grad=True)

    def _print_biases(self):
        m = self.model[-1]  # Detect() module
        for mi in m.m:  # from
            b = mi.bias.detach().view(m.na, -1).T  # conv.bias(255) to (3,85)
            print(('%6g Conv2d.bias:' + '%10.3g' * 6) % (mi.weight.shape[1], *b[:5].mean(1).tolist(), b[5:].mean()))

    def _print_weights(self):
        for m in self.model.modules():
            if type(m) is Bottleneck:
                print('%10.3g' % (m.w.detach().sigmoid() * 2))  # shortcut weights

# --------------------------repvgg & shuffle refuse---------------------------------

    def fuse(self):  # fuse model Conv2d() + BatchNorm2d() layers
        print('Fusing layers... ')
        for m in self.model.modules():
            # print(m)
            if type(m) is RepVGGBlock:
                if hasattr(m, 'rbr_1x1'):
                    # print(m)
                    kernel, bias = m.get_equivalent_kernel_bias()
                    rbr_reparam = nn.Conv2d(in_channels=m.rbr_dense.conv.in_channels,
                                            out_channels=m.rbr_dense.conv.out_channels,
                                            kernel_size=m.rbr_dense.conv.kernel_size,
                                            stride=m.rbr_dense.conv.stride,
                                            padding=m.rbr_dense.conv.padding, dilation=m.rbr_dense.conv.dilation,
                                            groups=m.rbr_dense.conv.groups, bias=True)
                    rbr_reparam.weight.data = kernel
                    rbr_reparam.bias.data = bias
                    for para in self.parameters():
                        para.detach_()
                    m.rbr_dense = rbr_reparam
                    # m.__delattr__('rbr_dense')
                    m.__delattr__('rbr_1x1')
                    if hasattr(m, 'rbr_identity'):
                        m.__delattr__('rbr_identity')
                    if hasattr(m, 'id_tensor'):
                        m.__delattr__('id_tensor')
                    m.deploy = True
                    delattr(m, 'se')
                    m.forward = m.fusevggforward  # update forward
                # continue
                # print(m)
            if type(m) is Conv and hasattr(m, 'bn'):
                # print(m)
                m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv
                delattr(m, 'bn')  # remove batchnorm
                m.forward = m.fuseforward  # update forward

            if type(m) is CBH and hasattr(m, 'bn'):
                m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv
                delattr(m, 'bn')  # remove batchnorm
                m.forward = m.fuseforward  # update forward

            if type(m) is Shuffle_Block:
                if hasattr(m, 'branch1'):
                    re_branch1 = nn.Sequential(
                        nn.Conv2d(m.branch1[0].in_channels, m.branch1[0].out_channels,
                                  kernel_size=m.branch1[0].kernel_size, stride=m.branch1[0].stride,
                                  padding=m.branch1[0].padding, groups=m.branch1[0].groups),
                        nn.Conv2d(m.branch1[2].in_channels, m.branch1[2].out_channels,
                                  kernel_size=m.branch1[2].kernel_size, stride=m.branch1[2].stride,
                                  padding=m.branch1[2].padding, bias=False),
                        nn.ReLU(inplace=True),
                    )
                    re_branch1[0] = fuse_conv_and_bn(m.branch1[0], m.branch1[1])
                    re_branch1[1] = fuse_conv_and_bn(m.branch1[2], m.branch1[3])
                    # pdb.set_trace()
                    # print(m.branch1[0])
                    m.branch1 = re_branch1
                if hasattr(m, 'branch2'):
                    re_branch2 = nn.Sequential(
                        nn.Conv2d(m.branch2[0].in_channels, m.branch2[0].out_channels,
                                  kernel_size=m.branch2[0].kernel_size, stride=m.branch2[0].stride,
                                  padding=m.branch2[0].padding, groups=m.branch2[0].groups),
                        nn.ReLU(inplace=True),
                        nn.Conv2d(m.branch2[3].in_channels, m.branch2[3].out_channels,
                                  kernel_size=m.branch2[3].kernel_size, stride=m.branch2[3].stride,
                                  padding=m.branch2[3].padding, bias=False),
                        nn.Conv2d(m.branch2[5].in_channels, m.branch2[5].out_channels,
                                  kernel_size=m.branch2[5].kernel_size, stride=m.branch2[5].stride,
                                  padding=m.branch2[5].padding, groups=m.branch2[5].groups),
                        nn.ReLU(inplace=True),
                    )
                    re_branch2[0] = fuse_conv_and_bn(m.branch2[0], m.branch2[1])
                    re_branch2[2] = fuse_conv_and_bn(m.branch2[3], m.branch2[4])
                    re_branch2[3] = fuse_conv_and_bn(m.branch2[5], m.branch2[6])
                    # pdb.set_trace()
                    m.branch2 = re_branch2
                    # print(m.branch2)
        self.info()
        return self

# --------------------------end repvgg & shuffle refuse--------------------------------

    def nms(self, mode=True):  # add or remove NMS module
        present = type(self.model[-1]) is NMS  # last layer is NMS
        if mode and not present:
            print('Adding NMS... ')
            m = NMS()  # module
            m.f = -1  # from
            m.i = self.model[-1].i + 1  # index
            self.model.add_module(name='%s' % m.i, module=m)  # add
            self.eval()
        elif not mode and present:
            print('Removing NMS... ')
            self.model = self.model[:-1]  # remove
        return self

    def autoshape(self):  # add autoShape module
        print('Adding autoShape... ')
        m = autoShape(self)  # wrap model
        copy_attr(m, self, include=('yaml', 'nc', 'hyp', 'names', 'stride'), exclude=())  # copy attributes
        return m

    def info(self, verbose=False, img_size=640):  # print model information
        model_info(self, verbose, img_size)


def parse_model(d, ch):  # model_dict, input_channels(3)
    logger.info('\n%3s%18s%3s%10s  %-40s%-30s' % ('', 'from', 'n', 'params', 'module', 'arguments'))
    anchors, nc, gd, gw = d['anchors'], d['nc'], d['depth_multiple'], d['width_multiple']
    na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors
    no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)

    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out
    for i, (f, n, m, args) in enumerate(d['backbone'] + d['head']):  # from, number, module, args
        m = eval(m) if isinstance(m, str) else m  # eval strings
        for j, a in enumerate(args):
            try:
                args[j] = eval(a) if isinstance(a, str) else a  # eval strings
            except:
                pass

        n = max(round(n * gd), 1) if n > 1 else n  # depth gain
        if m in [Conv, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, MixConv2d, Focus, CrossConv, BottleneckCSP,
                 C3, C3TR, Shuffle_Block, conv_bn_relu_maxpool, DWConvblock, MBConvBlock, LC3,
                 RepVGGBlock, SEBlock, mobilev3_bneck, Hswish, SELayer, stem, CBH, LC_Block, Dense,
                GhostConv, ES_Bottleneck, ES_SEModule]:
            c1, c2 = ch[f], args[0]
            if c2 != no:  # if not output
                c2 = make_divisible(c2 * gw, 8)

            args = [c1, c2, *args[1:]]
            if m in [BottleneckCSP, C3, C3TR]:
                args.insert(2, n)  # number of repeats
                n = 1
        elif m is nn.BatchNorm2d:
            args = [ch[f]]
        elif m is Concat:
            c2 = sum([ch[x] for x in f])
        elif m is ADD:
            c2 = sum([ch[x] for x in f])//2
        elif m is Detect:
            args.append([ch[x] for x in f])
            if isinstance(args[1], int):  # number of anchors
                args[1] = [list(range(args[1] * 2))] * len(f)
        elif m is Contract:
            c2 = ch[f] * args[0] ** 2
        elif m is Expand:
            c2 = ch[f] // args[0] ** 2
        else:
            c2 = ch[f]

        m_ = nn.Sequential(*[m(*args) for _ in range(n)]) if n > 1 else m(*args)  # module
        t = str(m)[8:-2].replace('__main__.', '')  # module type
        np = sum([x.numel() for x in m_.parameters()])  # number params
        m_.i, m_.f, m_.type, m_.np = i, f, t, np  # attach index, 'from' index, type, number params
        logger.info('%3s%18s%3s%10.0f  %-40s%-30s' % (i, f, n, np, t, args))  # print
        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # append to savelist
        layers.append(m_)
        if i == 0:
            ch = []
        ch.append(c2)
    return nn.Sequential(*layers), sorted(save)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--cfg', type=str, default='yolov5s.yaml', help='model.yaml')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    opt = parser.parse_args()
    opt.cfg = check_file(opt.cfg)  # check file
    set_logging()
    device = select_device(opt.device)

    # Create model
    model = Model(opt.cfg).to(device)
    model.train()

    # Profile
    # img = torch.rand(8 if torch.cuda.is_available() else 1, 3, 640, 640).to(device)
    # y = model(img, profile=True)

    # Tensorboard
    # from torch.utils.tensorboard import SummaryWriter
    # tb_writer = SummaryWriter()
    # print("Run 'tensorboard --logdir=models/runs' to view tensorboard at http://localhost:6006/")
    # tb_writer.add_graph(model.model, img)  # add model to tensorboard
    # tb_writer.add_image('test', img[0], dataformats='CWH')  # add model to tensorboard

===== .\models\package.xml =====
功能: 代码摘录
<?xml version="1.0"?>
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
<package format="3">
  <name>models</name>
  <version>0.0.0</version>
  <description>TODO: Package description</description>
  <maintainer email="macabaka@todo.todo">macabaka</maintainer>
  <license>TODO: License declaration</license>

  <depend>rclpy</depend>

  <test_depend>ament_copyright</test_depend>
  <test_depend>ament_flake8</test_depend>
  <test_depend>ament_pep257</test_depend>
  <test_depend>python3-pytest</test_depend>

  <export>
    <build_type>ament_python</build_type>
  </export>
</package>

===== .\models\setup.cfg =====
功能: 代码摘录
[develop]
script_dir=$base/lib/models
[install]
install_scripts=$base/lib/models

===== .\models\setup.py =====
功能: 代码摘录
from setuptools import setup

package_name = 'models'

setup(
    name=package_name,
    version='0.0.0',
    packages=[package_name],
    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),
        ('share/' + package_name, ['package.xml']),
    ],
    install_requires=['setuptools'],
    zip_safe=True,
    maintainer='macabaka',
    maintainer_email='macabaka@todo.todo',
    description='TODO: Package description',
    license='TODO: License declaration',
    tests_require=['pytest'],
    entry_points={
        'console_scripts': [
            "models_empty = models.empty:main",
        ],
    },
)

===== .\models\test\test_copyright.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_copyright.main import main
import pytest


# Remove the `skip` decorator once the source file(s) have a copyright header
@pytest.mark.skip(reason='No copyright header has been placed in the generated source file.')
@pytest.mark.copyright
@pytest.mark.linter
def test_copyright():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found errors'

===== .\models\test\test_flake8.py =====
功能: 代码摘录
# Copyright 2017 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_flake8.main import main_with_errors
import pytest


@pytest.mark.flake8
@pytest.mark.linter
def test_flake8():
    rc, errors = main_with_errors(argv=[])
    assert rc == 0, \
        'Found %d code style errors / warnings:\n' % len(errors) + \
        '\n'.join(errors)

===== .\models\test\test_pep257.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_pep257.main import main
import pytest


@pytest.mark.linter
@pytest.mark.pep257
def test_pep257():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found code style errors / warnings'

===== .\utils\package.xml =====
功能: 代码摘录
<?xml version="1.0"?>
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
<package format="3">
  <name>utils</name>
  <version>0.0.0</version>
  <description>TODO: Package description</description>
  <maintainer email="macabaka@todo.todo">macabaka</maintainer>
  <license>TODO: License declaration</license>

  <depend>rclpy</depend>

  <test_depend>ament_copyright</test_depend>
  <test_depend>ament_flake8</test_depend>
  <test_depend>ament_pep257</test_depend>
  <test_depend>python3-pytest</test_depend>

  <export>
    <build_type>ament_python</build_type>
  </export>
</package>

===== .\utils\setup.cfg =====
功能: 代码摘录
[develop]
script_dir=$base/lib/utils
[install]
install_scripts=$base/lib/utils

===== .\utils\setup.py =====
功能: 代码摘录
from setuptools import setup

package_name = 'utils'

setup(
    name=package_name,
    version='0.0.0',
    packages=[package_name],
    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),
        ('share/' + package_name, ['package.xml']),
    ],
    install_requires=['setuptools'],
    zip_safe=True,
    maintainer='macabaka',
    maintainer_email='macabaka@todo.todo',
    description='TODO: Package description',
    license='TODO: License declaration',
    tests_require=['pytest'],
    entry_points={
        'console_scripts': [
            "utils_empty = utils.empty:main",
        ],
    },
)

===== .\utils\test\test_copyright.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_copyright.main import main
import pytest


# Remove the `skip` decorator once the source file(s) have a copyright header
@pytest.mark.skip(reason='No copyright header has been placed in the generated source file.')
@pytest.mark.copyright
@pytest.mark.linter
def test_copyright():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found errors'

===== .\utils\test\test_flake8.py =====
功能: 代码摘录
# Copyright 2017 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_flake8.main import main_with_errors
import pytest


@pytest.mark.flake8
@pytest.mark.linter
def test_flake8():
    rc, errors = main_with_errors(argv=[])
    assert rc == 0, \
        'Found %d code style errors / warnings:\n' % len(errors) + \
        '\n'.join(errors)

===== .\utils\test\test_pep257.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_pep257.main import main
import pytest


@pytest.mark.linter
@pytest.mark.pep257
def test_pep257():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found code style errors / warnings'

===== .\utils\utils\__init__.py =====
功能: 代码摘录

===== .\utils\utils\activations.py =====
功能: 代码摘录
# Activation functions

import torch
import torch.nn as nn
import torch.nn.functional as F


# SiLU https://arxiv.org/pdf/1606.08415.pdf ----------------------------------------------------------------------------
class SiLU(nn.Module):  # export-friendly version of nn.SiLU()
    @staticmethod
    def forward(x):
        return x * torch.sigmoid(x)


class Hardswish(nn.Module):  # export-friendly version of nn.Hardswish()
    @staticmethod
    def forward(x):
        # return x * F.hardsigmoid(x)  # for torchscript and CoreML
        return x * F.hardtanh(x + 3, 0., 6.) / 6.  # for torchscript, CoreML and ONNX


class MemoryEfficientSwish(nn.Module):
    class F(torch.autograd.Function):
        @staticmethod
        def forward(ctx, x):
            ctx.save_for_backward(x)
            return x * torch.sigmoid(x)

        @staticmethod
        def backward(ctx, grad_output):
            x = ctx.saved_tensors[0]
            sx = torch.sigmoid(x)
            return grad_output * (sx * (1 + x * (1 - sx)))

    def forward(self, x):
        return self.F.apply(x)


# Mish https://github.com/digantamisra98/Mish --------------------------------------------------------------------------
class Mish(nn.Module):
    @staticmethod
    def forward(x):
        return x * F.softplus(x).tanh()


class MemoryEfficientMish(nn.Module):
    class F(torch.autograd.Function):
        @staticmethod
        def forward(ctx, x):
            ctx.save_for_backward(x)
            return x.mul(torch.tanh(F.softplus(x)))  # x * tanh(ln(1 + exp(x)))

        @staticmethod
        def backward(ctx, grad_output):
            x = ctx.saved_tensors[0]
            sx = torch.sigmoid(x)
            fx = F.softplus(x).tanh()
            return grad_output * (fx + x * sx * (1 - fx * fx))

    def forward(self, x):
        return self.F.apply(x)


# FReLU https://arxiv.org/abs/2007.11824 -------------------------------------------------------------------------------
class FReLU(nn.Module):
    def __init__(self, c1, k=3):  # ch_in, kernel
        super().__init__()
        self.conv = nn.Conv2d(c1, c1, k, 1, 1, groups=c1, bias=False)
        self.bn = nn.BatchNorm2d(c1)

    def forward(self, x):
        return torch.max(x, self.bn(self.conv(x)))

===== .\utils\utils\autoanchor.py =====
功能: 代码摘录
# Auto-anchor utils

import numpy as np
import torch
import yaml
from scipy.cluster.vq import kmeans
from tqdm import tqdm

from utils.general import colorstr


def check_anchor_order(m):
    # Check anchor order against stride order for YOLOv5 Detect() module m, and correct if necessary
    a = m.anchor_grid.prod(-1).view(-1)  # anchor area
    da = a[-1] - a[0]  # delta a
    ds = m.stride[-1] - m.stride[0]  # delta s
    if da.sign() != ds.sign():  # same order
        print('Reversing anchor order')
        m.anchors[:] = m.anchors.flip(0)
        m.anchor_grid[:] = m.anchor_grid.flip(0)


def check_anchors(dataset, model, thr=4.0, imgsz=640):
    # Check anchor fit to data, recompute if necessary
    prefix = colorstr('autoanchor: ')
    print(f'\n{prefix}Analyzing anchors... ', end='')
    m = model.module.model[-1] if hasattr(model, 'module') else model.model[-1]  # Detect()
    shapes = imgsz * dataset.shapes / dataset.shapes.max(1, keepdims=True)
    scale = np.random.uniform(0.9, 1.1, size=(shapes.shape[0], 1))  # augment scale
    wh = torch.tensor(np.concatenate([l[:, 3:5] * s for s, l in zip(shapes * scale, dataset.labels)])).float()  # wh

    def metric(k):  # compute metric
        r = wh[:, None] / k[None]
        x = torch.min(r, 1. / r).min(2)[0]  # ratio metric
        best = x.max(1)[0]  # best_x
        aat = (x > 1. / thr).float().sum(1).mean()  # anchors above threshold
        bpr = (best > 1. / thr).float().mean()  # best possible recall
        return bpr, aat

    anchors = m.anchor_grid.clone().cpu().view(-1, 2)  # current anchors
    bpr, aat = metric(anchors)
    print(f'anchors/target = {aat:.2f}, Best Possible Recall (BPR) = {bpr:.4f}', end='')
    if bpr < 0.98:  # threshold to recompute
        print('. Attempting to improve anchors, please wait...')
        na = m.anchor_grid.numel() // 2  # number of anchors
        try:
            anchors = kmean_anchors(dataset, n=na, img_size=imgsz, thr=thr, gen=1000, verbose=False)
        except Exception as e:
            print(f'{prefix}ERROR: {e}')
        new_bpr = metric(anchors)[0]
        if new_bpr > bpr:  # replace anchors
            anchors = torch.tensor(anchors, device=m.anchors.device).type_as(m.anchors)
            m.anchor_grid[:] = anchors.clone().view_as(m.anchor_grid)  # for inference
            m.anchors[:] = anchors.clone().view_as(m.anchors) / m.stride.to(m.anchors.device).view(-1, 1, 1)  # loss
            check_anchor_order(m)
            print(f'{prefix}New anchors saved to model. Update model *.yaml to use these anchors in the future.')
        else:
            print(f'{prefix}Original anchors better than new anchors. Proceeding with original anchors.')
    print('')  # newline


def kmean_anchors(path='./data/coco128.yaml', n=9, img_size=640, thr=4.0, gen=1000, verbose=True):
    """ Creates kmeans-evolved anchors from training dataset

        Arguments:
            path: path to dataset *.yaml, or a loaded dataset
            n: number of anchors
            img_size: image size used for training
            thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0
            gen: generations to evolve anchors using genetic algorithm
            verbose: print all results

        Return:
            k: kmeans evolved anchors

        Usage:
            from utils.autoanchor import *; _ = kmean_anchors()
    """
    thr = 1. / thr
    prefix = colorstr('autoanchor: ')

    def metric(k, wh):  # compute metrics
        r = wh[:, None] / k[None]
        x = torch.min(r, 1. / r).min(2)[0]  # ratio metric
        # x = wh_iou(wh, torch.tensor(k))  # iou metric
        return x, x.max(1)[0]  # x, best_x

    def anchor_fitness(k):  # mutation fitness
        _, best = metric(torch.tensor(k, dtype=torch.float32), wh)
        return (best * (best > thr).float()).mean()  # fitness

    def print_results(k):
        k = k[np.argsort(k.prod(1))]  # sort small to large
        x, best = metric(k, wh0)
        bpr, aat = (best > thr).float().mean(), (x > thr).float().mean() * n  # best possible recall, anch > thr
        print(f'{prefix}thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr')
        print(f'{prefix}n={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, '
              f'past_thr={x[x > thr].mean():.3f}-mean: ', end='')
        for i, x in enumerate(k):
            print('%i,%i' % (round(x[0]), round(x[1])), end=',  ' if i < len(k) - 1 else '\n')  # use in *.cfg
        return k

    if isinstance(path, str):  # *.yaml file
        with open(path) as f:
            data_dict = yaml.load(f, Loader=yaml.SafeLoader)  # model dict
        from utils.datasets import LoadImagesAndLabels
        dataset = LoadImagesAndLabels(data_dict['train'], augment=True, rect=True)
    else:
        dataset = path  # dataset

    # Get label wh
    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)
    wh0 = np.concatenate([l[:, 3:5] * s for s, l in zip(shapes, dataset.labels)])  # wh

    # Filter
    i = (wh0 < 3.0).any(1).sum()
    if i:
        print(f'{prefix}WARNING: Extremely small objects found. {i} of {len(wh0)} labels are < 3 pixels in size.')
    wh = wh0[(wh0 >= 2.0).any(1)]  # filter > 2 pixels
    # wh = wh * (np.random.rand(wh.shape[0], 1) * 0.9 + 0.1)  # multiply by random scale 0-1

    # Kmeans calculation
    print(f'{prefix}Running kmeans for {n} anchors on {len(wh)} points...')
    s = wh.std(0)  # sigmas for whitening
    k, dist = kmeans(wh / s, n, iter=30)  # points, mean distance
    assert len(k) == n, print(f'{prefix}ERROR: scipy.cluster.vq.kmeans requested {n} points but returned only {len(k)}')
    k *= s
    wh = torch.tensor(wh, dtype=torch.float32)  # filtered
    wh0 = torch.tensor(wh0, dtype=torch.float32)  # unfiltered
    k = print_results(k)

    # Plot
    # k, d = [None] * 20, [None] * 20
    # for i in tqdm(range(1, 21)):
    #     k[i-1], d[i-1] = kmeans(wh / s, i)  # points, mean distance
    # fig, ax = plt.subplots(1, 2, figsize=(14, 7), tight_layout=True)
    # ax = ax.ravel()
    # ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.')
    # fig, ax = plt.subplots(1, 2, figsize=(14, 7))  # plot wh
    # ax[0].hist(wh[wh[:, 0]<100, 0],400)
    # ax[1].hist(wh[wh[:, 1]<100, 1],400)
    # fig.savefig('wh.png', dpi=200)

    # Evolve
    npr = np.random
    f, sh, mp, s = anchor_fitness(k), k.shape, 0.9, 0.1  # fitness, generations, mutation prob, sigma
    pbar = tqdm(range(gen), desc=f'{prefix}Evolving anchors with Genetic Algorithm:')  # progress bar
    for _ in pbar:
        v = np.ones(sh)
        while (v == 1).all():  # mutate until a change occurs (prevent duplicates)
            v = ((npr.random(sh) < mp) * npr.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)
        kg = (k.copy() * v).clip(min=2.0)
        fg = anchor_fitness(kg)
        if fg > f:
            f, k = fg, kg.copy()
            pbar.desc = f'{prefix}Evolving anchors with Genetic Algorithm: fitness = {f:.4f}'
            if verbose:
                print_results(k)

    return print_results(k)

===== .\utils\utils\aws\__init__.py =====
功能: 代码摘录

===== .\utils\utils\aws\resume.py =====
功能: 代码摘录
# Resume all interrupted trainings in yolov5/ dir including DDP trainings
# Usage: $ python utils/aws/resume.py

import os
import sys
from pathlib import Path

import torch
import yaml

sys.path.append('./')  # to run '$ python *.py' files in subdirectories

port = 0  # --master_port
path = Path('').resolve()
for last in path.rglob('*/**/last.pt'):
    ckpt = torch.load(last)
    if ckpt['optimizer'] is None:
        continue

    # Load opt.yaml
    with open(last.parent.parent / 'opt.yaml') as f:
        opt = yaml.load(f, Loader=yaml.SafeLoader)

    # Get device count
    d = opt['device'].split(',')  # devices
    nd = len(d)  # number of devices
    ddp = nd > 1 or (nd == 0 and torch.cuda.device_count() > 1)  # distributed data parallel

    if ddp:  # multi-GPU
        port += 1
        cmd = f'python -m torch.distributed.launch --nproc_per_node {nd} --master_port {port} train.py --resume {last}'
    else:  # single-GPU
        cmd = f'python train.py --resume {last}'

    cmd += ' > /dev/null 2>&1 &'  # redirect output to dev/null and run in daemon thread
    print(cmd)
    os.system(cmd)

===== .\utils\utils\datasets.py =====
功能: 代码摘录
# Dataset utils and dataloaders

import glob
import logging
import math
import os
import random
import shutil
import time
from itertools import repeat
from multiprocessing.pool import ThreadPool
from pathlib import Path
from threading import Thread

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image, ExifTags
from torch.utils.data import Dataset
from tqdm import tqdm

from utils.general import check_requirements, xyxy2xywh, xywh2xyxy, xywhn2xyxy, xyn2xy, segment2box, segments2boxes, \
    resample_segments, clean_str
from utils.torch_utils import torch_distributed_zero_first

# Parameters
help_url = 'https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data'
img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng', 'webp', 'mpo']  # acceptable image suffixes
vid_formats = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes
logger = logging.getLogger(__name__)

# Get orientation exif tag
for orientation in ExifTags.TAGS.keys():
    if ExifTags.TAGS[orientation] == 'Orientation':
        break


def get_hash(files):
    # Returns a single hash value of a list of files
    return sum(os.path.getsize(f) for f in files if os.path.isfile(f))


def exif_size(img):
    # Returns exif-corrected PIL size
    s = img.size  # (width, height)
    try:
        rotation = dict(img._getexif().items())[orientation]
        if rotation == 6:  # rotation 270
            s = (s[1], s[0])
        elif rotation == 8:  # rotation 90
            s = (s[1], s[0])
    except:
        pass

    return s


def create_dataloader(path, imgsz, batch_size, stride, opt, hyp=None, augment=False, cache=False, pad=0.0, rect=False,
                      rank=-1, world_size=1, workers=8, image_weights=False, quad=False, prefix=''):
    # Make sure only the first process in DDP process the dataset first, and the following others can use the cache
    with torch_distributed_zero_first(rank):
        dataset = LoadImagesAndLabels(path, imgsz, batch_size,
                                      augment=augment,  # augment images
                                      hyp=hyp,  # augmentation hyperparameters
                                      rect=rect,  # rectangular training
                                      cache_images=cache,
                                      single_cls=opt.single_cls,
                                      stride=int(stride),
                                      pad=pad,
                                      image_weights=image_weights,
                                      prefix=prefix)

    batch_size = min(batch_size, len(dataset))
    nw = min([os.cpu_count() // world_size, batch_size if batch_size > 1 else 0, workers])  # number of workers
    sampler = torch.utils.data.distributed.DistributedSampler(dataset) if rank != -1 else None
    loader = torch.utils.data.DataLoader if image_weights else InfiniteDataLoader
    # Use torch.utils.data.DataLoader() if dataset.properties will update during training else InfiniteDataLoader()
    dataloader = loader(dataset,
                        batch_size=batch_size,
                        num_workers=nw,
                        sampler=sampler,
                        pin_memory=True,
                        collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn)
    return dataloader, dataset


class InfiniteDataLoader(torch.utils.data.dataloader.DataLoader):
    """ Dataloader that reuses workers

    Uses same syntax as vanilla DataLoader
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        object.__setattr__(self, 'batch_sampler', _RepeatSampler(self.batch_sampler))
        self.iterator = super().__iter__()

    def __len__(self):
        return len(self.batch_sampler.sampler)

    def __iter__(self):
        for i in range(len(self)):
            yield next(self.iterator)


class _RepeatSampler(object):
    """ Sampler that repeats forever

    Args:
        sampler (Sampler)
    """

    def __init__(self, sampler):
        self.sampler = sampler

    def __iter__(self):
        while True:
            yield from iter(self.sampler)


class LoadImages:  # for inference
    def __init__(self, path, img_size=640, stride=32):
        p = str(Path(path).absolute())  # os-agnostic absolute path
        if '*' in p:
            files = sorted(glob.glob(p, recursive=True))  # glob
        elif os.path.isdir(p):
            files = sorted(glob.glob(os.path.join(p, '*.*')))  # dir
        elif os.path.isfile(p):
            files = [p]  # files
        else:
            raise Exception(f'ERROR: {p} does not exist')

        images = [x for x in files if x.split('.')[-1].lower() in img_formats]
        videos = [x for x in files if x.split('.')[-1].lower() in vid_formats]
        ni, nv = len(images), len(videos)

        self.img_size = img_size
        self.stride = stride
        self.files = images + videos
        self.nf = ni + nv  # number of files
        self.video_flag = [False] * ni + [True] * nv
        self.mode = 'image'
        if any(videos):
            self.new_video(videos[0])  # new video
        else:
            self.cap = None
        assert self.nf > 0, f'No images or videos found in {p}. ' \
                            f'Supported formats are:\nimages: {img_formats}\nvideos: {vid_formats}'

    def __iter__(self):
        self.count = 0
        return self

    def __next__(self):
        if self.count == self.nf:
            raise StopIteration
        path = self.files[self.count]

        if self.video_flag[self.count]:
            # Read video
            self.mode = 'video'
            ret_val, img0 = self.cap.read()
            if not ret_val:
                self.count += 1
                self.cap.release()
                if self.count == self.nf:  # last video
                    raise StopIteration
                else:
                    path = self.files[self.count]
                    self.new_video(path)
                    ret_val, img0 = self.cap.read()

            self.frame += 1
            print(f'video {self.count + 1}/{self.nf} ({self.frame}/{self.nframes}) {path}: ', end='')

        else:
            # Read image
            self.count += 1
            img0 = cv2.imread(path)  # BGR
            assert img0 is not None, 'Image Not Found ' + path
            print(f'image {self.count}/{self.nf} {path}: ', end='')

        # Padded resize
        img = letterbox(img0, self.img_size, stride=self.stride)[0]

        # Convert
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
        img = np.ascontiguousarray(img)

        return path, img, img0, self.cap

    def new_video(self, path):
        self.frame = 0
        self.cap = cv2.VideoCapture(path)
        self.nframes = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

    def __len__(self):
        return self.nf  # number of files


class LoadWebcam:  # for inference
    def __init__(self, pipe='0', img_size=640, stride=32):
        self.img_size = img_size
        self.stride = stride

        if pipe.isnumeric():
            pipe = eval(pipe)  # local camera
        # pipe = 'rtsp://192.168.1.64/1'  # IP camera
        # pipe = 'rtsp://username:password@192.168.1.64/1'  # IP camera with login
        # pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg'  # IP golf camera

        self.pipe = pipe
        self.cap = cv2.VideoCapture(pipe)  # video capture object
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 3)  # set buffer size

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        if cv2.waitKey(1) == ord('q'):  # q to quit
            self.cap.release()
            cv2.destroyAllWindows()
            raise StopIteration

        # Read frame
        if self.pipe == 0:  # local camera
            ret_val, img0 = self.cap.read()
            img0 = cv2.flip(img0, 1)  # flip left-right
        else:  # IP camera
            n = 0
            while True:
                n += 1
                self.cap.grab()
                if n % 30 == 0:  # skip frames
                    ret_val, img0 = self.cap.retrieve()
                    if ret_val:
                        break

        # Print
        assert ret_val, f'Camera Error {self.pipe}'
        img_path = 'webcam.jpg'
        print(f'webcam {self.count}: ', end='')

        # Padded resize
        img = letterbox(img0, self.img_size, stride=self.stride)[0]

        # Convert
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
        img = np.ascontiguousarray(img)

        return img_path, img, img0, None

    def __len__(self):
        return 0


class LoadStreams:  # multiple IP or RTSP cameras
    def __init__(self, sources='streams.txt', img_size=640, stride=32):
        self.mode = 'stream'
        self.img_size = img_size
        self.stride = stride

        if os.path.isfile(sources):
            with open(sources, 'r') as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip())]
        else:
            sources = [sources]

        n = len(sources)
        self.imgs = [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        for i, s in enumerate(sources):
            # Start the thread to read frames from the video stream
            print(f'{i + 1}/{n}: {s}... ', end='')
            url = eval(s) if s.isnumeric() else s
            if 'youtube.com/' in url or 'youtu.be/' in url:  # if source is YouTube video
                check_requirements(('pafy', 'youtube_dl'))
                import pafy
                url = pafy.new(url).getbest(preftype="mp4").url
            cap = cv2.VideoCapture(url)
            assert cap.isOpened(), f'Failed to open {s}'
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            self.fps = cap.get(cv2.CAP_PROP_FPS) % 100

            _, self.imgs[i] = cap.read()  # guarantee first frame
            thread = Thread(target=self.update, args=([i, cap]), daemon=True)
            print(f' success ({w}x{h} at {self.fps:.2f} FPS).')
            thread.start()
        print('')  # newline

        # check for common shapes
        s = np.stack([letterbox(x, self.img_size, stride=self.stride)[0].shape for x in self.imgs], 0)  # shapes
        self.rect = np.unique(s, axis=0).shape[0] == 1  # rect inference if all shapes equal
        if not self.rect:
            print('WARNING: Different stream shapes detected. For optimal performance supply similarly-shaped streams.')

    def update(self, index, cap):
        # Read next stream frame in a daemon thread
        n = 0
        while cap.isOpened():
            n += 1
            # _, self.imgs[index] = cap.read()
            cap.grab()
            if n == 4:  # read every 4th frame
                success, im = cap.retrieve()
                self.imgs[index] = im if success else self.imgs[index] * 0
                n = 0
            time.sleep(1 / self.fps)  # wait time

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        img0 = self.imgs.copy()
        if cv2.waitKey(1) == ord('q'):  # q to quit
            cv2.destroyAllWindows()
            raise StopIteration

        # Letterbox
        img = [letterbox(x, self.img_size, auto=self.rect, stride=self.stride)[0] for x in img0]

        # Stack
        img = np.stack(img, 0)

        # Convert
        img = img[:, :, :, ::-1].transpose(0, 3, 1, 2)  # BGR to RGB, to bsx3x416x416
        img = np.ascontiguousarray(img)

        return self.sources, img, img0, None

    def __len__(self):
        return 0  # 1E12 frames = 32 streams at 30 FPS for 30 years


def img2label_paths(img_paths):
    # Define label paths as a function of image paths
    sa, sb = os.sep + 'images' + os.sep, os.sep + 'labels' + os.sep  # /images/, /labels/ substrings
    return ['txt'.join(x.replace(sa, sb, 1).rsplit(x.split('.')[-1], 1)) for x in img_paths]


class LoadImagesAndLabels(Dataset):  # for training/testing
    def __init__(self, path, img_size=640, batch_size=16, augment=False, hyp=None, rect=False, image_weights=False,
                 cache_images=False, single_cls=False, stride=32, pad=0.0, prefix=''):
        self.img_size = img_size
        self.augment = augment
        self.hyp = hyp
        self.image_weights = image_weights
        self.rect = False if image_weights else rect
        self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)
        self.mosaic_border = [-img_size // 2, -img_size // 2]
        self.stride = stride
        self.path = path

        try:
            f = []  # image files
            for p in path if isinstance(path, list) else [path]:
                p = Path(p)  # os-agnostic
                if p.is_dir():  # dir
                    f += glob.glob(str(p / '**' / '*.*'), recursive=True)
                    # f = list(p.rglob('**/*.*'))  # pathlib
                elif p.is_file():  # file
                    with open(p, 'r') as t:
                        t = t.read().strip().splitlines()
                        parent = str(p.parent) + os.sep
                        f += [x.replace('./', parent) if x.startswith('./') else x for x in t]  # local to global path
                        # f += [p.parent / x.lstrip(os.sep) for x in t]  # local to global path (pathlib)
                else:
                    raise Exception(f'{prefix}{p} does not exist')
            self.img_files = sorted([x.replace('/', os.sep) for x in f if x.split('.')[-1].lower() in img_formats])
            # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in img_formats])  # pathlib
            assert self.img_files, f'{prefix}No images found'
        except Exception as e:
            raise Exception(f'{prefix}Error loading data from {path}: {e}\nSee {help_url}')

        # Check cache
        self.label_files = img2label_paths(self.img_files)  # labels
        cache_path = (p if p.is_file() else Path(self.label_files[0]).parent).with_suffix('.cache')  # cached labels
        if cache_path.is_file():
            cache, exists = torch.load(cache_path), True  # load
            if cache['hash'] != get_hash(self.label_files + self.img_files) or 'version' not in cache:  # changed
                cache, exists = self.cache_labels(cache_path, prefix), False  # re-cache
        else:
            cache, exists = self.cache_labels(cache_path, prefix), False  # cache

        # Display cache
        nf, nm, ne, nc, n = cache.pop('results')  # found, missing, empty, corrupted, total
        if exists:
            d = f"Scanning '{cache_path}' images and labels... {nf} found, {nm} missing, {ne} empty, {nc} corrupted"
            tqdm(None, desc=prefix + d, total=n, initial=n)  # display cache results
        assert nf > 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {help_url}'

        # Read cache
        cache.pop('hash')  # remove hash
        cache.pop('version')  # remove version
        labels, shapes, self.segments = zip(*cache.values())
        self.labels = list(labels)
        self.shapes = np.array(shapes, dtype=np.float64)
        self.img_files = list(cache.keys())  # update
        self.label_files = img2label_paths(cache.keys())  # update
        if single_cls:
            for x in self.labels:
                x[:, 0] = 0

        n = len(shapes)  # number of images
        bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index
        nb = bi[-1] + 1  # number of batches
        self.batch = bi  # batch index of image
        self.n = n
        self.indices = range(n)

        # Rectangular Training
        if self.rect:
            # Sort by aspect ratio
            s = self.shapes  # wh
            ar = s[:, 1] / s[:, 0]  # aspect ratio
            irect = ar.argsort()
            self.img_files = [self.img_files[i] for i in irect]
            self.label_files = [self.label_files[i] for i in irect]
            self.labels = [self.labels[i] for i in irect]
            self.shapes = s[irect]  # wh
            ar = ar[irect]

            # Set training image shapes
            shapes = [[1, 1]] * nb
            for i in range(nb):
                ari = ar[bi == i]
                mini, maxi = ari.min(), ari.max()
                if maxi < 1:
                    shapes[i] = [maxi, 1]
                elif mini > 1:
                    shapes[i] = [1, 1 / mini]

            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(np.int) * stride

        # Cache images into memory for faster training (WARNING: large datasets may exceed system RAM)
        self.imgs = [None] * n
        if cache_images:
            gb = 0  # Gigabytes of cached images
            self.img_hw0, self.img_hw = [None] * n, [None] * n
            results = ThreadPool(8).imap(lambda x: load_image(*x), zip(repeat(self), range(n)))  # 8 threads
            pbar = tqdm(enumerate(results), total=n)
            for i, x in pbar:
                self.imgs[i], self.img_hw0[i], self.img_hw[i] = x  # img, hw_original, hw_resized = load_image(self, i)
                gb += self.imgs[i].nbytes
                pbar.desc = f'{prefix}Caching images ({gb / 1E9:.1f}GB)'
            pbar.close()

    def cache_labels(self, path=Path('./labels.cache'), prefix=''):
        # Cache dataset labels, check images and read shapes
        x = {}  # dict
        nm, nf, ne, nc = 0, 0, 0, 0  # number missing, found, empty, duplicate
        pbar = tqdm(zip(self.img_files, self.label_files), desc='Scanning images', total=len(self.img_files))
        for i, (im_file, lb_file) in enumerate(pbar):
            try:
                # verify images
                im = Image.open(im_file)
                im.verify()  # PIL verify
                shape = exif_size(im)  # image size
                segments = []  # instance segments
                assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'
                assert im.format.lower() in img_formats, f'invalid image format {im.format}'

                # verify labels
                if os.path.isfile(lb_file):
                    nf += 1  # label found
                    with open(lb_file, 'r') as f:
                        l = [x.split() for x in f.read().strip().splitlines()]
                        if any([len(x) > 8 for x in l]):  # is segment
                            classes = np.array([x[0] for x in l], dtype=np.float32)
                            segments = [np.array(x[1:], dtype=np.float32).reshape(-1, 2) for x in l]  # (cls, xy1...)
                            l = np.concatenate((classes.reshape(-1, 1), segments2boxes(segments)), 1)  # (cls, xywh)
                        l = np.array(l, dtype=np.float32)
                    if len(l):
                        assert l.shape[1] == 5, 'labels require 5 columns each'
                        assert (l >= 0).all(), 'negative labels'
                        assert (l[:, 1:] <= 1).all(), 'non-normalized or out of bounds coordinate labels'
                        assert np.unique(l, axis=0).shape[0] == l.shape[0], 'duplicate labels'
                    else:
                        ne += 1  # label empty
                        l = np.zeros((0, 5), dtype=np.float32)
                else:
                    nm += 1  # label missing
                    l = np.zeros((0, 5), dtype=np.float32)
                x[im_file] = [l, shape, segments]
            except Exception as e:
                nc += 1
                print(f'{prefix}WARNING: Ignoring corrupted image and/or label {im_file}: {e}')

            pbar.desc = f"{prefix}Scanning '{path.parent / path.stem}' images and labels... " \
                        f"{nf} found, {nm} missing, {ne} empty, {nc} corrupted"
        pbar.close()

        if nf == 0:
            print(f'{prefix}WARNING: No labels found in {path}. See {help_url}')

        x['hash'] = get_hash(self.label_files + self.img_files)
        x['results'] = nf, nm, ne, nc, i + 1
        x['version'] = 0.1  # cache version
        torch.save(x, path)  # save for next time
        logging.info(f'{prefix}New cache created: {path}')
        return x

    def __len__(self):
        return len(self.img_files)

    # def __iter__(self):
    #     self.count = -1
    #     print('ran dataset iter')
    #     #self.shuffled_vector = np.random.permutation(self.nF) if self.augment else np.arange(self.nF)
    #     return self

    def __getitem__(self, index):
        index = self.indices[index]  # linear, shuffled, or image_weights

        hyp = self.hyp
        mosaic = self.mosaic and random.random() < hyp['mosaic']
        if mosaic:
            # Load mosaic
            img, labels = load_mosaic(self, index)
            shapes = None

            # MixUp https://arxiv.org/pdf/1710.09412.pdf
            if random.random() < hyp['mixup']:
                img2, labels2 = load_mosaic(self, random.randint(0, self.n - 1))
                r = np.random.beta(8.0, 8.0)  # mixup ratio, alpha=beta=8.0
                img = (img * r + img2 * (1 - r)).astype(np.uint8)
                labels = np.concatenate((labels, labels2), 0)

        else:
            # Load image
            img, (h0, w0), (h, w) = load_image(self, index)

            # Letterbox
            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape
            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)
            shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling

            labels = self.labels[index].copy()
            if labels.size:  # normalized xywh to pixel xyxy format
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1])

        if self.augment:
            # Augment imagespace
            if not mosaic:
                img, labels = random_perspective(img, labels,
                                                 degrees=hyp['degrees'],
                                                 translate=hyp['translate'],
                                                 scale=hyp['scale'],
                                                 shear=hyp['shear'],
                                                 perspective=hyp['perspective'])

            # Augment colorspace
            augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])

            # Apply cutouts
            # if random.random() < 0.9:
            #     labels = cutout(img, labels)

        nL = len(labels)  # number of labels
        if nL:
            labels[:, 1:5] = xyxy2xywh(labels[:, 1:5])  # convert xyxy to xywh
            labels[:, [2, 4]] /= img.shape[0]  # normalized height 0-1
            labels[:, [1, 3]] /= img.shape[1]  # normalized width 0-1

        if self.augment:
            # flip up-down
            if random.random() < hyp['flipud']:
                img = np.flipud(img)
                if nL:
                    labels[:, 2] = 1 - labels[:, 2]

            # flip left-right
            if random.random() < hyp['fliplr']:
                img = np.fliplr(img)
                if nL:
                    labels[:, 1] = 1 - labels[:, 1]

        labels_out = torch.zeros((nL, 6))
        if nL:
            labels_out[:, 1:] = torch.from_numpy(labels)

        # Convert
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
        img = np.ascontiguousarray(img)

        return torch.from_numpy(img), labels_out, self.img_files[index], shapes

    @staticmethod
    def collate_fn(batch):
        img, label, path, shapes = zip(*batch)  # transposed
        for i, l in enumerate(label):
            l[:, 0] = i  # add target image index for build_targets()
        return torch.stack(img, 0), torch.cat(label, 0), path, shapes

    @staticmethod
    def collate_fn4(batch):
        img, label, path, shapes = zip(*batch)  # transposed
        n = len(shapes) // 4
        img4, label4, path4, shapes4 = [], [], path[:n], shapes[:n]

        ho = torch.tensor([[0., 0, 0, 1, 0, 0]])
        wo = torch.tensor([[0., 0, 1, 0, 0, 0]])
        s = torch.tensor([[1, 1, .5, .5, .5, .5]])  # scale
        for i in range(n):  # zidane torch.zeros(16,3,720,1280)  # BCHW
            i *= 4
            if random.random() < 0.5:
                im = F.interpolate(img[i].unsqueeze(0).float(), scale_factor=2., mode='bilinear', align_corners=False)[
                    0].type(img[i].type())
                l = label[i]
            else:
                im = torch.cat((torch.cat((img[i], img[i + 1]), 1), torch.cat((img[i + 2], img[i + 3]), 1)), 2)
                l = torch.cat((label[i], label[i + 1] + ho, label[i + 2] + wo, label[i + 3] + ho + wo), 0) * s
            img4.append(im)
            label4.append(l)

        for i, l in enumerate(label4):
            l[:, 0] = i  # add target image index for build_targets()

        return torch.stack(img4, 0), torch.cat(label4, 0), path4, shapes4


# Ancillary functions --------------------------------------------------------------------------------------------------
def load_image(self, index):
    # loads 1 image from dataset, returns img, original hw, resized hw
    img = self.imgs[index]
    if img is None:  # not cached
        path = self.img_files[index]
        img = cv2.imread(path)  # BGR
        assert img is not None, 'Image Not Found ' + path
        h0, w0 = img.shape[:2]  # orig hw
        r = self.img_size / max(h0, w0)  # resize image to img_size
        if r != 1:  # always resize down, only resize up if training with augmentation
            interp = cv2.INTER_AREA if r < 1 and not self.augment else cv2.INTER_LINEAR
            img = cv2.resize(img, (int(w0 * r), int(h0 * r)), interpolation=interp)
        return img, (h0, w0), img.shape[:2]  # img, hw_original, hw_resized
    else:
        return self.imgs[index], self.img_hw0[index], self.img_hw[index]  # img, hw_original, hw_resized


def augment_hsv(img, hgain=0.5, sgain=0.5, vgain=0.5):
    r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains
    hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))
    dtype = img.dtype  # uint8

    x = np.arange(0, 256, dtype=np.int16)
    lut_hue = ((x * r[0]) % 180).astype(dtype)
    lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)
    lut_val = np.clip(x * r[2], 0, 255).astype(dtype)

    img_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val))).astype(dtype)
    cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR, dst=img)  # no return needed


def hist_equalize(img, clahe=True, bgr=False):
    # Equalize histogram on BGR image 'img' with img.shape(n,m,3) and range 0-255
    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV if bgr else cv2.COLOR_RGB2YUV)
    if clahe:
        c = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        yuv[:, :, 0] = c.apply(yuv[:, :, 0])
    else:
        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])  # equalize Y channel histogram
    return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR if bgr else cv2.COLOR_YUV2RGB)  # convert YUV image to RGB


def load_mosaic(self, index):
    # loads images in a 4-mosaic

    labels4, segments4 = [], []
    s = self.img_size
    yc, xc = [int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border]  # mosaic center x, y
    indices = [index] + random.choices(self.indices, k=3)  # 3 additional image indices
    for i, index in enumerate(indices):
        # Load image
        img, _, (h, w) = load_image(self, index)

        # place img in img4
        if i == 0:  # top left
            img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
            x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)
            x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)
        elif i == 1:  # top right
            x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc
            x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h
        elif i == 2:  # bottom left
            x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)
            x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)
        elif i == 3:  # bottom right
            x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)
            x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)

        img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
        padw = x1a - x1b
        padh = y1a - y1b

        # Labels
        labels, segments = self.labels[index].copy(), self.segments[index].copy()
        if labels.size:
            labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padw, padh)  # normalized xywh to pixel xyxy format
            segments = [xyn2xy(x, w, h, padw, padh) for x in segments]
        labels4.append(labels)
        segments4.extend(segments)

    # Concat/clip labels
    labels4 = np.concatenate(labels4, 0)
    for x in (labels4[:, 1:], *segments4):
        np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
    # img4, labels4 = replicate(img4, labels4)  # replicate

    # Augment
    img4, labels4 = random_perspective(img4, labels4, segments4,
                                       degrees=self.hyp['degrees'],
                                       translate=self.hyp['translate'],
                                       scale=self.hyp['scale'],
                                       shear=self.hyp['shear'],
                                       perspective=self.hyp['perspective'],
                                       border=self.mosaic_border)  # border to remove

    return img4, labels4


def load_mosaic9(self, index):
    # loads images in a 9-mosaic

    labels9, segments9 = [], []
    s = self.img_size
    indices = [index] + random.choices(self.indices, k=8)  # 8 additional image indices
    for i, index in enumerate(indices):
        # Load image
        img, _, (h, w) = load_image(self, index)

        # place img in img9
        if i == 0:  # center
            img9 = np.full((s * 3, s * 3, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
            h0, w0 = h, w
            c = s, s, s + w, s + h  # xmin, ymin, xmax, ymax (base) coordinates
        elif i == 1:  # top
            c = s, s - h, s + w, s
        elif i == 2:  # top right
            c = s + wp, s - h, s + wp + w, s
        elif i == 3:  # right
            c = s + w0, s, s + w0 + w, s + h
        elif i == 4:  # bottom right
            c = s + w0, s + hp, s + w0 + w, s + hp + h
        elif i == 5:  # bottom
            c = s + w0 - w, s + h0, s + w0, s + h0 + h
        elif i == 6:  # bottom left
            c = s + w0 - wp - w, s + h0, s + w0 - wp, s + h0 + h
        elif i == 7:  # left
            c = s - w, s + h0 - h, s, s + h0
        elif i == 8:  # top left
            c = s - w, s + h0 - hp - h, s, s + h0 - hp

        padx, pady = c[:2]
        x1, y1, x2, y2 = [max(x, 0) for x in c]  # allocate coords

        # Labels
        labels, segments = self.labels[index].copy(), self.segments[index].copy()
        if labels.size:
            labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padx, pady)  # normalized xywh to pixel xyxy format
            segments = [xyn2xy(x, w, h, padx, pady) for x in segments]
        labels9.append(labels)
        segments9.extend(segments)

        # Image
        img9[y1:y2, x1:x2] = img[y1 - pady:, x1 - padx:]  # img9[ymin:ymax, xmin:xmax]
        hp, wp = h, w  # height, width previous

    # Offset
    yc, xc = [int(random.uniform(0, s)) for _ in self.mosaic_border]  # mosaic center x, y
    img9 = img9[yc:yc + 2 * s, xc:xc + 2 * s]

    # Concat/clip labels
    labels9 = np.concatenate(labels9, 0)
    labels9[:, [1, 3]] -= xc
    labels9[:, [2, 4]] -= yc
    c = np.array([xc, yc])  # centers
    segments9 = [x - c for x in segments9]

    for x in (labels9[:, 1:], *segments9):
        np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
    # img9, labels9 = replicate(img9, labels9)  # replicate

    # Augment
    img9, labels9 = random_perspective(img9, labels9, segments9,
                                       degrees=self.hyp['degrees'],
                                       translate=self.hyp['translate'],
                                       scale=self.hyp['scale'],
                                       shear=self.hyp['shear'],
                                       perspective=self.hyp['perspective'],
                                       border=self.mosaic_border)  # border to remove

    return img9, labels9


def replicate(img, labels):
    # Replicate labels
    h, w = img.shape[:2]
    boxes = labels[:, 1:].astype(int)
    x1, y1, x2, y2 = boxes.T
    s = ((x2 - x1) + (y2 - y1)) / 2  # side length (pixels)
    for i in s.argsort()[:round(s.size * 0.5)]:  # smallest indices
        x1b, y1b, x2b, y2b = boxes[i]
        bh, bw = y2b - y1b, x2b - x1b
        yc, xc = int(random.uniform(0, h - bh)), int(random.uniform(0, w - bw))  # offset x, y
        x1a, y1a, x2a, y2a = [xc, yc, xc + bw, yc + bh]
        img[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
        labels = np.append(labels, [[labels[i, 0], x1a, y1a, x2a, y2a]], axis=0)

    return img, labels


def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):
    # Resize and pad image while meeting stride-multiple constraints
    shape = img.shape[:2]  # current shape [height, width]
    if isinstance(new_shape, int):
        new_shape = (new_shape, new_shape)

    # Scale ratio (new / old)
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    if not scaleup:  # only scale down, do not scale up (for better test mAP)
        r = min(r, 1.0)

    # Compute padding
    ratio = r, r  # width, height ratios
    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding
    if auto:  # minimum rectangle
        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding
    elif scaleFill:  # stretch
        dw, dh = 0.0, 0.0
        new_unpad = (new_shape[1], new_shape[0])
        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios

    dw /= 2  # divide padding into 2 sides
    dh /= 2

    if shape[::-1] != new_unpad:  # resize
        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border
    return img, ratio, (dw, dh)


def random_perspective(img, targets=(), segments=(), degrees=10, translate=.1, scale=.1, shear=10, perspective=0.0,
                       border=(0, 0)):
    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))
    # targets = [cls, xyxy]

    height = img.shape[0] + border[0] * 2  # shape(h,w,c)
    width = img.shape[1] + border[1] * 2

    # Center
    C = np.eye(3)
    C[0, 2] = -img.shape[1] / 2  # x translation (pixels)
    C[1, 2] = -img.shape[0] / 2  # y translation (pixels)

    # Perspective
    P = np.eye(3)
    P[2, 0] = random.uniform(-perspective, perspective)  # x perspective (about y)
    P[2, 1] = random.uniform(-perspective, perspective)  # y perspective (about x)

    # Rotation and Scale
    R = np.eye(3)
    a = random.uniform(-degrees, degrees)
    # a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations
    s = random.uniform(1 - scale, 1 + scale)
    # s = 2 ** random.uniform(-scale, scale)
    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)

    # Shear
    S = np.eye(3)
    S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)
    S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)

    # Translation
    T = np.eye(3)
    T[0, 2] = random.uniform(0.5 - translate, 0.5 + translate) * width  # x translation (pixels)
    T[1, 2] = random.uniform(0.5 - translate, 0.5 + translate) * height  # y translation (pixels)

    # Combined rotation matrix
    M = T @ S @ R @ P @ C  # order of operations (right to left) is IMPORTANT
    if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any():  # image changed
        if perspective:
            img = cv2.warpPerspective(img, M, dsize=(width, height), borderValue=(114, 114, 114))
        else:  # affine
            img = cv2.warpAffine(img, M[:2], dsize=(width, height), borderValue=(114, 114, 114))

    # Visualize
    # import matplotlib.pyplot as plt
    # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel()
    # ax[0].imshow(img[:, :, ::-1])  # base
    # ax[1].imshow(img2[:, :, ::-1])  # warped

    # Transform label coordinates
    n = len(targets)
    if n:
        use_segments = any(x.any() for x in segments)
        new = np.zeros((n, 4))
        if use_segments:  # warp segments
            segments = resample_segments(segments)  # upsample
            for i, segment in enumerate(segments):
                xy = np.ones((len(segment), 3))
                xy[:, :2] = segment
                xy = xy @ M.T  # transform
                xy = xy[:, :2] / xy[:, 2:3] if perspective else xy[:, :2]  # perspective rescale or affine

                # clip
                new[i] = segment2box(xy, width, height)

        else:  # warp boxes
            xy = np.ones((n * 4, 3))
            xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1
            xy = xy @ M.T  # transform
            xy = (xy[:, :2] / xy[:, 2:3] if perspective else xy[:, :2]).reshape(n, 8)  # perspective rescale or affine

            # create new boxes
            x = xy[:, [0, 2, 4, 6]]
            y = xy[:, [1, 3, 5, 7]]
            new = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T

            # clip
            new[:, [0, 2]] = new[:, [0, 2]].clip(0, width)
            new[:, [1, 3]] = new[:, [1, 3]].clip(0, height)

        # filter candidates
        i = box_candidates(box1=targets[:, 1:5].T * s, box2=new.T, area_thr=0.01 if use_segments else 0.10)
        targets = targets[i]
        targets[:, 1:5] = new[i]

    return img, targets


def box_candidates(box1, box2, wh_thr=2, ar_thr=20, area_thr=0.1, eps=1e-16):  # box1(4,n), box2(4,n)
    # Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio
    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]
    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]
    ar = np.maximum(w2 / (h2 + eps), h2 / (w2 + eps))  # aspect ratio
    return (w2 > wh_thr) & (h2 > wh_thr) & (w2 * h2 / (w1 * h1 + eps) > area_thr) & (ar < ar_thr)  # candidates


def cutout(image, labels):
    # Applies image cutout augmentation https://arxiv.org/abs/1708.04552
    h, w = image.shape[:2]

    def bbox_ioa(box1, box2):
        # Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2
        box2 = box2.transpose()

        # Get the coordinates of bounding boxes
        b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]
        b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]

        # Intersection area
        inter_area = (np.minimum(b1_x2, b2_x2) - np.maximum(b1_x1, b2_x1)).clip(0) * \
                     (np.minimum(b1_y2, b2_y2) - np.maximum(b1_y1, b2_y1)).clip(0)

        # box2 area
        box2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1) + 1e-16

        # Intersection over box2 area
        return inter_area / box2_area

    # create random masks
    scales = [0.5] * 1 + [0.25] * 2 + [0.125] * 4 + [0.0625] * 8 + [0.03125] * 16  # image size fraction
    for s in scales:
        mask_h = random.randint(1, int(h * s))
        mask_w = random.randint(1, int(w * s))

        # box
        xmin = max(0, random.randint(0, w) - mask_w // 2)
        ymin = max(0, random.randint(0, h) - mask_h // 2)
        xmax = min(w, xmin + mask_w)
        ymax = min(h, ymin + mask_h)

        # apply random color mask
        image[ymin:ymax, xmin:xmax] = [random.randint(64, 191) for _ in range(3)]

        # return unobscured labels
        if len(labels) and s > 0.03:
            box = np.array([xmin, ymin, xmax, ymax], dtype=np.float32)
            ioa = bbox_ioa(box, labels[:, 1:5])  # intersection over area
            labels = labels[ioa < 0.60]  # remove >60% obscured labels

    return labels


def create_folder(path='./new'):
    # Create folder
    if os.path.exists(path):
        shutil.rmtree(path)  # delete output folder
    os.makedirs(path)  # make new output folder


def flatten_recursive(path='../coco128'):
    # Flatten a recursive directory by bringing all files to top level
    new_path = Path(path + '_flat')
    create_folder(new_path)
    for file in tqdm(glob.glob(str(Path(path)) + '/**/*.*', recursive=True)):
        shutil.copyfile(file, new_path / Path(file).name)


def extract_boxes(path='../coco128/'):  # from utils.datasets import *; extract_boxes('../coco128')
    # Convert detection dataset into classification dataset, with one directory per class

    path = Path(path)  # images dir
    shutil.rmtree(path / 'classifier') if (path / 'classifier').is_dir() else None  # remove existing
    files = list(path.rglob('*.*'))
    n = len(files)  # number of files
    for im_file in tqdm(files, total=n):
        if im_file.suffix[1:] in img_formats:
            # image
            im = cv2.imread(str(im_file))[..., ::-1]  # BGR to RGB
            h, w = im.shape[:2]

            # labels
            lb_file = Path(img2label_paths([str(im_file)])[0])
            if Path(lb_file).exists():
                with open(lb_file, 'r') as f:
                    lb = np.array([x.split() for x in f.read().strip().splitlines()], dtype=np.float32)  # labels

                for j, x in enumerate(lb):
                    c = int(x[0])  # class
                    f = (path / 'classifier') / f'{c}' / f'{path.stem}_{im_file.stem}_{j}.jpg'  # new filename
                    if not f.parent.is_dir():
                        f.parent.mkdir(parents=True)

                    b = x[1:] * [w, h, w, h]  # box
                    # b[2:] = b[2:].max()  # rectangle to square
                    b[2:] = b[2:] * 1.2 + 3  # pad
                    b = xywh2xyxy(b.reshape(-1, 4)).ravel().astype(np.int)

                    b[[0, 2]] = np.clip(b[[0, 2]], 0, w)  # clip boxes outside of image
                    b[[1, 3]] = np.clip(b[[1, 3]], 0, h)
                    assert cv2.imwrite(str(f), im[b[1]:b[3], b[0]:b[2]]), f'box failure in {f}'


def autosplit(path='../coco128', weights=(0.9, 0.1, 0.0), annotated_only=False):
    """ Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files
    Usage: from utils.datasets import *; autosplit('../coco128')
    Arguments
        path:           Path to images directory
        weights:        Train, val, test weights (list)
        annotated_only: Only use images with an annotated txt file
    """
    path = Path(path)  # images dir
    files = sum([list(path.rglob(f"*.{img_ext}")) for img_ext in img_formats], [])  # image files only
    n = len(files)  # number of files
    indices = random.choices([0, 1, 2], weights=weights, k=n)  # assign each image to a split

    txt = ['autosplit_train.txt', 'autosplit_val.txt', 'autosplit_test.txt']  # 3 txt files
    [(path / x).unlink() for x in txt if (path / x).exists()]  # remove existing

    print(f'Autosplitting images from {path}' + ', using *.txt labeled images only' * annotated_only)
    for i, img in tqdm(zip(indices, files), total=n):
        if not annotated_only or Path(img2label_paths([str(img)])[0]).exists():  # check label
            with open(path / txt[i], 'a') as f:
                f.write(str(img) + '\n')  # add image to txt file

===== .\utils\utils\empty.py =====
功能: 代码摘录
def main(args=None):
    print()

===== .\utils\utils\general.py =====
功能: 代码摘录
# YOLOv5 general utils

import glob
import logging
import math
import os
import platform
import random
import re
import subprocess
import time
from pathlib import Path

import cv2
import numpy as np
import pandas as pd
import torch
import torchvision
import yaml

from utils.google_utils import gsutil_getsize
from utils.metrics import fitness
from utils.torch_utils import init_torch_seeds

# Settings
torch.set_printoptions(linewidth=320, precision=5, profile='long')
np.set_printoptions(linewidth=320, formatter={'float_kind': '{:11.5g}'.format})  # format short g, %precision=5
pd.options.display.max_columns = 10
cv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)
os.environ['NUMEXPR_MAX_THREADS'] = str(min(os.cpu_count(), 8))  # NumExpr max threads


def set_logging(rank=-1):
    logging.basicConfig(
        format="%(message)s",
        level=logging.INFO if rank in [-1, 0] else logging.WARN)


def init_seeds(seed=0):
    # Initialize random number generator (RNG) seeds
    random.seed(seed)
    np.random.seed(seed)
    init_torch_seeds(seed)


def get_latest_run(search_dir='.'):
    # Return path to most recent 'last.pt' in /runs (i.e. to --resume from)
    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)
    return max(last_list, key=os.path.getctime) if last_list else ''


def isdocker():
    # Is environment a Docker container
    return Path('/workspace').exists()  # or Path('/.dockerenv').exists()


def emojis(str=''):
    # Return platform-dependent emoji-safe version of string
    return str.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else str


def check_online():
    # Check internet connectivity
    import socket
    try:
        socket.create_connection(("1.1.1.1", 443), 5)  # check host accesability
        return True
    except OSError:
        return False


def check_git_status():
    # Recommend 'git pull' if code is out of date
    print(colorstr('github: '), end='')
    try:
        assert Path('.git').exists(), 'skipping check (not a git repository)'
        assert not isdocker(), 'skipping check (Docker image)'
        assert check_online(), 'skipping check (offline)'

        cmd = 'git fetch && git config --get remote.origin.url'
        url = subprocess.check_output(cmd, shell=True).decode().strip().rstrip('.git')  # github repo url
        branch = subprocess.check_output('git rev-parse --abbrev-ref HEAD', shell=True).decode().strip()  # checked out
        n = int(subprocess.check_output(f'git rev-list {branch}..origin/master --count', shell=True))  # commits behind
        if n > 0:
            s = f"⚠️ WARNING: code is out of date by {n} commit{'s' * (n > 1)}. " \
                f"Use 'git pull' to update or 'git clone {url}' to download latest."
        else:
            s = f'up to date with {url} ✅'
        print(emojis(s))  # emoji-safe
    except Exception as e:
        print(e)


def check_requirements(requirements='requirements.txt', exclude=()):
    # Check installed dependencies meet requirements (pass *.txt file or list of packages)
    import pkg_resources as pkg
    prefix = colorstr('red', 'bold', 'requirements:')
    if isinstance(requirements, (str, Path)):  # requirements.txt file
        file = Path(requirements)
        if not file.exists():
            print(f"{prefix} {file.resolve()} not found, check failed.")
            return
        requirements = [f'{x.name}{x.specifier}' for x in pkg.parse_requirements(file.open()) if x.name not in exclude]
    else:  # list or tuple of packages
        requirements = [x for x in requirements if x not in exclude]

    n = 0  # number of packages updates
    for r in requirements:
        try:
            pkg.require(r)
        except Exception as e:  # DistributionNotFound or VersionConflict if requirements not met
            n += 1
            print(f"{prefix} {e.req} not found and is required by YOLOv5, attempting auto-update...")
            print(subprocess.check_output(f"pip install '{e.req}'", shell=True).decode())

    if n:  # if packages updated
        source = file.resolve() if 'file' in locals() else requirements
        s = f"{prefix} {n} package{'s' * (n > 1)} updated per {source}\n" \
            f"{prefix} ⚠️ {colorstr('bold', 'Restart runtime or rerun command for updates to take effect')}\n"
        print(emojis(s))  # emoji-safe


def check_img_size(img_size, s=32):
    # Verify img_size is a multiple of stride s
    new_size = make_divisible(img_size, int(s))  # ceil gs-multiple
    if new_size != img_size:
        print('WARNING: --img-size %g must be multiple of max stride %g, updating to %g' % (img_size, s, new_size))
    return new_size


def check_imshow():
    # Check if environment supports image displays
    try:
        assert not isdocker(), 'cv2.imshow() is disabled in Docker environments'
        cv2.imshow('test', np.zeros((1, 1, 3)))
        cv2.waitKey(1)
        cv2.destroyAllWindows()
        cv2.waitKey(1)
        return True
    except Exception as e:
        print(f'WARNING: Environment does not support cv2.imshow() or PIL Image.show() image displays\n{e}')
        return False


def check_file(file):
    # Search for file if not found
    if os.path.isfile(file) or file == '':
        return file
    else:
        files = glob.glob('./**/' + file, recursive=True)  # find file
        assert len(files), 'File Not Found: %s' % file  # assert file was found
        assert len(files) == 1, "Multiple files match '%s', specify exact path: %s" % (file, files)  # assert unique
        return files[0]  # return file


def check_dataset(dict):
    # Download dataset if not found locally
    val, s = dict.get('val'), dict.get('download')
    if val and len(val):
        val = [Path(x).resolve() for x in (val if isinstance(val, list) else [val])]  # val path
        if not all(x.exists() for x in val):
            print('\nWARNING: Dataset not found, nonexistent paths: %s' % [str(x) for x in val if not x.exists()])
            if s and len(s):  # download script
                print('Downloading %s ...' % s)
                if s.startswith('http') and s.endswith('.zip'):  # URL
                    f = Path(s).name  # filename
                    torch.hub.download_url_to_file(s, f)
                    r = os.system('unzip -q %s -d ../ && rm %s' % (f, f))  # unzip
                else:  # bash script
                    r = os.system(s)
                print('Dataset autodownload %s\n' % ('success' if r == 0 else 'failure'))  # analyze return value
            else:
                raise Exception('Dataset not found.')


def make_divisible(x, divisor):
    # Returns x evenly divisible by divisor
    return math.ceil(x / divisor) * divisor


def clean_str(s):
    # Cleans a string by replacing special characters with underscore _
    return re.sub(pattern="[|@#!¡·$€%&()=?¿^*;:,¨´><+]", repl="_", string=s)


def one_cycle(y1=0.0, y2=1.0, steps=100):
    # lambda function for sinusoidal ramp from y1 to y2
    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1


def colorstr(*input):
    # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e.  colorstr('blue', 'hello world')
    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # color arguments, string
    colors = {'black': '\033[30m',  # basic colors
              'red': '\033[31m',
              'green': '\033[32m',
              'yellow': '\033[33m',
              'blue': '\033[34m',
              'magenta': '\033[35m',
              'cyan': '\033[36m',
              'white': '\033[37m',
              'bright_black': '\033[90m',  # bright colors
              'bright_red': '\033[91m',
              'bright_green': '\033[92m',
              'bright_yellow': '\033[93m',
              'bright_blue': '\033[94m',
              'bright_magenta': '\033[95m',
              'bright_cyan': '\033[96m',
              'bright_white': '\033[97m',
              'end': '\033[0m',  # misc
              'bold': '\033[1m',
              'underline': '\033[4m'}
    return ''.join(colors[x] for x in args) + f'{string}' + colors['end']


def labels_to_class_weights(labels, nc=80):
    # Get class weights (inverse frequency) from training labels
    if labels[0] is None:  # no labels loaded
        return torch.Tensor()

    labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) for COCO
    classes = labels[:, 0].astype(np.int)  # labels = [class xywh]
    weights = np.bincount(classes, minlength=nc)  # occurrences per class

    # Prepend gridpoint count (for uCE training)
    # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # gridpoints per image
    # weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # prepend gridpoints to start

    weights[weights == 0] = 1  # replace empty bins with 1
    weights = 1 / weights  # number of targets per class
    weights /= weights.sum()  # normalize
    return torch.from_numpy(weights)


def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):
    # Produces image weights based on class_weights and image contents
    class_counts = np.array([np.bincount(x[:, 0].astype(np.int), minlength=nc) for x in labels])
    image_weights = (class_weights.reshape(1, nc) * class_counts).sum(1)
    # index = random.choices(range(n), weights=image_weights, k=1)  # weight image sample
    return image_weights


def coco80_to_coco91_class():  # converts 80-index (val2014) to 91-index (paper)
    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/
    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\n')
    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\n')
    # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco
    # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet
    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34,
         35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
         64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]
    return x


def xyxy2xywh(x):
    # Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] where xy1=top-left, xy2=bottom-right
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = (x[:, 0] + x[:, 2]) / 2  # x center
    y[:, 1] = (x[:, 1] + x[:, 3]) / 2  # y center
    y[:, 2] = x[:, 2] - x[:, 0]  # width
    y[:, 3] = x[:, 3] - x[:, 1]  # height
    return y


def xywh2xyxy(x):
    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x
    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y
    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x
    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y
    return y


def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):
    # Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = w * (x[:, 0] - x[:, 2] / 2) + padw  # top left x
    y[:, 1] = h * (x[:, 1] - x[:, 3] / 2) + padh  # top left y
    y[:, 2] = w * (x[:, 0] + x[:, 2] / 2) + padw  # bottom right x
    y[:, 3] = h * (x[:, 1] + x[:, 3] / 2) + padh  # bottom right y
    return y


def xyn2xy(x, w=640, h=640, padw=0, padh=0):
    # Convert normalized segments into pixel segments, shape (n,2)
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = w * x[:, 0] + padw  # top left x
    y[:, 1] = h * x[:, 1] + padh  # top left y
    return y


def segment2box(segment, width=640, height=640):
    # Convert 1 segment label to 1 box label, applying inside-image constraint, i.e. (xy1, xy2, ...) to (xyxy)
    x, y = segment.T  # segment xy
    inside = (x >= 0) & (y >= 0) & (x <= width) & (y <= height)
    x, y, = x[inside], y[inside]
    return np.array([x.min(), y.min(), x.max(), y.max()]) if any(x) else np.zeros((1, 4))  # xyxy


def segments2boxes(segments):
    # Convert segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh)
    boxes = []
    for s in segments:
        x, y = s.T  # segment xy
        boxes.append([x.min(), y.min(), x.max(), y.max()])  # cls, xyxy
    return xyxy2xywh(np.array(boxes))  # cls, xywh


def resample_segments(segments, n=1000):
    # Up-sample an (n,2) segment
    for i, s in enumerate(segments):
        x = np.linspace(0, len(s) - 1, n)
        xp = np.arange(len(s))
        segments[i] = np.concatenate([np.interp(x, xp, s[:, i]) for i in range(2)]).reshape(2, -1).T  # segment xy
    return segments


def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):
    # Rescale coords (xyxy) from img1_shape to img0_shape
    if ratio_pad is None:  # calculate from img0_shape
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new
        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding
    else:
        gain = ratio_pad[0][0]
        pad = ratio_pad[1]

    coords[:, [0, 2]] -= pad[0]  # x padding
    coords[:, [1, 3]] -= pad[1]  # y padding
    coords[:, :4] /= gain
    clip_coords(coords, img0_shape)
    return coords


def clip_coords(boxes, img_shape):
    # Clip bounding xyxy bounding boxes to image shape (height, width)
    boxes[:, 0].clamp_(0, img_shape[1])  # x1
    boxes[:, 1].clamp_(0, img_shape[0])  # y1
    boxes[:, 2].clamp_(0, img_shape[1])  # x2
    boxes[:, 3].clamp_(0, img_shape[0])  # y2


def bbox_iou(box1, box2, x1y1x2y2=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):
    # Returns the IoU of box1 to box2. box1 is 4, box2 is nx4
    box2 = box2.T

    # Get the coordinates of bounding boxes
    if x1y1x2y2:  # x1, y1, x2, y2 = box1
        b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]
        b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]
    else:  # transform from xywh to xyxy
        b1_x1, b1_x2 = box1[0] - box1[2] / 2, box1[0] + box1[2] / 2
        b1_y1, b1_y2 = box1[1] - box1[3] / 2, box1[1] + box1[3] / 2
        b2_x1, b2_x2 = box2[0] - box2[2] / 2, box2[0] + box2[2] / 2
        b2_y1, b2_y2 = box2[1] - box2[3] / 2, box2[1] + box2[3] / 2

    # Intersection area
    inter = (torch.min(b1_x2, b2_x2) - torch.max(b1_x1, b2_x1)).clamp(0) * \
            (torch.min(b1_y2, b2_y2) - torch.max(b1_y1, b2_y1)).clamp(0)

    # Union Area
    w1, h1 = b1_x2 - b1_x1, b1_y2 - b1_y1 + eps
    w2, h2 = b2_x2 - b2_x1, b2_y2 - b2_y1 + eps
    union = w1 * h1 + w2 * h2 - inter + eps

    iou = inter / union
    if GIoU or DIoU or CIoU:
        cw = torch.max(b1_x2, b2_x2) - torch.min(b1_x1, b2_x1)  # convex (smallest enclosing box) width
        ch = torch.max(b1_y2, b2_y2) - torch.min(b1_y1, b2_y1)  # convex height
        if CIoU or DIoU:  # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1
            c2 = cw ** 2 + ch ** 2 + eps  # convex diagonal squared
            rho2 = ((b2_x1 + b2_x2 - b1_x1 - b1_x2) ** 2 +
                    (b2_y1 + b2_y2 - b1_y1 - b1_y2) ** 2) / 4  # center distance squared
            if DIoU:
                return iou - rho2 / c2  # DIoU
            elif CIoU:  # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47
                v = (4 / math.pi ** 2) * torch.pow(torch.atan(w2 / h2) - torch.atan(w1 / h1), 2)
                with torch.no_grad():
                    alpha = v / (v - iou + (1 + eps))
                return iou - (rho2 / c2 + v * alpha)  # CIoU
        else:  # GIoU https://arxiv.org/pdf/1902.09630.pdf
            c_area = cw * ch + eps  # convex area
            return iou - (c_area - union) / c_area  # GIoU
    else:
        return iou  # IoU


def box_iou(box1, box2):
    # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py
    """
    Return intersection-over-union (Jaccard index) of boxes.
    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.
    Arguments:
        box1 (Tensor[N, 4])
        box2 (Tensor[M, 4])
    Returns:
        iou (Tensor[N, M]): the NxM matrix containing the pairwise
            IoU values for every element in boxes1 and boxes2
    """

    def box_area(box):
        # box = 4xn
        return (box[2] - box[0]) * (box[3] - box[1])

    area1 = box_area(box1.T)
    area2 = box_area(box2.T)

    # inter(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)
    inter = (torch.min(box1[:, None, 2:], box2[:, 2:]) - torch.max(box1[:, None, :2], box2[:, :2])).clamp(0).prod(2)
    return inter / (area1[:, None] + area2 - inter)  # iou = inter / (area1 + area2 - inter)


def wh_iou(wh1, wh2):
    # Returns the nxm IoU matrix. wh1 is nx2, wh2 is mx2
    wh1 = wh1[:, None]  # [N,1,2]
    wh2 = wh2[None]  # [1,M,2]
    inter = torch.min(wh1, wh2).prod(2)  # [N,M]
    return inter / (wh1.prod(2) + wh2.prod(2) - inter)  # iou = inter / (area1 + area2 - inter)


def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,
                        labels=()):
    """Runs Non-Maximum Suppression (NMS) on inference results

    Returns:
         list of detections, on (n,6) tensor per image [xyxy, conf, cls]
    """

    nc = prediction.shape[2] - 5  # number of classes
    xc = prediction[..., 4] > conf_thres  # candidates

    # Settings
    min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height
    max_det = 300  # maximum number of detections per image
    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()
    time_limit = 10.0  # seconds to quit after
    redundant = True  # require redundant detections
    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)
    merge = False  # use merge-NMS

    t = time.time()
    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]
    for xi, x in enumerate(prediction):  # image index, image inference
        # Apply constraints
        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height
        x = x[xc[xi]]  # confidence

        # Cat apriori labels if autolabelling
        if labels and len(labels[xi]):
            l = labels[xi]
            v = torch.zeros((len(l), nc + 5), device=x.device)
            v[:, :4] = l[:, 1:5]  # box
            v[:, 4] = 1.0  # conf
            v[range(len(l)), l[:, 0].long() + 5] = 1.0  # cls
            x = torch.cat((x, v), 0)

        # If none remain process next image
        if not x.shape[0]:
            continue

        # Compute conf
        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf

        # Box (center x, center y, width, height) to (x1, y1, x2, y2)
        box = xywh2xyxy(x[:, :4])

        # Detections matrix nx6 (xyxy, conf, cls)
        if multi_label:
            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T
            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)
        else:  # best class only
            conf, j = x[:, 5:].max(1, keepdim=True)
            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]

        # Filter by class
        if classes is not None:
            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]

        # Apply finite constraint
        # if not torch.isfinite(x).all():
        #     x = x[torch.isfinite(x).all(1)]

        # Check shape
        n = x.shape[0]  # number of boxes
        if not n:  # no boxes
            continue
        elif n > max_nms:  # excess boxes
            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence

        # Batched NMS
        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes
        boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores
        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS
        if i.shape[0] > max_det:  # limit detections
            i = i[:max_det]
        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)
            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)
            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix
            weights = iou * scores[None]  # box weights
            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes
            if redundant:
                i = i[iou.sum(1) > 1]  # require redundancy

        output[xi] = x[i]
        if (time.time() - t) > time_limit:
            print(f'WARNING: NMS time limit {time_limit}s exceeded')
            break  # time limit exceeded

    return output


def strip_optimizer(f='best.pt', s=''):  # from utils.general import *; strip_optimizer()
    # Strip optimizer from 'f' to finalize training, optionally save as 's'
    x = torch.load(f, map_location=torch.device('cpu'))
    if x.get('ema'):
        x['model'] = x['ema']  # replace model with ema
    for k in 'optimizer', 'training_results', 'wandb_id', 'ema', 'updates':  # keys
        x[k] = None
    x['epoch'] = -1
    x['model'].half()  # to FP16
    for p in x['model'].parameters():
        p.requires_grad = False
    torch.save(x, s or f)
    mb = os.path.getsize(s or f) / 1E6  # filesize
    print(f"Optimizer stripped from {f},{(' saved as %s,' % s) if s else ''} {mb:.1f}MB")


def print_mutation(hyp, results, yaml_file='hyp_evolved.yaml', bucket=''):
    # Print mutation results to evolve.txt (for use with train.py --evolve)
    a = '%10s' * len(hyp) % tuple(hyp.keys())  # hyperparam keys
    b = '%10.3g' * len(hyp) % tuple(hyp.values())  # hyperparam values
    c = '%10.4g' * len(results) % results  # results (P, R, mAP@0.5, mAP@0.5:0.95, val_losses x 3)
    print('\n%s\n%s\nEvolved fitness: %s\n' % (a, b, c))

    if bucket:
        url = 'gs://%s/evolve.txt' % bucket
        if gsutil_getsize(url) > (os.path.getsize('evolve.txt') if os.path.exists('evolve.txt') else 0):
            os.system('gsutil cp %s .' % url)  # download evolve.txt if larger than local

    with open('evolve.txt', 'a') as f:  # append result
        f.write(c + b + '\n')
    x = np.unique(np.loadtxt('evolve.txt', ndmin=2), axis=0)  # load unique rows
    x = x[np.argsort(-fitness(x))]  # sort
    np.savetxt('evolve.txt', x, '%10.3g')  # save sort by fitness

    # Save yaml
    for i, k in enumerate(hyp.keys()):
        hyp[k] = float(x[0, i + 7])
    with open(yaml_file, 'w') as f:
        results = tuple(x[0, :7])
        c = '%10.4g' * len(results) % results  # results (P, R, mAP@0.5, mAP@0.5:0.95, val_losses x 3)
        f.write('# Hyperparameter Evolution Results\n# Generations: %g\n# Metrics: ' % len(x) + c + '\n\n')
        yaml.dump(hyp, f, sort_keys=False)

    if bucket:
        os.system('gsutil cp evolve.txt %s gs://%s' % (yaml_file, bucket))  # upload


def apply_classifier(x, model, img, im0):
    # applies a second stage classifier to yolo outputs
    im0 = [im0] if isinstance(im0, np.ndarray) else im0
    for i, d in enumerate(x):  # per image
        if d is not None and len(d):
            d = d.clone()

            # Reshape and pad cutouts
            b = xyxy2xywh(d[:, :4])  # boxes
            b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # rectangle to square
            b[:, 2:] = b[:, 2:] * 1.3 + 30  # pad
            d[:, :4] = xywh2xyxy(b).long()

            # Rescale boxes from img_size to im0 size
            scale_coords(img.shape[2:], d[:, :4], im0[i].shape)

            # Classes
            pred_cls1 = d[:, 5].long()
            ims = []
            for j, a in enumerate(d):  # per item
                cutout = im0[i][int(a[1]):int(a[3]), int(a[0]):int(a[2])]
                im = cv2.resize(cutout, (224, 224))  # BGR
                # cv2.imwrite('test%i.jpg' % j, cutout)

                im = im[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
                im = np.ascontiguousarray(im, dtype=np.float32)  # uint8 to float32
                im /= 255.0  # 0 - 255 to 0.0 - 1.0
                ims.append(im)

            pred_cls2 = model(torch.Tensor(ims).to(d.device)).argmax(1)  # classifier prediction
            x[i] = x[i][pred_cls1 == pred_cls2]  # retain matching class detections

    return x


def increment_path(path, exist_ok=True, sep=''):
    # Increment path, i.e. runs/exp --> runs/exp{sep}0, runs/exp{sep}1 etc.
    path = Path(path)  # os-agnostic
    if (path.exists() and exist_ok) or (not path.exists()):
        return str(path)
    else:
        dirs = glob.glob(f"{path}{sep}*")  # similar paths
        matches = [re.search(rf"%s{sep}(\d+)" % path.stem, d) for d in dirs]
        i = [int(m.groups()[0]) for m in matches if m]  # indices
        n = max(i) + 1 if i else 2  # increment number
        return f"{path}{sep}{n}"  # update path

===== .\utils\utils\google_app_engine\additional_requirements.txt =====
功能: 代码摘录
# add these requirements in your app on top of the existing ones
pip==18.1
Flask==1.0.2
gunicorn==19.9.0

===== .\utils\utils\google_app_engine\app.yaml =====
功能: 代码摘录
runtime: custom
env: flex

service: yolov5app

liveness_check:
  initial_delay_sec: 600

manual_scaling:
  instances: 1
resources:
  cpu: 1
  memory_gb: 4
  disk_size_gb: 20

===== .\utils\utils\google_utils.py =====
功能: 代码摘录
# Google utils: https://cloud.google.com/storage/docs/reference/libraries

import os
import platform
import subprocess
import time
from pathlib import Path

import requests
import torch


def gsutil_getsize(url=''):
    # gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du
    s = subprocess.check_output(f'gsutil du {url}', shell=True).decode('utf-8')
    return eval(s.split(' ')[0]) if len(s) else 0  # bytes


def attempt_download(file, repo='ultralytics/yolov5'):
    # Attempt file download if does not exist
    file = Path(str(file).strip().replace("'", '').lower())

    if not file.exists():
        try:
            response = requests.get(f'https://api.github.com/repos/{repo}/releases/latest').json()  # github api
            assets = [x['name'] for x in response['assets']]  # release assets, i.e. ['yolov5s.pt', 'yolov5m.pt', ...]
            tag = response['tag_name']  # i.e. 'v1.0'
        except:  # fallback plan
            assets = ['yolov5s.pt', 'yolov5m.pt', 'yolov5l.pt', 'yolov5x.pt']
            tag = subprocess.check_output('git tag', shell=True).decode().split()[-1]

        name = file.name
        if name in assets:
            msg = f'{file} missing, try downloading from https://github.com/{repo}/releases/'
            redundant = False  # second download option
            try:  # GitHub
                url = f'https://github.com/{repo}/releases/download/{tag}/{name}'
                print(f'Downloading {url} to {file}...')
                torch.hub.download_url_to_file(url, file)
                assert file.exists() and file.stat().st_size > 1E6  # check
            except Exception as e:  # GCP
                print(f'Download error: {e}')
                assert redundant, 'No secondary mirror'
                url = f'https://storage.googleapis.com/{repo}/ckpt/{name}'
                print(f'Downloading {url} to {file}...')
                os.system(f'curl -L {url} -o {file}')  # torch.hub.download_url_to_file(url, weights)
            finally:
                if not file.exists() or file.stat().st_size < 1E6:  # check
                    file.unlink(missing_ok=True)  # remove partial downloads
                    print(f'ERROR: Download failure: {msg}')
                print('')
                return


def gdrive_download(id='16TiPfZj7htmTyhntwcZyEEAejOUxuT6m', file='tmp.zip'):
    # Downloads a file from Google Drive. from yolov5.utils.google_utils import *; gdrive_download()
    t = time.time()
    file = Path(file)
    cookie = Path('cookie')  # gdrive cookie
    print(f'Downloading https://drive.google.com/uc?export=download&id={id} as {file}... ', end='')
    file.unlink(missing_ok=True)  # remove existing file
    cookie.unlink(missing_ok=True)  # remove existing cookie

    # Attempt file download
    out = "NUL" if platform.system() == "Windows" else "/dev/null"
    os.system(f'curl -c ./cookie -s -L "drive.google.com/uc?export=download&id={id}" > {out}')
    if os.path.exists('cookie'):  # large file
        s = f'curl -Lb ./cookie "drive.google.com/uc?export=download&confirm={get_token()}&id={id}" -o {file}'
    else:  # small file
        s = f'curl -s -L -o {file} "drive.google.com/uc?export=download&id={id}"'
    r = os.system(s)  # execute, capture return
    cookie.unlink(missing_ok=True)  # remove existing cookie

    # Error check
    if r != 0:
        file.unlink(missing_ok=True)  # remove partial
        print('Download error ')  # raise Exception('Download error')
        return r

    # Unzip if archive
    if file.suffix == '.zip':
        print('unzipping... ', end='')
        os.system(f'unzip -q {file}')  # unzip
        file.unlink()  # remove zip to free space

    print(f'Done ({time.time() - t:.1f}s)')
    return r


def get_token(cookie="./cookie"):
    with open(cookie) as f:
        for line in f:
            if "download" in line:
                return line.split()[-1]
    return ""

# def upload_blob(bucket_name, source_file_name, destination_blob_name):
#     # Uploads a file to a bucket
#     # https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python
#
#     storage_client = storage.Client()
#     bucket = storage_client.get_bucket(bucket_name)
#     blob = bucket.blob(destination_blob_name)
#
#     blob.upload_from_filename(source_file_name)
#
#     print('File {} uploaded to {}.'.format(
#         source_file_name,
#         destination_blob_name))
#
#
# def download_blob(bucket_name, source_blob_name, destination_file_name):
#     # Uploads a blob from a bucket
#     storage_client = storage.Client()
#     bucket = storage_client.get_bucket(bucket_name)
#     blob = bucket.blob(source_blob_name)
#
#     blob.download_to_filename(destination_file_name)
#
#     print('Blob {} downloaded to {}.'.format(
#         source_blob_name,
#         destination_file_name))

===== .\utils\utils\loss.py =====
功能: 代码摘录
# Loss functions

import torch
import torch.nn as nn

from utils.general import bbox_iou
from utils.torch_utils import is_parallel

def smooth_BCE(eps=0.1):  # https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441
    # return positive, negative label smoothing BCE targets
    return 1.0 - 0.5 * eps, 0.5 * eps

class BCEBlurWithLogitsLoss(nn.Module):
    # BCEwithLogitLoss() with reduced missing label effects.
    def __init__(self, alpha=0.05):
        super(BCEBlurWithLogitsLoss, self).__init__()
        self.loss_fcn = nn.BCEWithLogitsLoss(reduction='none')  # must be nn.BCEWithLogitsLoss()
        self.alpha = alpha

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)
        pred = torch.sigmoid(pred)  # prob from logits
        dx = pred - true  # reduce only missing label effects
        # dx = (pred - true).abs()  # reduce missing label and false label effects
        alpha_factor = 1 - torch.exp((dx - 1) / (self.alpha + 1e-4))
        loss *= alpha_factor
        return loss.mean()


class FocalLoss(nn.Module):
    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super(FocalLoss, self).__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = loss_fcn.reduction
        self.loss_fcn.reduction = 'none'  # required to apply FL to each element

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)
        # p_t = torch.exp(-loss)
        # loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability

        # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py
        pred_prob = torch.sigmoid(pred)  # prob from logits
        p_t = true * pred_prob + (1 - true) * (1 - pred_prob)
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = (1.0 - p_t) ** self.gamma
        loss *= alpha_factor * modulating_factor

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:  # 'none'
            return loss


class QFocalLoss(nn.Module):
    # Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super(QFocalLoss, self).__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = loss_fcn.reduction
        self.loss_fcn.reduction = 'none'  # required to apply FL to each element

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)

        pred_prob = torch.sigmoid(pred)  # prob from logits
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = torch.abs(true - pred_prob) ** self.gamma
        loss *= alpha_factor * modulating_factor

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:  # 'none'
            return loss


class ComputeLoss:
    # Compute losses
    def __init__(self, model, autobalance=False):
        super(ComputeLoss, self).__init__()
        device = next(model.parameters()).device  # get model device
        h = model.hyp  # hyperparameters

        # Define criteria
        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))
        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))

        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3
        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets

        # Focal loss
        g = h['fl_gamma']  # focal loss gamma
        if g > 0:
            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)

        det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # Detect() module
        self.balance = {3: [4.0, 1.0, 0.4]}.get(det.nl, [4.0, 1.0, 0.25, 0.06, .02])  # P3-P7
        self.ssi = list(det.stride).index(16) if autobalance else 0  # stride 16 index
        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, model.gr, h, autobalance
        for k in 'na', 'nc', 'nl', 'anchors':
            setattr(self, k, getattr(det, k))

    def __call__(self, p, targets):  # predictions, targets, model
        device = targets.device
        lcls, lbox, lobj = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)
        tcls, tbox, indices, anchors = self.build_targets(p, targets)  # targets

        # Losses
        for i, pi in enumerate(p):  # layer index, layer predictions
            b, a, gj, gi = indices[i]  # image, anchor, gridy, gridx
            tobj = torch.zeros_like(pi[..., 0], device=device)  # target obj

            n = b.shape[0]  # number of targets
            if n:
                ps = pi[b, a, gj, gi]  # prediction subset corresponding to targets

                # Regression
                pxy = ps[:, :2].sigmoid() * 2. - 0.5
                pwh = (ps[:, 2:4].sigmoid() * 2) ** 2 * anchors[i]
                pbox = torch.cat((pxy, pwh), 1)  # predicted box
                iou = bbox_iou(pbox.T, tbox[i], x1y1x2y2=False, CIoU=True)  # iou(prediction, target)
                lbox += (1.0 - iou).mean()  # iou loss

                # Objectness
                tobj[b, a, gj, gi] = (1.0 - self.gr) + self.gr * iou.detach().clamp(0).type(tobj.dtype)  # iou ratio

                # Classification
                if self.nc > 1:  # cls loss (only if multiple classes)
                    t = torch.full_like(ps[:, 5:], self.cn, device=device)  # targets
                    t[range(n), tcls[i]] = self.cp
                    lcls += self.BCEcls(ps[:, 5:], t)  # BCE

                # Append targets to text file
                # with open('targets.txt', 'a') as file:
                #     [file.write('%11.5g ' * 4 % tuple(x) + '\n') for x in torch.cat((txy[i], twh[i]), 1)]

            obji = self.BCEobj(pi[..., 4], tobj)
            lobj += obji * self.balance[i]  # obj loss
            if self.autobalance:
                self.balance[i] = self.balance[i] * 0.9999 + 0.0001 / obji.detach().item()

        if self.autobalance:
            self.balance = [x / self.balance[self.ssi] for x in self.balance]
        lbox *= self.hyp['box']
        lobj *= self.hyp['obj']
        lcls *= self.hyp['cls']
        bs = tobj.shape[0]  # batch size

        loss = lbox + lobj + lcls
        return loss * bs, torch.cat((lbox, lobj, lcls, loss)).detach()

    def build_targets(self, p, targets):
        # Build targets for compute_loss(), input targets(image,class,x,y,w,h)
        na, nt = self.na, targets.shape[0]  # number of anchors, targets
        tcls, tbox, indices, anch = [], [], [], []
        gain = torch.ones(7, device=targets.device)  # normalized to gridspace gain
        ai = torch.arange(na, device=targets.device).float().view(na, 1).repeat(1, nt)  # same as .repeat_interleave(nt)
        targets = torch.cat((targets.repeat(na, 1, 1), ai[:, :, None]), 2)  # append anchor indices

        g = 0.5  # bias
        off = torch.tensor([[0, 0],
                            [1, 0], [0, 1], [-1, 0], [0, -1],  # j,k,l,m
                            # [1, 1], [1, -1], [-1, 1], [-1, -1],  # jk,jm,lk,lm
                            ], device=targets.device).float() * g  # offsets


        for i in range(self.nl):
            anchors, shape = self.anchors[i], p[i].shape
            gain[2:6] = torch.tensor(shape)[[3, 2, 3, 2]]  # xyxy gain
 
            # Match targets to anchors
            t = targets * gain  # shape(3,n,7)
            if nt:
                # Matches
                r = t[..., 4:6] / anchors[:, None]  # wh ratio
                j = torch.max(r, 1 / r).max(2)[0] < self.hyp['anchor_t']  # compare
                # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t']  # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))
                t = t[j]  # filter
 
                # Offsets
                gxy = t[:, 2:4]  # grid xy
                gxi = gain[[2, 3]] - gxy  # inverse
                j, k = ((gxy % 1 < g) & (gxy > 1)).T
                l, m = ((gxi % 1 < g) & (gxi > 1)).T
                j = torch.stack((torch.ones_like(j), j, k, l, m))
                t = t.repeat((5, 1, 1))[j]
                offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]
            else:
                t = targets[0]
                offsets = 0
 
            # Define
            bc, gxy, gwh, a = t.chunk(4, 1)  # (image, class), grid xy, grid wh, anchors
            a, (b, c) = a.long().view(-1), bc.long().T  # anchors, image, class
            gij = (gxy - offsets).long()
            gi, gj = gij.T  # grid indices
 
            # Append
            indices.append((b, a, gj.clamp_(0, shape[2] - 1), gi.clamp_(0, shape[3] - 1)))  # image, anchor, grid
            tbox.append(torch.cat((gxy - gij, gwh), 1))  # box
            anch.append(anchors[a])  # anchors
            tcls.append(c)  # class



        # for i in range(self.nl):
        #     anchors = self.anchors[i]
        #     gain[2:6] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain

        #     # Match targets to anchors
        #     t = targets * gain
        #     if nt:
        #         # Matches
        #         r = t[:, :, 4:6] / anchors[:, None]  # wh ratio
        #         j = torch.max(r, 1. / r).max(2)[0] < self.hyp['anchor_t']  # compare
        #         # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t']  # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))
        #         t = t[j]  # filter

        #         # Offsets
        #         gxy = t[:, 2:4]  # grid xy
        #         gxi = gain[[2, 3]] - gxy  # inverse
        #         j, k = ((gxy % 1. < g) & (gxy > 1.)).T
        #         l, m = ((gxi % 1. < g) & (gxi > 1.)).T
        #         j = torch.stack((torch.ones_like(j), j, k, l, m))
        #         t = t.repeat((5, 1, 1))[j]
        #         offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]
        #     else:
        #         t = targets[0]
        #         offsets = 0

        #     # Define
        #     b, c = t[:, :2].long().T  # image, class
        #     gxy = t[:, 2:4]  # grid xy
        #     gwh = t[:, 4:6]  # grid wh
        #     gij = (gxy - offsets).long()
        #     gi, gj = gij.T  # grid xy indices

        #     # Append
        #     a = t[:, 6].long()  # anchor indices
        #     indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  # image, anchor, grid indices
        #     tbox.append(torch.cat((gxy - gij, gwh), 1))  # box
        #     anch.append(anchors[a])  # anchors
        #     tcls.append(c)  # class

        return tcls, tbox, indices, anch

===== .\utils\utils\metrics.py =====
功能: 代码摘录
# Model validation metrics

from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import torch

from . import general


def fitness(x):
    # Model fitness as a weighted combination of metrics
    w = [0.0, 0.0, 0.1, 0.9]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]
    return (x[:, :4] * w).sum(1)


def ap_per_class(tp, conf, pred_cls, target_cls, plot=False, save_dir='.', names=()):
    """ Compute the average precision, given the recall and precision curves.
    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.
    # Arguments
        tp:  True positives (nparray, nx1 or nx10).
        conf:  Objectness value from 0-1 (nparray).
        pred_cls:  Predicted object classes (nparray).
        target_cls:  True object classes (nparray).
        plot:  Plot precision-recall curve at mAP@0.5
        save_dir:  Plot save directory
    # Returns
        The average precision as computed in py-faster-rcnn.
    """

    # Sort by objectness
    i = np.argsort(-conf)
    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]

    # Find unique classes
    unique_classes = np.unique(target_cls)
    nc = unique_classes.shape[0]  # number of classes, number of detections

    # Create Precision-Recall curve and compute AP for each class
    px, py = np.linspace(0, 1, 1000), []  # for plotting
    ap, p, r = np.zeros((nc, tp.shape[1])), np.zeros((nc, 1000)), np.zeros((nc, 1000))
    for ci, c in enumerate(unique_classes):
        i = pred_cls == c
        n_l = (target_cls == c).sum()  # number of labels
        n_p = i.sum()  # number of predictions

        if n_p == 0 or n_l == 0:
            continue
        else:
            # Accumulate FPs and TPs
            fpc = (1 - tp[i]).cumsum(0)
            tpc = tp[i].cumsum(0)

            # Recall
            recall = tpc / (n_l + 1e-16)  # recall curve
            r[ci] = np.interp(-px, -conf[i], recall[:, 0], left=0)  # negative x, xp because xp decreases

            # Precision
            precision = tpc / (tpc + fpc)  # precision curve
            p[ci] = np.interp(-px, -conf[i], precision[:, 0], left=1)  # p at pr_score

            # AP from recall-precision curve
            for j in range(tp.shape[1]):
                ap[ci, j], mpre, mrec = compute_ap(recall[:, j], precision[:, j])
                if plot and j == 0:
                    py.append(np.interp(px, mrec, mpre))  # precision at mAP@0.5

    # Compute F1 (harmonic mean of precision and recall)
    f1 = 2 * p * r / (p + r + 1e-16)
    if plot:
        plot_pr_curve(px, py, ap, Path(save_dir) / 'PR_curve.png', names)
        plot_mc_curve(px, f1, Path(save_dir) / 'F1_curve.png', names, ylabel='F1')
        plot_mc_curve(px, p, Path(save_dir) / 'P_curve.png', names, ylabel='Precision')
        plot_mc_curve(px, r, Path(save_dir) / 'R_curve.png', names, ylabel='Recall')

    i = f1.mean(0).argmax()  # max F1 index
    return p[:, i], r[:, i], ap, f1[:, i], unique_classes.astype('int32')


def compute_ap(recall, precision):
    """ Compute the average precision, given the recall and precision curves
    # Arguments
        recall:    The recall curve (list)
        precision: The precision curve (list)
    # Returns
        Average precision, precision curve, recall curve
    """

    # Append sentinel values to beginning and end
    mrec = np.concatenate(([0.], recall, [recall[-1] + 0.01]))
    mpre = np.concatenate(([1.], precision, [0.]))

    # Compute the precision envelope
    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))

    # Integrate area under curve
    method = 'interp'  # methods: 'continuous', 'interp'
    if method == 'interp':
        x = np.linspace(0, 1, 101)  # 101-point interp (COCO)
        ap = np.trapz(np.interp(x, mrec, mpre), x)  # integrate
    else:  # 'continuous'
        i = np.where(mrec[1:] != mrec[:-1])[0]  # points where x axis (recall) changes
        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  # area under curve

    return ap, mpre, mrec


class ConfusionMatrix:
    # Updated version of https://github.com/kaanakan/object_detection_confusion_matrix
    def __init__(self, nc, conf=0.25, iou_thres=0.45):
        self.matrix = np.zeros((nc + 1, nc + 1))
        self.nc = nc  # number of classes
        self.conf = conf
        self.iou_thres = iou_thres

    def process_batch(self, detections, labels):
        """
        Return intersection-over-union (Jaccard index) of boxes.
        Both sets of boxes are expected to be in (x1, y1, x2, y2) format.
        Arguments:
            detections (Array[N, 6]), x1, y1, x2, y2, conf, class
            labels (Array[M, 5]), class, x1, y1, x2, y2
        Returns:
            None, updates confusion matrix accordingly
        """
        detections = detections[detections[:, 4] > self.conf]
        gt_classes = labels[:, 0].int()
        detection_classes = detections[:, 5].int()
        iou = general.box_iou(labels[:, 1:], detections[:, :4])

        x = torch.where(iou > self.iou_thres)
        if x[0].shape[0]:
            matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()
            if x[0].shape[0] > 1:
                matches = matches[matches[:, 2].argsort()[::-1]]
                matches = matches[np.unique(matches[:, 1], return_index=True)[1]]
                matches = matches[matches[:, 2].argsort()[::-1]]
                matches = matches[np.unique(matches[:, 0], return_index=True)[1]]
        else:
            matches = np.zeros((0, 3))

        n = matches.shape[0] > 0
        m0, m1, _ = matches.transpose().astype(np.int16)
        for i, gc in enumerate(gt_classes):
            j = m0 == i
            if n and sum(j) == 1:
                self.matrix[gc, detection_classes[m1[j]]] += 1  # correct
            else:
                self.matrix[self.nc, gc] += 1  # background FP

        if n:
            for i, dc in enumerate(detection_classes):
                if not any(m1 == i):
                    self.matrix[dc, self.nc] += 1  # background FN

    def matrix(self):
        return self.matrix

    def plot(self, save_dir='', names=()):
        try:
            import seaborn as sn

            array = self.matrix / (self.matrix.sum(0).reshape(1, self.nc + 1) + 1E-6)  # normalize
            array[array < 0.005] = np.nan  # don't annotate (would appear as 0.00)

            fig = plt.figure(figsize=(12, 9), tight_layout=True)
            sn.set(font_scale=1.0 if self.nc < 50 else 0.8)  # for label size
            labels = (0 < len(names) < 99) and len(names) == self.nc  # apply names to ticklabels
            sn.heatmap(array, annot=self.nc < 30, annot_kws={"size": 8}, cmap='Blues', fmt='.2f', square=True,
                       xticklabels=names + ['background FP'] if labels else "auto",
                       yticklabels=names + ['background FN'] if labels else "auto").set_facecolor((1, 1, 1))
            fig.axes[0].set_xlabel('True')
            fig.axes[0].set_ylabel('Predicted')
            fig.savefig(Path(save_dir) / 'confusion_matrix.png', dpi=250)
        except Exception as e:
            pass

    def print(self):
        for i in range(self.nc + 1):
            print(' '.join(map(str, self.matrix[i])))


# Plots ----------------------------------------------------------------------------------------------------------------

def plot_pr_curve(px, py, ap, save_dir='pr_curve.png', names=()):
    # Precision-recall curve
    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)
    py = np.stack(py, axis=1)

    if 0 < len(names) < 21:  # display per-class legend if < 21 classes
        for i, y in enumerate(py.T):
            ax.plot(px, y, linewidth=1, label=f'{names[i]} {ap[i, 0]:.3f}')  # plot(recall, precision)
    else:
        ax.plot(px, py, linewidth=1, color='grey')  # plot(recall, precision)

    ax.plot(px, py.mean(1), linewidth=3, color='blue', label='all classes %.3f mAP@0.5' % ap[:, 0].mean())
    ax.set_xlabel('Recall')
    ax.set_ylabel('Precision')
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    plt.legend(bbox_to_anchor=(1.04, 1), loc="upper left")
    fig.savefig(Path(save_dir), dpi=250)


def plot_mc_curve(px, py, save_dir='mc_curve.png', names=(), xlabel='Confidence', ylabel='Metric'):
    # Metric-confidence curve
    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)

    if 0 < len(names) < 21:  # display per-class legend if < 21 classes
        for i, y in enumerate(py):
            ax.plot(px, y, linewidth=1, label=f'{names[i]}')  # plot(confidence, metric)
    else:
        ax.plot(px, py.T, linewidth=1, color='grey')  # plot(confidence, metric)

    y = py.mean(0)
    ax.plot(px, y, linewidth=3, color='blue', label=f'all classes {y.max():.2f} at {px[y.argmax()]:.3f}')
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    plt.legend(bbox_to_anchor=(1.04, 1), loc="upper left")
    fig.savefig(Path(save_dir), dpi=250)
    
def box_iou(box1, box2):
    # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py
    """
    Return intersection-over-union (Jaccard index) of boxes.
    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.
    Arguments:
        box1 (Tensor[N, 4])
        box2 (Tensor[M, 4])
    Returns:
        iou (Tensor[N, M]): the NxM matrix containing the pairwise
            IoU values for every element in boxes1 and boxes2
    """

    def box_area(box):
        # box = 4xn
        return (box[2] - box[0]) * (box[3] - box[1])

    area1 = box_area(box1.T)
    area2 = box_area(box2.T)

    # inter(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)
    inter = (torch.min(box1[:, None, 2:], box2[:, 2:]) - torch.max(box1[:, None, :2], box2[:, :2])).clamp(0).prod(2)
    return inter / (area1[:, None] + area2 - inter)  # iou = inter / (area1 + area2 - inter)

===== .\utils\utils\plots.py =====
功能: 代码摘录
# Plotting utils

import glob
import math
import os
import random
from copy import copy
from pathlib import Path

import cv2
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
import yaml
from PIL import Image, ImageDraw, ImageFont
from scipy.signal import butter, filtfilt

from utils.general import xywh2xyxy, xyxy2xywh
from utils.metrics import fitness

# Settings
matplotlib.rc('font', **{'size': 11})
matplotlib.use('Agg')  # for writing to files only


def color_list():
    # Return first 10 plt colors as (r,g,b) https://stackoverflow.com/questions/51350872/python-from-color-name-to-rgb
    def hex2rgb(h):
        return tuple(int(h[1 + i:1 + i + 2], 16) for i in (0, 2, 4))

    return [hex2rgb(h) for h in matplotlib.colors.TABLEAU_COLORS.values()]  # or BASE_ (8), CSS4_ (148), XKCD_ (949)


def hist2d(x, y, n=100):
    # 2d histogram used in labels.png and evolve.png
    xedges, yedges = np.linspace(x.min(), x.max(), n), np.linspace(y.min(), y.max(), n)
    hist, xedges, yedges = np.histogram2d(x, y, (xedges, yedges))
    xidx = np.clip(np.digitize(x, xedges) - 1, 0, hist.shape[0] - 1)
    yidx = np.clip(np.digitize(y, yedges) - 1, 0, hist.shape[1] - 1)
    return np.log(hist[xidx, yidx])


def butter_lowpass_filtfilt(data, cutoff=1500, fs=50000, order=5):
    # https://stackoverflow.com/questions/28536191/how-to-filter-smooth-with-scipy-numpy
    def butter_lowpass(cutoff, fs, order):
        nyq = 0.5 * fs
        normal_cutoff = cutoff / nyq
        return butter(order, normal_cutoff, btype='low', analog=False)

    b, a = butter_lowpass(cutoff, fs, order=order)
    return filtfilt(b, a, data)  # forward-backward filter


def plot_one_box(x, img, color=None, label=None, line_thickness=3):
    # Plots one bounding box on image img
    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness
    color = color or [random.randint(0, 255) for _ in range(3)]
    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))
    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)
    if label:
        tf = max(tl - 1, 1)  # font thickness
        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]
        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3
        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled
        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)


def plot_one_box_PIL(box, img, color=None, label=None, line_thickness=None):
    img = Image.fromarray(img)
    draw = ImageDraw.Draw(img)
    line_thickness = line_thickness or max(int(min(img.size) / 200), 2)
    draw.rectangle(box, width=line_thickness, outline=tuple(color))  # plot
    if label:
        fontsize = max(round(max(img.size) / 40), 12)
        font = ImageFont.truetype("Arial.ttf", fontsize)
        txt_width, txt_height = font.getsize(label)
        draw.rectangle([box[0], box[1] - txt_height + 4, box[0] + txt_width, box[1]], fill=tuple(color))
        draw.text((box[0], box[1] - txt_height + 1), label, fill=(255, 255, 255), font=font)
    return np.asarray(img)


def plot_wh_methods():  # from utils.plots import *; plot_wh_methods()
    # Compares the two methods for width-height anchor multiplication
    # https://github.com/ultralytics/yolov3/issues/168
    x = np.arange(-4.0, 4.0, .1)
    ya = np.exp(x)
    yb = torch.sigmoid(torch.from_numpy(x)).numpy() * 2

    fig = plt.figure(figsize=(6, 3), tight_layout=True)
    plt.plot(x, ya, '.-', label='YOLOv3')
    plt.plot(x, yb ** 2, '.-', label='YOLOv5 ^2')
    plt.plot(x, yb ** 1.6, '.-', label='YOLOv5 ^1.6')
    plt.xlim(left=-4, right=4)
    plt.ylim(bottom=0, top=6)
    plt.xlabel('input')
    plt.ylabel('output')
    plt.grid()
    plt.legend()
    fig.savefig('comparison.png', dpi=200)


def output_to_target(output):
    # Convert model output to target format [batch_id, class_id, x, y, w, h, conf]
    targets = []
    for i, o in enumerate(output):
        for *box, conf, cls in o.cpu().numpy():
            targets.append([i, cls, *list(*xyxy2xywh(np.array(box)[None])), conf])
    return np.array(targets)


def plot_images(images, targets, paths=None, fname='images.jpg', names=None, max_size=640, max_subplots=16):
    # Plot image grid with labels

    if isinstance(images, torch.Tensor):
        images = images.cpu().float().numpy()
    if isinstance(targets, torch.Tensor):
        targets = targets.cpu().numpy()

    # un-normalise
    if np.max(images[0]) <= 1:
        images *= 255

    tl = 3  # line thickness
    tf = max(tl - 1, 1)  # font thickness
    bs, _, h, w = images.shape  # batch size, _, height, width
    bs = min(bs, max_subplots)  # limit plot images
    ns = np.ceil(bs ** 0.5)  # number of subplots (square)

    # Check if we should resize
    scale_factor = max_size / max(h, w)
    if scale_factor < 1:
        h = math.ceil(scale_factor * h)
        w = math.ceil(scale_factor * w)

    colors = color_list()  # list of colors
    mosaic = np.full((int(ns * h), int(ns * w), 3), 255, dtype=np.uint8)  # init
    for i, img in enumerate(images):
        if i == max_subplots:  # if last batch has fewer images than we expect
            break

        block_x = int(w * (i // ns))
        block_y = int(h * (i % ns))

        img = img.transpose(1, 2, 0)
        if scale_factor < 1:
            img = cv2.resize(img, (w, h))

        mosaic[block_y:block_y + h, block_x:block_x + w, :] = img
        if len(targets) > 0:
            image_targets = targets[targets[:, 0] == i]
            boxes = xywh2xyxy(image_targets[:, 2:6]).T
            classes = image_targets[:, 1].astype('int')
            labels = image_targets.shape[1] == 6  # labels if no conf column
            conf = None if labels else image_targets[:, 6]  # check for confidence presence (label vs pred)

            if boxes.shape[1]:
                if boxes.max() <= 1.01:  # if normalized with tolerance 0.01
                    boxes[[0, 2]] *= w  # scale to pixels
                    boxes[[1, 3]] *= h
                elif scale_factor < 1:  # absolute coords need scale if image scales
                    boxes *= scale_factor
            boxes[[0, 2]] += block_x
            boxes[[1, 3]] += block_y
            for j, box in enumerate(boxes.T):
                cls = int(classes[j])
                color = colors[cls % len(colors)]
                cls = names[cls] if names else cls
                if labels or conf[j] > 0.25:  # 0.25 conf thresh
                    label = '%s' % cls if labels else '%s %.1f' % (cls, conf[j])
                    plot_one_box(box, mosaic, label=label, color=color, line_thickness=tl)

        # Draw image filename labels
        if paths:
            label = Path(paths[i]).name[:40]  # trim to 40 char
            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]
            cv2.putText(mosaic, label, (block_x + 5, block_y + t_size[1] + 5), 0, tl / 3, [220, 220, 220], thickness=tf,
                        lineType=cv2.LINE_AA)

        # Image border
        cv2.rectangle(mosaic, (block_x, block_y), (block_x + w, block_y + h), (255, 255, 255), thickness=3)

    if fname:
        r = min(1280. / max(h, w) / ns, 1.0)  # ratio to limit image size
        mosaic = cv2.resize(mosaic, (int(ns * w * r), int(ns * h * r)), interpolation=cv2.INTER_AREA)
        # cv2.imwrite(fname, cv2.cvtColor(mosaic, cv2.COLOR_BGR2RGB))  # cv2 save
        Image.fromarray(mosaic).save(fname)  # PIL save
    return mosaic


def plot_lr_scheduler(optimizer, scheduler, epochs=300, save_dir=''):
    # Plot LR simulating training for full epochs
    optimizer, scheduler = copy(optimizer), copy(scheduler)  # do not modify originals
    y = []
    for _ in range(epochs):
        scheduler.step()
        y.append(optimizer.param_groups[0]['lr'])
    plt.plot(y, '.-', label='LR')
    plt.xlabel('epoch')
    plt.ylabel('LR')
    plt.grid()
    plt.xlim(0, epochs)
    plt.ylim(0)
    plt.savefig(Path(save_dir) / 'LR.png', dpi=200)
    plt.close()


def plot_test_txt():  # from utils.plots import *; plot_test()
    # Plot test.txt histograms
    x = np.loadtxt('test.txt', dtype=np.float32)
    box = xyxy2xywh(x[:, :4])
    cx, cy = box[:, 0], box[:, 1]

    fig, ax = plt.subplots(1, 1, figsize=(6, 6), tight_layout=True)
    ax.hist2d(cx, cy, bins=600, cmax=10, cmin=0)
    ax.set_aspect('equal')
    plt.savefig('hist2d.png', dpi=300)

    fig, ax = plt.subplots(1, 2, figsize=(12, 6), tight_layout=True)
    ax[0].hist(cx, bins=600)
    ax[1].hist(cy, bins=600)
    plt.savefig('hist1d.png', dpi=200)


def plot_targets_txt():  # from utils.plots import *; plot_targets_txt()
    # Plot targets.txt histograms
    x = np.loadtxt('targets.txt', dtype=np.float32).T
    s = ['x targets', 'y targets', 'width targets', 'height targets']
    fig, ax = plt.subplots(2, 2, figsize=(8, 8), tight_layout=True)
    ax = ax.ravel()
    for i in range(4):
        ax[i].hist(x[i], bins=100, label='%.3g +/- %.3g' % (x[i].mean(), x[i].std()))
        ax[i].legend()
        ax[i].set_title(s[i])
    plt.savefig('targets.jpg', dpi=200)


def plot_study_txt(path='', x=None):  # from utils.plots import *; plot_study_txt()
    # Plot study.txt generated by test.py
    fig, ax = plt.subplots(2, 4, figsize=(10, 6), tight_layout=True)
    # ax = ax.ravel()

    fig2, ax2 = plt.subplots(1, 1, figsize=(8, 4), tight_layout=True)
    # for f in [Path(path) / f'study_coco_{x}.txt' for x in ['yolov5s6', 'yolov5m6', 'yolov5l6', 'yolov5x6']]:
    for f in sorted(Path(path).glob('study*.txt')):
        y = np.loadtxt(f, dtype=np.float32, usecols=[0, 1, 2, 3, 7, 8, 9], ndmin=2).T
        x = np.arange(y.shape[1]) if x is None else np.array(x)
        s = ['P', 'R', 'mAP@.5', 'mAP@.5:.95', 't_inference (ms/img)', 't_NMS (ms/img)', 't_total (ms/img)']
        # for i in range(7):
        #     ax[i].plot(x, y[i], '.-', linewidth=2, markersize=8)
        #     ax[i].set_title(s[i])

        j = y[3].argmax() + 1
        ax2.plot(y[6, 1:j], y[3, 1:j] * 1E2, '.-', linewidth=2, markersize=8,
                 label=f.stem.replace('study_coco_', '').replace('yolo', 'YOLO'))

    ax2.plot(1E3 / np.array([209, 140, 97, 58, 35, 18]), [34.6, 40.5, 43.0, 47.5, 49.7, 51.5],
             'k.-', linewidth=2, markersize=8, alpha=.25, label='EfficientDet')

    ax2.grid(alpha=0.2)
    ax2.set_yticks(np.arange(20, 60, 5))
    ax2.set_xlim(0, 57)
    ax2.set_ylim(30, 55)
    ax2.set_xlabel('GPU Speed (ms/img)')
    ax2.set_ylabel('COCO AP val')
    ax2.legend(loc='lower right')
    plt.savefig(str(Path(path).name) + '.png', dpi=300)


def plot_labels(labels, names=(), save_dir=Path(''), loggers=None):
    # plot dataset labels
    print('Plotting labels... ')
    c, b = labels[:, 0], labels[:, 1:].transpose()  # classes, boxes
    nc = int(c.max() + 1)  # number of classes
    colors = color_list()
    x = pd.DataFrame(b.transpose(), columns=['x', 'y', 'width', 'height'])

    # seaborn correlogram
    sns.pairplot(x, corner=True, diag_kind='auto', kind='hist', diag_kws=dict(bins=50), plot_kws=dict(pmax=0.9))
    plt.savefig(save_dir / 'labels_correlogram.jpg', dpi=200)
    plt.close()

    # matplotlib labels
    matplotlib.use('svg')  # faster
    ax = plt.subplots(2, 2, figsize=(8, 8), tight_layout=True)[1].ravel()
    ax[0].hist(c, bins=np.linspace(0, nc, nc + 1) - 0.5, rwidth=0.8)
    ax[0].set_ylabel('instances')
    if 0 < len(names) < 30:
        ax[0].set_xticks(range(len(names)))
        ax[0].set_xticklabels(names, rotation=90, fontsize=10)
    else:
        ax[0].set_xlabel('classes')
    sns.histplot(x, x='x', y='y', ax=ax[2], bins=50, pmax=0.9)
    sns.histplot(x, x='width', y='height', ax=ax[3], bins=50, pmax=0.9)

    # rectangles
    labels[:, 1:3] = 0.5  # center
    labels[:, 1:] = xywh2xyxy(labels[:, 1:]) * 2000
    img = Image.fromarray(np.ones((2000, 2000, 3), dtype=np.uint8) * 255)
    for cls, *box in labels[:1000]:
        ImageDraw.Draw(img).rectangle(box, width=1, outline=colors[int(cls) % 10])  # plot
    ax[1].imshow(img)
    ax[1].axis('off')

    for a in [0, 1, 2, 3]:
        for s in ['top', 'right', 'left', 'bottom']:
            ax[a].spines[s].set_visible(False)

    plt.savefig(save_dir / 'labels.jpg', dpi=200)
    matplotlib.use('Agg')
    plt.close()

    # loggers
    for k, v in loggers.items() or {}:
        if k == 'wandb' and v:
            v.log({"Labels": [v.Image(str(x), caption=x.name) for x in save_dir.glob('*labels*.jpg')]}, commit=False)


def plot_evolution(yaml_file='data/hyp.finetune.yaml'):  # from utils.plots import *; plot_evolution()
    # Plot hyperparameter evolution results in evolve.txt
    with open(yaml_file) as f:
        hyp = yaml.load(f, Loader=yaml.SafeLoader)
    x = np.loadtxt('evolve.txt', ndmin=2)
    f = fitness(x)
    # weights = (f - f.min()) ** 2  # for weighted results
    plt.figure(figsize=(10, 12), tight_layout=True)
    matplotlib.rc('font', **{'size': 8})
    for i, (k, v) in enumerate(hyp.items()):
        y = x[:, i + 7]
        # mu = (y * weights).sum() / weights.sum()  # best weighted result
        mu = y[f.argmax()]  # best single result
        plt.subplot(6, 5, i + 1)
        plt.scatter(y, f, c=hist2d(y, f, 20), cmap='viridis', alpha=.8, edgecolors='none')
        plt.plot(mu, f.max(), 'k+', markersize=15)
        plt.title('%s = %.3g' % (k, mu), fontdict={'size': 9})  # limit to 40 characters
        if i % 5 != 0:
            plt.yticks([])
        print('%15s: %.3g' % (k, mu))
    plt.savefig('evolve.png', dpi=200)
    print('\nPlot saved as evolve.png')


def profile_idetection(start=0, stop=0, labels=(), save_dir=''):
    # Plot iDetection '*.txt' per-image logs. from utils.plots import *; profile_idetection()
    ax = plt.subplots(2, 4, figsize=(12, 6), tight_layout=True)[1].ravel()
    s = ['Images', 'Free Storage (GB)', 'RAM Usage (GB)', 'Battery', 'dt_raw (ms)', 'dt_smooth (ms)', 'real-world FPS']
    files = list(Path(save_dir).glob('frames*.txt'))
    for fi, f in enumerate(files):
        try:
            results = np.loadtxt(f, ndmin=2).T[:, 90:-30]  # clip first and last rows
            n = results.shape[1]  # number of rows
            x = np.arange(start, min(stop, n) if stop else n)
            results = results[:, x]
            t = (results[0] - results[0].min())  # set t0=0s
            results[0] = x
            for i, a in enumerate(ax):
                if i < len(results):
                    label = labels[fi] if len(labels) else f.stem.replace('frames_', '')
                    a.plot(t, results[i], marker='.', label=label, linewidth=1, markersize=5)
                    a.set_title(s[i])
                    a.set_xlabel('time (s)')
                    # if fi == len(files) - 1:
                    #     a.set_ylim(bottom=0)
                    for side in ['top', 'right']:
                        a.spines[side].set_visible(False)
                else:
                    a.remove()
        except Exception as e:
            print('Warning: Plotting error for %s; %s' % (f, e))

    ax[1].legend()
    plt.savefig(Path(save_dir) / 'idetection_profile.png', dpi=200)


def plot_results_overlay(start=0, stop=0):  # from utils.plots import *; plot_results_overlay()
    # Plot training 'results*.txt', overlaying train and val losses
    s = ['train', 'train', 'train', 'Precision', 'mAP@0.5', 'val', 'val', 'val', 'Recall', 'mAP@0.5:0.95']  # legends
    t = ['Box', 'Objectness', 'Classification', 'P-R', 'mAP-F1']  # titles
    for f in sorted(glob.glob('results*.txt') + glob.glob('../../Downloads/results*.txt')):
        results = np.loadtxt(f, usecols=[2, 3, 4, 8, 9, 12, 13, 14, 10, 11], ndmin=2).T
        n = results.shape[1]  # number of rows
        x = range(start, min(stop, n) if stop else n)
        fig, ax = plt.subplots(1, 5, figsize=(14, 3.5), tight_layout=True)
        ax = ax.ravel()
        for i in range(5):
            for j in [i, i + 5]:
                y = results[j, x]
                ax[i].plot(x, y, marker='.', label=s[j])
                # y_smooth = butter_lowpass_filtfilt(y)
                # ax[i].plot(x, np.gradient(y_smooth), marker='.', label=s[j])

            ax[i].set_title(t[i])
            ax[i].legend()
            ax[i].set_ylabel(f) if i == 0 else None  # add filename
        fig.savefig(f.replace('.txt', '.png'), dpi=200)


def plot_results(start=0, stop=0, bucket='', id=(), labels=(), save_dir=''):
    # Plot training 'results*.txt'. from utils.plots import *; plot_results(save_dir='runs/train/exp')
    fig, ax = plt.subplots(2, 5, figsize=(12, 6), tight_layout=True)
    ax = ax.ravel()
    s = ['Box', 'Objectness', 'Classification', 'Precision', 'Recall',
         'val Box', 'val Objectness', 'val Classification', 'mAP@0.5', 'mAP@0.5:0.95']
    if bucket:
        # files = ['https://storage.googleapis.com/%s/results%g.txt' % (bucket, x) for x in id]
        files = ['results%g.txt' % x for x in id]
        c = ('gsutil cp ' + '%s ' * len(files) + '.') % tuple('gs://%s/results%g.txt' % (bucket, x) for x in id)
        os.system(c)
    else:
        files = list(Path(save_dir).glob('results*.txt'))
    assert len(files), 'No results.txt files found in %s, nothing to plot.' % os.path.abspath(save_dir)
    for fi, f in enumerate(files):
        try:
            results = np.loadtxt(f, usecols=[2, 3, 4, 8, 9, 12, 13, 14, 10, 11], ndmin=2).T
            n = results.shape[1]  # number of rows
            x = range(start, min(stop, n) if stop else n)
            for i in range(10):
                y = results[i, x]
                if i in [0, 1, 2, 5, 6, 7]:
                    y[y == 0] = np.nan  # don't show zero loss values
                    # y /= y[0]  # normalize
                label = labels[fi] if len(labels) else f.stem
                ax[i].plot(x, y, marker='.', label=label, linewidth=2, markersize=8)
                ax[i].set_title(s[i])
                # if i in [5, 6, 7]:  # share train and val loss y axes
                #     ax[i].get_shared_y_axes().join(ax[i], ax[i - 5])
        except Exception as e:
            print('Warning: Plotting error for %s; %s' % (f, e))

    ax[1].legend()
    fig.savefig(Path(save_dir) / 'results.png', dpi=200)

===== .\utils\utils\torch_utils.py =====
功能: 代码摘录
# YOLOv5 PyTorch utils

import datetime
import logging
import math
import os
import platform
import subprocess
import time
from contextlib import contextmanager
from copy import deepcopy
from pathlib import Path

import torch
import torch.backends.cudnn as cudnn
import torch.nn as nn
import torch.nn.functional as F
import torchvision

try:
    import thop  # for FLOPS computation
except ImportError:
    thop = None
logger = logging.getLogger(__name__)


@contextmanager
def torch_distributed_zero_first(local_rank: int):
    """
    Decorator to make all processes in distributed training wait for each local_master to do something.
    """
    if local_rank not in [-1, 0]:
        torch.distributed.barrier()
    yield
    if local_rank == 0:
        torch.distributed.barrier()


def init_torch_seeds(seed=0):
    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html
    torch.manual_seed(seed)
    if seed == 0:  # slower, more reproducible
        cudnn.benchmark, cudnn.deterministic = False, True
    else:  # faster, less reproducible
        cudnn.benchmark, cudnn.deterministic = True, False


def date_modified(path=__file__):
    # return human-readable file modification date, i.e. '2021-3-26'
    t = datetime.datetime.fromtimestamp(Path(path).stat().st_mtime)
    return f'{t.year}-{t.month}-{t.day}'


def git_describe(path=Path(__file__).parent):  # path must be a directory
    # return human-readable git description, i.e. v5.0-5-g3e25f1e https://git-scm.com/docs/git-describe
    s = f'git -C {path} describe --tags --long --always'
    try:
        return subprocess.check_output(s, shell=True, stderr=subprocess.STDOUT).decode()[:-1]
    except subprocess.CalledProcessError as e:
        return ''  # not a git repository


def select_device(device='', batch_size=None):
    # device = 'cpu' or '0' or '0,1,2,3'
    s = f'YOLOv5 🚀 {git_describe() or date_modified()} torch {torch.__version__} '  # string
    cpu = device.lower() == 'cpu'
    if cpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False
    elif device:  # non-cpu device requested
        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable
        assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # check availability

    cuda = not cpu and torch.cuda.is_available()
    if cuda:
        n = torch.cuda.device_count()
        if n > 1 and batch_size:  # check that batch_size is compatible with device_count
            assert batch_size % n == 0, f'batch-size {batch_size} not multiple of GPU count {n}'
        space = ' ' * len(s)
        for i, d in enumerate(device.split(',') if device else range(n)):
            p = torch.cuda.get_device_properties(i)
            s += f"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / 1024 ** 2}MB)\n"  # bytes to MB
    else:
        s += 'CPU\n'

    logger.info(s.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else s)  # emoji-safe
    return torch.device('cuda:0' if cuda else 'cpu')


def time_synchronized():
    # pytorch-accurate time
    if torch.cuda.is_available():
        torch.cuda.synchronize()
    return time.time()


def profile(x, ops, n=100, device=None):
    # profile a pytorch module or list of modules. Example usage:
    #     x = torch.randn(16, 3, 640, 640)  # input
    #     m1 = lambda x: x * torch.sigmoid(x)
    #     m2 = nn.SiLU()
    #     profile(x, [m1, m2], n=100)  # profile speed over 100 iterations

    device = device or torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    x = x.to(device)
    x.requires_grad = True
    print(torch.__version__, device.type, torch.cuda.get_device_properties(0) if device.type == 'cuda' else '')
    print(f"\n{'Params':>12s}{'GFLOPS':>12s}{'forward (ms)':>16s}{'backward (ms)':>16s}{'input':>24s}{'output':>24s}")
    for m in ops if isinstance(ops, list) else [ops]:
        m = m.to(device) if hasattr(m, 'to') else m  # device
        m = m.half() if hasattr(m, 'half') and isinstance(x, torch.Tensor) and x.dtype is torch.float16 else m  # type
        dtf, dtb, t = 0., 0., [0., 0., 0.]  # dt forward, backward
        try:
            flops = thop.profile(m, inputs=(x,), verbose=False)[0] / 1E9 * 2  # GFLOPS
        except:
            flops = 0

        for _ in range(n):
            t[0] = time_synchronized()
            y = m(x)
            t[1] = time_synchronized()
            try:
                _ = y.sum().backward()
                t[2] = time_synchronized()
            except:  # no backward method
                t[2] = float('nan')
            dtf += (t[1] - t[0]) * 1000 / n  # ms per op forward
            dtb += (t[2] - t[1]) * 1000 / n  # ms per op backward

        s_in = tuple(x.shape) if isinstance(x, torch.Tensor) else 'list'
        s_out = tuple(y.shape) if isinstance(y, torch.Tensor) else 'list'
        p = sum(list(x.numel() for x in m.parameters())) if isinstance(m, nn.Module) else 0  # parameters
        print(f'{p:12}{flops:12.4g}{dtf:16.4g}{dtb:16.4g}{str(s_in):>24s}{str(s_out):>24s}')


def is_parallel(model):
    return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)


def intersect_dicts(da, db, exclude=()):
    # Dictionary intersection of matching keys and shapes, omitting 'exclude' keys, using da values
    return {k: v for k, v in da.items() if k in db and not any(x in k for x in exclude) and v.shape == db[k].shape}


def initialize_weights(model):
    for m in model.modules():
        t = type(m)
        if t is nn.Conv2d:
            pass  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        elif t is nn.BatchNorm2d:
            m.eps = 1e-3
            m.momentum = 0.03
        elif t in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6]:
            m.inplace = True


def find_modules(model, mclass=nn.Conv2d):
    # Finds layer indices matching module class 'mclass'
    return [i for i, m in enumerate(model.module_list) if isinstance(m, mclass)]


def sparsity(model):
    # Return global model sparsity
    a, b = 0., 0.
    for p in model.parameters():
        a += p.numel()
        b += (p == 0).sum()
    return b / a


def prune(model, amount=0.3):
    # Prune model to requested global sparsity
    import torch.nn.utils.prune as prune
    print('Pruning model... ', end='')
    for name, m in model.named_modules():
        if isinstance(m, nn.Conv2d):
            prune.l1_unstructured(m, name='weight', amount=amount)  # prune
            prune.remove(m, 'weight')  # make permanent
    print(' %.3g global sparsity' % sparsity(model))


def fuse_conv_and_bn(conv, bn):
    # Fuse convolution and batchnorm layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/
    fusedconv = nn.Conv2d(conv.in_channels,
                          conv.out_channels,
                          kernel_size=conv.kernel_size,
                          stride=conv.stride,
                          padding=conv.padding,
                          groups=conv.groups,
                          bias=True).requires_grad_(False).to(conv.weight.device)

    # prepare filters
    w_conv = conv.weight.clone().view(conv.out_channels, -1)
    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))
    fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.shape))

    # prepare spatial bias
    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias
    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))
    fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)

    return fusedconv


def model_info(model, verbose=False, img_size=640):
    # Model information. img_size may be int or list, i.e. img_size=640 or img_size=[640, 320]
    n_p = sum(x.numel() for x in model.parameters())  # number parameters
    n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  # number gradients
    if verbose:
        print('%5s %40s %9s %12s %20s %10s %10s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))
        for i, (name, p) in enumerate(model.named_parameters()):
            name = name.replace('module_list.', '')
            print('%5g %40s %9s %12g %20s %10.3g %10.3g' %
                  (i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))

    try:  # FLOPS
        from thop import profile
        stride = max(int(model.stride.max()), 32) if hasattr(model, 'stride') else 32
        img = torch.zeros((1, model.yaml.get('ch', 3), stride, stride), device=next(model.parameters()).device)  # input
        flops = profile(deepcopy(model), inputs=(img,), verbose=False)[0] / 1E9 * 2  # stride GFLOPS
        img_size = img_size if isinstance(img_size, list) else [img_size, img_size]  # expand if int/float
        fs = ', %.1f GFLOPS' % (flops * img_size[0] / stride * img_size[1] / stride)  # 640x640 GFLOPS
    except (ImportError, Exception):
        fs = ''

    logger.info(f"Model Summary: {len(list(model.modules()))} layers, {n_p} parameters, {n_g} gradients{fs}")


def load_classifier(name='resnet101', n=2):
    # Loads a pretrained model reshaped to n-class output
    model = torchvision.models.__dict__[name](pretrained=True)

    # ResNet model properties
    # input_size = [3, 224, 224]
    # input_space = 'RGB'
    # input_range = [0, 1]
    # mean = [0.485, 0.456, 0.406]
    # std = [0.229, 0.224, 0.225]

    # Reshape output to n classes
    filters = model.fc.weight.shape[1]
    model.fc.bias = nn.Parameter(torch.zeros(n), requires_grad=True)
    model.fc.weight = nn.Parameter(torch.zeros(n, filters), requires_grad=True)
    model.fc.out_features = n
    return model


def scale_img(img, ratio=1.0, same_shape=False, gs=32):  # img(16,3,256,416)
    # scales img(bs,3,y,x) by ratio constrained to gs-multiple
    if ratio == 1.0:
        return img
    else:
        h, w = img.shape[2:]
        s = (int(h * ratio), int(w * ratio))  # new size
        img = F.interpolate(img, size=s, mode='bilinear', align_corners=False)  # resize
        if not same_shape:  # pad/crop img
            h, w = [math.ceil(x * ratio / gs) * gs for x in (h, w)]
        return F.pad(img, [0, w - s[1], 0, h - s[0]], value=0.447)  # value = imagenet mean


def copy_attr(a, b, include=(), exclude=()):
    # Copy attributes from b to a, options to only include [...] and to exclude [...]
    for k, v in b.__dict__.items():
        if (len(include) and k not in include) or k.startswith('_') or k in exclude:
            continue
        else:
            setattr(a, k, v)


class ModelEMA:
    """ Model Exponential Moving Average from https://github.com/rwightman/pytorch-image-models
    Keep a moving average of everything in the model state_dict (parameters and buffers).
    This is intended to allow functionality like
    https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage
    A smoothed version of the weights is necessary for some training schemes to perform well.
    This class is sensitive where it is initialized in the sequence of model init,
    GPU assignment and distributed training wrappers.
    """

    def __init__(self, model, decay=0.9999, updates=0):
        # Create EMA
        self.ema = deepcopy(model.module if is_parallel(model) else model).eval()  # FP32 EMA
        # if next(model.parameters()).device.type != 'cpu':
        #     self.ema.half()  # FP16 EMA
        self.updates = updates  # number of EMA updates
        self.decay = lambda x: decay * (1 - math.exp(-x / 2000))  # decay exponential ramp (to help early epochs)
        for p in self.ema.parameters():
            p.requires_grad_(False)

    def update(self, model):
        # Update EMA parameters
        with torch.no_grad():
            self.updates += 1
            d = self.decay(self.updates)

            msd = model.module.state_dict() if is_parallel(model) else model.state_dict()  # model state_dict
            for k, v in self.ema.state_dict().items():
                if v.dtype.is_floating_point:
                    v *= d
                    v += (1. - d) * msd[k].detach()

    def update_attr(self, model, include=(), exclude=('process_group', 'reducer')):
        # Update EMA attributes
        copy_attr(self.ema, model, include, exclude)

===== .\uv_ai\package.xml =====
功能: 代码摘录
<?xml version="1.0"?>
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
<package format="3">
  <name>uv_ai</name>
  <version>0.0.0</version>
  <description>TODO: Package description</description>
  <maintainer email="macabaka@todo.todo">macabaka</maintainer>
  <license>TODO: License declaration</license>

  <depend>rclpy</depend>

  <test_depend>ament_copyright</test_depend>
  <test_depend>ament_flake8</test_depend>
  <test_depend>ament_pep257</test_depend>
  <test_depend>python3-pytest</test_depend>

  <exec_depend>tutorial_interfaces</exec_depend>
  
  <export>
    <build_type>ament_python</build_type>
  </export>
</package>

===== .\uv_ai\setup.cfg =====
功能: 代码摘录
[develop]
script_dir=$base/lib/uv_ai
[install]
install_scripts=$base/lib/uv_ai

===== .\uv_ai\setup.py =====
功能: 代码摘录
from setuptools import setup

package_name = 'uv_ai'

setup(
    name=package_name,
    version='0.0.0',
    packages=[package_name],
    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),
        ('share/' + package_name, ['package.xml']),
    ],
    install_requires=['setuptools'],
    zip_safe=True,
    maintainer='macabaka',
    maintainer_email='macabaka@todo.todo',
    description='TODO: Package description',
    license='TODO: License declaration',
    tests_require=['pytest'],
    entry_points={
        'console_scripts': [
            "uv_detect = uv_ai.uv_detect:main",
            "uv_detect_test = uv_ai.uv_detect_test:main",
            "uv_automation = uv_ai.uv_automaton:main",
            "uv_detect_demo = uv_ai.uv_detect_demo:main",
            "uv_segment = uv_ai.uv_segment:main",
        ],
    },
)

===== .\uv_ai\test\test_copyright.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_copyright.main import main
import pytest


# Remove the `skip` decorator once the source file(s) have a copyright header
@pytest.mark.skip(reason='No copyright header has been placed in the generated source file.')
@pytest.mark.copyright
@pytest.mark.linter
def test_copyright():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found errors'

===== .\uv_ai\test\test_flake8.py =====
功能: 代码摘录
# Copyright 2017 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_flake8.main import main_with_errors
import pytest


@pytest.mark.flake8
@pytest.mark.linter
def test_flake8():
    rc, errors = main_with_errors(argv=[])
    assert rc == 0, \
        'Found %d code style errors / warnings:\n' % len(errors) + \
        '\n'.join(errors)

===== .\uv_ai\test\test_pep257.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_pep257.main import main
import pytest


@pytest.mark.linter
@pytest.mark.pep257
def test_pep257():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found code style errors / warnings'

===== .\uv_ai\uv_ai\__init__.py =====
功能: 代码摘录

===== .\uv_ai\uv_ai\uv_auto_tuning_close_loop.py =====
功能: 代码摘录
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
水下机器人全自动推力曲线调整系统
功能：通过开环控制测试电机推力，自动调整推力曲线参数，使机器人运动更平滑
电机编号：0(左上)，1(右上)，2(左垂推)，3(右垂推)，4(左后)，5(右后)
"""

import rclpy
from rclpy.node import Node
import time
import math
from math import cos, radians
import json
import numpy as np
from collections import deque
import signal  # 添加信号处理

from uv_msgs.msg import RobotAxis, RobotMotionController, ThrustCurve, ThrustCurves, TargetPosDown
from uv_control_py import Curve
from uv_control_py import Serial


AllowedError = {  # 位置容许误差
    "x": 0.02,
    "y": 0.02,
    "z": 0.02,
    "rz": 1.3
}

Trust_List=[-1500, -750, 0, 750, 1500]

kp = 5

class AutoThrustTuner(Node):
    def __init__(self, name):
        super().__init__(name)
        self.get_logger().info("全自动推力曲线调整器初始化中...")
        
        # 初始化参数
        self.initialize_parameters()
        
        # 设置信号处理，用于紧急停止
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
        
        # 订阅机器人运动状态
        self.motion_sub = self.create_subscription(
            RobotMotionController, "motion_controller", self.motion_callback, 10)
        
        # 创建发布者，用于发布调整后的推力曲线
        self.curve_pub = self.create_publisher(ThrustCurves, "curves", 10)
        
        # 创建开环推力发布者
        self.thrust_pub = self.create_publisher(RobotAxis, "openloop_thrust", 10)

        # 创建目标位置发布者
        self.target_pos_down_pub = self.create_publisher(TargetPosDown, "target_pos_down", 10)
        
        # 初始化曲线管理器
        self.initialize_curve_manager()
        
        self.get_logger().info("全自动推力曲线调整器初始化完成！")

        # 等待移动至指定位置
    def move_wait(self):
        cnt = 0
        time.sleep(0.5)
        while True:
            judge = 0
            if abs(self.current_motion.tpos_inbase.x) > AllowedError["x"]:
                judge += 1
            if abs(self.current_motion.tpos_inbase.y) > AllowedError["y"]:
                judge += 1
            if abs(self.current_motion.tpos_inbase.z) > AllowedError["z"]:
                judge += 1
            if abs(self.current_motion.tpos_inbase.rz) > AllowedError["rz"]:
                judge += 1

            if judge == 0:  # 进入容许范围
                return True

            if cnt > 200:  # 超时退出
                return False

            cnt += 1
            time.sleep(0.05)

    def move_to_pos(self, pos):

        if self.should_stop:
            return False

        distance = abs(pos - self.current_motion.tpos_inbase.z)
        self.get_logger().info(f"移动到位置 {pos}，距离 {distance}")
        times = distance / 0.1
        for i in range(int(times)):
            self.target_pos_down_pub.publish(TargetPosDown(target_pos=pos))
            self.move_wait()
        self.move_wait()
        num = 0
        while True:
            if abs(pos - self.current_motion.tpos_inbase.z) < 0.02:
                num += 1
            time.sleep(0.5)
            if num > 3:
                break
        self.get_logger().info("到达目标位置")



    
    def signal_handler(self, signum, frame):
        """信号处理函数，用于紧急停止"""
        self.get_logger().info(f"收到信号 {signum}，执行紧急停止")
        self.emergency_stop()
        
    def emergency_stop(self):
        """紧急停止所有电机"""
        self.get_logger().info("执行紧急停止！")
        
        # 立即停止所有推力
        stop_msg = RobotAxis()
        stop_msg.x = 0
        stop_msg.y = 0
        stop_msg.z = 0
        stop_msg.rz = 0
        self.thrust_pub.publish(stop_msg)        
        # 保存当前状态
        self.save_state()
        
        # 设置停止标志
        self.should_stop = True
        
        self.get_logger().info("紧急停止完成，状态已保存")
    
    def initialize_parameters(self):
        """初始化所有必要的参数"""
        # 电机编号定义
        self.motor_pairs = [(0, 1), (1, 5), (5, 4)]  # 需要调整的电机对
        self.motor_positions = ["左上", "右上", "左垂推", "右垂推", "左后", "右后"]
        
        # 测试参数
        self.test_force_range = range(0, -1600, -100)  # 测试推力范围新这个地方要改
        self.stabilization_time = 0.5  # 稳定时间(秒)
        self.test_duration = 0.1  # 测试时间(秒)
        
        # 当前机器人状态
        self.current_motion = None
        self.test_results = {}
        
        # 中断和恢复相关状态
        self.current_motor_pair_index = 0  # 当前正在调整的电机对索引
        self.current_force_index = 0       # 当前正在测试的推力索引
        self.is_paused = False             # 是否暂停状态
        self.should_stop = False           # 是否应该停止
    
    def initialize_curve_manager(self):
        """初始化推力曲线管理器"""
        # 获取曲线文件路径
        self.curve_path = '/home/nvidia/Workspace/Cruise/datas/thrust_cureves.json'
        
        # 创建串口写入器（这里不实际使用，仅为了初始化Curve类）
        dummy_serial = type('obj', (object,), {"write": lambda *args: None})
        
        # 初始化曲线管理器
        self.curve_manager = Curve.CURVE(dummy_serial, self.curve_path)
        
        # 加载当前曲线参数
        try:
            self.curve_manager.fileread()
            self.get_logger().info(f"成功加载推力曲线参数文件: {self.curve_path}")
        except Exception as e:
            self.get_logger().error(f"加载推力曲线参数失败: {e}")
            # 使用默认参数
            self.curve_manager.curves_dic = Curve.CURVE_DIC_INIT
            self.curve_manager.dic2class()
    
    def motion_callback(self, data):
        """接收机器人运动状态数据"""
        self.current_motion = data
    
    def set_motor_zero(self, exclude_pair=None):
        """将除指定电机对外的所有电机推力设为0"""
        # 使用零推力曲线参数
        zero_curves = self.curve_manager.curves_dic.copy()
        
        # 如果指定了电机对，则不将这对电机设为零
        if exclude_pair:
            # 恢复指定电机对的原始参数
            for motor_idx in exclude_pair:
                motor_name = f"m{motor_idx}"
                zero_curves[motor_name] = self.curve_manager.curves_dic[motor_name].copy()
        
        # 更新曲线参数
        self.curve_manager.curves_dic = zero_curves
        self.curve_manager.dic2class()
        
        # 保存曲线
        self.apply_curves()
    
    def apply_thrust(self, motor_pair, force):
        """对指定电机对施加推力，通过整体控制指令间接实现单个电机的控制"""
        if self.should_stop:
            stop_msg = RobotAxis()
            stop_msg.x = 0
            stop_msg.y = 0
            stop_msg.rz = 0
            self.thrust_pub.publish(stop_msg)
            return False
        # 发布开环推力指令
        thrust_msg = RobotAxis()
        
        # 用户需求：控制单个电机的推力，通过force反推向下位机发送的总体推力
        # 因为程序架构里没有设计上位机直接控制单个电机的功能
        # 所以我们需要通过整体控制指令来间接实现单个电机的控制
        
        # 定义常量
        A1 = 0.20489
        A2 = 0.19341
        B = 0.45725
        C = 0.20475
        
        # 根据电机对和目标推力，计算需要的6自由度指令
        # 对于每个电机对，我们通过组合不同的自由度指令来实现单个电机的控制
        if motor_pair == (0, 1):  # 左右上电机
            # 目标：控制电机0的推力为force，电机1的推力为0
            # 根据推力分配公式：
            # motor0 = -A2*x/B + C*y + rz/B
            # motor1 = A2*x/B + C*y - rz/B
            
            # 解方程组：
            # -A2*x/B + C*y + rz/B = force
            # A2*x/B + C*y - rz/B = 0
            # 将两个方程相加：2*C*y = force → y = force/(2*C)
            # 将两个方程相减：-2*A2*x/B + 2*rz/B = force → -A2*x + rz = force*B/2
            # 我们选择x=0，这样rz = force*B/2
            
            y = force / (2 * C)
            rz = force * B / 2
            
            # 设置推力指令
            thrust_msg.y = y
            thrust_msg.rz = rz
            
        elif motor_pair == (1, 5):  # 右上前后电机
            # 目标：控制电机1的推力为force，电机5的推力为0
            # 根据推力分配公式：
            # motor1 = A2*x/B + C*y - rz/B
            # motor5 = A1*x/B - C*y + rz/B
            
            # 解方程组：
            # A2*x/B + C*y - rz/B = force
            # A1*x/B - C*y + rz/B = 0
            # 将两个方程相加：(A2+A1)*x/B = force → x = force*B/(A2+A1)
            # 将两个方程相减：2*C*y - 2*rz/B = force → C*y - rz/B = force/2
            # 我们选择y=0，这样rz = -force*B/2
            
            x = force * B / (A2 + A1)
            rz = -force * B / 2
            
            # 设置推力指令
            thrust_msg.x = x
            thrust_msg.rz = rz
            
        elif motor_pair == (5, 4):  # 左右后电机
            # 目标：控制电机5的推力为force，电机4的推力为0
            # 根据推力分配公式：
            # motor5 = A1*x/B - C*y + rz/B
            # motor4 = -A1*x/B - C*y - rz/B
            
            # 解方程组：
            # A1*x/B - C*y + rz/B = force
            # -A1*x/B - C*y - rz/B = 0
            # 将两个方程相加：-2*C*y = force → y = -force/(2*C)
            # 将两个方程相减：2*A1*x/B + 2*rz/B = force → A1*x + rz = force*B/2
            # 我们选择x=0，这样rz = force*B/2
            
            y = -force / (2 * C)
            rz = force * B / 2
            
            # 设置推力指令
            thrust_msg.y = y
            thrust_msg.rz = rz
        
        # 发布推力指令
        self.thrust_pub.publish(thrust_msg)
    
    def apply_equal_thrust(self, motor_pair, force):
        """对指定电机对施加相同的推力，通过整体控制指令间接实现"""

        if self.should_stop:
            return False
        # 发布开环推力指令
        thrust_msg = RobotAxis()
        
        # 定义常量
        A1 = 0.20489
        A2 = 0.19341
        B = 0.45725
        C = 0.20475
        
        # 根据电机对和目标推力，计算需要的6自由度指令
        # 目标：使电机对中的两个电机都产生相同的推力 force
        if motor_pair == (0, 1):  # 左右上电机
            # 目标：控制电机0和电机1的推力都为force
            # 根据推力分配公式：
            # motor0 = -A2*x/B + C*y + rz/B = force
            # motor1 = A2*x/B + C*y - rz/B = force
            
            # 解方程组：
            # -A2*x/B + C*y + rz/B = force
            # A2*x/B + C*y - rz/B = force
            # 将两个方程相加：2*C*y = 2*force → y = force/C
            # 将两个方程相减：-2*A2*x/B + 2*rz/B = 0 → -A2*x + rz = 0 → rz = A2*x
            # 我们可以选择x=0，这样rz=0，简化控制
            
            y = force / C
            
            # 设置推力指令
            thrust_msg.y = y
            
        elif motor_pair == (1, 5):  # 右上前后电机
            # 目标：控制电机1和电机5的推力都为force
            # 根据推力分配公式：
            # motor1 = A2*x/B + C*y - rz/B = force
            # motor5 = A1*x/B - C*y + rz/B = force
            
            # 解方程组：
            # A2*x/B + C*y - rz/B = force
            # A1*x/B - C*y + rz/B = force
            # 将两个方程相加：(A2+A1)*x/B = 2*force → x = 2*force*B/(A2+A1)
            # 将两个方程相减：2*C*y - 2*rz/B = 0 → C*y = rz/B → rz = B*C*y
            # 我们可以选择y=0，这样rz=0，简化控制
            
            x = 2 * force * B / (A2 + A1)
            
            # 设置推力指令
            thrust_msg.x = x
            
        elif motor_pair == (5, 4):  # 左右后电机
            # 目标：控制电机5和电机4的推力都为force
            # 根据推力分配公式：
            # motor5 = A1*x/B - C*y + rz/B = force
            # motor4 = -A1*x/B - C*y - rz/B = force
            
            # 解方程组：
            # A1*x/B - C*y + rz/B = force
            # -A1*x/B - C*y - rz/B = force
            # 将两个方程相加：-2*C*y = 2*force → y = -force/C
            # 将两个方程相减：2*A1*x/B + 2*rz/B = 0 → A1*x + rz = 0 → rz = -A1*x
            # 我们可以选择x=0，这样rz=0，简化控制
            
            y = -force / C
            
            # 设置推力指令
            thrust_msg.y = y
        
        # 发布推力指令
        self.thrust_pub.publish(thrust_msg)

    def measure_angular_acceleration(self):
        """
        测量角加速度
        过程将持续test_duration秒
        """
        # 记录初始角速度
        initial_rz = self.current_motion.imu.spd.rz if self.current_motion else 0.0
        
        # 记录开始时间
        start_time = time.time()
        
        # 收集数据
        rz_values = []
        times = []
        
        # 持续测试一段时间
        while time.time() - start_time < self.test_duration:
            if self.current_motion:
                rz_values.append(self.current_motion.imu.spd.rz)
                times.append(time.time() - start_time)
            time.sleep(0.01)  # 100Hz采样
        
        # 计算角加速度
        if len(rz_values) > 1:
            # 使用线性回归计算角加速度
            coeffs = np.polyfit(times, rz_values, 1)
            angular_acceleration = coeffs[0]  # 角速度变化率即为角加速度
        else:
            angular_acceleration = 0.0
        
        return angular_acceleration
    
    def measure_angular_velocity(self):
        """测量角速度"""
        # 记录初始角速度
        initial_rz = self.current_motion.imu.spd.rz if self.current_motion else 0.0
        
        # 记录开始时间
        start_time = time.time()
        
        # 收集数据
        rz_values = []
        times = []
        
        # 持续测试一段时间
        while time.time() - start_time < self.test_duration:
            if self.current_motion:
                rz_values.append(self.current_motion.imu.spd.rz)
                times.append(time.time() - start_time)
            time.sleep(0.01)  # 100Hz采样
        
        # 计算角速度
        if len(rz_values) > 1:
            # 使用线性回归计算角速度
            coeffs = np.polyfit(times, rz_values, 1)
            angular_velocity = coeffs[0]  # 角速度变化率即为角速度
        else:
            angular_velocity = 0.0
        
        return angular_velocity
    
    def thrust_allocate(self, askedthrust):
        """
        推力分配函数
        
        参数:
            askedthrust (list or np.array): 6个自由度的控制指令 [x, y, z, rx, ry, rz]
        
        返回:
            list: 分配给6个推进器的推力 [motor0, motor1, motor2, motor3, motor4, motor5]
        """
        # 定义常量
        __A_1 = 0.20489
        __A_2 = 0.19341
        __B = 0.45725
        __C = 0.20475
        __2b = 0.22000
        
        # 初始化电机推力数组
        motorthrust = [0.0] * 6
        
        # 根据C代码中的公式进行推力分配
        motorthrust[0] = -__A_2 * askedthrust[0] / __B + __C * askedthrust[1] + askedthrust[5] / __B
        motorthrust[1] = __A_2 * askedthrust[0] / __B + __C * askedthrust[1] - askedthrust[5] / __B
        motorthrust[2] = -0.5 * askedthrust[2] + askedthrust[4] / __2b
        motorthrust[3] = -0.5 * askedthrust[2] - askedthrust[4] / __2b
        motorthrust[4] = -__A_1 * askedthrust[0] / __B - __C * askedthrust[1] - askedthrust[5] / __B
        motorthrust[5] = __A_1 * askedthrust[0] / __B - __C * askedthrust[1] + askedthrust[5] / __B
        
        return motorthrust
    
    def thrust_deallocate(self, motor_thrusts, direction):
        """
        推力逆运算函数 - 从单个电机的推力反推某个方向上的整体推力
        
        参数:
            motor_thrusts (list): 6个推进器的推力 [motor0, motor1, motor2, motor3, motor4, motor5]
            direction (str): 要计算的方向，可选值为 'x', 'y', 'z', 'rx', 'ry', 'rz'
        
        返回:
            float: 指定方向上的整体推力
        """
        # 定义常量
        __A_1 = 0.20489
        __A_2 = 0.19341
        __B = 0.45725
        __C = 0.20475
        __2b = 0.22000
        
        # 方向索引映射
        direction_map = {'x': 0, 'y': 1, 'z': 2, 'rx': 3, 'ry': 4, 'rz': 5}
        
        if direction not in direction_map:
            self.get_logger().error(f"无效的方向: {direction}，可选值为 'x', 'y', 'z', 'rx', 'ry', 'rz'")
            return 0.0
        
        idx = direction_map[direction]
        
        # 根据不同方向计算整体推力
        if idx == 0:  # x方向
            # 从分配公式反解x方向的整体推力
            # 基于motor1和motor5的方程联立求解
            # (motor1 - motor5) = (2*__A_2 + 2*__A_1) * askedthrust[0] / __B
            # 所以 askedthrust[0] = (motor1 - motor5) * __B / (2*__A_2 + 2*__A_1)
            return (motor_thrusts[1] - motor_thrusts[5]) * __B / (2*__A_2 + 2*__A_1)
        
        elif idx == 1:  # y方向
            # 从分配公式反解y方向的整体推力
            # 基于motor0和motor4的方程联立求解
            # (motor0 + motor4) = 2*__C * askedthrust[1]
            # 所以 askedthrust[1] = (motor0 + motor4) / (2*__C)
            return (motor_thrusts[0] + motor_thrusts[4]) / (2*__C)
        
        elif idx == 2:  # z方向
            # 从分配公式反解z方向的整体推力
            # motor2 + motor3 = -askedthrust[2]
            return -(motor_thrusts[2] + motor_thrusts[3])
        
        elif idx == 4:  # ry方向 (绕y轴旋转)
            # 从分配公式反解ry方向的整体推力
            # motor2 - motor3 = 2*askedthrust[4] / __2b
            # 所以 askedthrust[4] = (motor2 - motor3) * __2b / 2
            return (motor_thrusts[2] - motor_thrusts[3]) * __2b / 2
        
        elif idx == 5:  # rz方向 (绕z轴旋转)
            # 从分配公式反解rz方向的整体推力
            # (motor0 + motor5 - motor1 - motor4) = 4*askedthrust[5] / __B
            # 所以 askedthrust[5] = (motor0 + motor5 - motor1 - motor4) * __B / 4
            return (motor_thrusts[0] + motor_thrusts[5] - motor_thrusts[1] - motor_thrusts[4]) * __B / 4
        
        else:  # rx方向 (绕x轴旋转)
            # 当前分配函数中没有直接涉及rx方向的控制
            self.get_logger().warning(f"当前推力分配函数中未直接涉及 '{direction}' 方向的控制")
            return 0.0
        
    def limit_parameters(self, params):
        """限制参数在合理范围内"""
        # PWM相关参数范围限制
        params['np_mid'] = max(2000.0, min(3000.0, params['np_mid']))
        params['np_ini'] = max(2500.0, min(3500.0, params['np_ini']))
        params['pp_ini'] = max(2500.0, min(3500.0, params['pp_ini']))
        params['pp_mid'] = max(3000.0, min(4000.0, params['pp_mid']))
        
        # 推力相关参数范围限制
        params['nt_end'] = max(-2000.0, min(-500.0, params['nt_end']))
        params['nt_mid'] = max(-1500.0, min(-250.0, params['nt_mid']))
        params['pt_mid'] = max(250.0, min(1500.0, params['pt_mid']))
        params['pt_end'] = max(500.0, min(2000.0, params['pt_end']))
    
    def save_curves(self):
        """保存并应用新的推力曲线"""
        try:
            # 保存到文件
            self.curve_manager.filesave()
            self.get_logger().info(f"已保存更新后的推力曲线参数到: {self.curve_path}")
            return True
        except Exception as e:
            self.get_logger().error(f"保存推力曲线失败: {e}")
            return False
    def apply_curves(self):
        """保存并应用新的推力曲线"""
        try:
            # 发布更新后的曲线，供其他节点使用
            self.curve_pub.publish(self.curve_manager.curves)
            self.get_logger().info("已发布更新后的推力曲线")
            
            return True
        except Exception as e:
            self.get_logger().error(f"应用推力曲线失败: {e}")
            return False
    
    def tune_motor_pair(self, motor_pair):
        """调整指定电机对的推力曲线，支持从中断点恢复"""
        self.get_logger().info(f"开始调整电机对 {motor_pair[0]}({self.motor_positions[motor_pair[0]]}) 和 {motor_pair[1]}({self.motor_positions[motor_pair[1]]}) ")
        
        # 将其他电机推力设为0
        self.set_motor_zero(exclude_pair=motor_pair)
        
        # 等待稳定
        time.sleep(1.0)
        

        self.get_logger().info("尝试回归原点")
        self.move_to_pos(0.0)

        # 等待回归完成
        time.sleep(1.0)

        force = Trust_List[0]

        self.get_logger().info(f"测试推力: {force}")
            
        # 使用apply_equal_thrust让两个电机输出相同的力
        self.apply_equal_thrust(motor_pair, force)

        num = 0
        times = 0

        #简易p控制器闭环控制
        index_map = {
            0: "pp_ini",
            1: "pp_mid",
            2: "pt_mid",
            3: "pt_end"
        }


        for i in range(4):

            index = index_map.get(i, "default_value")

            while True:
                # 检查是否应该中断
                if self.should_stop:
                    self.get_logger().info("收到停止信号，中断调整流程")
                    self.save_state()
                    return False
                
                # 检查是否应该暂停
                if self.is_paused:
                    self.get_logger().info("收到暂停信号，暂停调整流程")
                    self.save_state()
                    return True

                # 等待稳定
                time.sleep(0.5)
                # 测量角速度
                angular_velocity = self.measure_angular_velocity()
                self.get_logger().info(f"测量到的角速度: {angular_velocity}")
                # 计算误差
                error = abs(angular_velocity)

                if angular_velocity > 0.1:
                    #减小右侧推力
                    self.curve_manager.curves_dic[f"m{motor_pair[1]}"]["index"] -= kp * error
                    self.get_logger().info(f"调整后的pp_ini: {self.curve_manager.curves_dic[f'm{motor_pair[1]}']['index']}")

                elif angular_velocity < -0.1:
                    #增大右侧推力
                    self.curve_manager.curves_dic[f"m{motor_pair[1]}"]["index"] += kp * error
                    self.get_logger().info(f"调整后的pp_ini: {self.curve_manager.curves_dic[f'm{motor_pair[1]}']['index']}")

                else:
                    num += 1
                
                times += 1

                # 保存并应用新的推力曲线
                self.apply_curves()

                # 保存调整日志
                self.save_log()

                if num > 3:
                    break

                if times > 100:
                    self.get_logger().info("调整超时")
                    return False
                    
            
            self.get_logger().info("i调整完成")
            # 保存调整日志
            self.save_log()

        return True

    def run_tuning(self):
        """运行完整的推力曲线调整流程，支持中断和恢复"""
        try:
            # 尝试加载之前的状态
            state_loaded = self.load_state()
            
            # 如果没有加载到状态，从头开始
            if not state_loaded:
                self.current_motor_pair_index = 0
                self.current_force_index = 0
                self.test_results = {}
            
            # 依次调整各电机对，从中断点开始
            for i in range(self.current_motor_pair_index, len(self.motor_pairs)):
                motor_pair = self.motor_pairs[i]
                self.current_motor_pair_index = i  # 更新当前电机对索引
                
                # 检查是否应该中断
                if self.should_stop:
                    self.get_logger().info("收到停止信号，中断调整流程")
                    self.save_state()
                    break
                
                self.get_logger().info(f"开始调整第 {i+1}/{len(self.motor_pairs)} 组电机对: {motor_pair}")
                
                # 调整当前电机对，从中断的推力点开始
                result = self.tune_motor_pair(motor_pair)
                
                # 保存调整日志
                self.save_log()
                
                # 如果返回False表示完全停止，返回True表示暂停或完成
                if result is False:
                    self.get_logger().info("调整被中断")
                    self.save_state()
                    break
                


                # 如果不是最后一个电机对，询问用户是否继续
                if i < len(self.motor_pairs) - 1:
                    user_input = input("\n按回车键继续调整下一组电机对，输入 'pause' 暂停，输入 'quit' 退出: ")
                    
                    if user_input.strip().lower() == 'quit':
                        self.get_logger().info("用户请求退出调整流程")
                        self.should_stop = True
                        self.save_state()
                        # 保存调整日志
                        self.save_log()
                        break
                    elif user_input.strip().lower() == 'pause':
                        self.get_logger().info("用户请求暂停调整流程")
                        self.is_paused = True
                        self.save_state()
                        # 保存调整日志
                        self.save_log()
                        return  # 暂停并退出，等待下次继续
            
            # 如果所有电机对都调整完成
            if not self.should_stop and not self.is_paused:
                self.get_logger().info("所有电机对调整完成！")
                # 清除状态文件和备份文件
                try:
                    import os
                    state_file = '/home/nvidia/Workspace/Cruise/datas/tuning_state.json'
                    backup_file = '/home/nvidia/Workspace/Cruise/datas/tuning_state_backup.json'
                    
                    if os.path.exists(state_file):
                        os.remove(state_file)
                        self.get_logger().info("状态文件已清除")
                    
                    if os.path.exists(backup_file):
                        os.remove(backup_file)
                        self.get_logger().info("状态备份文件已清除")
                except Exception as e:
                    self.get_logger().error(f"清除状态文件失败: {e}")
            
        except Exception as e:
            self.get_logger().error(f"调整过程中发生错误: {e}")
            self.save_state()  # 出错时保存状态
        finally:
        # 立即停止所有推力
            stop_msg = RobotAxis()
            stop_msg.x = 0
            stop_msg.y = 0
            stop_msg.z = 0
            stop_msg.rz = 0
            self.thrust_pub.publish(stop_msg)   
            
            # 保存日志
            self.save_log()
    
    def resume_tuning(self):
        """恢复暂停的调整流程"""
        if not self.is_paused:
            self.get_logger().info("当前没有暂停的调整流程")
            return False
        
        self.get_logger().info("恢复调整流程")
        self.is_paused = False
        self.run_tuning()
        return True
    
    def stop_tuning(self):
        """停止调整流程"""
        self.get_logger().info("停止调整流程")
        self.should_stop = True
        self.save_state()

    def save_log(self):
        """保存调整日志到文件"""
        try:
            # 创建日志数据
            log_data = {
                'timestamp': time.time(),
                'current_motor_pair_index': self.current_motor_pair_index,
                'current_force_index': self.current_force_index,
                'is_paused': self.is_paused,
                'should_stop': self.should_stop,
                'motor_pairs': self.motor_pairs
            }
            
            with open('/home/nvidia/Workspace/Cruise/datas/tuning_log.json', 'w') as f:
                json.dump(log_data, f, indent=2)
            self.get_logger().info("调整日志已保存")
        except Exception as e:
            self.get_logger().error(f"保存调整日志失败: {e}")

def main(args=None):
    """主函数"""
    rclpy.init(args=args)
    node = AutoThrustTuner("uv_auto_thrust_tuner")
    
    # 解析命令行参数
    import argparse
    parser = argparse.ArgumentParser(description='水下机器人推力曲线自动调整系统')
    parser.add_argument('--resume', action='store_true', help='恢复暂停的调整流程')
    parser.add_argument('--stop', action='store_true', help='停止当前的调整流程')
    parser.add_argument('--status', action='store_true', help='显示当前调整状态')
    
    # 解析ROS参数
    args = parser.parse_args(rclpy.utilities.remove_ros_args())
    
    if args.stop:
        # 停止调整流程
        node.stop_tuning()
        node.get_logger().info("已发送停止信号")
    elif args.resume:
        # 恢复调整流程
        if node.resume_tuning():
            node.get_logger().info("调整流程已恢复")
        else:
            node.get_logger().info("没有可恢复的调整流程")
    elif args.status:
        # 显示状态
        node.load_state()
        node.get_logger().info(f"当前状态: 电机对索引={node.current_motor_pair_index}, 推力索引={node.current_force_index}, 暂停={node.is_paused}, 停止={node.should_stop}")
    else:
        # 运行调整流程
        node.run_tuning()
    
    # 关闭节点
    node.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()
    
#增加暂停功能，急停功能
#从一个电机的推力倒推整体推力，这样比较灵活
    def save_state(self):
        """保存当前状态到文件"""
        try:
            # 创建状态数据
            state = {
                'current_motor_pair_index': self.current_motor_pair_index,
                'current_force_index': self.current_force_index,
                'test_results': self.test_results,
                'motor_pairs': self.motor_pairs,
                'is_paused': self.is_paused,
                'should_stop': self.should_stop
            }
            
            # 状态文件路径
            state_file = '/home/nvidia/Workspace/Cruise/datas/tuning_state.json'
            backup_file = '/home/nvidia/Workspace/Cruise/datas/tuning_state_backup.json'
            
            # 如果状态文件已存在，创建备份
            import os
            if os.path.exists(state_file):
                try:
                    import shutil
                    shutil.copy2(state_file, backup_file)
                    self.get_logger().debug("状态文件备份已创建")
                except Exception as backup_error:
                    self.get_logger().warn(f"创建状态文件备份失败: {backup_error}")
            
            # 保存状态到文件
            with open(state_file, 'w') as f:
                json.dump(state, f, indent=2)
            self.get_logger().info(f"状态已保存到 {state_file}")
        except Exception as e:
            self.get_logger().error(f"保存状态失败: {e}")
            # 尝试保存到备份文件
            try:
                with open('/home/nvidia/Workspace/Cruise/datas/tuning_state_backup.json', 'w') as f:
                    json.dump(state, f, indent=2)
                self.get_logger().warn("状态已保存到备份文件")
            except Exception as backup_save_error:
                self.get_logger().error(f"保存状态到备份文件也失败了: {backup_save_error}")
    
    def load_state(self):
        """从文件加载状态"""
        state_file = '/home/nvidia/Workspace/Cruise/datas/tuning_state.json'
        backup_file = '/home/nvidia/Workspace/Cruise/datas/tuning_state_backup.json'
        
        # 尝试从主状态文件加载
        state = None
        try:
            with open(state_file, 'r') as f:
                state = json.load(f)
        except FileNotFoundError:
            self.get_logger().info("未找到状态文件，尝试从备份文件加载")
            # 尝试从备份文件加载
            try:
                with open(backup_file, 'r') as f:
                    state = json.load(f)
                self.get_logger().info("从备份文件成功加载状态")
            except FileNotFoundError:
                self.get_logger().info("未找到备份状态文件，从头开始调整")
                return False
            except Exception as backup_error:
                self.get_logger().error(f"从备份文件加载状态失败: {backup_error}")
                return False
        except Exception as e:
            self.get_logger().error(f"从主状态文件加载状态失败: {e}")
            return False
        
        # 验证状态数据
        if not isinstance(state, dict):
            self.get_logger().error("状态数据格式不正确")
            return False
        
        required_keys = ['current_motor_pair_index', 'current_force_index', 'test_results', 'motor_pairs']
        for key in required_keys:
            if key not in state:
                self.get_logger().error(f"状态数据缺少必要字段: {key}")
                return False
        
        # 加载状态
        try:
            self.current_motor_pair_index = state['current_motor_pair_index']
            self.current_force_index = state['current_force_index']
            self.test_results = state['test_results']
            self.motor_pairs = state['motor_pairs']
            
            # 加载可选状态
            self.is_paused = state.get('is_paused', False)
            self.should_stop = state.get('should_stop', False)
            
            self.get_logger().info(f"状态已加载: 电机对索引={self.current_motor_pair_index}, 推力索引={self.current_force_index}, 暂停={self.is_paused}, 停止={self.should_stop}")
            return True
        except Exception as e:
            self.get_logger().error(f"加载状态数据时发生错误: {e}")
            return False

===== .\uv_ai\uv_ai\uv_automation_v1.py =====
功能: 代码摘录
"""Modernised orchestration layer for the UV automaton node.

This module keeps behavioural parity with :mod:`uv_automaton` while providing
clearer structure around task dispatching and the interactive CLI utilities.
Low level motion / perception logic is reused by inheriting from the legacy
implementation.  The goal is to make it easier to maintain the behaviour
catalogue (task list) and related tooling without having to touch the lengthy
legacy file.
"""

from __future__ import annotations

import argparse
import json
import threading
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, Mapping, Optional, Sequence, Tuple

import rclpy

from . import uv_automaton as legacy

TaskPayload = Any
TaskHandler = Callable[[legacy.CoreNode, TaskPayload], None]


def _to_float(value: str) -> float:
    return float(value)


def _to_int(value: str) -> int:
    return int(value)


def _to_str(value: str) -> str:
    return value


@dataclass(frozen=True)
class ParameterSpec:
    """Specification for a command line parameter."""

    name: str
    converter: Callable[[str], Any]


@dataclass(frozen=True)
class TaskDescriptor:
    """Metadata describing how to execute and configure a task."""

    name: str
    handler: TaskHandler
    parameters: Tuple[ParameterSpec, ...] = field(default_factory=tuple)
    store_as_mapping: bool = True

    def build_payload(self, args: Sequence[str]) -> TaskPayload:
        """Convert CLI arguments into the payload expected by ``handler``."""
        if len(args) != len(self.parameters):
            raise ValueError(
                f"{self.name} 需要 {len(self.parameters)} 个参数, 实际得到 {len(args)} 个"
            )

        if not self.parameters:
            return {} if self.store_as_mapping else None

        converted = [spec.converter(arg) for spec, arg in zip(self.parameters, args)]

        if self.store_as_mapping:
            return {
                spec.name: value
                for spec, value in zip(self.parameters, converted)
            }

        if len(converted) == 1:
            return converted[0]

        return tuple(converted)

    def normalise_payload(self, raw: TaskPayload) -> TaskPayload:
        """Ensure a payload loaded from disk matches the expected shape."""
        if self.store_as_mapping:
            if raw is None:
                return {}
            if not isinstance(raw, Mapping):
                raise TypeError(f"{self.name} 需要字典参数, 当前为 {type(raw)!r}")
            return dict(raw)

        # 非映射参数允许直接传入数字或 None。
        return raw

    def execute(self, node: legacy.CoreNode, payload: TaskPayload) -> None:
        self.handler(node, payload)


def _build_default_registry() -> Dict[str, TaskDescriptor]:
    """Factory producing the default task registry used by ``CoreNode``."""

    def _bind_args(method_name: str, *arg_names: str) -> TaskHandler:
        def _run(node: legacy.CoreNode, params: Mapping[str, Any]) -> None:
            kwargs = {name: params[name] for name in arg_names}
            getattr(node, method_name)(**kwargs)

        return _run

    def _bind_direct(method_name: str) -> TaskHandler:
        def _run(node: legacy.CoreNode, value: Any) -> None:
            getattr(node, method_name)(value)

        return _run

    def _bind_no_args(method_name: str) -> TaskHandler:
        def _run(node: legacy.CoreNode, _: TaskPayload) -> None:
            getattr(node, method_name)()

        return _run

    return {
        "movexyz": TaskDescriptor(
            name="movexyz",
            handler=_bind_args("movexyz", "x", "y", "z"),
            parameters=(
                ParameterSpec("x", _to_float),
                ParameterSpec("y", _to_float),
                ParameterSpec("z", _to_float),
            ),
        ),
        "throw_golf": TaskDescriptor(
            name="throw_golf",
            handler=_bind_args("throw_golf", "dy", "depth"),
            parameters=(
                ParameterSpec("dy", _to_float),
                ParameterSpec("depth", _to_float),
            ),
        ),
        "movexy": TaskDescriptor(
            name="movexy",
            handler=_bind_args("movexy", "x", "y"),
            parameters=(
                ParameterSpec("x", _to_float),
                ParameterSpec("y", _to_float),
            ),
        ),
        "movex": TaskDescriptor(
            name="movex",
            handler=_bind_args("movex", "x"),
            parameters=(ParameterSpec("x", _to_float),),
        ),
        "movey": TaskDescriptor(
            name="movey",
            handler=_bind_args("movey", "y"),
            parameters=(ParameterSpec("y", _to_float),),
        ),
        "movez": TaskDescriptor(
            name="movez",
            handler=_bind_args("movez", "z"),
            parameters=(ParameterSpec("z", _to_float),),
        ),
        "moverz": TaskDescriptor(
            name="moverz",
            handler=_bind_args("moverz", "rz"),
            parameters=(ParameterSpec("rz", _to_float),),
        ),
        "setz": TaskDescriptor(
            name="setz",
            handler=_bind_args("setz", "z"),
            parameters=(ParameterSpec("z", _to_float),),
        ),
        "setrz": TaskDescriptor(
            name="setrz",
            handler=_bind_args("setrz", "rz"),
            parameters=(ParameterSpec("rz", _to_float),),
        ),
        "search": TaskDescriptor(
            name="search",
            handler=_bind_args("search", "name", "cam"),
            parameters=(
                ParameterSpec("name", _to_str),
                ParameterSpec("cam", _to_str),
            ),
        ),
        "mtty": TaskDescriptor(
            name="mtty",
            handler=_bind_args("mtty", "y", "z"),
            parameters=(
                ParameterSpec("y", _to_float),
                ParameterSpec("z", _to_float),
            ),
        ),
        "mttxf": TaskDescriptor(
            name="mttxf",
            handler=_bind_args("mttxf", "dx", "dy"),
            parameters=(
                ParameterSpec("dx", _to_float),
                ParameterSpec("dy", _to_float),
            ),
        ),
        "mttz": TaskDescriptor(
            name="mttz",
            handler=_bind_args("mttz", "y", "z"),
            parameters=(
                ParameterSpec("y", _to_float),
                ParameterSpec("z", _to_float),
            ),
        ),
        "mttzxy": TaskDescriptor(
            name="mttzxy",
            handler=_bind_args("mttzxy", "dz", "dx", "dy"),
            parameters=(
                ParameterSpec("dz", _to_float),
                ParameterSpec("dx", _to_float),
                ParameterSpec("dy", _to_float),
            ),
        ),
        "setp": TaskDescriptor(
            name="setp",
            handler=_bind_no_args("setp"),
            parameters=(),
        ),
        "back": TaskDescriptor(
            name="back",
            handler=_bind_no_args("back"),
            parameters=(),
        ),
        "backy": TaskDescriptor(
            name="backy",
            handler=_bind_no_args("backy"),
            parameters=(),
        ),
        "pow": TaskDescriptor(
            name="pow",
            handler=_bind_direct("pow"),
            parameters=(ParameterSpec("value", _to_int),),
            store_as_mapping=False,
        ),
        "line": TaskDescriptor(
            name="line",
            handler=_bind_args("line", "ys_dep"),
            parameters=(ParameterSpec("ys_dep", _to_float),),
        ),
        "graball": TaskDescriptor(
            name="graball",
            handler=_bind_args("graball", "color", "depth", "timeout", "pr", "k", "step_time"),
            parameters=(
                ParameterSpec("color", _to_str),
                ParameterSpec("depth", _to_float),
                ParameterSpec("timeout", _to_float),
                ParameterSpec("pr", _to_float),
                ParameterSpec("k", _to_float),
                ParameterSpec("step_time", _to_float),
            ),
        ),
        "thrball": TaskDescriptor(
            name="thrball",
            handler=_bind_args("thrball", "pr", "timeout", "k", "step_time"),
            parameters=(
                ParameterSpec("pr", _to_float),
                ParameterSpec("timeout", _to_float),
                ParameterSpec("k", _to_float),
                ParameterSpec("step_time", _to_float),
            ),
        ),
        "pass_door": TaskDescriptor(
            name="pass_door",
            handler=_bind_args("pass_door", "num"),
            parameters=(ParameterSpec("num", _to_int),),
        ),
        "mttpos": TaskDescriptor(
            name="mttpos",
            handler=_bind_args("mttpos", "x", "y", "z", "rz", "dy"),
            parameters=(
                ParameterSpec("x", _to_float),
                ParameterSpec("y", _to_float),
                ParameterSpec("z", _to_float),
                ParameterSpec("rz", _to_float),
                ParameterSpec("dy", _to_float),
            ),
        ),
        "mttzpos_amend": TaskDescriptor(
            name="mttzpos_amend",
            handler=_bind_args("mttzpos_amend", "x", "y", "z", "dy"),
            parameters=(
                ParameterSpec("x", _to_float),
                ParameterSpec("y", _to_float),
                ParameterSpec("z", _to_float),
                ParameterSpec("dy", _to_float),
            ),
        ),
        "mttpos_amend": TaskDescriptor(
            name="mttpos_amend",
            handler=_bind_args("mttpos_amend", "x", "y", "z", "rz", "dy"),
            parameters=(
                ParameterSpec("x", _to_float),
                ParameterSpec("y", _to_float),
                ParameterSpec("z", _to_float),
                ParameterSpec("rz", _to_float),
                ParameterSpec("dy", _to_float),
            ),
        ),
        "mttzpos_": TaskDescriptor(
            name="mttzpos_",
            handler=_bind_args("mttzpos", "x", "y", "z", "dy"),
            parameters=(
                ParameterSpec("x", _to_float),
                ParameterSpec("y", _to_float),
                ParameterSpec("z", _to_float),
                ParameterSpec("dy", _to_float),
            ),
        ),
        "delay": TaskDescriptor(
            name="delay",
            handler=_bind_direct("delay"),
            parameters=(ParameterSpec("seconds", _to_float),),
            store_as_mapping=False,
        ),
        "led": TaskDescriptor(
            name="led",
            handler=_bind_args("led", "led0", "led1"),
            parameters=(
                ParameterSpec("led0", _to_int),
                ParameterSpec("led1", _to_int),
            ),
        ),
        "grab_golf": TaskDescriptor(
            name="grab_golf",
            handler=_bind_args("grab_golf", "kind", "dx", "dy", "down_depth", "up_depth"),
            parameters=(
                ParameterSpec("kind", _to_str),
                ParameterSpec("dx", _to_float),
                ParameterSpec("dy", _to_float),
                ParameterSpec("down_depth", _to_float),
                ParameterSpec("up_depth", _to_float),
            ),
        ),
        "put_t": TaskDescriptor(
            name="put_t",
            handler=_bind_args("put_t", "num", "dy", "dz"),
            parameters=(
                ParameterSpec("num", _to_int),
                ParameterSpec("dy", _to_float),
                ParameterSpec("dz", _to_float),
            ),
        ),
        "strike_ball": TaskDescriptor(
            name="strike_ball",
            handler=_bind_args("strike_ball", "num"),
            parameters=(ParameterSpec("num", _to_int),),
        ),
        "strike_ball3": TaskDescriptor(
            name="strike_ball3",
            handler=_bind_args("strike_ball3", "num1", "num2", "num3"),
            parameters=(
                ParameterSpec("num1", _to_int),
                ParameterSpec("num2", _to_int),
                ParameterSpec("num3", _to_int),
            ),
        ),
        "line_qd": TaskDescriptor(
            name="line_qd",
            handler=_bind_no_args("line_qd"),
            parameters=(),
        ),
        "endfloat": TaskDescriptor(
            name="endfloat",
            handler=_bind_no_args("endfloat"),
            parameters=(),
        ),
    }


class TaskRegistry:
    """Holds all available task descriptors and provides helpers."""

    def __init__(self, descriptors: Optional[Dict[str, TaskDescriptor]] = None) -> None:
        self._descriptors = descriptors or _build_default_registry()

    def get(self, name: str) -> Optional[TaskDescriptor]:
        return self._descriptors.get(name)

    def names(self) -> Iterable[str]:
        return self._descriptors.keys()

    def parse_cli_task(self, command: str) -> Optional[Dict[str, Any]]:
        parts = command.strip().split()
        if not parts:
            return None

        name, args = parts[0], parts[1:]
        descriptor = self.get(name)
        if not descriptor:
            print(f"Warn: 未知任务 {name}")
            return None

        try:
            payload = descriptor.build_payload(args)
        except ValueError as exc:
            print(f"Warn: 参数错误 - {exc}")
            return None

        return {
            "name": name,
            "params": payload,
        }


class TaskRunner:
    """Executes tasks using a registry and a bound node."""

    def __init__(self, node: legacy.CoreNode, registry: Optional[TaskRegistry] = None) -> None:
        self._node = node
        self._registry = registry or TaskRegistry()

    def run(self, task: Mapping[str, Any]) -> None:
        name = task.get("name")
        descriptor = self._registry.get(name)
        if not descriptor:
            self._node.get_logger().info(f"Warn:非法任务 {name}")
            return
        try:
            payload = descriptor.normalise_payload(task.get("params"))
            descriptor.execute(self._node, payload)
        except Exception as exc:  # pragma: no cover - defensive logging
            self._node.get_logger().error(f"任务 {name} 执行失败: {exc}")

    def run_sequence(self, tasks: Sequence[Mapping[str, Any]], start_index: int = 0) -> None:
        for index in range(start_index, len(tasks)):
            task = tasks[index]
            name = task.get("name", "<unknown>")
            self._node.get_logger().info(
                f"Info:=========执行第 {index:d} 步任务 {name}========="
            )
            self.run(task)
            self._node.get_logger().info(
                f"Info:=========完成第 {index:d} 步任务 {name}========="
            )

    @property
    def registry(self) -> TaskRegistry:
        return self._registry


class CoreNode(legacy.CoreNode):
    """Drop-in replacement node that reuses legacy behaviour with modern tooling."""

    def __init__(self, name: str, opt: argparse.Namespace):
        super().__init__(name, opt)
        self.task_runner = TaskRunner(self)

    def run(self, task: Mapping[str, Any]) -> None:  # type: ignore[override]
        """Override legacy ``run`` to use the task runner registry."""
        self.task_runner.run(task)


def load_actions(path: str) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as stream:
        return json.load(stream)


def save_actions(data: Mapping[str, Any], path: str) -> None:
    print(f"所保存的任务:\n{data}\n")
    with open(path, "w", encoding="utf-8") as stream:
        json.dump(data, stream, ensure_ascii=False, indent=2)


def get_act(registry: TaskRegistry) -> Optional[Dict[str, Any]]:
    command = input("请输入任务指令: ")
    return registry.parse_cli_task(command)


def commom_loop(node: CoreNode, opt: argparse.Namespace) -> None:
    tasks_doc = load_actions(opt.data_path[0] + "uv_tasks.json")
    tasks = tasks_doc.get("tasks", [])

    node.start()
    node.task_runner.run_sequence(tasks)
    node.end()


def _print_task_list(tasks: Sequence[Mapping[str, Any]]) -> None:
    for index, task in enumerate(tasks):
        print(f"编号:   {index}")
        print(f"任务名: {task.get('name')}")
        print(f"参数:   {task.get('params')}")


def debug_loop(node: CoreNode, opt: argparse.Namespace) -> None:
    node.get_logger().info("Info:进入调试模式")

    registry = node.task_runner.registry
    tasklist = load_actions(opt.data_path[0] + "uv_tasks.json")
    tasks = tasklist.setdefault("tasks", [])

    help_path = Path(opt.data_path[0] + "help.txt")
    help_text = help_path.read_text(encoding="utf-8") if help_path.exists() else ""

    node.start()

    while True:
        node.get_logger().info("Info:等待指令输入")
        command = input("请输入调试指令: \n").strip()
        if not command:
            continue

        parts = command.split()
        head = parts[0]

        if head == "help":
            print(help_text)
            continue

        if head == "act":
            task = get_act(registry)
            if task is None:
                node.get_logger().info("Warn:非法任务")
                continue
            node.get_logger().info(f"Info:=========执行任务: {task['name']}=========")
            node.run(task)
            node.get_logger().info(f"Info:=========完成任务: {task['name']}=========")
            continue

        if head != "task":
            node.get_logger().info("Warn:非法指令")
            continue

        if len(parts) < 2:
            node.get_logger().info("Warn:非法指令")
            continue

        action = parts[1]

        if action == "run":
            if len(parts) == 2:
                node.task_runner.run_sequence(tasks, start_index=0)
            elif len(parts) == 3:
                idx = int(parts[2])
                if idx < 0 or idx >= len(tasks):
                    node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                else:
                    node.task_runner.run_sequence(tasks, start_index=idx)
            else:
                node.get_logger().info("Warn:非法指令")
            continue

        if action == "runonly" and len(parts) == 3:
            idx = int(parts[2])
            if idx < 0 or idx >= len(tasks):
                node.get_logger().info("Warn: 所请求任务不在列表范围内！")
            else:
                task = tasks[idx]
                node.get_logger().info(f"Info:=========执行任务: {task['name']}=========")
                node.run(task)
                node.get_logger().info(f"Info:=========完成任务: {task['name']}=========")
            continue

        if action == "add":
            if len(parts) == 3:
                idx = int(parts[2])
                if idx < 0 or idx > len(tasks):
                    node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    continue
                task = get_act(registry)
                if task:
                    tasks.insert(idx, task)
                    save_actions(tasklist, opt.data_path[0] + "uv_tasks.json")
            elif len(parts) == 2:
                task = get_act(registry)
                if task:
                    tasks.append(task)
                    save_actions(tasklist, opt.data_path[0] + "uv_tasks.json")
            else:
                node.get_logger().info("Warn:非法指令")
            continue

        if action == "del" and len(parts) == 3:
            idx = int(parts[2])
            if idx < 0 or idx >= len(tasks):
                node.get_logger().info("Warn: 所请求任务不在列表范围内！")
            else:
                tasks.pop(idx)
                save_actions(tasklist, opt.data_path[0] + "uv_tasks.json")
            continue

        if action == "clear" and len(parts) == 2:
            tasks.clear()
            save_actions(tasklist, opt.data_path[0] + "uv_tasks.json")
            continue

        if action == "list" and len(parts) == 2:
            node.get_logger().info("Info: 打印任务列表")
            _print_task_list(tasks)
            continue

        if action == "mod" and len(parts) == 3:
            idx = int(parts[2])
            if idx < 0 or idx >= len(tasks):
                node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                continue
            task = get_act(registry)
            if task:
                tasks[idx] = task
                save_actions(tasklist, opt.data_path[0] + "uv_tasks.json")
            continue

        node.get_logger().info("Warn:非法指令")


def main(args: Optional[Sequence[str]] = None) -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--front-topic",
        nargs="+",
        type=str,
        default=["front_cam/rectified"],
        help="前视摄像话题",
    )
    parser.add_argument(
        "--down-topic",
        nargs="+",
        type=str,
        default=["down_cam/rectified"],
        help="下视摄像话题",
    )
    parser.add_argument(
        "--data-path",
        nargs="+",
        type=str,
        default=["/home/nvidia/Workspace/Cruise/datas/"],
        help="数据存储路径",
    )
    parser.add_argument(
        "--debug",
        nargs="+",
        type=bool,
        default=False,
        help="是否启用调试模式",
    )

    opt = parser.parse_args(args=args)

    rclpy.init(args=args)

    if opt.debug:
        node = CoreNode("uv_automaton_debug", opt)
        thread = threading.Thread(target=debug_loop, args=(node, opt))
        thread.start()
    else:
        node = CoreNode("uv_automaton", opt)
        thread = threading.Thread(target=commom_loop, args=(node, opt))
        thread.start()

    node.get_logger().info("节点与调度线程成功启动")

    rclpy.spin(node)
    rclpy.shutdown()


if __name__ == "__main__":
    main()

===== .\uv_ai\uv_ai\uv_automation_v2.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import time
import os
import termios
import struct
import threading
import json
import argparse
from uv_control_py import Pid
from uv_control_py.CoordinateSystem import CoordinateSystems, MotionState, Cs_Back, Cs_Move, AngleCorrect

from typing import Any, Callable, Dict, Optional
from uv_msgs.msg import RobotDeviceManager  # 机器人设备管理器
from uv_msgs.msg import RobotMotionController  # 机器人运动控制器

from uv_msgs.msg import PidControllersState
from uv_msgs.msg import PidParams#巡线的pid参数

from uv_msgs.msg import RobotAxis
from uv_msgs.msg import ServoSet
from uv_msgs.msg import TargetPosDown
from uv_msgs.msg import Yolov8
from uv_msgs.msg import LedControllers
from uv_msgs.msg import MagnetController

from sensor_msgs.msg import Image
from uv_msgs.srv import DetectRequest
import cv2
import numpy as np
from cv_bridge import CvBridge
from filterpy.kalman import KalmanFilter


from math import sin, cos, atan2, sqrt

PI = 3.141592653589793
DEG2RAD = PI/180
RAD2DEG = 180/PI

Step = {  # 领航点拖曳速度(10hz)
    "x": 0.01,
    "y": 0.01,
    "z": 0.05,
    "rz": 5.0
}

AllowedError = {  # 位置容许误差
    "x": 0.02,
    "y": 0.02,
    "z": 0.02,
    "rz": 1.3
}


class MovementHelper:
    """Utility helpers to keep the motion primitives compact and consistent."""

    _AXES = ("x", "y", "z", "rz")

    def __init__(self, node: "CoreNode") -> None:
        self._node = node

    @staticmethod
    def _reset_axes(cmd: TargetPosDown) -> None:
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.0

    def _make_command(self, cs: int = 2) -> TargetPosDown:
        cmd = TargetPosDown()
        cmd.cs = cs
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        self._reset_axes(cmd)
        return cmd

    def publish_delta(self, axis: str, value: float, *, cs: int = 2) -> None:
        if axis not in self._AXES:
            raise ValueError(f"Unsupported axis {axis!r}")
        cmd = self._make_command(cs=cs)
        setattr(cmd.pos, axis, value)
        self._node.target_pos_down_pub.publish(cmd)

    def stepwise_move(
        self,
        axis: str,
        delta: float,
        *,
        step: float,
        sleep: float,
        on_iteration: Optional[Callable[[int, float], None]] = None,
        on_final: Optional[Callable[[float], None]] = None,
        wait_callback: Optional[Callable[[], bool]] = None,
    ) -> bool:
        """Perform the traditional stepped movement used by the legacy node."""
        if axis not in self._AXES:
            raise ValueError(f"Unsupported axis {axis!r}")

        remaining = float(delta)
        if abs(remaining) < 1e-9:
            if on_final:
                on_final(0.0)
            if wait_callback:
                return wait_callback()
            return True

        count = 0
        while True:
            count += 1
            if on_iteration:
                on_iteration(count, remaining)

            if abs(remaining) <= step:
                if on_final:
                    on_final(remaining)
                self.publish_delta(axis, remaining)
                return wait_callback() if wait_callback else True

            step_value = step if remaining > 0 else -step
            remaining -= step_value
            self.publish_delta(axis, step_value)
            time.sleep(sleep)

class CoreNode(Node):
    def __init__(self, name, opt):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)
        self.opt = opt

        self.robot = CoordinateSystems()
        self.motion = MovementHelper(self)

        self.MotionController = RobotMotionController()
        #pid参数初始化
        self.pid_parameters = PidParams()
        # self.pid_parameters.p = 0.0
        # self.pid_parameters.i = 0.0
        # self.pid_parameters.d = 0.0

        self.previous_error = 0.0
        self.i_error = 0.0
        self.dt = 1

        self.task_lock = True
        self.yolov8_data_down = Yolov8()
        self.yolov8_data_front = Yolov8()
        self.magnet = MagnetController()

        self.target = {
            "name": "none",
            "x": 0.0,
            "y": 0.0,
            "z": 0.0
        }

        self.backpoint = {
            "x": 0.0,
            "y": 0.0,
            "z": 0.0,
            "rz": 0.0
        }

        self.front_cam = CoordinateSystems()
        self.down_cam = CoordinateSystems()
        #前视相机坐标偏置
        self.front_cam.base.vector.x = 107.6/1000
        self.front_cam.base.vector.y = 320.0/1000
        self.front_cam.base.vector.z = 65.0/1000
        self.front_cam.base.vector.rx = -90.0
        self.front_cam.base.extract()
        #下视相机坐标偏置
        self.down_cam.base.vector.x = 0.0/1000
        self.down_cam.base.vector.y = 170.0/1000
        self.down_cam.base.vector.z = 42.7/1000
        self.down_cam.base.vector.rz = 0.0
        self.down_cam.base.extract()

        self.get_logger().info(
            f"前置摄像机偏置: x: {self.front_cam.base.vector.x:.2f} y: { self.front_cam.base.vector.y : .2f} z: {self.front_cam.base.vector.z : .2f}")
        self.get_logger().info(
            f"          : rx: {self.front_cam.base.vector.rx:.2f} ry: { self.front_cam.base.vector.ry : .2f} rz: {self.front_cam.base.vector.rz : .2f}")
        self.get_logger().info(
            f"下置摄像机偏置: x: {self.down_cam.base.vector.x:.2f} y: { self.down_cam.base.vector.y : .2f} z: {self.down_cam.base.vector.z : .2f}")
        self.get_logger().info(
            f"          : rx: {self.down_cam.base.vector.rx:.2f} ry: { self.down_cam.base.vector.ry : .2f} rz: {self.down_cam.base.vector.rz : .2f}")
        
        self.start_pos = CoordinateSystems()
        
        self.front_cam_Image_data = None
        self.down_cam_Image_data = None
        self.front_cam_left_Image_data = None
        self.segment_img = None

        # 话题发布
        # 创建话题发布 target_pos_down ，定义其中的消息类型为 TargetPosDown
        self.target_pos_down_pub = self.create_publisher(
            TargetPosDown, "target_pos_down", 10)
        # 创建话题发布 servo_control ，定义其中的消息类型为 ServoSet
        self.servo_control_pub = self.create_publisher(
            ServoSet, "servo_control", 10)
        #创建话题发布  led_controllers, 定义其中的消息类型为 LedControllers
        self.led_controllers_pub = self.create_publisher(
            LedControllers, 'led_controllers', 10)
        # 创建话题发布 magnet_controller ，定义其中的消息类型为 MagnetController
        self.magnet_controller_pub = self.create_publisher(
            MagnetController, "magnet_controller", 10)
        # 创建话题发布 pid_controllers_set ，定义其中的消息类型为 PidControllersState
        self.pid_controllers_set_pub = self.create_publisher(
            PidControllersState, 'pid_controllers_set', 10)
        #创建话题发布 line_patrol_img , 定义消息类型为Image
        self.line_patrol_img_pub = self.create_publisher(
            Image, 'line_patrol_img', 10)

        self.openthrust_data_pub = self.create_publisher(
            RobotAxis, 'openloop_thrust', 10)

        # 话题接收
        # 创建话题接收 motion_controller ，定义其中的消息类型为 RobotMotionController
        self.create_subscription(
            RobotMotionController, 'motion_controller', self.motion_controller_callback, 10)
        # 创建话题接收 front_cam/rectified ，定义其中的消息类型为 Image
        self.create_subscription(
            Image, opt.front_topic[0], self.front_cam_callback, 10)
        # 创建话题接收 down_cam/rectified ，定义其中的消息类型为 Image
        self.create_subscription(
            Image, opt.down_topic[0], self.down_cam_callback, 10)
        #创建话题接收 front_cam/rectified/left,定义其中的消息类型为 Image
        self.create_subscription(
            Image, 'front_cam/rectified/left', self.front_cam_left_callback, 10)
        self.create_subscription(
            PidParams, 'track_pid_parameter', self.track_pid_parameter_callback, 10)
        # 创建话题接收 uv_detect ，定义其中的消息类型为 Yolov8
        self.create_subscription(
            Yolov8, 'uv_detect_down', self.yolov8_down_callback, 10)
        
        self.create_subscription(
            Yolov8, 'uv_detect_front', self.yolov8_front_callback, 10)
        
        #创建话题接收 binary_segment_img , 定义消息类型为Image，用于接收二值化后的分割结果
        self.create_subscription(
            Image, 'binary_segment_img', self.segment_img_callback, 10)

        # 服务请求
        # 创建服务请求 detect_request_client ，定义其中的消息类型为 RobotAxis , 请求服务 uv_detect_srv
        self.detect_request_client = self.create_client(
            DetectRequest, "uv_detect_srv")

        self.magnet.state = 1
        self.magnet_controller_pub.publish(self.magnet)

        self._task_handlers = self._build_task_handlers()
        self.get_logger().info("节点初始化完成")

    def track_pid_parameter_callback(self, data):
        pass
        # self.pid_parameters = data
    
    # 更新摄像头图像
    def front_cam_callback(self, data):
        self.front_cam_Image_data = data

    def down_cam_callback(self, data):
        self.down_cam_Image_data = data

    def front_cam_left_callback(self, data):
        self.front_cam_left_Image_data = data
    # 更新巡线图像
    def segment_img_callback(self, data):
        self.segment_img = data

    #更新目标检测结果
    def yolov8_down_callback(self, data):
        self.yolov8_data_down = data
    
    def yolov8_front_callback(self, data):
        self.yolov8_data_front = data
    
    # 更新机器人位置数据
    def motion_controller_callback(self, data):
        self.MotionController = data

        self.robot.base.vector.x = self.MotionController.pos.x
        self.robot.base.vector.y = self.MotionController.pos.y
        self.robot.base.vector.z = self.MotionController.pos.z
        self.robot.base.vector.rx = self.MotionController.pos.rx
        self.robot.base.vector.ry = self.MotionController.pos.ry
        self.robot.base.vector.rz = self.MotionController.pos.rz
        self.robot.base.extract()

    # 等待移动至指定位置
    def move_wait(self):
        cnt = 0
        time.sleep(0.5)
        while True:
            judge = 0
            if abs(self.MotionController.tpos_inbase.x) > AllowedError["x"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.y) > AllowedError["y"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.z) > AllowedError["z"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.rz) > AllowedError["rz"]:
                judge += 1

            if judge == 0:  # 进入容许范围
                return True

            if cnt > 200:  # 超时退出
                return False

            cnt += 1
            time.sleep(0.05)

    def movez(self, z):
        if self.robot.base.vector.z + z < -1.0:
            self.get_logger().info("Warn: 深度设置超出范围")
            z = -self.robot.base.vector.z

        self.get_logger().info("======开始移动======")

        step_cnt = int(abs(z) / Step["z"]) + 1
        self.get_logger().info(f"Info: 开始调整深度 需要调整{step_cnt:d} 次")

        def _log_iteration(count: int, _remaining: float) -> None:
            self.get_logger().info(f"Info: 开始第 {count:d} 次调整深度")

        def _log_final(_value: float) -> None:
            self.get_logger().info("Info: 最终深度调整开始")

        success = self.motion.stepwise_move(
            axis="z",
            delta=z,
            step=Step["z"],
            sleep=0.2,
            on_iteration=_log_iteration,
            on_final=_log_final,
            wait_callback=self.move_wait,
        )

        if success:
            self.get_logger().info("Info: 最终深度调整完毕")
        else:
            self.get_logger().info("Warn: 最终深度调整超时！")

        self.get_logger().info("======移动结束======")

    def fast_movez(self, z):
        if self.robot.base.vector.z + z < 0:
            self.get_logger().info("Warn: 深度设置超出范围")
            return

        self.get_logger().info("======开始移动======")
        self.get_logger().info("Info: 深度快速微调开始")
        self.motion.publish_delta("z", z)
        self.get_logger().info("======移动结束======")

    # 移动 x 的相对位移
    def movex(self, x):
        if x > 10:
            self.get_logger().info("Warn: 横向位置设置超出范围")
            return

        self.get_logger().info("======开始移动======")

        step_cnt = int(abs(x) / Step["x"]) + 1
        self.get_logger().info(f"Info: 开始调整横向位置 需要调整{step_cnt:d} 次")

        def _log_final(_value: float) -> None:
            self.get_logger().info("Info: 最终横向位置调整开始")

        success = self.motion.stepwise_move(
            axis="x",
            delta=x,
            step=Step["x"],
            sleep=0.1,
            on_final=_log_final,
            wait_callback=self.move_wait,
        )

        if success:
            self.get_logger().info("Info: 最终横向位置调整完毕")
        else:
            self.get_logger().info("Warn: 最终横向位置调整超时！")

        self.get_logger().info("======移动结束======")

    def fast_movex(self, x):
        if x > 10:
            self.get_logger().info("Warn: 横向位置设置超出范围")
            return

        self.get_logger().info("======开始移动======")
        self.get_logger().info("Info: 横向位置快速微调开始")
        self.motion.publish_delta("x", x)
        self.get_logger().info("======移动结束======")

    # 移动 y 的相对位移
    def movey(self, y):
        if y > 10:
            self.get_logger().info("Warn: 前后位置设置超出范围")
            return

        self.get_logger().info("======开始移动======")

        step_cnt = int(abs(y) / Step["y"]) + 1
        self.get_logger().info(f"Info: 开始调整前后位置 需要调整{step_cnt:d} 次")

        def _log_final(_value: float) -> None:
            self.get_logger().info("Info: 最终前后位置调整开始")

        success = self.motion.stepwise_move(
            axis="y",
            delta=y,
            step=Step["y"],
            sleep=0.1,
            on_final=_log_final,
            wait_callback=self.move_wait,
        )

        if success:
            self.get_logger().info("Info: 最终前后位置调整完毕")
        else:
            self.get_logger().info("Warn: 最终前后位置调整超时！")

        self.get_logger().info("======移动结束======")

    def fast_movey(self, y):
        if y > 10:
            self.get_logger().info("Warn: 前后位置设置超出范围")
            return

        self.get_logger().info("======开始移动======")
        self.get_logger().info("Info: 前后位置快速微整开始")
        self.motion.publish_delta("y", y)
        self.get_logger().info("======移动结束======")

    def moverz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为{rz:.2f}°")

        self.get_logger().info("======开始旋转======")

        step_cnt = int(abs(rz) / Step["rz"]) + 1
        self.get_logger().info(f"Info: 开始调整角度 需要调整{step_cnt:d} 次")

        def _log_final(_value: float) -> None:
            self.get_logger().info("Info: 最终角度调整开始")

        success = self.motion.stepwise_move(
            axis="rz",
            delta=rz,
            step=Step["rz"],
            sleep=0.1,
            on_final=_log_final,
            wait_callback=self.move_wait,
        )

        if success:
            self.get_logger().info("Info: 最终角度调整完毕")
        else:
            self.get_logger().info("Warn: 最终角度调整超时！")

        self.get_logger().info("======旋转结束======")

    def fast_moverz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为{rz:.2f}°")

        self.get_logger().info("======开始旋转======")
        self.get_logger().info("Info: 前后位置快速微整开始")
        self.motion.publish_delta("rz", rz)
        self.get_logger().info("======移动结束======")

    # 移动x,y相对位移
    def movexy(self, x, y):
        if x == 0 and y == 0:
            self.get_logger().info("Warn: 未设置合法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")
            time.sleep(0.1)
            #self.get_logger().info(f"Info: ======朝向回正,旋转{-rz:.2f}°======")
            #self.moverz(-rz)
            #self.get_logger().info("Info: ======转向结束======")

    # 移动x,y,z相对位移
    def movexyz(self, x, y, z):
        if z == 0:
            self.get_logger().info("Warn: 未设置合法深度位移！")
        else:
            self.movez(z)
        time.sleep(0.1)
        self.movexy(x, y)

    # 设置 z
    def setz(self, z):
        if z >= -1.0:
            self.get_logger().info("======开始调整深度======")
            cmd = TargetPosDown()
            cmd.cs = 0
            cmd.pos.rx = self.MotionController.pos.rx
            cmd.pos.ry = self.MotionController.pos.ry
            cmd.pos.x = self.MotionController.pos.x
            cmd.pos.y = self.MotionController.pos.y
            cmd.pos.rz = self.MotionController.pos.rz
            cmd.pos.z = z
            self.target_pos_down_pub.publish(cmd)
            s = self.move_wait()
            if s:
                self.get_logger().info("Info: 深度调整完成")
            else:
                self.get_logger().info("Warn: 深度调整超时！")
            self.get_logger().info("======移动结束======")
        else:
            self.get_logger().info("Warn: 深度设置错误！")

    # 设置rz
    def setrz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始调整角度======")
        cmd = TargetPosDown()
        cmd.cs = 0
        cmd.pos.rx = self.MotionController.pos.rx
        cmd.pos.ry = self.MotionController.pos.ry
        cmd.pos.x = self.MotionController.pos.x
        cmd.pos.y = self.MotionController.pos.y
        cmd.pos.z = self.MotionController.pos.z
        cmd.pos.rz = rz
        self.target_pos_down_pub.publish(cmd)
        s = self.move_wait()
        if s:
            self.get_logger().info("Info: 角度调整完成")
        else:
            self.get_logger().info("Warn: 角度调整超时！")
        self.get_logger().info("======移动结束======")

    # 设置路径点
    def setp(self):
        self.backpoint["x"] = self.MotionController.pos.x
        self.backpoint["y"] = self.MotionController.pos.y
        self.backpoint["z"] = self.MotionController.pos.z
        self.backpoint["rz"] = self.MotionController.pos.rz
        self.get_logger().info(
            f'Info:已保存当前位置 x: {self.backpoint["x"]:.2f} y: {self.backpoint["y"]:.2f} z: {self.backpoint["z"]:.2f} rz : {self.backpoint["rz"]:.2f}')

    # 回到路径点
    def back(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(-d)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz-rz_)
            self.get_logger().info("Info: ======转向结束======")
            
    def fast_back(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.fast_movez(z)
        time.sleep(2)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.fast_moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.fast_moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(5.0)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.fast_movey(-d)
            time.sleep(5.0)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.fast_moverz(rz-rz_)
            time.sleep(2.0)
            self.get_logger().info("Info: ======转向结束======")
            
    # 回到路径点
    def backy(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")


        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(-d)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz-rz_)
            self.get_logger().info("Info: ======转向结束======")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

    # 移动至寄存器 self.target 所指定的位置
    def mtty(self, dy, dz):

        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        z -= dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y) - dy
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")

    def mttzxy(self, dz, dx, dy):
        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        x += dx
        y += dy
        z += dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")
        
        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.get_logger().info(f"Info: ======深度移动指定距离,移动{z:.2f}m======")
            self.movez(z)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if x == 0:
            self.get_logger().info("Warn: 水平位移非法！")
        else:
            self.get_logger().info(f"Info: ======横移指定距离,移动{x:.2f}m======")
            self.movex(x)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if y == 0:
            self.get_logger().info("Warn: 前后位移非法！")
        else:
            self.get_logger().info(f"Info: ======前后指定距离,移动{y:.2f}m======")
            self.movey(y)
        time.sleep(0.1)

        self.get_logger().info(f"Info: ======移动结束======")


    def mttxf(self,dx,dy):
        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")
        x_target = x - dx
        self.get_logger().info(f"Info: ======横移指定距离,移动{x:.2f}m======")
        self.movex(x_target)
        self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            d = y - dy
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)


    # 移动至寄存器 self.target 所指定的位置
    def mttz(self, dy, dz):

        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        z -= dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y) - dy
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)
    
    #移动至指定世界坐标位置
    def mttpos(self, x, y, z, rz, dy):
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z

        Step["y"] = 0.04
        self.mttz(dy, 0.0)#小范围微调
        self.setrz(rz)
        Step["y"] = 0.02
    
    #移动至指定世界坐标位置，但最后不旋转
    def mttzpos(self, x, y, z, dy):
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z
        Step["z"] = 0.2
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        Step["y"] = 0.02
        Step["z"] = 0.05
    
    #移动至指定世界坐标位置，以比赛开始位置为坐标
    def mttpos_amend(self, x, y, z, rz, dy):
        self.start_pos.target_inbase.vector.x = x
        self.start_pos.target_inbase.vector.y = y
        self.start_pos.target_inbase.vector.z = z
        self.start_pos.target_inbase.vector.rz = rz
        self.start_pos.target_inbase.vector.rx = self.start_pos.target_inbase.vector.ry= 0.0
        self.start_pos.base2world()
        self.target["x"] = self.start_pos.target_inworld.vector.x
        self.target["y"] = self.start_pos.target_inworld.vector.y
        self.target["z"] = self.start_pos.target_inworld.vector.z
        self.target["rz"] = self.start_pos.target_inworld.vector.rz
        
        self.get_logger().info(
            f"x: {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
              
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        self.setrz(rz+self.start_pos.base.vector.rz)
        Step["y"] = 0.02
    
    #移动至指定世界坐标位置，以比赛开始位置为坐标
    def mttzpos_amend(self, x, y, z, dy):
        self.start_pos.target_inbase.vector.x = x
        self.start_pos.target_inbase.vector.y = y
        self.start_pos.target_inbase.vector.z = z
        self.start_pos.target_inbase.vector.rx = self.start_pos.target_inbase.vector.ry= 0.0
        self.start_pos.base2world()
        self.target["x"] = self.start_pos.target_inworld.vector.x
        self.target["y"] = self.start_pos.target_inworld.vector.y
        self.target["z"] = self.start_pos.target_inworld.vector.z
        Step["z"] = 0.2
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        Step["y"] = 0.02
        Step["z"] = 0.05
    
    # 搜寻目标
    def search(self, name, cam):
        # 定位目标
        # 等待服务段上线
        wait = True
        while rclpy.ok() and self.detect_request_client.wait_for_service(0.1) == False:
            if wait:
                wait = False
                self.get_logger().info("Info:等待服务端上线....")
        self.get_logger().info("Info:服务端已启动")

        request = DetectRequest.Request()
        request.stero = cam
        request.target = name
        responce = None

        pos_list = []
        fail_cnt = 0

        image = False

        while True:
            if cam == "front" and self.front_cam_Image_data != None:
                request.imagein = self.front_cam_Image_data
                image = True
            if cam == "down" and self.down_cam_Image_data != None:
                request.imagein = self.down_cam_Image_data
                image = True

            if image == True:
                responce = self.detect_request_client.call(request)
                if responce.s == 1:
                    if cam == "front":
                        self.front_cam.target_inbase.vector.x = responce.x
                        self.front_cam.target_inbase.vector.y = responce.y
                        self.front_cam.target_inbase.vector.z = responce.z
                        #相机坐标系到机器人坐标系
                        self.front_cam.base2world()

                        self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                        self.robot.base2world()

                    if cam == "down":
                        self.down_cam.target_inbase.vector.x = responce.x
                        self.down_cam.target_inbase.vector.y = responce.y
                        self.down_cam.target_inbase.vector.z = responce.z
                        self.down_cam.base2world()

                        self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                        self.robot.base2world()

                    # self.get_logger().info(
                    #     f"Info:目标在机器人坐标系中的位置: x: {self.robot.target_inbase.vector.x: .3f} y: {self.robot.target_inbase.vector.y: .3f} z: {self.robot.target_inbase.vector.z: .3f}")
                    self.get_logger().info(
                        f"Info:目标在相机坐标系中的位置: x: {responce.x: .3f} y: {responce.y: .3f} z: {responce.z: .3f}")

                    pos_list.append([self.robot.target_inworld.vector.x,
                                    self.robot.target_inworld.vector.y, self.robot.target_inworld.vector.z])

                    if len(pos_list) >= 5:
                        break
                else:
                    fail_cnt += 1
                    time
                    if fail_cnt >= 1000 & len(pos_list) < 5:
                        self.get_logger().info(f"确认无目标，退出函数")
                        return responce.s

            else:
                self.get_logger().info("无图像传入")

            image = False
        x = y = z = 0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)

        self.robot.base2world()
        self.target["name"] = name
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z

        self.get_logger().info(
            f"目标位置: x : {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
        return responce.s

    def search2(self, name, cam,dy,dz,z_target,times):
        # 定位目标
        # 等待服务段上线
        wait = True
        while rclpy.ok() and self.detect_request_client.wait_for_service(0.1) == False:
            if wait:
                wait = False
                self.get_logger().info("Info:等待服务端上线....")
        self.get_logger().info("Info:服务端已启动")

        request = DetectRequest.Request()
        request.stero = cam
        request.target = name

        pos_list = []

        image = False
        times_none = 0 #
        flag_to_next = 0 #

        while True:
            if cam == "front" and self.front_cam_Image_data != None:
                request.imagein = self.front_cam_Image_data
                image = True
            if cam == "down" and self.down_cam_Image_data != None:
                request.imagein = self.down_cam_Image_data
                image = True

            if image == True:
                responce = self.detect_request_client.call(request)
                if responce.s == 1:
                    if cam == "front":
                        self.front_cam.target_inbase.vector.x = responce.x
                        self.front_cam.target_inbase.vector.y = responce.y
                        self.front_cam.target_inbase.vector.z = responce.z
                        #相机坐标系到机器人坐标系
                        self.front_cam.base2world()

                        self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                        self.robot.base2world()

                    if cam == "down":
                        self.down_cam.target_inbase.vector.x = responce.x
                        self.down_cam.target_inbase.vector.y = responce.y
                        self.down_cam.target_inbase.vector.z = responce.z
                        self.down_cam.base2world()

                        self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                        self.robot.base2world()

                    self.get_logger().info(
                        f"Info:目标在世界坐标系中的位置: x: {self.robot.target_inworld.vector.x: .3f} y: {self.robot.target_inworld.vector.y: .3f} z: {self.robot.target_inworld.vector.z: .3f}")

                    pos_list.append([self.robot.target_inworld.vector.x,
                                    self.robot.target_inworld.vector.y, self.robot.target_inworld.vector.z])

                    if len(pos_list) >= 100:
                        break
                else:
                    if (times > 0):
                        times_none += 1
                        self.get_logger().info(f"第{times_none}次无目标")
                        if (times_none >= 50) & (len(pos_list) < 10):
                            flag_to_next = 1
                            self.get_logger().info(f"确认无目标，进行下一步")
                            break
            else:
                self.get_logger().info("无图像传入")

            image = False

        times += 1
        if flag_to_next == 0:
            x = y = z = 0
            for i in pos_list:
                x += i[0]
                y += i[1]
                z += i[2]
            x /= len(pos_list)
            y /= len(pos_list)
            z /= len(pos_list)

            self.robot.base2world()
            self.target["name"] = name
            self.target["x"] = x
            self.target["y"] = y
            self.target["z"] = z

            self.get_logger().info(
                f"目标位置: x : {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
            
            self.mttz(dy,dz)
            self.setz(z_target)
            self.get_logger().info(
                f"开始第{times}次搜查是否抓球成功")            
            self.search2(self, name, cam,dy,dz,z_target,times)
    
    def search4(self, name1, name2,dx,dy,dz,z_target,rz_target,times,distance):#1为圈，2为T插
       
        times_none = 0
        flag_to_next = 0
        
        T_cnt = 0
        while True:
            
            s = self.search(self, "scaffolding", "front")
            if s == 0:
                self.get_logger().info("======无目标======")
                self.led(0, 0)
                self.get_logger().info("======旋转寻找目标目标======")
                self.moverz(40)
                T_cnt += 1
            else :
                self.get_logger().info("======发现基架======")  
                self.target["y"] -= 0.50  
                self.mttz(dy,dz)
                self.setrz(rz_target)
                break
            if T_cnt > 10:
                self.get_logger().info("======未找到目标======")
                break
        
        """
        计算法线方向
        """
        # 解包坐标
        x1, y1, z1 = self.cam2robot(2, 4,"front")
        x2, y2, z2 = self.cam2robot(2, 4,"front")
        x3, y3, z3 = self.cam2robot(2, 4,"front")
            
            
        # 计算向量AC的分量
        a = x1 - x3
        b = y1 - y3
            
        # 计算向量模长的平方
        length_squared = a**2 + b**2
            
            
        # 计算u和v的可能值
        if  abs(b) >= 0.001:
            # 一般情况
            factor = distance * abs(b) / (length_squared ** 0.5)
            u1 = factor
            v1 = -a * u1 / b
                
            u2 = -factor
            v2 = -a * u2 / b
        else:
            # b为0的特殊情况（AC垂直于x轴）
            u1 = 0
            v1 = distance
                
            u2 = 0
            v2 = -distance
            
            # 计算点D的坐标
        d1 = (x2 + u1, y2 + v1, z3)
        d2 = (x2 + u2, y2 + v2, z3)
            
        real_d = min(d1, d2)    
             
        
              
    # 机械爪控制
    def pow(self, s):
        servo = ServoSet()
        servo.num = 0
        if s == 1:
            servo.angle = 0.35
            self.servo_control_pub.publish(servo)
        if s == 0:
            servo.angle = 0.92#推球，夹T插
            self.servo_control_pub.publish(servo)
        time.sleep(0.1)


    # 任务启动
    def start(self):
        time.sleep(5)
        #  载入当前目标值
        tpos = TargetPosDown()
        tpos.cs = 0
        self.start_pos.base.vector.x = tpos.pos.x = self.MotionController.pos.x
        self.start_pos.base.vector.y = tpos.pos.y = self.MotionController.pos.y
        tpos.pos.z = self.MotionController.pos.z
        self.start_pos.base.vector.z = 0.0
        self.start_pos.base.vector.rz = tpos.pos.rz = self.MotionController.pos.rz
        self.start_pos.base.vector.ry = self.start_pos.base.vector.rx = tpos.pos.rx = tpos.pos.ry =  0.0
        self.start_pos.base.extract()
        self.get_logger().info(f"载入当前世界坐标 x:{tpos.pos.x:.3f} y:{tpos.pos.y:.3f} z:{tpos.pos.z:.3f} rz:{tpos.pos.rz:.3f}")
        self.led(1,0)#绿灯
        time.sleep(3.0)
        self.led(0,1)#黄灯
        time.sleep(3.0)
        self.led(1,1)#红灯
        time.sleep(3.0)
        self.led(0,0)
        self.target_pos_down_pub.publish(tpos)
        # 机械爪加紧T插
        self.pow(0) 
        
        # 开启PID控制器
        pid = PidControllersState()
        pid.x = pid.y = pid.z = pid.rz = 1
        pid.rx = pid.ry = 0
        self.pid_controllers_set_pub.publish(pid)
        time.sleep(0.1)

    # 任务结束
    def end(self):
        # 关闭PID控制器
        pid = PidControllersState()
        pid.x = pid.y = pid.z = pid.rz = 0
        pid.rx = pid.ry = 0
        self.pid_controllers_set_pub.publish(pid)
        time.sleep(0.1)

    def _build_task_handlers(self) -> Dict[str, Callable[[Dict[str, Any]], None]]:
        def require_params(task: Dict[str, Any]) -> Dict[str, Any]:
            params = task.get("params")
            if not isinstance(params, dict):
                raise TypeError(f"任务 {task.get('name')} 缺少参数字典")
            return params

        def get(task: Dict[str, Any], *keys: str) -> tuple:
            params = require_params(task)
            return tuple(params[key] for key in keys)

        def get_single(task: Dict[str, Any], key: str) -> Any:
            return require_params(task)[key]

        return {
            "movexyz": lambda task: self.movexyz(*get(task, "x", "y", "z")),
            "throw_golf": lambda task: self.throw_golf(*get(task, "dy", "depth")),
            "movexy": lambda task: self.movexy(*get(task, "x", "y")),
            "movex": lambda task: self.movex(get_single(task, "x")),
            "movey": lambda task: self.movey(get_single(task, "y")),
            "movez": lambda task: self.movez(get_single(task, "z")),
            "moverz": lambda task: self.moverz(get_single(task, "rz")),
            "setz": lambda task: self.setz(get_single(task, "z")),
            "setrz": lambda task: self.setrz(get_single(task, "rz")),
            "search": lambda task: self.search(*get(task, "name", "cam")),
            "mtty": lambda task: self.mtty(*get(task, "y", "z")),
            "mttxf": lambda task: self.mttxf(*get(task, "dx", "dy")),
            "mttz": lambda task: self.mttz(*get(task, "y", "z")),
            "mttzxy": lambda task: self.mttzxy(*get(task, "dz", "dx", "dy")),
            "setp": lambda task: self.setp(),
            "back": lambda task: self.back(),
            "backy": lambda task: self.backy(),
            "pow": lambda task: self.pow(task.get("params")),
            "line": lambda task: self.line(get_single(task, "ys_dep")),
            "graball": lambda task: self.graball(*get(task, "color", "depth", "timeout", "pr", "k", "step_time")),
            "thrball": lambda task: self.thrball(*get(task, "pr", "timeout", "k", "step_time")),
            "pass_door": lambda task: self.pass_door(get_single(task, "num")),
            "mttpos": lambda task: self.mttpos(*get(task, "x", "y", "z", "rz", "dy")),
            "mttzpos_amend": lambda task: self.mttzpos_amend(*get(task, "x", "y", "z", "dy")),
            "mttpos_amend": lambda task: self.mttpos_amend(*get(task, "x", "y", "z", "rz", "dy")),
            "mttzpos_": lambda task: self.mttzpos(*get(task, "x", "y", "z", "dy")),
            "delay": lambda task: self.delay(task.get("params")),
            "led": lambda task: self.led(*get(task, "led0", "led1")),
            "grab_golf": lambda task: self.grab_golf(*get(task, "kind", "dx", "dy", "down_depth", "up_depth")),
            "put_t": lambda task: self.put_t(*get(task, "num", "dy", "dz")),
            "strike_ball": lambda task: self.strike_ball(get_single(task, "num")),
            "strike_ball3": lambda task: self.strike_ball3(*get(task, "num1", "num2", "num3")),
            "line_qd": lambda task: self.line_qd(),
            "endfloat": lambda task: self.endfloat(),
        }


    def run(self, task: Dict[str, Any]):
        handler = self._task_handlers.get(task.get("name"))
        if handler is None:
            self.get_logger().info(f"Info:非法任务: {task.get('name')}")
            return

        try:
            handler(task)
        except Exception as exc:  # noqa: BLE001 - surface detailed failure for operators
            self.get_logger().error(f"任务 {task.get('name')} 执行失败: {exc}")
            raise

    def pid_update(self, error):
        self.dt = self.dt + 1 if abs(error-self.previous_error) < 2 else 1
        p_value = self.pid_parameters.p * error
        self.i_error += error * self.dt
        i_value = self.pid_parameters.i * self.i_error
        d_value = self.pid_parameters.d * (error - self.previous_error) / self.dt
        self.previous_error = error
        output = p_value + i_value + d_value
        if output > self.pid_parameters.output_limit:
            output = self.pid_parameters.output_limit
        elif output < -self.pid_parameters.output_limit:
            output = -self.pid_parameters.output_limit
        return output
    

    def cam2robot(self, clas, timeout,cam):
        pos_list = []
        start_time = time.time()

        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # 检查超时
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                return 0.0, 0.0, 0.0
            if cam == "down":
                if self.yolov8_data_down.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.z != 0:
                    self.down_cam.target_inbase.vector.x = self.yolov8_data_down.targets[clas].tpos_inworld.x
                    self.down_cam.target_inbase.vector.y = self.yolov8_data_down.targets[clas].tpos_inworld.y
                    self.down_cam.target_inbase.vector.z = self.yolov8_data_down.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.down_cam.base2world()

                    t_x = self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                    t_z =  self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                    self.robot.base2world()
                    time.sleep(0.015)
                                    # 检查返回的坐标是否为 0
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if cam == "front":
                if self.yolov8_data_front.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.z != 0:
                    self.front_cam.target_inbase.vector.x = self.yolov8_data_front.targets[clas].tpos_inworld.x
                    self.front_cam.target_inbase.vector.y = self.yolov8_data_front.targets[clas].tpos_inworld.y
                    self.front_cam.target_inbase.vector.z = self.yolov8_data_front.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.front_cam.base2world()
                    t_x = self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                    t_z = self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                    self.robot.base2world()
                    time.sleep(0.015)
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")

            if len(pos_list) >= 80:
                break
        x = y = z = 0.0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)
        self.get_logger().info(
            f"目标在机器人坐标系下的位置: x : {x:.2f} y: {y:.2f} z: {z:.2f}")

        return x, y, z
    

    def cam2robot_fast(self, clas, timeout,cam):
        pos_list = []
        start_time = time.time()

        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # 检查超时
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                return 0.0, 0.0, 0.0
            if cam == "down":
                if self.yolov8_data_down.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.z != 0:
                    self.down_cam.target_inbase.vector.x = self.yolov8_data_down.targets[clas].tpos_inworld.x
                    self.down_cam.target_inbase.vector.y = self.yolov8_data_down.targets[clas].tpos_inworld.y
                    self.down_cam.target_inbase.vector.z = self.yolov8_data_down.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.down_cam.base2world()

                    t_x = self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                    t_z =  self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                    self.robot.base2world()
                                    # 检查返回的坐标是否为 0
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if cam == "front":
                if self.yolov8_data_front.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.z != 0:
                    self.front_cam.target_inbase.vector.x = self.yolov8_data_front.targets[clas].tpos_inworld.x
                    self.front_cam.target_inbase.vector.y = self.yolov8_data_front.targets[clas].tpos_inworld.y
                    self.front_cam.target_inbase.vector.z = self.yolov8_data_front.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.front_cam.base2world()
                    t_x = self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                    t_z = self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                    self.robot.base2world()
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if len(pos_list) >= 50:
                break
        x = y = z = 0.0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)
        self.get_logger().info(
            f"目标在机器人坐标系下的位置: x : {x:.2f} y: {y:.2f} z: {z:.2f}")

        return x, y, z
    
    #抓球 pr为百分比距离
    def graball(self,color,depth,timeout,pr,k,step_time):
        led = LedControllers()
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                break
            if all(x==0 for x in self.yolov8_data_down.state):
                self.led(0,0)
                self.get_logger().info(
                f"没有找到任何物体")
            elif self.yolov8_data_down.state[5] == 1 and self.yolov8_data_down.state[4] == 1: #5是黄色，4是pink
                self.led(1,0)
                self.get_logger().info(
                f"发现高尔夫球")
                if color == "pink":
                    a, b, c = self.cam2robot(4, 5,"down")
                    self.movex(a)
                    self.movey(b-0.175)
                    self.movez(depth)
                    self.movez(-depth)
                    break
                elif color == "yellow":
                    a, b, c = self.cam2robot(5, 5,"down")
                    self.movex(a)
                    self.movey(b-0.175)
                    self.movez(depth)
                    self.movez(-depth)
                    break
            elif self.yolov8_data_down.state[6] == 1:
                led.led0 = 0
                led.led1 = 1
                r = sqrt((self.yolov8_data_down.targets[6].tpos_inpic.y -  480)**2 + (self.yolov8_data_down.targets[6].tpos_inpic.x -  640)**2)/sqrt(480**2+640**2)
                a, b, c = self.cam2robot_fast(6, 5,"down")
                if r >= pr:
                    self.led_controllers_pub.publish(led)
                    self.get_logger().info(
                    f"只发现陈列框")
                    vx = k*a
                    vy = k*b
                    if abs(vx) < 0.01:
                        vx = 0.01 if vx >= 0 else -0.01
                    if abs(vy) < 0.01:
                        vy = 0.01 if vy >= 0 else -0.01
                    if abs(vx) > 0.04:
                        vx = 0.04 if vx >= 0 else -0.04
                    if abs(vy) > 0.04:
                        vy = 0.04 if vy >= 0 else -0.04
                    self.fast_movex(vx)
                    self.fast_movey(vy)
                    time.sleep(step_time)
                else:
                    self.get_logger().info(
                    f"陈列框已经进入视野中心")
            else:
                self.led(1,1)
                self.get_logger().info(
                f"检测到非必要物体")       
        self.led(0,0)
    #投球
    def thrball(self,pr,timeout,k,step_time):
        led = LedControllers()
        bridge = CvBridge()
        img = bridge.imgmsg_to_cv2(self.down_cam_Image_data,"bgr8")
        row_index = img.shape[0] // 2
        column_index = img.shape[1] // 4
        self.get_logger().info(f"row: {row_index} , column: {column_index}")
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                break
            if all(x==0 for x in self.yolov8_data_down.state):
                led.led0 = 0
                led.led1 = 0
                self.led_controllers_pub.publish(led)
                self.get_logger().info(
                f"没有找到任何物体")
            elif self.yolov8_data_down.state[5] == 1:
                r = sqrt((self.yolov8_data_down.targets[5].tpos_inpic.y -  row_index)**2 + (self.yolov8_data_down.targets[5].tpos_inpic.x -  column_index)**2)/sqrt(480**2+640**2)
                led.led0 = 1
                led.led1 = 0
                a, b, c = self.cam2robot_fast(5, 5,"down")
                if r >= pr:
                    self.led_controllers_pub.publish(led)
                    self.get_logger().info(
                                            f"发现收集框")
                    vx = k*a
                    vy = k*b
                    if abs(vx) < 0.01:
                        vx = 0.01 if vx >= 0 else -0.01
                    if abs(vy) < 0.01:
                        vy = 0.01 if vy >= 0 else -0.01
                    if abs(vx) > 0.04:
                        vx = 0.04 if vx >= 0 else -0.04
                    if abs(vy) > 0.04:
                        vy = 0.04 if vy >= 0 else -0.04
                    self.fast_movex(vx)
                    self.fast_movey(vy)
                    time.sleep(step_time)
                else:
                    self.get_logger().info(f"收集框已进入视野中心")
                    break
            else:
                led.led0 = 1
                led.led1 = 1
                self.led_controllers_pub.publish(led)
                self.get_logger().info(
                f"检测到非必要物体")
        a, b, c = self.cam2robot(5, 5,"down")
        led.led0 = 1
        led.led1 = 0
        self.led_controllers_pub.publish(led)
        self.movex(a)
        self.movey(b-0.175)   
        self.pow(0) 
        time.sleep(1)      
        led.led0 = 0
        led.led1 = 0
        self.led_controllers_pub.publish(led)

    def pass_door(self,num):
        self.setz(0.5)
        #self.setrz(0)
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= 30:
                self.get_logger().info("超时,采用planB")
                self.movey(1.0)
                break
            if self.yolov8_data_front.state[num] == 1:
                self.get_logger().info(f"检测到资格门")
                time.sleep(2)
                a, b, c = self.cam2robot_fast(num, 5,"front")
                b = b 
                rz = atan2(b, a)*RAD2DEG - 90
                self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
                self.moverz(rz)
                cnt = 0
                cnt2 = 0
                cnt3 = 0
                cnt4 = 0
                cmd = TargetPosDown()
                cmd.cs = 2
                cmd.pos.rx = 0.0
                cmd.pos.ry = 0.0
                cmd.pos.x = 0.0
                cmd.pos.y = 0.01
                cmd.pos.z = 0.0
                cmd.pos.rz = 0.0
                time.sleep(0.5)
                while True:
                    cnt+=1
                    if self.yolov8_data_front.state[num] == 0 or cnt > 300:
                        cnt4 += 1
                        time.sleep(0.1)
                        if self.yolov8_data_front.state[num] == 0 or cnt > 300:
                            cnt4 += 1#0.1秒后再进行一次检测
                    if cnt4 > 20 or cnt > 300:    
                        while True:
                            cnt3+=1
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(0.08)
                            if cnt3 > 60 :
                                break              
                        break
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(0.1)
                break

        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        time.sleep(1.0)
        if num == 5:#红，顺时针
            self.get_logger().info("开始旋转")
            cmd.pos.rz = 0.55
            while True:
                cnt2+=1
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.025)
                if cnt2 > 680:
                    break
            
        elif num == 11:#蓝
            self.get_logger().info("开始旋转")
            cmd.pos.rz = -0.55
            while True:
                cnt2+=1
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.025)
                if cnt2 > 680:
                    break
        #self.movey(0.5)
        time.sleep(1.5)
        self.movey(0.5)
        self.get_logger().info(f"过门任务完成")

    def led(self, led0, led1):
        led = LedControllers()
        led.led0 = led0
        led.led1 = led1
        self.led_controllers_pub.publish(led)
    
    def delay(self, t):
        time.sleep(t)
    
    def grab_golf(self, kind, dx, dy, down_depth, up_depth):
        
        num = 0
        
        if kind == "blue_golf":
            num = 4
        if kind == "red_golf":
            num = 3

        
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.1
        
        sample_flag = 0
        golf_cnt = 0
        
        self.pow(1)
        self.led(0, 0)
        s = 1
        while True:
            if all(x == 0 for x in self.yolov8_data_front.state) and \
               all(y == 0 for y in self.yolov8_data_down.state):
                # pass
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                golf_cnt+=1
                
            else:
                if self.yolov8_data_front.state[6]!= 0 :
                    self.get_logger().info("前视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"front")
                    a = a + 0.1
                    b = b - 0.1                    
                    self.movex(a)
                    self.movey(b)
                    self.setz(0.2)
                    time.sleep(2)
                    break
                elif self.yolov8_data_down.state[6]!= 0 :
                    self.get_logger().info("下视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"down")
                    a = a + 0.1
                    b = b - 0.1                      
                    self.movex(a)
                    self.movey(b)
                    self.setz(0.2)
                    time.sleep(2)
                    break
                else:
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(0.01)
                    golf_cnt+=1 
            if  golf_cnt>4000 :
                self.get_logger().info("任务失败")
                self.get_logger().info("======上浮======")
                self.setz(-0.5)
                return
                     
        '''s = self.search(kind, "down")
        if s == 0:
            self.get_logger().info("======下无目标======")
            self.get_logger().info("======第一次平移寻找目标目标======")
            self.movex(0.2)
            self.movey(0.2)
            s = self.search( kind, "down")
            if s == 0:
                self.get_logger().info("======下无目标======")
                self.get_logger().info("======第二次平移寻找目标目标======")
                self.movey(-0.4)
                s = self.search( kind, "down")
                if s == 0:
                    self.get_logger().info("======下无目标======")
                    self.get_logger().info("======第三次平移寻找目标目标======")
                    self.movex(-0.4)
                    s = self.search( kind, "down")
                    if s == 0:
                        self.get_logger().info("======下无目标======")
                        self.get_logger().info("======第四次平移寻找目标目标======")
                        self.movey(0.4)
                        s = self.search(kind, "down")
                        if s == 0:
                            self.get_logger().info("======下无目标======")
                            self.get_logger().info("======任务失败======")
                            return
        if s != 0 :
            self.get_logger().info("======发现球======")  
            self.get_logger().info("======正在移向球======")   
            self.mttxf(0,0) '''
        golf_cnt = 0
        while True: 
            if all(x == 0 for x in self.yolov8_data_front.state) and \
               all(y == 0 for y in self.yolov8_data_down.state):
                golf_cnt+=1
                time.sleep(0.01)
                if golf_cnt>2000:
                    self.get_logger().info("======确认无目标======")
                    self.get_logger().info("======上浮======")
                    self.setz(-0.5)
                    time.sleep(5.0)
                    self.get_logger().info("=====上浮结束======")
                    return                  
            elif self.yolov8_data_down.state[num] !=0:
                self.get_logger().info("======发现目标球=====")
                a, b, c = self.cam2robot(num, 5,"down")
                a = a - dx
                b = b - dy 
                self.movex(a)
                self.movey(b)

                self.delay(1)
                self.led(1, 0)
                self.movez(down_depth)
                self.get_logger().info("=====抓球结束，开始上浮======")
                self.setz(0.15)
                time.sleep(8.0)
                self.led(0, 0)
                if self.yolov8_data_down.state[6]!= 0 :
                    self.get_logger().info("下视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"down")
                    a = a + 0.1
                    b = b - 0.1                      
                    self.movex(a)
                    self.movey(b)
                    time.sleep(2)
                    break
                self.setz(-0.5)
                time.sleep(8.0)
                self.get_logger().info("=====上浮结束======")
                return
            else:
                golf_cnt+=1
                time.sleep(0.01)
                if golf_cnt>2000:
                    self.get_logger().info("======确认无目标======")
                    self.get_logger().info("======上浮======")
                    self.setz(-0.5)
                    time.sleep(5)
                    self.get_logger().info("=====上浮结束======")
                    return  
    
    
    def put_t(self, num,dy,dz):
        T_cnt = 0
        T_cnt2 = 0
        T_cnt3 = 0
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.01

        while True:
            if self.yolov8_data_front.state[num] == 0: 
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.001)
                T_cnt+=1
                

            elif  self.yolov8_data_front.state[num] != 0:
                time.sleep(2)
                T_cnt = 0
                self.get_logger().info("发现目标")
                a, b, c = self.cam2robot(num, 5,"front")
                a=a-dy
                c=c-dz
                self.movex(a)
                self.movez(c)
                time.sleep(1)
                cmd.pos.rz = 0.0
                while True:
                    T_cnt2+=1
                    if self.yolov8_data_front.state[num] != 0 and T_cnt2 % 600 == 0: 
                        time.sleep(2)
                        a, b, c = self.cam2robot(num, 5,"front")
                        a=a-dy
                        c=c-dz
                        if (abs(a) > 0.03 or abs(c) > 0.03) and b > 0.25:
                            self.get_logger().info("======目标偏移======")
                            cmd.pos.x = float(a)
                            cmd.pos.z = float(c)
                            cmd.pos.y = 0.0
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(2)
                        else:
                            cmd.pos.y = 0.001
                            cmd.pos.x = 0.0
                            cmd.pos.z = 0.0
                            self.target_pos_down_pub.publish(cmd)
                            self.get_logger().info("======正在前进======")
                            T_cnt+=1
                            time.sleep(0.01)

                    else:
                        cmd.pos.y = 0.001
                        cmd.pos.x = 0.0
                        cmd.pos.z = 0.0
                        self.target_pos_down_pub.publish(cmd)
                        T_cnt+=1
                        time.sleep(0.01)
                    if T_cnt > 1000*(b+0.7):
                            self.pow(1)
                            self.get_logger().info("======任务完成======")
                            return
            if T_cnt>4000:
                self.get_logger().info("======未发现目标 任务失败======")            
                
    def endfloat(self):
   
        num = 5
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.2
        plate_cnt = 0
        while True:
            if self.yolov8_data_front.state[num] ==0 and \
               self.yolov8_data_down.state[num] ==0 :
                # pass
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                golf_cnt+=1
                
            else:
                if self.yolov8_data_front.state[num] ==1:
                    self.get_logger().info("前视发现目标")
                    time.sleep(2)
                    a, b, c = self.cam2robot(num, 5,"front")
                    a = a - 0.3
                    b = b - 0.5                    
                    self.movex(a)
                    self.movey(b)
                    time.sleep(1)
                    self.setz(-0.1)
                    self.get_logger().info("任务成功")
                    break
                else:
                    self.get_logger().info("下视发现目标")
                    a, b, c = self.cam2robot(num, 5,"down")
                    a = a - 0.3
                    b = b - 0.5                    
                    self.movex(a)
                    self.movey(b)
                    time.sleep(1)
                    self.setz(-0.1)
                    self.get_logger().info("任务成功")
                    break
            if  plate_cnt>2000 :
                self.get_logger().info("任务失败")
                return


    def throw_golf(self, dy, depth):
        self.get_logger().info("======开始投球======")
        self.led(0, 1)
        self.search('col_basket', 'down')
        self.led(1, 1)
        self.mttxf(0, dy)
        self.movez(depth)
        self.led(1, 0)
        self.pow(0)
        self.delay(1)
        self.led(0, 0)
        self.get_logger().info("======投球结束======")
        
    def strike_ball(self,num):
        
        ball_cnt = 0
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.05

        while True:
            if self.yolov8_data_front.state[num] == 0: 
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                ball_cnt+=1
            elif  self.yolov8_data_front.state[num] != 0:
                time.sleep(2)
                ball_cnt = 0
                self.get_logger().info("发现目标")
                a, b, c = self.cam2robot(num, 5,"front")
                #a = a 
                c = c - 0.32
                b = b - 0.2
                self.fast_movez(c)
                time.sleep(1)
                self.movexy(a,b)
                time.sleep(1)
                self.get_logger().info("======任务完成 正在返回======")
                self.fast_movey(-b)
                self.move_wait()
                time.sleep(4)
                self.get_logger().info("======返回完成======")
                               
                return
            if ball_cnt>75000:
                self.get_logger().info("======未发现目标 任务失败======")
                return
                
    def strike_ball3(self,num1,num2,num3):
        self.get_logger().info("======撞球任务开始======")
        #self.setp()
        self.get_logger().info("======撞第一个球======")
        self.strike_ball(num1)
        #self.fast_moverz(180.0)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        #time.sleep(4)
        self.get_logger().info("======撞第二个球======")
        self.strike_ball(num2)
        #self.fast_moverz(180.0)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        #time.sleep(4)
        self.get_logger().info("======撞第三个球======")
        self.strike_ball(num3)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        
    def line_qd(self):
        
            
        self.led(0,0)
        
        self.pid_parameters.p = 0.0009
        self.pid_parameters.i = 0.0
        self.pid_parameters.d = 0.08
        self.pid_parameters.output_limit = 5.0

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        drz = 0.0

        timesleep = 0.025
        
        self.task_lock = [0,0,0]
        
        magnet = MagnetController()
        led = LedControllers()
        bridge = CvBridge()
    
        window_size = 3  # 滑动窗口的大小
        last_positions = []  # 使用列表来存储最近的位置
        cnt = 0
        cnt_1 = 0
        #等待准备就绪
        time.sleep(1.0)
        while True:
            #try:
            # 转化为opencv图像
            img1 = bridge.imgmsg_to_cv2(self.down_cam_Image_data, "mono8")
            img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
            if img is None:
                self.get_logger().error("bridge.imgmsg_to_cv2 returned None")
                return
            img = cv2.flip(img, -1)

            row_index = img.shape[0] // 3
            row_index1 = img.shape[0] // 2
            column_index = img.shape[1] // 2
            row = img[row_index, :]
            white_pixels = np.where(row == 255)[0]

            # 计算白点的平均位置作为线的中心
            if white_pixels.size > 0:
                line_center = np.mean(white_pixels).astype(int)
                last_positions.append(line_center)
                if len(last_positions) > window_size:  # 如果列表长度超过窗口大小，删除最旧的元素
                    last_positions.pop(0)
            else:
                if last_positions:
                    line_center = last_positions[-1]  # 如果没有检测到新的，则使用上一个

            # 计算滑动平均
            if len(last_positions) > 1:
                smoothed_center = int(np.mean(last_positions))
                cv2.circle(img, (smoothed_center, row_index), 10, (0, 0, 0), -1)  # 标记平滑后的中心点
            else:
                smoothed_center = img.shape[1] // 2
                cv2.circle(img, (smoothed_center, row_index), 10, (0, 0, 0), -1)

            # 在图像上添加文字
            cv2.putText(img, "output: {:.2f}".format(drz), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)

            img_msg = bridge.cv2_to_imgmsg(img, "mono8")
            self.line_patrol_img_pub.publish(img_msg)

            angle_error = smoothed_center - column_index
            drz = self.pid_update(angle_error)

            if all(x==0 for x in self.yolov8_data_down.state):
                # pass
                cmd.pos.x = 0.0
                cmd.pos.y = 0.002
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt_1 += 1
                
            elif not all(x==0 for x in self.yolov8_data_down.state):
                if  self.yolov8_data_down.state[0] != 0 and  self.yolov8_data_down.targets[0].tpos_inpic.y > row_index1 :
                    if self.task_lock[0] == 0 :
                        self.get_logger().info("Info:检测A，开始执行任务") 
                        #self.setp()
                        #a, b, c = self.cam2robot(1, 5,"down")
                        #self.movex(a)
                        #self.movey(b)
                    
                        # 保存任务结束时的图片
                        task1_end_img_path = f"A.png"
                        cv2.imwrite(task1_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task1_end_img_path}")

                        self.get_logger().info("Info:任务执行完毕")
                        #self.back()
                        self.task_lock[0] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[1] != 0 and self.yolov8_data_down.targets[1].tpos_inpic.y > row_index1:
                    if self.task_lock[1] == 0 :
                        self.get_logger().info("Info:检测B，开始执行任务")
                        #self.setp()
                        #a, b, c = self.cam2robot(2, 4,"down")
                        #self.movex(a)
                        #self.movey(b)
                        
                        # 保存任务结束时的图片
                        task2_end_img_path = f"B.png"
                        cv2.imwrite(task2_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task2_end_img_path}")

                        #self.back()
                        self.get_logger().info("Info:任务执行完毕")
                        self.task_lock[1] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[2] != 0 and self.yolov8_data_down.targets[2].tpos_inpic.y > row_index1:
                    if self.task_lock[2] == 0 :
                        self.get_logger().info("Info:检测C，开始执行任务") 
                        #self.setp()
                        #a, b, c = self.cam2robot(0, 4,"down")
                        #self.movex(a)
                       # self.movey(b)
                        # 保存任务结束时的图片
                        task3_end_img_path = f"C.png"
                        cv2.imwrite(task3_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task3_end_img_path}")

                        self.get_logger().info("Info:任务执行完毕")
                        self.task_lock[2] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)

                else:
                    #pass
                    cmd.pos.x = 0.0
                    cmd.pos.y = 0.002
                    cmd.pos.z = 0.0
                    cmd.pos.rz = drz
                    self.target_pos_down_pub.publish(cmd)
                    cnt_1 += 1
                    time.sleep(timesleep)
            if cnt_1 > 1200:
                self.get_logger().info("Info:任务全部执行完毕")
                return
            if all(x == 1 for x in self.task_lock):
                cmd.pos.x = 0.0
                cmd.pos.y = 0.004
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt+=1
                if cnt > 200:
                    self.get_logger().info("Info:任务全部执行完毕")
                    return

          
    #巡线
    def line(self, ys_dep):
        self.led(0, 0)
        
        self.pid_parameters.p = 0.0009
        self.pid_parameters.i = 0.0
        self.pid_parameters.d = 0.08
        self.pid_parameters.output_limit = 5.0

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        drz = 0.0
        depth = ys_dep
        timesleep = 0.025
        
        self.task_lock = [0, 0, 0]
        
        magnet = MagnetController()
        bridge = CvBridge()
        
        # 初始化1D卡尔曼滤波器（仅跟踪位置）
        kf = KalmanFilter(dim_x=1, dim_z=1)
        kf.x = np.array([320.])  # 初始位置（图像中心附近）
        kf.F = np.array([[1.]])  # 状态转移矩阵（简单恒速模型）
        kf.H = np.array([[1.]])  # 观测矩阵
        kf.P *= 100.  # 初始协方差
        kf.R = 3.0    # 观测噪声
        kf.Q = np.array([[1.0]])  # 过程噪声
        
        # 图像状态跟踪变量
        last_valid_image_time = None
        has_valid_image = False
        last_filtered_center = 320  # 初始中心位置
        img_shape = (480, 640)  # 预设图像尺寸，根据实际情况调整
        row_index = img_shape[0] // 3  # 预设行索引
        row_index1 = img_shape[0] // 2  # 预设任务检测行索引
        column_index = img_shape[1] // 2  # 预设列中心
        
        # 新增：图像初始化等待机制
        init_wait_time = 0.1  # 初始化等待0.1秒
        start_time = time.time()
        self.get_logger().info(f"等待图像初始化，最多等待{init_wait_time}秒...")
        
        # 等待图像或超时
        while not has_valid_image and (time.time() - start_time) < init_wait_time:
            try:
                if self.segment_img is not None:
                    img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
                    img_shape = img.shape
                    row_index = img_shape[0] // 3
                    row_index1 = img_shape[0] // 2
                    column_index = img_shape[1] // 2
                    has_valid_image = True
                    last_valid_image_time = time.time()
                    self.get_logger().info("成功获取初始图像")
            except Exception as e:
                self.get_logger().debug(f"初始化阶段图像获取失败: {str(e)}")
            time.sleep(0.1)  # 短时间等待后重试
        
        if not has_valid_image:
            self.get_logger().warn(f"初始化超时，未获取到图像，将使用默认参数运行")
            
        cnt = 0
        cnt_1 = 0
        while True:
            cnt_1 = cnt_1 + 1
            if cnt_1 > 2000:
                self.get_logger().warn(f"时间结束自动退出")
                return
                
            # 尝试获取和处理图像
            try:
                if self.segment_img is not None:
                    img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
                    img = cv2.flip(img, -1)
                    img_shape = img.shape
                    row_index = img_shape[0] // 3
                    row_index1 = img_shape[0] // 2
                    column_index = img_shape[1] // 2
                    last_valid_image_time = time.time()
                    has_valid_image = True
                    
                    # 处理图像获取线中心
                    row = img[row_index, :]
                    white_pixels = np.where(row == 255)[0]

                    # 卡尔曼滤波处理
                    kf.predict()
                    
                    # 有观测值时更新
                    if white_pixels.size > 0:
                        line_center = np.mean(white_pixels).astype(int)
                        kf.update(line_center)
                    
                    # 使用滤波后的值
                    filtered_center = int(kf.x[0])
                    last_filtered_center = filtered_center
                    
                    # 绘制标记并发布图像
                    cv2.circle(img, (filtered_center, row_index), 10, (0, 0, 0), -1)
                    cv2.putText(img, "output: {:.2f}".format(drz), (50, 50), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)
                    img_msg = bridge.cv2_to_imgmsg(img, "mono8")
                    self.line_patrol_img_pub.publish(img_msg)
                    

                        
            except Exception as e:
                # 图像处理失败时的处理
                self.get_logger().warn(f"无分割图像: {str(e)}")
                
                # 仅使用预测
                kf.predict()
                filtered_center = int(kf.x[0])
                last_filtered_center = filtered_center
                
                # 状态判断与警示
                if not has_valid_image:
                    self.get_logger().warn("持续未接收到图像，使用默认控制策略")
                elif (time.time() - last_valid_image_time) > 1.0:
                    self.get_logger().warn("图像已丢失超过1秒，使用预测值控制")
    
            
            # 计算控制量
            angle_error = filtered_center - column_index
            # 无图像时减小控制增益，采用更保守的控制
            if not has_valid_image:
                drz = self.pid_update(angle_error) * 0.5  # 降低控制强度
                dy = 0.004  # 降低前进速度
            else:
                drz = self.pid_update(angle_error)
                dy = 0.005 - 0.0004 * abs(drz)
            
            # 控制逻辑
            if all(x == 0 for x in self.yolov8_data_down.state):
                cmd.pos.x = 0.0
                cmd.pos.y = dy
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                
            elif not all(x == 0 for x in self.yolov8_data_down.state):
                if self.yolov8_data_down.state[1] != 0 and self.yolov8_data_down.targets[1].tpos_inpic.y > row_index1:
                        if self.task_lock[0] == 0:
                            self.get_logger().info("检测到黑色方块，开始执行任务")
                            time.sleep(2)
                            magnet.state = 0
                            self.magnet_controller_pub.publish(magnet)
                            self.led(1, 1)
                            time.sleep(1)
                            self.get_logger().info("任务执行完毕")
                            self.task_lock[0] = 1
                        else:
                            cmd.pos.x = 0.0
                            cmd.pos.y = dy
                            cmd.pos.z = 0.0
                            cmd.pos.rz = drz
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(timesleep)
                elif self.yolov8_data_down.state[2] != 0 and self.yolov8_data_down.targets[2].tpos_inpic.y > row_index1:
                    if self.task_lock[1] == 0:
                        self.get_logger().info("检测到绿色圆形，开始执行任务")
                        time.sleep(2)
                        a, b, c = self.cam2robot(2, 4, "down")
                        b = b - 0.4
                        self.movex(a)
                        self.movey(b)
                        self.movez(depth)
                        self.led(1,0)
                        self.movez(-depth)
                        self.led(0,0)
                        self.get_logger().info("任务执行完毕")
                        self.task_lock[1] = 1
                    else:
                        cmd.pos.x = 0.0
                        cmd.pos.y = dy
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[0] != 0 and self.yolov8_data_down.targets[0].tpos_inpic.y > row_index1:
                    if self.task_lock[2] == 0:
                        self.get_logger().info("检测到黄色三角，开始执行任务")
                        time.sleep(2)
                        self.moverz(179.9)
                        time.sleep(1)
                        self.moverz(179.9)
                        time.sleep(1)
                        self.get_logger().info("任务执行完毕")
                        self.task_lock[2] = 1
                    else:
                        cmd.pos.x = 0.0
                        cmd.pos.y = dy
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        time.sleep(timesleep)
                else:
                    cmd.pos.x = 0.0
                    cmd.pos.y = dy
                    cmd.pos.z = 0.0
                    cmd.pos.rz = drz
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(timesleep)
                    
            if all(x == 1 for x in self.task_lock):
                cmd.pos.x = 0.0
                cmd.pos.y = dy
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt += 1
                if cnt > 190:
                    return
    

            # except Exception as e:
            #     self.get_logger().error(f"图像处理过程中出现错误 {e}")
            #     break
                # except Exception as e:
                #     self.get_logger().error(f"图像处理过程中出现错误 {e}")
                #     break
 


# 从命令行获取任务
def get_act():
    command = input("请输入任务: \n")
    parts = command.split()
    if parts[0] == 'movexyz':
        args = parts[1:]
        if len(args) == 3:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dic = {
                "name": "movexyz",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'throw_golf':
        args = parts[1:]
        if len(args) == 2:
            dy = float(args[0])
            depth = float(args[1])
            dic = {
                "name": "throw_golf",
                "params": {
                    "dy": dy,
                    "depth": depth,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'movexy':
        args = parts[1:]
        if len(args) == 2:
            x = float(args[0])
            y = float(args[1])
            dic = {
                "name": "movexy",
                "params": {
                    "x": x,
                    "y": y,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movex':
        args = parts[1:]
        if len(args) == 1:
            x = float(args[0])
            dic = {
                "name": "movex",
                "params": {
                    "x": x,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movey':
        args = parts[1:]
        if len(args) == 1:
            y = float(args[0])
            dic = {
                "name": "movey",
                "params": {
                    "y": y,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movez':
        args = parts[1:]
        if len(args) == 1:
            z = float(args[0])
            dic = {
                "name": "movez",
                "params": {
                    "z": z,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'moverz':
        args = parts[1:]
        if len(args) == 1:
            rz = float(args[0])
            dic = {
                "name": "moverz",
                "params": {
                    "rz": rz,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'setz':
        args = parts[1:]
        if len(args) == 1:
            z = float(args[0])
            dic = {
                "name": "setz",
                "params": {
                    "z": z,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'setrz':
        args = parts[1:]
        if len(args) == 1:
            rz = float(args[0])
            dic = {
                "name": "setrz",
                "params": {
                    "rz": rz,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'pow':
        args = parts[1:]
        if len(args) == 1:
            a = int(args[0])
            dic = {
                "name": "pow",
                "params": a
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mtty':
        args = parts[1:]
        if len(args) == 2:
            y = float(args[0])
            z = float(args[1])
            dic = {
                "name": "mtty",
                "params": {
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttxf':
        args = parts[1:]
        if len(args) == 2:
            dx = float(args[0])
            dy = float(args[1])
            dic = {
                "name": "mttxf",
                "params": {
                    "dx": dx,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttz':
        args = parts[1:]
        if len(args) == 2:
            y = float(args[0])
            z = float(args[1])
            dic = {
                "name": "mttz",
                "params": {
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttzxy':
        args = parts[1:]
        if len(args) == 3:
            dz = float(args[0])
            dx = float(args[1])
            dy = float(args[2])
            dic = {
                "name": "mttzxy",
                "params": {
                    "dz": dz,
                    "dx": dx,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
    elif parts[0] == 'setp':
        if len(parts) == 1:
            dic = {
                "name": "setp",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'back':
        if len(parts) == 1:
            dic = {
                "name": "back",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'backy':
        if len(parts) == 1:
            dic = {
                "name": "backy",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'search':
        args = parts[1:]
        if len(args) == 2:
            name = args[0]
            cam = args[1]
            dic = {
                "name": "search",
                "params": {
                    "name": name,
                    "cam": cam
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'line':
        args = parts[1:]
        if len(args) == 1:
            ys_dep = float(args[0])
            dic = {
                "name": "line",
                "params": {
                    "ys_dep": ys_dep
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None 
        
    elif parts[0] == 'mttpos':
        args = parts[1:]
        if len(args) == 5:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            rz = float(args[3])
            dy = float(args[4])
            dic = {
                "name": "mttpos",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "rz": rz,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'mttzpos':
        args = parts[1:]
        if len(args) == 4:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dy = float(args[3])
            dic = {
                "name": "mttzpos",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'mttpos_amend':
        args = parts[1:]
        if len(args) == 5:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            rz = float(args[3])
            dy = float(args[4])
            dic = {
                "name": "mttpos_amend",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "rz": rz,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'mttzpos_amend':
        args = parts[1:]
        if len(args) == 4:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dy = float(args[3])
            dic = {
                "name": "mttzpos_amend",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'graball':
        args = parts[1:]
        if len(args) == 6:
            color       =   str(args[0])
            depth       =   float(args[1])
            timeout     =   float(args[2])
            pr          =   float(args[3])
            k           =   float(args[4])
            step_time   =   float(args[5])           
            dic = {
                "name": "graball",
                "params": {
                    "color": color,
                    "depth": depth,
                    "timeout": timeout,
                    "pr": pr,
                    "k" : k,
                    "step_time":step_time
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'thrball':
        args = parts[1:]
        if len(args) == 4:
            pr        =   float(args[0])
            timeout   =   float(args[1])
            k         =   float(args[2])
            step_time =   float(args[3])  
            dic = {
                "name": "thrball",
                "params": {
                    "pr": pr,
                    "timeout": timeout,
                    "k" : k,
                    "step_time":step_time
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None  
    elif parts[0] == 'pass_door':
        args = parts[1:]
        if len(args) == 1:
            num       =   int(args[0])
            dic = {
                "name": "pass_door",
                "params": {
                    "num":num
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'led':
        args = parts[1:]
        if len(args) == 2:
            led0 = int(args[0])
            led1 = int(args[1])
            dic = {
                "name": "led",
                "params": {
                    "led0": led0,
                    "led1": led1
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'delay':
        args = parts[1:]
        if len(args) == 1:
            t = float(args[0])
            dic = {
                "name": "delay",
                "params": t
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'grab_golf':
        args = parts[1:]
        if len(args) == 5:
            kind = str(args[0])
            dx = float(args[1])
            dy = float(args[2])
            down_depth = float(args[3])
            up_depth = float(args[4])
            dic = {
                "name": "grab_golf",
                "params": {
                    "kind": kind,
                    "dx": dx,
                    "dy": dy,
                    "down_depth": down_depth,
                    "up_depth": up_depth
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'line_qd':
        args = parts[1:]
        if len(args) == 0:
            dic = {
                "name": "line_qd",
                "params": {}  # 无参数时为空字典
            }
            return dic
        else:
            print("指令格式不正确，line_qd不需要参数")
            return None 
        
    elif parts[0] == 'endfloat':
        args = parts[1:]
        if len(args) == 0:
            dic = {
                "name": "endfloat",
                "params": {}  # 无参数时为空字典
            }
            return dic
        else:
            print("指令格式不正确，line_qd不需要参数")
            return None 
    
    elif parts[0] == 'put_t':
        args = parts[1:]
        if len(args) == 3:
            num = int(args[0])
            dy = float(args[1])
            dz = float(args[2])
            dic = {
                "name": "put_t",
                "params": {
                    "num": num,
                    "dy": dy,
                    "dz": dz
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'strike_ball':
        args = parts[1:]
        if len(args) == 1:
            num = int(args[0])
            dic = {
                "name": "strike_ball",
                "params": {
                    "num": num
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'strike_ball3':
        args = parts[1:]
        if len(args) == 3:
            num1 = int(args[0])
            num2 = int(args[1])
            num3 = int(args[2])
            dic = {
                "name": "strike_ball3",
                "params": {
                    "num1": num1,
                    "num2": num2,
                    "num3": num3
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    else:
        print("无效指令")
        return None
    
    


# 读取并从文件中加载任务队列
def load_actions(path):
    with open(path, 'r', encoding='utf-8') as f:
        dic = json.load(f)
    return dic

# 保存任务队列


def save_actions(dic, path):
    print("所保存的任务:\n"+str(dic)+"\n")
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(dic, f)

# 普通模式


def commom_loop(node, opt):
    list = load_actions(opt.data_path[0]+"uv_tasks.json")

    node.start()
    num = 0

    for act in list["tasks"]:
        node.get_logger().info(
            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
        node.run(act)
        node.get_logger().info(
            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
        num += 1
    
    node.end()

# 调试模式


def debug_loop(node: CoreNode, opt):
    node.get_logger().info("Info:进入调试模式")

    tasklist = load_actions(opt.data_path[0]+"uv_tasks.json")
     
    help_txt = ""
    with open(opt.data_path[0]+"help.txt", 'r', encoding='utf-8') as f:
        s = f.read()
        help_txt = s

    node.start()

    while True:
        node.get_logger().info(f"Info:等待指令输入")
        command = input("请输入调试指令: \n")
        parts = command.split()
        if parts[0] == 'help':
            print(help_txt)
        elif parts[0] == 'act':
            act = get_act()

            if act == None:
                node.get_logger().info(f"Warn:非法任务")
            else:
                node.get_logger().info(
                    f"Info:=========执行任务: " + act["name"] + "=========")
                node.run(act)
                node.get_logger().info(
                    f"Info:=========完成任务: " + act["name"] + "=========")
        elif parts[0] == "task":
            if parts[1] == "run":
                if len(parts[1:]) == 1:
                    num = 0
                    for act in tasklist["tasks"]:
                        node.get_logger().info(
                            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
                        node.run(act)
                        node.get_logger().info(
                            f"Info:=========完成第 {num:d} 步任务: " + act["name"] + "=========")
                        num += 1
                elif len(parts[1:]) == 2:
                    num = int(parts[parts.index('run') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        n = num
                        for act in tasklist["tasks"][num:]:
                            node.get_logger().info(
                                f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
                            node.run(act)
                            node.get_logger().info(
                                f"Info:=========完成第 {num:d} 步任务: " + act["name"] + "=========")
                            n += 1
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "runonly":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('runonly') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = tasklist["tasks"][num]
                        node.get_logger().info(
                            "Info:=========执行任务: " + act["name"] + "=========")
                        node.run(act)
                        node.get_logger().info(
                            "Info:=========完成任务: " + act["name"] + "=========")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "add":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('add') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = get_act()
                        if act == None:
                            node.get_logger().info("非法任务")
                        else:
                            tasklist["tasks"].insert(num, act)
                            save_actions(
                                tasklist, opt.data_path[0]+"uv_tasks.json")
                elif len(parts[1:]) == 1:
                    act = get_act()
                    if act == None:
                        node.get_logger().info("非法任务")
                    else:
                        tasklist["tasks"].append(act)
                        save_actions(
                            tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "del":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('del') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        tasklist["tasks"].pop(num)
                        save_actions(
                            tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "clear":
                tasklist["tasks"] = []
                save_actions(tasklist, opt.data_path[0]+"uv_tasks.json")
            elif parts[1] == "list":
                node.get_logger().info("Info: 打印任务列表")
                num = 0
                for i in tasklist["tasks"]:
                    print("编号:   " + str(num))
                    print("任务名: "+i["name"])
                    print("参数:   " + str(i["params"]))
                    num += 1
            elif parts[1] == "mod":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('mod') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = get_act()
                        if act == None:
                            node.get_logger().info("非法任务")
                        else:
                            tasklist["tasks"][num] = act
                            save_actions(
                                tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            else:
                node.get_logger().info("Warn:非法指令")


def main(args=None):

    # 加载参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--front-topic', nargs='+', type=str, default=[
                        'front_cam/rectified'], help='前视摄像头')
    parser.add_argument('--down-topic', nargs='+', type=str, default=[
                        'down_cam/rectified'], help='下视摄像头')
    parser.add_argument('--data-path', nargs='+', type=str, default=[
                        '/home/nvidia/Workspace/Cruise/datas/'], help='PID参数路径')
    parser.add_argument('--debug', nargs='+', type=bool,
                        default=False, help='PID参数路径')

    opt = parser.parse_args()

    rclpy.init(args=args)  # 初始化rclpy

    if opt.debug:
        node = CoreNode("uv_automaton_debug", opt)  # 新建一个节点
        thread_debug = threading.Thread(
            target=debug_loop, args=(node, opt))  # 创建调度线程
        thread_debug.start()
    else:
        node = CoreNode("uv_automaton", opt)  # 新建一个节点
        thread_common = threading.Thread(
            target=commom_loop, args=(node, opt))    # 创建调度线程
        thread_common.start()

    node.get_logger().info("节点与调度线程成功启动")

    rclpy.spin(node)  # 保持节点运行，检测是否收到退出指令（Ctrl+Z）
    rclpy.shutdown()  # 关闭rclpy

===== .\uv_ai\uv_ai\uv_automaton - 副本.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import time
import os
import termios
import struct
import threading
import json
import argparse
from uv_control_py import Pid
from uv_control_py.CoordinateSystem import CoordinateSystems, MotionState, Cs_Back, Cs_Move, AngleCorrect

from uv_msgs.msg import RobotDeviceManager  # 机器人设备管理器
from uv_msgs.msg import RobotMotionController  # 机器人运动控制器

from uv_msgs.msg import PidControllersState
from uv_msgs.msg import PidParams#巡线的pid参数

from uv_msgs.msg import RobotAxis
from uv_msgs.msg import ServoSet
from uv_msgs.msg import TargetPosDown
from uv_msgs.msg import Yolov8
from uv_msgs.msg import LedControllers
from uv_msgs.msg import MagnetController

from sensor_msgs.msg import Image
from uv_msgs.srv import DetectRequest
import cv2
import numpy as np
from cv_bridge import CvBridge
from filterpy.kalman import KalmanFilter


from math import sin, cos, atan2, sqrt

PI = 3.141592653589793
DEG2RAD = PI/180
RAD2DEG = 180/PI

Step = {  # 领航点拖曳速度(10hz)
    "x": 0.01,
    "y": 0.01,
    "z": 0.05,
    "rz": 5.0
}

AllowedError = {  # 位置容许误差
    "x": 0.02,
    "y": 0.02,
    "z": 0.02,
    "rz": 1.3
}


class CoreNode(Node):
    def __init__(self, name, opt):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)
        self.opt = opt

        self.robot = CoordinateSystems()

        self.MotionController = RobotMotionController()
        #pid参数初始化
        self.pid_parameters = PidParams()
        # self.pid_parameters.p = 0.0
        # self.pid_parameters.i = 0.0
        # self.pid_parameters.d = 0.0

        self.previous_error = 0.0
        self.i_error = 0.0
        self.dt = 1

        self.task_lock = True
        self.yolov8_data_down = Yolov8()
        self.yolov8_data_front = Yolov8()
        self.magnet = MagnetController()

        self.target = {
            "name": "none",
            "x": 0.0,
            "y": 0.0,
            "z": 0.0
        }

        self.backpoint = {
            "x": 0.0,
            "y": 0.0,
            "z": 0.0,
            "rz": 0.0
        }

        self.front_cam = CoordinateSystems()
        self.down_cam = CoordinateSystems()
        #前视相机坐标偏置
        self.front_cam.base.vector.x = 107.6/1000
        self.front_cam.base.vector.y = 320.0/1000
        self.front_cam.base.vector.z = 65.0/1000
        self.front_cam.base.vector.rx = -90.0
        self.front_cam.base.extract()
        #下视相机偏置
        self.down_cam.base.vector.x = 0.0/1000
        self.down_cam.base.vector.y = 170.0/1000
        self.down_cam.base.vector.z = 42.7/1000
        self.down_cam.base.vector.rz = 0.0
        self.down_cam.base.extract()

        self.get_logger().info(
            f"前置摄像机偏置: x: {self.front_cam.base.vector.x:.2f} y: { self.front_cam.base.vector.y : .2f} z: {self.front_cam.base.vector.z : .2f}")
        self.get_logger().info(
            f"          : rx: {self.front_cam.base.vector.rx:.2f} ry: { self.front_cam.base.vector.ry : .2f} rz: {self.front_cam.base.vector.rz : .2f}")
        self.get_logger().info(
            f"下置摄像机偏置: x: {self.down_cam.base.vector.x:.2f} y: { self.down_cam.base.vector.y : .2f} z: {self.down_cam.base.vector.z : .2f}")
        self.get_logger().info(
            f"          : rx: {self.down_cam.base.vector.rx:.2f} ry: { self.down_cam.base.vector.ry : .2f} rz: {self.down_cam.base.vector.rz : .2f}")
        
        self.start_pos = CoordinateSystems()
        
        self.front_cam_Image_data = None
        self.down_cam_Image_data = None
        self.front_cam_left_Image_data = None
        self.segment_img = None

        # 话题发布
        # 创建话题发布 target_pos_down ，定义其中的消息类型为 TargetPosDown
        self.target_pos_down_pub = self.create_publisher(
            TargetPosDown, "target_pos_down", 10)
        # 创建话题发布 servo_control ，定义其中的消息类型为 ServoSet
        self.servo_control_pub = self.create_publisher(
            ServoSet, "servo_control", 10)
        #创建话题发布  led_controllers, 定义其中的消息类型为 LedControllers
        self.led_controllers_pub = self.create_publisher(
            LedControllers, 'led_controllers', 10)
        # 创建话题发布 magnet_controller ，定义其中的消息类型为 MagnetController
        self.magnet_controller_pub = self.create_publisher(
            MagnetController, "magnet_controller", 10)
        # 创建话题发布 pid_controllers_set ，定义其中的消息类型为 PidControllersState
        self.pid_controllers_set_pub = self.create_publisher(
            PidControllersState, 'pid_controllers_set', 10)
        #创建话题发布 line_patrol_img , 定义消息类型为Image
        self.line_patrol_img_pub = self.create_publisher(
            Image, 'line_patrol_img', 10)

        self.openthrust_data_pub = self.create_publisher(
            RobotAxis, 'openloop_thrust', 10)

        # 话题接收
        # 创建话题接收 motion_controller ，定义其中的消息类型为 RobotMotionController
        self.create_subscription(
            RobotMotionController, 'motion_controller', self.motion_controller_callback, 10)
        # 创建话题接收 front_cam/rectified ，定义其中的消息类型为 Image
        self.create_subscription(
            Image, opt.front_topic[0], self.front_cam_callback, 10)
        # 创建话题接收 down_cam/rectified ，定义其中的消息类型为 Image
        self.create_subscription(
            Image, opt.down_topic[0], self.down_cam_callback, 10)
        #创建话题接收 front_cam/rectified/left,定义其中的消息类型为 Image
        self.create_subscription(
            Image, 'front_cam/rectified/left', self.front_cam_left_callback, 10)
        self.create_subscription(
            PidParams, 'track_pid_parameter', self.track_pid_parameter_callback, 10)
        # 创建话题接收 uv_detect ，定义其中的消息类型为 Yolov8
        self.create_subscription(
            Yolov8, 'uv_detect_down', self.yolov8_down_callback, 10)
        
        self.create_subscription(
            Yolov8, 'uv_detect_front', self.yolov8_front_callback, 10)
        
        #创建话题接收 binary_segment_img , 定义消息类型为Image，用于接收二值化后的分割结果
        self.create_subscription(
            Image, 'binary_segment_img', self.segment_img_callback, 10)

        # 服务请求
        # 创建服务请求 detect_request_client ，定义其中的消息类型为 RobotAxis , 请求服务 uv_detect_srv
        self.detect_request_client = self.create_client(
            DetectRequest, "uv_detect_srv")

        self.magnet.state = 1
        self.magnet_controller_pub.publish(self.magnet)

        self.get_logger().info("节点初始化完成")

    def track_pid_parameter_callback(self, data):
        pass
        # self.pid_parameters = data
    
    # 更新摄像头图像
    def front_cam_callback(self, data):
        self.front_cam_Image_data = data

    def down_cam_callback(self, data):
        self.down_cam_Image_data = data

    def front_cam_left_callback(self, data):
        self.front_cam_left_Image_data = data
    # 更新巡线图像
    def segment_img_callback(self, data):
        self.segment_img = data

    #更新目标检测结果
    def yolov8_down_callback(self, data):
        self.yolov8_data_down = data
    
    def yolov8_front_callback(self, data):
        self.yolov8_data_front = data
    
    # 更新机器人位置数据
    def motion_controller_callback(self, data):
        self.MotionController = data

        self.robot.base.vector.x = self.MotionController.pos.x
        self.robot.base.vector.y = self.MotionController.pos.y
        self.robot.base.vector.z = self.MotionController.pos.z
        self.robot.base.vector.rx = self.MotionController.pos.rx
        self.robot.base.vector.ry = self.MotionController.pos.ry
        self.robot.base.vector.rz = self.MotionController.pos.rz
        self.robot.base.extract()

    # 等待移动至指定位置
    def move_wait(self):
        cnt = 0
        time.sleep(0.5)
        while True:
            judge = 0
            if abs(self.MotionController.tpos_inbase.x) > AllowedError["x"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.y) > AllowedError["y"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.z) > AllowedError["z"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.rz) > AllowedError["rz"]:
                judge += 1

            if judge == 0:  # 进入容许范围
                return True

            if cnt > 200:  # 超时退出
                return False

            cnt += 1
            time.sleep(0.05)

    def movez(self, z):
         # 校验
        if self.robot.base.vector.z + z < -1.0:
            self.get_logger().info("Warn: 深度设置超出范围")
            z = -self.robot.base.vector.z

        self.get_logger().info("======开始移动======")

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        # 调整深度
        step_cnt = int(abs(z)/Step["z"]) + 1
        #self.get_logger().info(f"Info: 开始调整深度, 需要调整 {step_cnt:d} 次")
        cnt = 0
        while True:
            cnt += 1
            self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整深度")
            if abs(z) <= Step["z"]:
                self.get_logger().info("Info: 最终深度调整开始")
                cmd.pos.z = z
                cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
                self.target_pos_down_pub.publish(cmd)
                re = self.move_wait()
                if re:
                    self.get_logger().info("Info: 最终深度调整完成")
                else:
                    self.get_logger().info("Warn: 最终深度调整超时！")
                break
            else:
                if z > 0:
                    z -= Step["z"]
                    cmd.pos.z = Step["z"]
                else:
                    z += Step["z"]
                    cmd.pos.z = -Step["z"]
                cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
                self.target_pos_down_pub.publish(cmd)
                #self.get_logger().info(f"Info: 第 {cnt:d} 次深度调整完成")
                time.sleep(0.2)

        self.get_logger().info("======移动结束======")
    
        # 移动 z 的相对位移
    def fast_movez(self, z):
        # 直接调整
        if self.robot.base.vector.z + z < 0:
            self.get_logger().info("Warn: 深度设置超出范围")
        else:
            self.get_logger().info("======开始移动======")
            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0
            self.get_logger().info("Info: 深度快速微调开始")
            cmd.pos.z = z
            cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
            self.target_pos_down_pub.publish(cmd)
            self.get_logger().info("======移动结束======")

        # 渐进调整
        # # 校验
        # if self.robot.base.vector.z + z < 0.2:
        #     self.get_logger().info("Warn: 深度设置超出范围")
        # else:
        #     self.get_logger().info("======开始移动======")

        #     cmd = TargetPosDown()
        #     cmd.cs = 2
        #     cmd.pos.rx = 0.0
        #     cmd.pos.ry = 0.0

        #     # 调整深度
        #     step_cnt = int(abs(z)/Step["z"]) + 1
        #     self.get_logger().info(f"Info: 开始调整深度, 需要调整 {step_cnt:d} 次")
        #     cnt = 0
        #     while True:
        #         cnt += 1
        #         self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整深度")
        #         if abs(z) <= Step["z"]:
        #             self.get_logger().info("Info: 最终深度调整开始")
        #             cmd.pos.z = z
        #             cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
        #             self.target_pos_down_pub.publish(cmd)
        #             re = self.move_wait()
        #             if re:
        #                 self.get_logger().info("Info: 最终深度调整完成")
        #             else:
        #                 self.get_logger().info("Warn: 最终深度调整超时！")
        #             break
        #         else:
        #             if z > 0:
        #                 z -= Step["z"]
        #                 cmd.pos.z = Step["z"]
        #             else:
        #                 z += Step["z"]
        #                 cmd.pos.z = -Step["z"]
        #             cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
        #             self.target_pos_down_pub.publish(cmd)
        #             self.get_logger().info(f"Info: 第 {cnt:d} 次深度调整完成")
        #             time.sleep(0.2)

        #     self.get_logger().info("======移动结束======")

    # 移动 x 的相对位移
    def movex(self, x):
        if x > 10:
            self.get_logger().info("Warn: 横向位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0

            # 调整横向位置
            step_cnt = int(abs(x)/Step["x"]) + 1
            self.get_logger().info(f"Info: 开始调整横向位置, 需要调整 {step_cnt:d} 次")
            cnt = 0
            while True:
                cnt += 1
                #self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整横向位置")
                if abs(x) <= Step["x"]:
                    self.get_logger().info("Info: 最终横向位置调整开始")
                    cmd.pos.x = x
                    cmd.pos.y = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    s = self.move_wait()
                    if s:
                        self.get_logger().info("Info: 最终横向位置调整完成")
                    else:
                        self.get_logger().info("Warn: 最终横向位置调整超时！")
                    break
                else:
                    if x > 0:
                        x -= Step["x"]
                        cmd.pos.x = Step["x"]
                    else:
                        x += Step["x"]
                        cmd.pos.x = -Step["x"]
                    cmd.pos.y = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    #self.get_logger().info(f"Info: 第 {cnt:d} 次横向位置调整完成")
                    time.sleep(0.1)
            self.get_logger().info("======移动结束======")

    # 移动 x 的相对位移
    def fast_movex(self, x):
        if x > 10:
            self.get_logger().info("Warn: 横向位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0
            self.get_logger().info("Info: 横向位置快速微调开始")
            cmd.pos.x = x
            cmd.pos.y = cmd.pos.z = cmd.pos.rz = 0.0
            self.target_pos_down_pub.publish(cmd)
            self.get_logger().info("======移动结束======")
    


    # 移动 y 的相对位移
    def movey(self, y):
        if y > 10:
            self.get_logger().info("Warn: 前后位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0

            # 调整
            step_cnt = int(abs(y)/Step["y"]) + 1
            self.get_logger().info(f"Info: 开始调整前后位置, 需要调整 {step_cnt:d} 次")
            cnt = 0
            while True:
                cnt += 1
                #self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整前后位置")
                if abs(y) <= Step["y"]:
                    self.get_logger().info("Info: 最终前后位置调整开始")
                    cmd.pos.y = y
                    cmd.pos.x = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    s = self.move_wait()
                    if s:
                        self.get_logger().info("Info: 最终前后位置调整完成")
                    else:
                        self.get_logger().info("Warn: 最终前后位置调整超时！")
                    break
                else:
                    if y > 0:
                        y -= Step["y"]
                        cmd.pos.y = Step["y"]
                    else:
                        y += Step["y"]
                        cmd.pos.y = -Step["y"]
                    cmd.pos.x = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    #self.get_logger().info(f"Info: 第 {cnt:d} 次前后位置调整完成")
                    time.sleep(0.1)
            self.get_logger().info("======移动结束======")

                # 移动 y 的相对位移
    def fast_movey(self, y):
        if y > 10:
            self.get_logger().info("Warn: 前后位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0
            self.get_logger().info("Info: 前后位置快速微整开始")
            cmd.pos.y = y
            cmd.pos.x = cmd.pos.z = cmd.pos.rz = 0.0
            self.target_pos_down_pub.publish(cmd)
            self.get_logger().info("======移动结束======")

    # 移动 rz 的相对位移
    def moverz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始旋转======")

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        # 调整
        step_cnt = int(abs(rz)/Step["rz"]) + 1
        self.get_logger().info(f"Info: 开始调整角度, 需要调整 {step_cnt:d} 次")
        cnt = 0
        while True:
            cnt += 1
            #self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整角度")
            if abs(rz) <= Step["rz"]:
                self.get_logger().info("Info: 最终角度调整开始")
                cmd.pos.rz = rz
                cmd.pos.x = cmd.pos.z = cmd.pos.y = 0.0
                self.target_pos_down_pub.publish(cmd)
                s = self.move_wait()
                if s:
                    self.get_logger().info("Info: 最终角度调整完成")
                else:
                    self.get_logger().info("Warn: 最终角度调整超时！")
                break
            else:
                if rz > 0:
                    rz -= Step["rz"]
                    cmd.pos.rz = Step["rz"]
                else:
                    rz += Step["rz"]
                    cmd.pos.rz = -Step["rz"]
                cmd.pos.x = cmd.pos.z = cmd.pos.y = 0.0
                self.target_pos_down_pub.publish(cmd)
                #self.get_logger().info(f"Info: 第 {cnt:d} 次角度调整完成")
                time.sleep(0.1)
        self.get_logger().info("======旋转结束======")
        
        
    def fast_moverz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始旋转======")

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        self.get_logger().info("Info: 前后位置快速微整开始")
        cmd.pos.rz = rz
        cmd.pos.x = cmd.pos.z = cmd.pos.y = 0.0
        self.target_pos_down_pub.publish(cmd)
        self.get_logger().info("======移动结束======")

    # 移动x,y相对位移
    def movexy(self, x, y):
        if x == 0 and y == 0:
            self.get_logger().info("Warn: 未设置合法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")
            time.sleep(0.1)
            #self.get_logger().info(f"Info: ======朝向回正,旋转{-rz:.2f}°======")
            #self.moverz(-rz)
            #self.get_logger().info("Info: ======转向结束======")

    # 移动x,y,z相对位移
    def movexyz(self, x, y, z):
        if z == 0:
            self.get_logger().info("Warn: 未设置合法深度位移！")
        else:
            self.movez(z)
        time.sleep(0.1)
        self.movexy(x, y)

    # 设置 z
    def setz(self, z):
        if z >= -1.0:
            self.get_logger().info("======开始调整深度======")
            cmd = TargetPosDown()
            cmd.cs = 0
            cmd.pos.rx = self.MotionController.pos.rx
            cmd.pos.ry = self.MotionController.pos.ry
            cmd.pos.x = self.MotionController.pos.x
            cmd.pos.y = self.MotionController.pos.y
            cmd.pos.rz = self.MotionController.pos.rz
            cmd.pos.z = z
            self.target_pos_down_pub.publish(cmd)
            s = self.move_wait()
            if s:
                self.get_logger().info("Info: 深度调整完成")
            else:
                self.get_logger().info("Warn: 深度调整超时！")
            self.get_logger().info("======移动结束======")
        else:
            self.get_logger().info("Warn: 深度设置错误！")

    # 设置rz
    def setrz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始调整角度======")
        cmd = TargetPosDown()
        cmd.cs = 0
        cmd.pos.rx = self.MotionController.pos.rx
        cmd.pos.ry = self.MotionController.pos.ry
        cmd.pos.x = self.MotionController.pos.x
        cmd.pos.y = self.MotionController.pos.y
        cmd.pos.z = self.MotionController.pos.z
        cmd.pos.rz = rz
        self.target_pos_down_pub.publish(cmd)
        s = self.move_wait()
        if s:
            self.get_logger().info("Info: 角度调整完成")
        else:
            self.get_logger().info("Warn: 角度调整超时！")
        self.get_logger().info("======移动结束======")

    # 设置路径点
    def setp(self):
        self.backpoint["x"] = self.MotionController.pos.x
        self.backpoint["y"] = self.MotionController.pos.y
        self.backpoint["z"] = self.MotionController.pos.z
        self.backpoint["rz"] = self.MotionController.pos.rz
        self.get_logger().info(
            f'Info:已保存当前位置 x: {self.backpoint["x"]:.2f} y: {self.backpoint["y"]:.2f} z: {self.backpoint["z"]:.2f} rz : {self.backpoint["rz"]:.2f}')

    # 回到路径点
    def back(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(-d)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz-rz_)
            self.get_logger().info("Info: ======转向结束======")
            
    def fast_back(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.fast_movez(z)
        time.sleep(2)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.fast_moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.fast_moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(5.0)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.fast_movey(-d)
            time.sleep(5.0)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.fast_moverz(rz-rz_)
            time.sleep(2.0)
            self.get_logger().info("Info: ======转向结束======")
            
    # 回到路径点
    def backy(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")


        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(-d)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz-rz_)
            self.get_logger().info("Info: ======转向结束======")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

    # 移动至寄存器 self.target 所指定的位置
    def mtty(self, dy, dz):

        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        z -= dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y) - dy
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")

    def mttzxy(self, dz, dx, dy):
        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        x += dx
        y += dy
        z += dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")
        
        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.get_logger().info(f"Info: ======深度移动指定距离,移动{z:.2f}m======")
            self.movez(z)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if x == 0:
            self.get_logger().info("Warn: 水平位移非法！")
        else:
            self.get_logger().info(f"Info: ======横移指定距离,移动{x:.2f}m======")
            self.movex(x)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if y == 0:
            self.get_logger().info("Warn: 前后位移非法！")
        else:
            self.get_logger().info(f"Info: ======前后指定距离,移动{y:.2f}m======")
            self.movey(y)
        time.sleep(0.1)

        self.get_logger().info(f"Info: ======移动结束======")


    def mttxf(self,dx,dy):
        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")
        x_target = x - dx
        self.get_logger().info(f"Info: ======横移指定距离,移动{x:.2f}m======")
        self.movex(x_target)
        self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            d = y - dy
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)


    # 移动至寄存器 self.target 所指定的位置
    def mttz(self, dy, dz):

        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        z -= dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y) - dy
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)
    
    #移动至指定世界坐标位置
    def mttpos(self, x, y, z, rz, dy):
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z

        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        self.setrz(rz)
        Step["y"] = 0.02
    
    #移动至指定世界坐标位置，但最后不旋转
    def mttzpos(self, x, y, z, dy):
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z
        Step["z"] = 0.2
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        Step["y"] = 0.02
        Step["z"] = 0.05
    
    #移动至指定世界坐标位置，以比赛开始位置为坐标
    def mttpos_amend(self, x, y, z, rz, dy):
        self.start_pos.target_inbase.vector.x = x
        self.start_pos.target_inbase.vector.y = y
        self.start_pos.target_inbase.vector.z = z
        self.start_pos.target_inbase.vector.rz = rz
        self.start_pos.target_inbase.vector.rx = self.start_pos.target_inbase.vector.ry= 0.0
        self.start_pos.base2world()
        self.target["x"] = self.start_pos.target_inworld.vector.x
        self.target["y"] = self.start_pos.target_inworld.vector.y
        self.target["z"] = self.start_pos.target_inworld.vector.z
        self.target["rz"] = self.start_pos.target_inworld.vector.rz
        
        self.get_logger().info(
            f"x: {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
              
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        self.setrz(rz+self.start_pos.base.vector.rz)
        Step["y"] = 0.02
    
    #移动至指定世界坐标位置，以比赛开始位置为坐标
    def mttzpos_amend(self, x, y, z, dy):
        self.start_pos.target_inbase.vector.x = x
        self.start_pos.target_inbase.vector.y = y
        self.start_pos.target_inbase.vector.z = z
        self.start_pos.target_inbase.vector.rx = self.start_pos.target_inbase.vector.ry= 0.0
        self.start_pos.base2world()
        self.target["x"] = self.start_pos.target_inworld.vector.x
        self.target["y"] = self.start_pos.target_inworld.vector.y
        self.target["z"] = self.start_pos.target_inworld.vector.z
        Step["z"] = 0.2
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        Step["y"] = 0.02
        Step["z"] = 0.05
    
    # 搜寻目标
    def search(self, name, cam):
        # 定位目标
        # 等待服务段上线
        wait = True
        while rclpy.ok() and self.detect_request_client.wait_for_service(0.1) == False:
            if wait:
                wait = False
                self.get_logger().info("Info:等待服务端上线....")
        self.get_logger().info("Info:服务端已启动")

        request = DetectRequest.Request()
        request.stero = cam
        request.target = name
        responce = None

        pos_list = []
        fail_cnt = 0

        image = False

        while True:
            if cam == "front" and self.front_cam_Image_data != None:
                request.imagein = self.front_cam_Image_data
                image = True
            if cam == "down" and self.down_cam_Image_data != None:
                request.imagein = self.down_cam_Image_data
                image = True

            if image == True:
                responce = self.detect_request_client.call(request)
                if responce.s == 1:
                    if cam == "front":
                        self.front_cam.target_inbase.vector.x = responce.x
                        self.front_cam.target_inbase.vector.y = responce.y
                        self.front_cam.target_inbase.vector.z = responce.z
                        #相机坐标系到机器人坐标系
                        self.front_cam.base2world()

                        self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                        self.robot.base2world()

                    if cam == "down":
                        self.down_cam.target_inbase.vector.x = responce.x
                        self.down_cam.target_inbase.vector.y = responce.y
                        self.down_cam.target_inbase.vector.z = responce.z
                        self.down_cam.base2world()

                        self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                        self.robot.base2world()

                    # self.get_logger().info(
                    #     f"Info:目标在机器人坐标系中的位置: x: {self.robot.target_inbase.vector.x: .3f} y: {self.robot.target_inbase.vector.y: .3f} z: {self.robot.target_inbase.vector.z: .3f}")
                    self.get_logger().info(
                        f"Info:目标在相机坐标系中的位置: x: {responce.x: .3f} y: {responce.y: .3f} z: {responce.z: .3f}")

                    pos_list.append([self.robot.target_inworld.vector.x,
                                    self.robot.target_inworld.vector.y, self.robot.target_inworld.vector.z])

                    if len(pos_list) >= 5:
                        break
                else:
                    fail_cnt += 1
                    time
                    if fail_cnt >= 1000 & len(pos_list) < 5:
                        self.get_logger().info(f"确认无目标，退出函数")
                        return responce.s

            else:
                self.get_logger().info("无图像传入")

            image = False
        x = y = z = 0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)

        self.robot.base2world()
        self.target["name"] = name
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z

        self.get_logger().info(
            f"目标位置: x : {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
        return responce.s

    def search2(self, name, cam,dy,dz,z_target,times):
        # 定位目标
        # 等待服务段上线
        wait = True
        while rclpy.ok() and self.detect_request_client.wait_for_service(0.1) == False:
            if wait:
                wait = False
                self.get_logger().info("Info:等待服务端上线....")
        self.get_logger().info("Info:服务端已启动")

        request = DetectRequest.Request()
        request.stero = cam
        request.target = name

        pos_list = []

        image = False
        times_none = 0 #
        flag_to_next = 0 #

        while True:
            if cam == "front" and self.front_cam_Image_data != None:
                request.imagein = self.front_cam_Image_data
                image = True
            if cam == "down" and self.down_cam_Image_data != None:
                request.imagein = self.down_cam_Image_data
                image = True

            if image == True:
                responce = self.detect_request_client.call(request)
                if responce.s == 1:
                    if cam == "front":
                        self.front_cam.target_inbase.vector.x = responce.x
                        self.front_cam.target_inbase.vector.y = responce.y
                        self.front_cam.target_inbase.vector.z = responce.z
                        #相机坐标系到机器人坐标系
                        self.front_cam.base2world()

                        self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                        self.robot.base2world()

                    if cam == "down":
                        self.down_cam.target_inbase.vector.x = responce.x
                        self.down_cam.target_inbase.vector.y = responce.y
                        self.down_cam.target_inbase.vector.z = responce.z
                        self.down_cam.base2world()

                        self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                        self.robot.base2world()

                    self.get_logger().info(
                        f"Info:目标在世界坐标系中的位置: x: {self.robot.target_inworld.vector.x: .3f} y: {self.robot.target_inworld.vector.y: .3f} z: {self.robot.target_inworld.vector.z: .3f}")

                    pos_list.append([self.robot.target_inworld.vector.x,
                                    self.robot.target_inworld.vector.y, self.robot.target_inworld.vector.z])

                    if len(pos_list) >= 100:
                        break
                else:
                    if (times > 0):
                        times_none += 1
                        self.get_logger().info(f"第{times_none}次无目标")
                        if (times_none >= 50) & (len(pos_list) < 10):
                            flag_to_next = 1
                            self.get_logger().info(f"确认无目标，进行下一步")
                            break
            else:
                self.get_logger().info("无图像传入")

            image = False

        times += 1
        if flag_to_next == 0:
            x = y = z = 0
            for i in pos_list:
                x += i[0]
                y += i[1]
                z += i[2]
            x /= len(pos_list)
            y /= len(pos_list)
            z /= len(pos_list)

            self.robot.base2world()
            self.target["name"] = name
            self.target["x"] = x
            self.target["y"] = y
            self.target["z"] = z

            self.get_logger().info(
                f"目标位置: x : {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
            
            self.mttz(dy,dz)
            self.setz(z_target)
            self.get_logger().info(
                f"开始第{times}次搜查是否抓球成功")            
            self.search2(self, name, cam,dy,dz,z_target,times)
    
    def search4(self, name1, name2,dx,dy,dz,z_target,rz_target,times,distance):#1为圈，2为T插
       
        times_none = 0
        flag_to_next = 0
        
        T_cnt = 0
        while True:
            
            s = self.search(self, "scaffolding", "front")
            if s == 0:
                self.get_logger().info("======无目标======")
                self.led(0, 0)
                self.get_logger().info("======旋转寻找目标目标======")
                self.moverz(40)
                T_cnt += 1
            else :
                self.get_logger().info("======发现基架======")  
                self.target["y"] -= 0.50  
                self.mttz(dy,dz)
                self.setrz(rz_target)
                break
            if T_cnt > 10:
                self.get_logger().info("======未找到目标======")
                break
        
        """
        计算法线方向
        """
        # 解包坐标
        x1, y1, z1 = self.cam2robot(2, 4,"front")
        x2, y2, z2 = self.cam2robot(2, 4,"front")
        x3, y3, z3 = self.cam2robot(2, 4,"front")
            
            
        # 计算向量AC的分量
        a = x1 - x3
        b = y1 - y3
            
        # 计算向量模长的平方
        length_squared = a**2 + b**2
            
            
        # 计算u和v的可能值
        if  abs(b) >= 0.001:
            # 一般情况
            factor = distance * abs(b) / (length_squared ** 0.5)
            u1 = factor
            v1 = -a * u1 / b
                
            u2 = -factor
            v2 = -a * u2 / b
        else:
            # b为0的特殊情况（AC垂直于x轴）
            u1 = 0
            v1 = distance
                
            u2 = 0
            v2 = -distance
            
            # 计算点D的坐标
        d1 = (x2 + u1, y2 + v1, z3)
        d2 = (x2 + u2, y2 + v2, z3)
            
        real_d = min(d1, d2)    
             
        
              
    # 机械爪控制
    def pow(self, s):
        servo = ServoSet()
        servo.num = 0
        if s == 1:
            servo.angle = 0.35
            self.servo_control_pub.publish(servo)
        if s == 0:
            servo.angle = 0.92#推球，夹T插
            self.servo_control_pub.publish(servo)
        time.sleep(0.1)


    # 任务启动
    def start(self):
        time.sleep(5)
        #  载入当前目标值
        tpos = TargetPosDown()
        tpos.cs = 0
        self.start_pos.base.vector.x = tpos.pos.x = self.MotionController.pos.x
        self.start_pos.base.vector.y = tpos.pos.y = self.MotionController.pos.y
        tpos.pos.z = self.MotionController.pos.z
        self.start_pos.base.vector.z = 0.0
        self.start_pos.base.vector.rz = tpos.pos.rz = self.MotionController.pos.rz
        self.start_pos.base.vector.ry = self.start_pos.base.vector.rx = tpos.pos.rx = tpos.pos.ry =  0.0
        self.start_pos.base.extract()
        self.get_logger().info(f"载入当前世界坐标 x:{tpos.pos.x:.3f} y:{tpos.pos.y:.3f} z:{tpos.pos.z:.3f} rz:{tpos.pos.rz:.3f}")
        self.led(1,0)#绿灯
        time.sleep(3.0)
        self.led(0,1)#黄灯
        time.sleep(3.0)
        self.led(1,1)#红灯
        time.sleep(3.0)
        self.led(0,0)
        self.target_pos_down_pub.publish(tpos)
        # 机械爪加紧T插
        self.pow(0) 
        
        # 开启PID控制器
        pid = PidControllersState()
        pid.x = pid.y = pid.z = pid.rz = 1
        pid.rx = pid.ry = 0
        self.pid_controllers_set_pub.publish(pid)
        time.sleep(0.1)

    # 任务结束
    def end(self):
        # 关闭PID控制器
        pid = PidControllersState()
        pid.x = pid.y = pid.z = pid.rz = 0
        pid.rx = pid.ry = 0
        self.pid_controllers_set_pub.publish(pid)
        time.sleep(0.1)

    def run(self, task: dict):
        if task["name"] == "movexyz":
            self.movexyz(task["params"]["x"], task["params"]
                         ["y"], task["params"]["z"])

        elif task["name"] == "throw_golf":
            self.throw_golf(task["params"]["dy"],
                            task["params"]["depth"])
            
        elif task["name"] == "movexy":
            self.movexy(task["params"]["x"], task["params"]["y"])

            
        elif task["name"] == "movex":
            self.movex(task["params"]["x"])

        elif task["name"] == "movey":
            self.movey(task["params"]["y"])

        elif task["name"] == "movez":
            self.movez(task["params"]["z"])

        elif task["name"] == "moverz":
            self.moverz(task["params"]["rz"])

        elif task["name"] == "setz":
            self.setz(task["params"]["z"])

        elif task["name"] == "setrz":
            self.setrz(task["params"]["rz"])

        elif task["name"] == "search":
            self.search(task["params"]["name"], task["params"]["cam"])

        elif task["name"] == "mtty":
            self.mtty(task["params"]["y"], task["params"]["z"])
        elif task["name"] == "mttxf":
            self.mttxf(task["params"]["dx"],task["params"]["dy"])
        elif task["name"] == "mttz":
            self.mttz(task["params"]["y"], task["params"]["z"])
        elif task["name"] == "mttzxy":
            self.mttzxy(task["params"]["dz"], task["params"]["dx"], task["params"]["dy"])
        elif task["name"] == "setp":
            self.setp()

        elif task["name"] == "back":
            self.back()
            
        elif task["name"] == "backy":
            self.backy()
            
        elif task["name"] == "pow":
            self.pow(task["params"])
        
        elif task["name"] == "line":
            self.line(task["params"]["ys_dep"])

        elif task["name"] == "graball":
            self.graball(task["params"]["color"], task["params"]["depth"], task["params"]["timeout"],task["params"]["pr"],task["params"]["k"],task["params"]["step_time"])

        elif task["name"] == "thrball":
            self.thrball(task["params"]["pr"], task["params"]["timeout"],task["params"]["k"],task["params"]["step_time"])
        
        elif task["name"] == "pass_door":
            self.pass_door(task["params"]["num"])

        elif task["name"] == "mttpos":
            self.mttpos(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["rz"], task["params"]["dy"])
            
        elif task["name"] == "mttzpos_amend":
            self.mttzpos_amend(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["dy"])
        
        elif task["name"] == "mttpos_amend":
            self.mttpos_amend(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["rz"], task["params"]["dy"])
            
        elif task["name"] == "mttzpos_":
            self.mttzpos(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["dy"])
        
        elif task["name"] == "delay":
            self.delay(task["params"])

        elif task["name"] == "led":
            self.led(task["params"]["led0"],
                     task["params"]["led1"])

        elif task["name"] == "grab_golf":
            self.grab_golf(task["params"]["kind"],
                           task["params"]["dx"],
                           task["params"]["dy"],
                           task["params"]["down_depth"],
                           task["params"]["up_depth"])
        
        elif task["name"] == "put_t":
            self.put_t(task["params"]["num"],
                           task["params"]["dy"],
                           task["params"]["dz"])
        
        elif task["name"] == "strike_ball":
            self.strike_ball(task["params"]["num"])
        
        elif task["name"] == "strike_ball3":
            self.strike_ball3(task["params"]["num1"],
                       task["params"]["num2"],
                       task["params"]["num3"],)
        
        elif task["name"] == "line_qd":
            # 无参数，直接调用line_qd方法
            self.line_qd()
            
        elif task["name"] == "endfloat":
            # 无参数，直接调用line_qd方法
            self.endfloat()

        else:
            self.get_logger().info("Info:非法任务名:  " + task["name"])
    
    def pid_update(self, error):
        self.dt = self.dt + 1 if abs(error-self.previous_error) < 2 else 1
        p_value = self.pid_parameters.p * error
        self.i_error += error * self.dt
        i_value = self.pid_parameters.i * self.i_error
        d_value = self.pid_parameters.d * (error - self.previous_error) / self.dt
        self.previous_error = error
        output = p_value + i_value + d_value
        if output > self.pid_parameters.output_limit:
            output = self.pid_parameters.output_limit
        elif output < -self.pid_parameters.output_limit:
            output = -self.pid_parameters.output_limit
        return output
    

    def cam2robot(self, clas, timeout,cam):
        pos_list = []
        start_time = time.time()

        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # 检查超时
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                return 0.0, 0.0, 0.0
            if cam == "down":
                if self.yolov8_data_down.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.z != 0:
                    self.down_cam.target_inbase.vector.x = self.yolov8_data_down.targets[clas].tpos_inworld.x
                    self.down_cam.target_inbase.vector.y = self.yolov8_data_down.targets[clas].tpos_inworld.y
                    self.down_cam.target_inbase.vector.z = self.yolov8_data_down.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.down_cam.base2world()

                    t_x = self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                    t_z =  self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                    self.robot.base2world()
                    time.sleep(0.015)
                                    # 检查返回的坐标是否为 0
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if cam == "front":
                if self.yolov8_data_front.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.z != 0:
                    self.front_cam.target_inbase.vector.x = self.yolov8_data_front.targets[clas].tpos_inworld.x
                    self.front_cam.target_inbase.vector.y = self.yolov8_data_front.targets[clas].tpos_inworld.y
                    self.front_cam.target_inbase.vector.z = self.yolov8_data_front.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.front_cam.base2world()
                    t_x = self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                    t_z = self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                    self.robot.base2world()
                    time.sleep(0.015)
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")

            if len(pos_list) >= 80:
                break
        x = y = z = 0.0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)
        self.get_logger().info(
            f"目标在机器人坐标系下的位置: x : {x:.2f} y: {y:.2f} z: {z:.2f}")

        return x, y, z
    

    def cam2robot_fast(self, clas, timeout,cam):
        pos_list = []
        start_time = time.time()

        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # 检查超时
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                return 0.0, 0.0, 0.0
            if cam == "down":
                if self.yolov8_data_down.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.z != 0:
                    self.down_cam.target_inbase.vector.x = self.yolov8_data_down.targets[clas].tpos_inworld.x
                    self.down_cam.target_inbase.vector.y = self.yolov8_data_down.targets[clas].tpos_inworld.y
                    self.down_cam.target_inbase.vector.z = self.yolov8_data_down.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.down_cam.base2world()

                    t_x = self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                    t_z =  self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                    self.robot.base2world()
                                    # 检查返回的坐标是否为 0
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if cam == "front":
                if self.yolov8_data_front.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.z != 0:
                    self.front_cam.target_inbase.vector.x = self.yolov8_data_front.targets[clas].tpos_inworld.x
                    self.front_cam.target_inbase.vector.y = self.yolov8_data_front.targets[clas].tpos_inworld.y
                    self.front_cam.target_inbase.vector.z = self.yolov8_data_front.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.front_cam.base2world()
                    t_x = self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                    t_z = self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                    self.robot.base2world()
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if len(pos_list) >= 50:
                break
        x = y = z = 0.0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)
        self.get_logger().info(
            f"目标在机器人坐标系下的位置: x : {x:.2f} y: {y:.2f} z: {z:.2f}")

        return x, y, z
    
    #抓球 pr为百分比距离
    def graball(self,color,depth,timeout,pr,k,step_time):
        led = LedControllers()
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                break
            if all(x==0 for x in self.yolov8_data_down.state):
                self.led(0,0)
                self.get_logger().info(
                f"没有找到任何物体")
            elif self.yolov8_data_down.state[5] == 1 and self.yolov8_data_down.state[4] == 1: #5是黄色，4是pink
                self.led(1,0)
                self.get_logger().info(
                f"发现高尔夫球")
                if color == "pink":
                    a, b, c = self.cam2robot(4, 5,"down")
                    self.movex(a)
                    self.movey(b-0.175)
                    self.movez(depth)
                    self.movez(-depth)
                    break
                elif color == "yellow":
                    a, b, c = self.cam2robot(5, 5,"down")
                    self.movex(a)
                    self.movey(b-0.175)
                    self.movez(depth)
                    self.movez(-depth)
                    break
            elif self.yolov8_data_down.state[6] == 1:
                led.led0 = 0
                led.led1 = 1
                r = sqrt((self.yolov8_data_down.targets[6].tpos_inpic.y -  480)**2 + (self.yolov8_data_down.targets[6].tpos_inpic.x -  640)**2)/sqrt(480**2+640**2)
                a, b, c = self.cam2robot_fast(6, 5,"down")
                if r >= pr:
                    self.led_controllers_pub.publish(led)
                    self.get_logger().info(
                    f"只发现陈列框")
                    vx = k*a
                    vy = k*b
                    if abs(vx) < 0.01:
                        vx = 0.01 if vx >= 0 else -0.01
                    if abs(vy) < 0.01:
                        vy = 0.01 if vy >= 0 else -0.01
                    if abs(vx) > 0.04:
                        vx = 0.04 if vx >= 0 else -0.04
                    if abs(vy) > 0.04:
                        vy = 0.04 if vy >= 0 else -0.04
                    self.fast_movex(vx)
                    self.fast_movey(vy)
                    time.sleep(step_time)
                else:
                    self.get_logger().info(
                    f"陈列框已经进入视野中心")
            else:
                self.led(1,1)
                self.get_logger().info(
                f"检测到非必要物体")       
        self.led(0,0)
    #投球
    def thrball(self,pr,timeout,k,step_time):
        led = LedControllers()
        bridge = CvBridge()
        img = bridge.imgmsg_to_cv2(self.down_cam_Image_data,"bgr8")
        row_index = img.shape[0] // 2
        column_index = img.shape[1] // 4
        self.get_logger().info(f"row: {row_index} , column: {column_index}")
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                break
            if all(x==0 for x in self.yolov8_data_down.state):
                led.led0 = 0
                led.led1 = 0
                self.led_controllers_pub.publish(led)
                self.get_logger().info(
                f"没有找到任何物体")
            elif self.yolov8_data_down.state[5] == 1:
                r = sqrt((self.yolov8_data_down.targets[5].tpos_inpic.y -  row_index)**2 + (self.yolov8_data_down.targets[5].tpos_inpic.x -  column_index)**2)/sqrt(480**2+640**2)
                led.led0 = 1
                led.led1 = 0
                a, b, c = self.cam2robot_fast(5, 5,"down")
                if r >= pr:
                    self.led_controllers_pub.publish(led)
                    self.get_logger().info(
                                            f"发现收集框")
                    vx = k*a
                    vy = k*b
                    if abs(vx) < 0.01:
                        vx = 0.01 if vx >= 0 else -0.01
                    if abs(vy) < 0.01:
                        vy = 0.01 if vy >= 0 else -0.01
                    if abs(vx) > 0.04:
                        vx = 0.04 if vx >= 0 else -0.04
                    if abs(vy) > 0.04:
                        vy = 0.04 if vy >= 0 else -0.04
                    self.fast_movex(vx)
                    self.fast_movey(vy)
                    time.sleep(step_time)
                else:
                    self.get_logger().info(f"收集框已进入视野中心")
                    break
            else:
                led.led0 = 1
                led.led1 = 1
                self.led_controllers_pub.publish(led)
                self.get_logger().info(
                f"检测到非必要物体")
        a, b, c = self.cam2robot(5, 5,"down")
        led.led0 = 1
        led.led1 = 0
        self.led_controllers_pub.publish(led)
        self.movex(a)
        self.movey(b-0.175)   
        self.pow(0) 
        time.sleep(1)      
        led.led0 = 0
        led.led1 = 0
        self.led_controllers_pub.publish(led)

    def pass_door(self,num):
        self.setz(0.5)
        #self.setrz(0)
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= 30:
                self.get_logger().info("超时,采用planB")
                self.movey(3.5)
                break
            if self.yolov8_data_front.state[num] == 1:
                self.get_logger().info(f"检测到资格门")
                time.sleep(2)
                a, b, c = self.cam2robot_fast(num, 5,"front")
                b = b 
                rz = atan2(b, a)*RAD2DEG - 90
                self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
                self.moverz(rz)
                cnt = 0
                cnt2 = 0
                cnt3 = 0
                cnt4 = 0
                cmd = TargetPosDown()
                cmd.cs = 2
                cmd.pos.rx = 0.0
                cmd.pos.ry = 0.0
                cmd.pos.x = 0.0
                cmd.pos.y = 0.01
                cmd.pos.z = 0.0
                cmd.pos.rz = 1.5
                time.sleep(0.5)
                while True:
                    cnt+=1
                    cnt4 += 1#0.1秒后再进行一次检测
                    if cnt > 100 * b:             
                        break
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(0.05)
                break

        time.sleep(5.0)
        self.movey(0.5)
        self.get_logger().info(f"过门任务完成")

    def led(self, led0, led1):
        led = LedControllers()
        led.led0 = led0
        led.led1 = led1
        self.led_controllers_pub.publish(led)
    
    def delay(self, t):
        time.sleep(t)
    
    def grab_golf(self, kind, dx, dy, down_depth, up_depth):
        
        num = 0
        
        if kind == "blue_golf":
            num = 4
        if kind == "red_golf":
            num = 3

        
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.1
        
        sample_flag = 0
        golf_cnt = 0
        
        self.pow(1)
        self.led(0, 0)
        s = 1
        while True:
            if all(x == 0 for x in self.yolov8_data_front.state) and \
               all(y == 0 for y in self.yolov8_data_down.state):
                # pass
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                golf_cnt+=1
                
            else:
                if self.yolov8_data_front.state[6]!= 0 :
                    self.get_logger().info("前视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"front")
                    a = a + 0.1
                    b = b - 0.1                    
                    self.movex(a)
                    self.movey(b)
                    self.setz(0.2)
                    time.sleep(2)
                    break
                elif self.yolov8_data_down.state[6]!= 0 :
                    self.get_logger().info("下视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"down")
                    a = a + 0.1
                    b = b - 0.1                      
                    self.movex(a)
                    self.movey(b)
                    self.setz(0.2)
                    time.sleep(2)
                    break
                else:
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(0.01)
                    golf_cnt+=1 
            if  golf_cnt>4000 :
                self.get_logger().info("任务失败")
                self.get_logger().info("======上浮======")
                self.setz(-0.5)
                return
                     
        '''s = self.search(kind, "down")
        if s == 0:
            self.get_logger().info("======下无目标======")
            self.get_logger().info("======第一次平移寻找目标目标======")
            self.movex(0.2)
            self.movey(0.2)
            s = self.search( kind, "down")
            if s == 0:
                self.get_logger().info("======下无目标======")
                self.get_logger().info("======第二次平移寻找目标目标======")
                self.movey(-0.4)
                s = self.search( kind, "down")
                if s == 0:
                    self.get_logger().info("======下无目标======")
                    self.get_logger().info("======第三次平移寻找目标目标======")
                    self.movex(-0.4)
                    s = self.search( kind, "down")
                    if s == 0:
                        self.get_logger().info("======下无目标======")
                        self.get_logger().info("======第四次平移寻找目标目标======")
                        self.movey(0.4)
                        s = self.search(kind, "down")
                        if s == 0:
                            self.get_logger().info("======下无目标======")
                            self.get_logger().info("======任务失败======")
                            return
        if s != 0 :
            self.get_logger().info("======发现球======")  
            self.get_logger().info("======正在移向球======")   
            self.mttxf(0,0) '''
        golf_cnt = 0
        while True: 
            if all(x == 0 for x in self.yolov8_data_front.state) and \
               all(y == 0 for y in self.yolov8_data_down.state):
                golf_cnt+=1
                time.sleep(0.01)
                if golf_cnt>2000:
                    self.get_logger().info("======确认无目标======")
                    self.get_logger().info("======上浮======")
                    self.setz(-0.5)
                    time.sleep(5.0)
                    self.get_logger().info("=====上浮结束======")
                    return                  
            elif self.yolov8_data_down.state[num] !=0:
                self.get_logger().info("======发现目标球=====")
                a, b, c = self.cam2robot(num, 5,"down")
                a = a - dx
                b = b - dy 
                self.movex(a)
                self.movey(b)

                self.delay(1)
                self.led(1, 0)
                self.movez(down_depth)
                self.get_logger().info("=====抓球结束，开始上浮======")
                self.setz(-0.5)
                time.sleep(5.0)
                self.led(0, 0)
                self.get_logger().info("=====上浮结束======")
                return
            else:
                golf_cnt+=1
                time.sleep(0.01)
                if golf_cnt>2000:
                    self.get_logger().info("======确认无目标======")
                    self.get_logger().info("======上浮======")
                    self.setz(-0.5)
                    time.sleep(5)
                    self.get_logger().info("=====上浮结束======")
                    return  
    
    
    def put_t(self, num,dy,dz):
        T_cnt = 0
        T_cnt2 = 0
        T_cnt3 = 0
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.01

        while True:
            if self.yolov8_data_front.state[num] == 0: 
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.001)
                T_cnt+=1
                

            elif  self.yolov8_data_front.state[num] != 0:
                time.sleep(2)
                T_cnt = 0
                self.get_logger().info("发现目标")
                a, b, c = self.cam2robot(num, 5,"front")
                a=a-dy
                c=c-dz
                self.movex(a)
                self.movez(c)
                time.sleep(1)
                cmd.pos.rz = 0.0
                while True:
                    T_cnt2+=1
                    if self.yolov8_data_front.state[num] != 0 and T_cnt2 % 600 == 0: 
                        time.sleep(2)
                        a, b, c = self.cam2robot(num, 5,"front")
                        a=a-dy
                        c=c-dz
                        if (abs(a) > 0.03 or abs(c) > 0.03) and b > 0.25:
                            self.get_logger().info("======目标偏移======")
                            cmd.pos.x = float(a)
                            cmd.pos.z = float(c)
                            cmd.pos.y = 0.0
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(2)
                        else:
                            cmd.pos.y = 0.001
                            cmd.pos.x = 0.0
                            cmd.pos.z = 0.0
                            self.target_pos_down_pub.publish(cmd)
                            self.get_logger().info("======正在前进======")
                            T_cnt+=1
                            time.sleep(0.01)

                    else:
                        cmd.pos.y = 0.001
                        cmd.pos.x = 0.0
                        cmd.pos.z = 0.0
                        self.target_pos_down_pub.publish(cmd)
                        T_cnt+=1
                        time.sleep(0.01)
                    if T_cnt > 1000*(b+0.7):
                            self.pow(1)
                            self.get_logger().info("======任务完成======")
                            return
            if T_cnt>4000:
                self.get_logger().info("======未发现目标 任务失败======")            
                
    def endfloat(self):
   
        num = 5
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.2
        plate_cnt = 0
        while True:
            if self.yolov8_data_front.state[num] ==0 and \
               self.yolov8_data_down.state[num] ==0 :
                # pass
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                golf_cnt+=1
                
            else:
                if self.yolov8_data_front.state[num] ==1:
                    self.get_logger().info("前视发现目标")
                    time.sleep(2)
                    a, b, c = self.cam2robot(num, 5,"front")
                    a = a - 0.3
                    b = b - 0.5                    
                    self.movex(a)
                    self.movey(b)
                    time.sleep(1)
                    self.setz(-0.1)
                    self.get_logger().info("任务成功")
                    break
                else:
                    self.get_logger().info("下视发现目标")
                    a, b, c = self.cam2robot(num, 5,"down")
                    a = a - 0.3
                    b = b - 0.5                    
                    self.movex(a)
                    self.movey(b)
                    time.sleep(1)
                    self.setz(-0.1)
                    self.get_logger().info("任务成功")
                    break
            if  plate_cnt>2000 :
                self.get_logger().info("任务失败")
                return


    def throw_golf(self, dy, depth):
        self.get_logger().info("======开始投球======")
        self.led(0, 1)
        self.search('col_basket', 'down')
        self.led(1, 1)
        self.mttxf(0, dy)
        self.movez(depth)
        self.led(1, 0)
        self.pow(0)
        self.delay(1)
        self.led(0, 0)
        self.get_logger().info("======投球结束======")
        
    def strike_ball(self,num):
        
        ball_cnt = 0
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.05

        while True:
            if self.yolov8_data_front.state[num] == 0: 
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                ball_cnt+=1
            elif  self.yolov8_data_front.state[num] != 0:
                time.sleep(2)
                ball_cnt = 0
                self.get_logger().info("发现目标")
                a, b, c = self.cam2robot(num, 5,"front")
                #a = a 
                c = c - 0.32
                b = b - 0.2
                self.fast_movez(c)
                time.sleep(1)
                self.movexy(a,b)
                time.sleep(1)
                self.get_logger().info("======任务完成 正在返回======")
                self.fast_movey(-b)
                self.move_wait()
                time.sleep(4)
                self.get_logger().info("======返回完成======")
                               
                return
            if ball_cnt>75000:
                self.get_logger().info("======未发现目标 任务失败======")
                return
                
    def strike_ball3(self,num1,num2,num3):
        self.get_logger().info("======撞球任务开始======")
        #self.setp()
        self.get_logger().info("======撞第一个球======")
        self.strike_ball(num1)
        #self.fast_moverz(180.0)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        #time.sleep(4)
        self.get_logger().info("======撞第二个球======")
        self.strike_ball(num2)
        #self.fast_moverz(180.0)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        #time.sleep(4)
        self.get_logger().info("======撞第三个球======")
        self.strike_ball(num3)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        
    def line_qd(self):
        
            
        self.led(0,0)
        
        self.pid_parameters.p = 0.0009
        self.pid_parameters.i = 0.0
        self.pid_parameters.d = 0.08
        self.pid_parameters.output_limit = 5.0

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        drz = 0.0

        timesleep = 0.025
        
        self.task_lock = [0,0,0]
        
        magnet = MagnetController()
        led = LedControllers()
        bridge = CvBridge()
    
        window_size = 3  # 滑动窗口的大小
        last_positions = []  # 使用列表来存储最近的位置
        cnt = 0
        cnt_1 = 0
        #等待准备就绪
        time.sleep(1.0)
        while True:
            #try:
            # 转化为opencv图像
            img1 = bridge.imgmsg_to_cv2(self.down_cam_Image_data, "mono8")
            img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
            if img is None:
                self.get_logger().error("bridge.imgmsg_to_cv2 returned None")
                return
            img = cv2.flip(img, -1)

            row_index = img.shape[0] // 3
            row_index1 = img.shape[0] // 2
            column_index = img.shape[1] // 2
            row = img[row_index, :]
            white_pixels = np.where(row == 255)[0]

            # 计算白点的平均位置作为线的中心
            if white_pixels.size > 0:
                line_center = np.mean(white_pixels).astype(int)
                last_positions.append(line_center)
                if len(last_positions) > window_size:  # 如果列表长度超过窗口大小，删除最旧的元素
                    last_positions.pop(0)
            else:
                if last_positions:
                    line_center = last_positions[-1]  # 如果没有检测到新的，则使用上一个

            # 计算滑动平均
            if len(last_positions) > 1:
                smoothed_center = int(np.mean(last_positions))
                cv2.circle(img, (smoothed_center, row_index), 10, (0, 0, 0), -1)  # 标记平滑后的中心点
            else:
                smoothed_center = img.shape[1] // 2
                cv2.circle(img, (smoothed_center, row_index), 10, (0, 0, 0), -1)

            # 在图像上添加文字
            cv2.putText(img, "output: {:.2f}".format(drz), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)

            img_msg = bridge.cv2_to_imgmsg(img, "mono8")
            self.line_patrol_img_pub.publish(img_msg)

            angle_error = smoothed_center - column_index
            drz = self.pid_update(angle_error)

            if all(x==0 for x in self.yolov8_data_down.state):
                # pass
                cmd.pos.x = 0.0
                cmd.pos.y = 0.002
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt_1 += 1
                
            elif not all(x==0 for x in self.yolov8_data_down.state):
                if  self.yolov8_data_down.state[0] != 0 and  self.yolov8_data_down.targets[0].tpos_inpic.y > row_index1 :
                    if self.task_lock[0] == 0 :
                        self.get_logger().info("Info:检测A，开始执行任务") 
                        #self.setp()
                        #a, b, c = self.cam2robot(1, 5,"down")
                        #self.movex(a)
                        #self.movey(b)
                    
                        # 保存任务结束时的图片
                        task1_end_img_path = f"A.png"
                        cv2.imwrite(task1_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task1_end_img_path}")

                        self.get_logger().info("Info:任务执行完毕")
                        #self.back()
                        self.task_lock[0] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[1] != 0 and self.yolov8_data_down.targets[1].tpos_inpic.y > row_index1:
                    if self.task_lock[1] == 0 :
                        self.get_logger().info("Info:检测B，开始执行任务")
                        #self.setp()
                        #a, b, c = self.cam2robot(2, 4,"down")
                        #self.movex(a)
                        #self.movey(b)
                        
                        # 保存任务结束时的图片
                        task2_end_img_path = f"B.png"
                        cv2.imwrite(task2_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task2_end_img_path}")

                        #self.back()
                        self.get_logger().info("Info:任务执行完毕")
                        self.task_lock[1] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[2] != 0 and self.yolov8_data_down.targets[2].tpos_inpic.y > row_index1:
                    if self.task_lock[2] == 0 :
                        self.get_logger().info("Info:检测C，开始执行任务") 
                        #self.setp()
                        #a, b, c = self.cam2robot(0, 4,"down")
                        #self.movex(a)
                       # self.movey(b)
                        # 保存任务结束时的图片
                        task3_end_img_path = f"C.png"
                        cv2.imwrite(task3_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task3_end_img_path}")

                        self.get_logger().info("Info:任务执行完毕")
                        self.task_lock[2] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)

                else:
                    #pass
                    cmd.pos.x = 0.0
                    cmd.pos.y = 0.002
                    cmd.pos.z = 0.0
                    cmd.pos.rz = drz
                    self.target_pos_down_pub.publish(cmd)
                    cnt_1 += 1
                    time.sleep(timesleep)
            if cnt_1 > 1200:
                self.get_logger().info("Info:任务全部执行完毕")
                return
            if all(x == 1 for x in self.task_lock):
                cmd.pos.x = 0.0
                cmd.pos.y = 0.004
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt+=1
                if cnt > 200:
                    self.get_logger().info("Info:任务全部执行完毕")
                    return

          
    #巡线
    def line(self, ys_dep):
        self.led(0, 0)
        
        self.pid_parameters.p = 0.0009
        self.pid_parameters.i = 0.0
        self.pid_parameters.d = 0.08
        self.pid_parameters.output_limit = 5.0

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        drz = 0.0
        depth = ys_dep
        timesleep = 0.025
        
        self.task_lock = [0, 0, 0]
        
        magnet = MagnetController()
        bridge = CvBridge()
        
        # 初始化1D卡尔曼滤波器（仅跟踪位置）
        kf = KalmanFilter(dim_x=1, dim_z=1)
        kf.x = np.array([320.])  # 初始位置（图像中心附近）
        kf.F = np.array([[1.]])  # 状态转移矩阵（简单恒速模型）
        kf.H = np.array([[1.]])  # 观测矩阵
        kf.P *= 100.  # 初始协方差
        kf.R = 3.0    # 观测噪声
        kf.Q = np.array([[1.0]])  # 过程噪声
        
        # 图像状态跟踪变量
        last_valid_image_time = None
        has_valid_image = False
        last_filtered_center = 320  # 初始中心位置
        img_shape = (480, 640)  # 预设图像尺寸，根据实际情况调整
        row_index = img_shape[0] // 3  # 预设行索引
        row_index1 = img_shape[0] // 2  # 预设任务检测行索引
        column_index = img_shape[1] // 2  # 预设列中心
        
        # 新增：图像初始化等待机制
        init_wait_time = 0.1  # 初始化等待0.1秒
        start_time = time.time()
        self.get_logger().info(f"等待图像初始化，最多等待{init_wait_time}秒...")
        
        # 等待图像或超时
        while not has_valid_image and (time.time() - start_time) < init_wait_time:
            try:
                if self.segment_img is not None:
                    img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
                    img_shape = img.shape
                    row_index = img_shape[0] // 3
                    row_index1 = img_shape[0] // 2
                    column_index = img_shape[1] // 2
                    has_valid_image = True
                    last_valid_image_time = time.time()
                    self.get_logger().info("成功获取初始图像")
            except Exception as e:
                self.get_logger().debug(f"初始化阶段图像获取失败: {str(e)}")
            time.sleep(0.1)  # 短时间等待后重试
        
        if not has_valid_image:
            self.get_logger().warn(f"初始化超时，未获取到图像，将使用默认参数运行")
            
        cnt = 0
        cnt_1 = 0
        while True:
            cnt_1 = cnt_1 + 1
            if cnt_1 > 2000:
                self.get_logger().warn(f"时间结束自动退出")
                return
                
            # 尝试获取和处理图像
            try:
                if self.segment_img is not None:
                    img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
                    img = cv2.flip(img, -1)
                    img_shape = img.shape
                    row_index = img_shape[0] // 3
                    row_index1 = img_shape[0] // 2
                    column_index = img_shape[1] // 2
                    last_valid_image_time = time.time()
                    has_valid_image = True
                    
                    # 处理图像获取线中心
                    row = img[row_index, :]
                    white_pixels = np.where(row == 255)[0]

                    # 卡尔曼滤波处理
                    kf.predict()
                    
                    # 有观测值时更新
                    if white_pixels.size > 0:
                        line_center = np.mean(white_pixels).astype(int)
                        kf.update(line_center)
                    
                    # 使用滤波后的值
                    filtered_center = int(kf.x[0])
                    last_filtered_center = filtered_center
                    
                    # 绘制标记并发布图像
                    cv2.circle(img, (filtered_center, row_index), 10, (0, 0, 0), -1)
                    cv2.putText(img, "output: {:.2f}".format(drz), (50, 50), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)
                    img_msg = bridge.cv2_to_imgmsg(img, "mono8")
                    self.line_patrol_img_pub.publish(img_msg)
                    

                        
            except Exception as e:
                # 图像处理失败时的处理
                self.get_logger().warn(f"无分割图像: {str(e)}")
                
                # 仅使用预测
                kf.predict()
                filtered_center = int(kf.x[0])
                last_filtered_center = filtered_center
                
                # 状态判断与警示
                if not has_valid_image:
                    self.get_logger().warn("持续未接收到图像，使用默认控制策略")
                elif (time.time() - last_valid_image_time) > 1.0:
                    self.get_logger().warn("图像已丢失超过1秒，使用预测值控制")
    
            
            # 计算控制量
            angle_error = filtered_center - column_index
            # 无图像时减小控制增益，采用更保守的控制
            if not has_valid_image:
                drz = self.pid_update(angle_error) * 0.5  # 降低控制强度
                dy = 0.004  # 降低前进速度
            else:
                drz = self.pid_update(angle_error)
                dy = 0.005 - 0.0004 * abs(drz)
            
            # 控制逻辑
            if all(x == 0 for x in self.yolov8_data_down.state):
                cmd.pos.x = 0.0
                cmd.pos.y = dy
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                
            elif not all(x == 0 for x in self.yolov8_data_down.state):
                if self.yolov8_data_down.state[1] != 0 and self.yolov8_data_down.targets[1].tpos_inpic.y > row_index1:
                        if self.task_lock[0] == 0:
                            self.get_logger().info("检测到黑色方块，开始执行任务")
                            time.sleep(2)
                            magnet.state = 0
                            self.magnet_controller_pub.publish(magnet)
                            self.led(1, 1)
                            time.sleep(1)
                            self.get_logger().info("任务执行完毕")
                            self.task_lock[0] = 1
                        else:
                            cmd.pos.x = 0.0
                            cmd.pos.y = dy
                            cmd.pos.z = 0.0
                            cmd.pos.rz = drz
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(timesleep)
                elif self.yolov8_data_down.state[2] != 0 and self.yolov8_data_down.targets[2].tpos_inpic.y > row_index1:
                    if self.task_lock[1] == 0:
                        self.get_logger().info("检测到绿色圆形，开始执行任务")
                        time.sleep(2)
                        a, b, c = self.cam2robot(2, 4, "down")
                        b = b - 0.4
                        self.movex(a)
                        self.movey(b)
                        self.movez(depth)
                        self.led(1,0)
                        self.movez(-depth)
                        self.led(0,0)
                        self.get_logger().info("任务执行完毕")
                        self.task_lock[1] = 1
                    else:
                        cmd.pos.x = 0.0
                        cmd.pos.y = dy
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[0] != 0 and self.yolov8_data_down.targets[0].tpos_inpic.y > row_index1:
                    if self.task_lock[2] == 0:
                        self.get_logger().info("检测到黄色三角，开始执行任务")
                        time.sleep(2)
                        self.moverz(179.9)
                        time.sleep(1)
                        self.moverz(179.9)
                        time.sleep(1)
                        self.get_logger().info("任务执行完毕")
                        self.task_lock[2] = 1
                    else:
                        cmd.pos.x = 0.0
                        cmd.pos.y = dy
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        time.sleep(timesleep)
                else:
                    cmd.pos.x = 0.0
                    cmd.pos.y = dy
                    cmd.pos.z = 0.0
                    cmd.pos.rz = drz
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(timesleep)
                    
            if all(x == 1 for x in self.task_lock):
                cmd.pos.x = 0.0
                cmd.pos.y = dy
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt += 1
                if cnt > 60:
                    return
    

            # except Exception as e:
            #     self.get_logger().error(f"图像处理过程中出现错误 {e}")
            #     break
                # except Exception as e:
                #     self.get_logger().error(f"图像处理过程中出现错误 {e}")
                #     break
 


# 从命令行获取任务
def get_act():
    command = input("请输入任务: \n")
    parts = command.split()
    if parts[0] == 'movexyz':
        args = parts[1:]
        if len(args) == 3:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dic = {
                "name": "movexyz",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'throw_golf':
        args = parts[1:]
        if len(args) == 2:
            dy = float(args[0])
            depth = float(args[1])
            dic = {
                "name": "throw_golf",
                "params": {
                    "dy": dy,
                    "depth": depth,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'movexy':
        args = parts[1:]
        if len(args) == 2:
            x = float(args[0])
            y = float(args[1])
            dic = {
                "name": "movexy",
                "params": {
                    "x": x,
                    "y": y,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movex':
        args = parts[1:]
        if len(args) == 1:
            x = float(args[0])
            dic = {
                "name": "movex",
                "params": {
                    "x": x,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movey':
        args = parts[1:]
        if len(args) == 1:
            y = float(args[0])
            dic = {
                "name": "movey",
                "params": {
                    "y": y,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movez':
        args = parts[1:]
        if len(args) == 1:
            z = float(args[0])
            dic = {
                "name": "movez",
                "params": {
                    "z": z,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'moverz':
        args = parts[1:]
        if len(args) == 1:
            rz = float(args[0])
            dic = {
                "name": "moverz",
                "params": {
                    "rz": rz,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'setz':
        args = parts[1:]
        if len(args) == 1:
            z = float(args[0])
            dic = {
                "name": "setz",
                "params": {
                    "z": z,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'setrz':
        args = parts[1:]
        if len(args) == 1:
            rz = float(args[0])
            dic = {
                "name": "setrz",
                "params": {
                    "rz": rz,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'pow':
        args = parts[1:]
        if len(args) == 1:
            a = int(args[0])
            dic = {
                "name": "pow",
                "params": a
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mtty':
        args = parts[1:]
        if len(args) == 2:
            y = float(args[0])
            z = float(args[1])
            dic = {
                "name": "mtty",
                "params": {
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttxf':
        args = parts[1:]
        if len(args) == 2:
            dx = float(args[0])
            dy = float(args[1])
            dic = {
                "name": "mttxf",
                "params": {
                    "dx": dx,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttz':
        args = parts[1:]
        if len(args) == 2:
            y = float(args[0])
            z = float(args[1])
            dic = {
                "name": "mttz",
                "params": {
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttzxy':
        args = parts[1:]
        if len(args) == 3:
            dz = float(args[0])
            dx = float(args[1])
            dy = float(args[2])
            dic = {
                "name": "mttzxy",
                "params": {
                    "dz": dz,
                    "dx": dx,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
    elif parts[0] == 'setp':
        if len(parts) == 1:
            dic = {
                "name": "setp",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'back':
        if len(parts) == 1:
            dic = {
                "name": "back",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'backy':
        if len(parts) == 1:
            dic = {
                "name": "backy",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'search':
        args = parts[1:]
        if len(args) == 2:
            name = args[0]
            cam = args[1]
            dic = {
                "name": "search",
                "params": {
                    "name": name,
                    "cam": cam
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'line':
        args = parts[1:]
        if len(args) == 1:
            ys_dep = float(args[0])
            dic = {
                "name": "line",
                "params": {
                    "ys_dep": ys_dep
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None 
        
    elif parts[0] == 'mttpos':
        args = parts[1:]
        if len(args) == 5:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            rz = float(args[3])
            dy = float(args[4])
            dic = {
                "name": "mttpos",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "rz": rz,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'mttzpos':
        args = parts[1:]
        if len(args) == 4:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dy = float(args[3])
            dic = {
                "name": "mttzpos",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'mttpos_amend':
        args = parts[1:]
        if len(args) == 5:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            rz = float(args[3])
            dy = float(args[4])
            dic = {
                "name": "mttpos_amend",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "rz": rz,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'mttzpos_amend':
        args = parts[1:]
        if len(args) == 4:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dy = float(args[3])
            dic = {
                "name": "mttzpos_amend",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'graball':
        args = parts[1:]
        if len(args) == 6:
            color       =   str(args[0])
            depth       =   float(args[1])
            timeout     =   float(args[2])
            pr          =   float(args[3])
            k           =   float(args[4])
            step_time   =   float(args[5])           
            dic = {
                "name": "graball",
                "params": {
                    "color": color,
                    "depth": depth,
                    "timeout": timeout,
                    "pr": pr,
                    "k" : k,
                    "step_time":step_time
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'thrball':
        args = parts[1:]
        if len(args) == 4:
            pr        =   float(args[0])
            timeout   =   float(args[1])
            k         =   float(args[2])
            step_time =   float(args[3])  
            dic = {
                "name": "thrball",
                "params": {
                    "pr": pr,
                    "timeout": timeout,
                    "k" : k,
                    "step_time":step_time
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None  
    elif parts[0] == 'pass_door':
        args = parts[1:]
        if len(args) == 1:
            num       =   int(args[0])
            dic = {
                "name": "pass_door",
                "params": {
                    "num":num
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'led':
        args = parts[1:]
        if len(args) == 2:
            led0 = int(args[0])
            led1 = int(args[1])
            dic = {
                "name": "led",
                "params": {
                    "led0": led0,
                    "led1": led1
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'delay':
        args = parts[1:]
        if len(args) == 1:
            t = float(args[0])
            dic = {
                "name": "delay",
                "params": t
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'grab_golf':
        args = parts[1:]
        if len(args) == 5:
            kind = str(args[0])
            dx = float(args[1])
            dy = float(args[2])
            down_depth = float(args[3])
            up_depth = float(args[4])
            dic = {
                "name": "grab_golf",
                "params": {
                    "kind": kind,
                    "dx": dx,
                    "dy": dy,
                    "down_depth": down_depth,
                    "up_depth": up_depth
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'line_qd':
        args = parts[1:]
        if len(args) == 0:
            dic = {
                "name": "line_qd",
                "params": {}  # 无参数时为空字典
            }
            return dic
        else:
            print("指令格式不正确，line_qd不需要参数")
            return None 
        
    elif parts[0] == 'endfloat':
        args = parts[1:]
        if len(args) == 0:
            dic = {
                "name": "endfloat",
                "params": {}  # 无参数时为空字典
            }
            return dic
        else:
            print("指令格式不正确，line_qd不需要参数")
            return None 
    
    elif parts[0] == 'put_t':
        args = parts[1:]
        if len(args) == 3:
            num = int(args[0])
            dy = float(args[1])
            dz = float(args[2])
            dic = {
                "name": "put_t",
                "params": {
                    "num": num,
                    "dy": dy,
                    "dz": dz
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'strike_ball':
        args = parts[1:]
        if len(args) == 1:
            num = int(args[0])
            dic = {
                "name": "strike_ball",
                "params": {
                    "num": num
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'strike_ball3':
        args = parts[1:]
        if len(args) == 3:
            num1 = int(args[0])
            num2 = int(args[1])
            num3 = int(args[2])
            dic = {
                "name": "strike_ball3",
                "params": {
                    "num1": num1,
                    "num2": num2,
                    "num3": num3
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    else:
        print("无效指令")
        return None
    
    


# 读取并从文件中加载任务队列
def load_actions(path):
    with open(path, 'r', encoding='utf-8') as f:
        dic = json.load(f)
    return dic

# 保存任务队列


def save_actions(dic, path):
    print("所保存的任务:\n"+str(dic)+"\n")
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(dic, f)

# 普通模式


def commom_loop(node, opt):
    list = load_actions(opt.data_path[0]+"uv_tasks.json")

    node.start()
    num = 0

    for act in list["tasks"]:
        node.get_logger().info(
            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
        node.run(act)
        node.get_logger().info(
            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
        num += 1
    
    node.end()

# 调试模式


def debug_loop(node: CoreNode, opt):
    node.get_logger().info("Info:进入调试模式")

    tasklist = load_actions(opt.data_path[0]+"uv_tasks.json")
     
    help_txt = ""
    with open(opt.data_path[0]+"help.txt", 'r', encoding='utf-8') as f:
        s = f.read()
        help_txt = s

    node.start()

    while True:
        node.get_logger().info(f"Info:等待指令输入")
        command = input("请输入调试指令: \n")
        parts = command.split()
        if parts[0] == 'help':
            print(help_txt)
        elif parts[0] == 'act':
            act = get_act()

            if act == None:
                node.get_logger().info(f"Warn:非法任务")
            else:
                node.get_logger().info(
                    f"Info:=========执行任务: " + act["name"] + "=========")
                node.run(act)
                node.get_logger().info(
                    f"Info:=========完成任务: " + act["name"] + "=========")
        elif parts[0] == "task":
            if parts[1] == "run":
                if len(parts[1:]) == 1:
                    num = 0
                    for act in tasklist["tasks"]:
                        node.get_logger().info(
                            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
                        node.run(act)
                        node.get_logger().info(
                            f"Info:=========完成第 {num:d} 步任务: " + act["name"] + "=========")
                        num += 1
                elif len(parts[1:]) == 2:
                    num = int(parts[parts.index('run') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        n = num
                        for act in tasklist["tasks"][num:]:
                            node.get_logger().info(
                                f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
                            node.run(act)
                            node.get_logger().info(
                                f"Info:=========完成第 {num:d} 步任务: " + act["name"] + "=========")
                            n += 1
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "runonly":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('runonly') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = tasklist["tasks"][num]
                        node.get_logger().info(
                            "Info:=========执行任务: " + act["name"] + "=========")
                        node.run(act)
                        node.get_logger().info(
                            "Info:=========完成任务: " + act["name"] + "=========")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "add":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('add') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = get_act()
                        if act == None:
                            node.get_logger().info("非法任务")
                        else:
                            tasklist["tasks"].insert(num, act)
                            save_actions(
                                tasklist, opt.data_path[0]+"uv_tasks.json")
                elif len(parts[1:]) == 1:
                    act = get_act()
                    if act == None:
                        node.get_logger().info("非法任务")
                    else:
                        tasklist["tasks"].append(act)
                        save_actions(
                            tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "del":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('del') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        tasklist["tasks"].pop(num)
                        save_actions(
                            tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "clear":
                tasklist["tasks"] = []
                save_actions(tasklist, opt.data_path[0]+"uv_tasks.json")
            elif parts[1] == "list":
                node.get_logger().info("Info: 打印任务列表")
                num = 0
                for i in tasklist["tasks"]:
                    print("编号:   " + str(num))
                    print("任务名: "+i["name"])
                    print("参数:   " + str(i["params"]))
                    num += 1
            elif parts[1] == "mod":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('mod') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = get_act()
                        if act == None:
                            node.get_logger().info("非法任务")
                        else:
                            tasklist["tasks"][num] = act
                            save_actions(
                                tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            else:
                node.get_logger().info("Warn:非法指令")


def main(args=None):

    # 加载参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--front-topic', nargs='+', type=str, default=[
                        'front_cam/rectified'], help='前视摄像头')
    parser.add_argument('--down-topic', nargs='+', type=str, default=[
                        'down_cam/rectified'], help='下视摄像头')
    parser.add_argument('--data-path', nargs='+', type=str, default=[
                        '/home/nvidia/Workspace/Cruise/datas/'], help='PID参数路径')
    parser.add_argument('--debug', nargs='+', type=bool,
                        default=False, help='PID参数路径')

    opt = parser.parse_args()

    rclpy.init(args=args)  # 初始化rclpy

    if opt.debug:
        node = CoreNode("uv_automaton_debug", opt)  # 新建一个节点
        thread_debug = threading.Thread(
            target=debug_loop, args=(node, opt))  # 创建调度线程
        thread_debug.start()
    else:
        node = CoreNode("uv_automaton", opt)  # 新建一个节点
        thread_common = threading.Thread(
            target=commom_loop, args=(node, opt))    # 创建调度线程
        thread_common.start()

    node.get_logger().info("节点与调度线程成功启动")

    rclpy.spin(node)  # 保持节点运行，检测是否收到退出指令（Ctrl+Z）
    rclpy.shutdown()  # 关闭rclpy

===== .\uv_ai\uv_ai\uv_automaton.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import time
import os
import termios
import struct
import threading
import json
import argparse
from uv_control_py import Pid
from uv_control_py.CoordinateSystem import CoordinateSystems, MotionState, Cs_Back, Cs_Move, AngleCorrect

from uv_msgs.msg import RobotDeviceManager  # 机器人设备管理器
from uv_msgs.msg import RobotMotionController  # 机器人运动控制器

from uv_msgs.msg import PidControllersState
from uv_msgs.msg import PidParams#巡线的pid参数

from uv_msgs.msg import RobotAxis
from uv_msgs.msg import ServoSet
from uv_msgs.msg import TargetPosDown
from uv_msgs.msg import Yolov8   
from uv_msgs.msg import LedControllers
from uv_msgs.msg import MagnetController

from sensor_msgs.msg import Image
from uv_msgs.srv import DetectRequest
import cv2
import numpy as np
from cv_bridge import CvBridge
from filterpy.kalman import KalmanFilter


from math import sin, cos, atan2, sqrt

PI = 3.141592653589793
DEG2RAD = PI/180
RAD2DEG = 180/PI

Step = {  # 领航点拖曳速度(10hz)
    "x": 0.01,
    "y": 0.01,
    "z": 0.05,
    "rz": 5.0
}

AllowedError = {  # 位置容许误差
    "x": 0.02,
    "y": 0.02,
    "z": 0.02,
    "rz": 1.3
}


class CoreNode(Node):
    def __init__(self, name, opt):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)
        self.opt = opt

        self.robot = CoordinateSystems()

        self.MotionController = RobotMotionController()
        #pid参数初始化
        self.pid_parameters = PidParams()
        # self.pid_parameters.p = 0.0
        # self.pid_parameters.i = 0.0
        # self.pid_parameters.d = 0.0

        self.previous_error = 0.0
        self.i_error = 0.0
        self.dt = 1

        self.task_lock = True
        self.yolov8_data_down = Yolov8()
        self.yolov8_data_front = Yolov8()
        self.magnet = MagnetController()

        self.target = {
            "name": "none",
            "x": 0.0,
            "y": 0.0,
            "z": 0.0
        }

        self.backpoint = {
            "x": 0.0,
            "y": 0.0,
            "z": 0.0,
            "rz": 0.0
        }

        self.front_cam = CoordinateSystems()
        self.down_cam = CoordinateSystems()
        #前视相机坐标偏置
        self.front_cam.base.vector.x = 107.6/1000
        self.front_cam.base.vector.y = 320.0/1000
        self.front_cam.base.vector.z = 65.0/1000
        self.front_cam.base.vector.rx = -90.0
        self.front_cam.base.extract()
        #下视相机坐标偏置
        self.down_cam.base.vector.x = 0.0/1000
        self.down_cam.base.vector.y = 170.0/1000
        self.down_cam.base.vector.z = 42.7/1000
        self.down_cam.base.vector.rz = 0.0
        self.down_cam.base.extract()

        self.get_logger().info(
            f"前置摄像机偏置: x: {self.front_cam.base.vector.x:.2f} y: { self.front_cam.base.vector.y : .2f} z: {self.front_cam.base.vector.z : .2f}")
        self.get_logger().info(
            f"          : rx: {self.front_cam.base.vector.rx:.2f} ry: { self.front_cam.base.vector.ry : .2f} rz: {self.front_cam.base.vector.rz : .2f}")
        self.get_logger().info(
            f"下置摄像机偏置: x: {self.down_cam.base.vector.x:.2f} y: { self.down_cam.base.vector.y : .2f} z: {self.down_cam.base.vector.z : .2f}")
        self.get_logger().info(
            f"          : rx: {self.down_cam.base.vector.rx:.2f} ry: { self.down_cam.base.vector.ry : .2f} rz: {self.down_cam.base.vector.rz : .2f}")
        
        self.start_pos = CoordinateSystems()
        
        self.front_cam_Image_data = None
        self.down_cam_Image_data = None
        self.front_cam_left_Image_data = None
        self.segment_img = None

        # 话题发布
        # 创建话题发布 target_pos_down ，定义其中的消息类型为 TargetPosDown
        self.target_pos_down_pub = self.create_publisher(
            TargetPosDown, "target_pos_down", 10)
        # 创建话题发布 servo_control ，定义其中的消息类型为 ServoSet
        self.servo_control_pub = self.create_publisher(
            ServoSet, "servo_control", 10)
        #创建话题发布  led_controllers, 定义其中的消息类型为 LedControllers
        self.led_controllers_pub = self.create_publisher(
            LedControllers, 'led_controllers', 10)
        # 创建话题发布 magnet_controller ，定义其中的消息类型为 MagnetController
        self.magnet_controller_pub = self.create_publisher(
            MagnetController, "magnet_controller", 10)
        # 创建话题发布 pid_controllers_set ，定义其中的消息类型为 PidControllersState
        self.pid_controllers_set_pub = self.create_publisher(
            PidControllersState, 'pid_controllers_set', 10)
        #创建话题发布 line_patrol_img , 定义消息类型为Image
        self.line_patrol_img_pub = self.create_publisher(
            Image, 'line_patrol_img', 10)

        self.openthrust_data_pub = self.create_publisher(
            RobotAxis, 'openloop_thrust', 10)

        # 话题接收
        # 创建话题接收 motion_controller ，定义其中的消息类型为 RobotMotionController
        self.create_subscription(
            RobotMotionController, 'motion_controller', self.motion_controller_callback, 10)
        # 创建话题接收 front_cam/rectified ，定义其中的消息类型为 Image
        self.create_subscription(
            Image, opt.front_topic[0], self.front_cam_callback, 10)
        # 创建话题接收 down_cam/rectified ，定义其中的消息类型为 Image
        self.create_subscription(
            Image, opt.down_topic[0], self.down_cam_callback, 10)
        #创建话题接收 front_cam/rectified/left,定义其中的消息类型为 Image
        self.create_subscription(
            Image, 'front_cam/rectified/left', self.front_cam_left_callback, 10)
        self.create_subscription(
            PidParams, 'track_pid_parameter', self.track_pid_parameter_callback, 10)
        # 创建话题接收 uv_detect ，定义其中的消息类型为 Yolov8
        self.create_subscription(
            Yolov8, 'uv_detect_down', self.yolov8_down_callback, 10)
        
        self.create_subscription(
            Yolov8, 'uv_detect_front', self.yolov8_front_callback, 10)
        
        #创建话题接收 binary_segment_img , 定义消息类型为Image，用于接收二值化后的分割结果
        self.create_subscription(
            Image, 'binary_segment_img', self.segment_img_callback, 10)

        # 服务请求
        # 创建服务请求 detect_request_client ，定义其中的消息类型为 RobotAxis , 请求服务 uv_detect_srv
        self.detect_request_client = self.create_client(
            DetectRequest, "uv_detect_srv")

        self.magnet.state = 1
        self.magnet_controller_pub.publish(self.magnet)

        self.get_logger().info("节点初始化完成")

    def track_pid_parameter_callback(self, data):
        pass
        # self.pid_parameters = data
    
    # 更新摄像头图像
    def front_cam_callback(self, data):
        self.front_cam_Image_data = data

    def down_cam_callback(self, data):
        self.down_cam_Image_data = data

    def front_cam_left_callback(self, data):
        self.front_cam_left_Image_data = data
    # 更新巡线图像
    def segment_img_callback(self, data):
        self.segment_img = data

    #更新目标检测结果
    def yolov8_down_callback(self, data):
        self.yolov8_data_down = data
    
    def yolov8_front_callback(self, data):
        self.yolov8_data_front = data
    
    # 更新机器人位置数据
    def motion_controller_callback(self, data):
        self.MotionController = data

        self.robot.base.vector.x = self.MotionController.pos.x
        self.robot.base.vector.y = self.MotionController.pos.y
        self.robot.base.vector.z = self.MotionController.pos.z
        self.robot.base.vector.rx = self.MotionController.pos.rx
        self.robot.base.vector.ry = self.MotionController.pos.ry
        self.robot.base.vector.rz = self.MotionController.pos.rz
        self.robot.base.extract()

    # 等待移动至指定位置
    def move_wait(self):
        cnt = 0
        time.sleep(0.5)
        while True:
            judge = 0
            if abs(self.MotionController.tpos_inbase.x) > AllowedError["x"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.y) > AllowedError["y"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.z) > AllowedError["z"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.rz) > AllowedError["rz"]:
                judge += 1

            if judge == 0:  # 进入容许范围
                return True

            if cnt > 200:  # 超时退出
                return False

            cnt += 1
            time.sleep(0.05)

    def movez(self, z):
         # 校验
        if self.robot.base.vector.z + z < -1.0:
            self.get_logger().info("Warn: 深度设置超出范围")
            z = -self.robot.base.vector.z

        self.get_logger().info("======开始移动======")

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        # 调整深度
        step_cnt = int(abs(z)/Step["z"]) + 1
        #self.get_logger().info(f"Info: 开始调整深度, 需要调整 {step_cnt:d} 次")
        cnt = 0
        while True:
            cnt += 1
            self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整深度")
            if abs(z) <= Step["z"]:
                self.get_logger().info("Info: 最终深度调整开始")
                cmd.pos.z = z
                cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
                self.target_pos_down_pub.publish(cmd)
                re = self.move_wait()
                if re:
                    self.get_logger().info("Info: 最终深度调整完成")
                else:
                    self.get_logger().info("Warn: 最终深度调整超时！")
                break
            else:
                if z > 0:
                    z -= Step["z"]
                    cmd.pos.z = Step["z"]
                else:
                    z += Step["z"]
                    cmd.pos.z = -Step["z"]
                cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
                self.target_pos_down_pub.publish(cmd)
                #self.get_logger().info(f"Info: 第 {cnt:d} 次深度调整完成")
                time.sleep(0.2)

        self.get_logger().info("======移动结束======")
    
        # 移动 z 的相对位移
    def fast_movez(self, z):
        # 直接调整
        if self.robot.base.vector.z + z < 0:
            self.get_logger().info("Warn: 深度设置超出范围")
        else:
            self.get_logger().info("======开始移动======")
            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0
            self.get_logger().info("Info: 深度快速微调开始")
            cmd.pos.z = z
            cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
            self.target_pos_down_pub.publish(cmd)
            self.get_logger().info("======移动结束======")

        # 渐进调整
        # # 校验
        # if self.robot.base.vector.z + z < 0.2:
        #     self.get_logger().info("Warn: 深度设置超出范围")
        # else:
        #     self.get_logger().info("======开始移动======")

        #     cmd = TargetPosDown()
        #     cmd.cs = 2
        #     cmd.pos.rx = 0.0
        #     cmd.pos.ry = 0.0

        #     # 调整深度
        #     step_cnt = int(abs(z)/Step["z"]) + 1
        #     self.get_logger().info(f"Info: 开始调整深度, 需要调整 {step_cnt:d} 次")
        #     cnt = 0
        #     while True:
        #         cnt += 1
        #         self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整深度")
        #         if abs(z) <= Step["z"]:
        #             self.get_logger().info("Info: 最终深度调整开始")
        #             cmd.pos.z = z
        #             cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
        #             self.target_pos_down_pub.publish(cmd)
        #             re = self.move_wait()
        #             if re:
        #                 self.get_logger().info("Info: 最终深度调整完成")
        #             else:
        #                 self.get_logger().info("Warn: 最终深度调整超时！")
        #             break
        #         else:
        #             if z > 0:
        #                 z -= Step["z"]
        #                 cmd.pos.z = Step["z"]
        #             else:
        #                 z += Step["z"]
        #                 cmd.pos.z = -Step["z"]
        #             cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
        #             self.target_pos_down_pub.publish(cmd)
        #             self.get_logger().info(f"Info: 第 {cnt:d} 次深度调整完成")
        #             time.sleep(0.2)

        #     self.get_logger().info("======移动结束======")

    # 移动 x 的相对位移
    def movex(self, x):
        if x > 10:
            self.get_logger().info("Warn: 横向位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0

            # 调整横向位置
            step_cnt = int(abs(x)/Step["x"]) + 1
            self.get_logger().info(f"Info: 开始调整横向位置, 需要调整 {step_cnt:d} 次")
            cnt = 0
            while True:
                cnt += 1
                #self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整横向位置")
                if abs(x) <= Step["x"]:
                    self.get_logger().info("Info: 最终横向位置调整开始")
                    cmd.pos.x = x
                    cmd.pos.y = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    s = self.move_wait()
                    if s:
                        self.get_logger().info("Info: 最终横向位置调整完成")
                    else:
                        self.get_logger().info("Warn: 最终横向位置调整超时！")
                    break
                else:
                    if x > 0:
                        x -= Step["x"]
                        cmd.pos.x = Step["x"]
                    else:
                        x += Step["x"]
                        cmd.pos.x = -Step["x"]
                    cmd.pos.y = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    #self.get_logger().info(f"Info: 第 {cnt:d} 次横向位置调整完成")
                    time.sleep(0.1)
            self.get_logger().info("======移动结束======")

    # 移动 x 的相对位移
    def fast_movex(self, x):
        if x > 10:
            self.get_logger().info("Warn: 横向位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0
            self.get_logger().info("Info: 横向位置快速微调开始")
            cmd.pos.x = x
            cmd.pos.y = cmd.pos.z = cmd.pos.rz = 0.0
            self.target_pos_down_pub.publish(cmd)
            self.get_logger().info("======移动结束======")
    


    # 移动 y 的相对位移
    def movey(self, y):
        if y > 10:
            self.get_logger().info("Warn: 前后位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0

            # 调整
            step_cnt = int(abs(y)/Step["y"]) + 1
            self.get_logger().info(f"Info: 开始调整前后位置, 需要调整 {step_cnt:d} 次")
            cnt = 0
            while True:
                cnt += 1
                #self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整前后位置")
                if abs(y) <= Step["y"]:
                    self.get_logger().info("Info: 最终前后位置调整开始")
                    cmd.pos.y = y
                    cmd.pos.x = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    s = self.move_wait()
                    if s:
                        self.get_logger().info("Info: 最终前后位置调整完成")
                    else:
                        self.get_logger().info("Warn: 最终前后位置调整超时！")
                    break
                else:
                    if y > 0:
                        y -= Step["y"]
                        cmd.pos.y = Step["y"]
                    else:
                        y += Step["y"]
                        cmd.pos.y = -Step["y"]
                    cmd.pos.x = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    #self.get_logger().info(f"Info: 第 {cnt:d} 次前后位置调整完成")
                    time.sleep(0.1)
            self.get_logger().info("======移动结束======")

                # 移动 y 的相对位移
    def fast_movey(self, y):
        if y > 10:
            self.get_logger().info("Warn: 前后位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0
            self.get_logger().info("Info: 前后位置快速微整开始")
            cmd.pos.y = y
            cmd.pos.x = cmd.pos.z = cmd.pos.rz = 0.0
            self.target_pos_down_pub.publish(cmd)
            self.get_logger().info("======移动结束======")

    # 移动 rz 的相对位移
    def moverz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始旋转======")

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        # 调整
        step_cnt = int(abs(rz)/Step["rz"]) + 1
        self.get_logger().info(f"Info: 开始调整角度, 需要调整 {step_cnt:d} 次")
        cnt = 0
        while True:
            cnt += 1
            #self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整角度")
            if abs(rz) <= Step["rz"]:
                self.get_logger().info("Info: 最终角度调整开始")
                cmd.pos.rz = rz
                cmd.pos.x = cmd.pos.z = cmd.pos.y = 0.0
                self.target_pos_down_pub.publish(cmd)
                s = self.move_wait()
                if s:
                    self.get_logger().info("Info: 最终角度调整完成")
                else:
                    self.get_logger().info("Warn: 最终角度调整超时！")
                break
            else:
                if rz > 0:
                    rz -= Step["rz"]
                    cmd.pos.rz = Step["rz"]
                else:
                    rz += Step["rz"]
                    cmd.pos.rz = -Step["rz"]
                cmd.pos.x = cmd.pos.z = cmd.pos.y = 0.0
                self.target_pos_down_pub.publish(cmd)
                #self.get_logger().info(f"Info: 第 {cnt:d} 次角度调整完成")
                time.sleep(0.1)
        self.get_logger().info("======旋转结束======")
        
        
    def fast_moverz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始旋转======")

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        self.get_logger().info("Info: 前后位置快速微整开始")
        cmd.pos.rz = rz
        cmd.pos.x = cmd.pos.z = cmd.pos.y = 0.0
        self.target_pos_down_pub.publish(cmd)
        self.get_logger().info("======移动结束======")

    # 移动x,y相对位移
    def movexy(self, x, y):
        if x == 0 and y == 0:
            self.get_logger().info("Warn: 未设置合法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")
            time.sleep(0.1)
            #self.get_logger().info(f"Info: ======朝向回正,旋转{-rz:.2f}°======")
            #self.moverz(-rz)
            #self.get_logger().info("Info: ======转向结束======")

    # 移动x,y,z相对位移
    def movexyz(self, x, y, z):
        if z == 0:
            self.get_logger().info("Warn: 未设置合法深度位移！")
        else:
            self.movez(z)
        time.sleep(0.1)
        self.movexy(x, y)

    # 设置 z
    def setz(self, z):
        if z >= -1.0:
            self.get_logger().info("======开始调整深度======")
            cmd = TargetPosDown()
            cmd.cs = 0
            cmd.pos.rx = self.MotionController.pos.rx
            cmd.pos.ry = self.MotionController.pos.ry
            cmd.pos.x = self.MotionController.pos.x
            cmd.pos.y = self.MotionController.pos.y
            cmd.pos.rz = self.MotionController.pos.rz
            cmd.pos.z = z
            self.target_pos_down_pub.publish(cmd)
            s = self.move_wait()
            if s:
                self.get_logger().info("Info: 深度调整完成")
            else:
                self.get_logger().info("Warn: 深度调整超时！")
            self.get_logger().info("======移动结束======")
        else:
            self.get_logger().info("Warn: 深度设置错误！")

    # 设置rz
    def setrz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始调整角度======")
        cmd = TargetPosDown()
        cmd.cs = 0
        cmd.pos.rx = self.MotionController.pos.rx
        cmd.pos.ry = self.MotionController.pos.ry
        cmd.pos.x = self.MotionController.pos.x
        cmd.pos.y = self.MotionController.pos.y
        cmd.pos.z = self.MotionController.pos.z
        cmd.pos.rz = rz
        self.target_pos_down_pub.publish(cmd)
        s = self.move_wait()
        if s:
            self.get_logger().info("Info: 角度调整完成")
        else:
            self.get_logger().info("Warn: 角度调整超时！")
        self.get_logger().info("======移动结束======")

    # 设置路径点
    def setp(self):
        self.backpoint["x"] = self.MotionController.pos.x
        self.backpoint["y"] = self.MotionController.pos.y
        self.backpoint["z"] = self.MotionController.pos.z
        self.backpoint["rz"] = self.MotionController.pos.rz
        self.get_logger().info(
            f'Info:已保存当前位置 x: {self.backpoint["x"]:.2f} y: {self.backpoint["y"]:.2f} z: {self.backpoint["z"]:.2f} rz : {self.backpoint["rz"]:.2f}')

    # 回到路径点
    def back(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(-d)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz-rz_)
            self.get_logger().info("Info: ======转向结束======")
            
    def fast_back(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.fast_movez(z)
        time.sleep(2)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.fast_moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.fast_moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(5.0)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.fast_movey(-d)
            time.sleep(5.0)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.fast_moverz(rz-rz_)
            time.sleep(2.0)
            self.get_logger().info("Info: ======转向结束======")
            
    # 回到路径点
    def backy(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")


        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(-d)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz-rz_)
            self.get_logger().info("Info: ======转向结束======")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

    # 移动至寄存器 self.target 所指定的位置
    def mtty(self, dy, dz):

        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        z -= dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y) - dy
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")

    def mttzxy(self, dz, dx, dy):
        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        x += dx
        y += dy
        z += dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")
        
        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.get_logger().info(f"Info: ======深度移动指定距离,移动{z:.2f}m======")
            self.movez(z)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if x == 0:
            self.get_logger().info("Warn: 水平位移非法！")
        else:
            self.get_logger().info(f"Info: ======横移指定距离,移动{x:.2f}m======")
            self.movex(x)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if y == 0:
            self.get_logger().info("Warn: 前后位移非法！")
        else:
            self.get_logger().info(f"Info: ======前后指定距离,移动{y:.2f}m======")
            self.movey(y)
        time.sleep(0.1)

        self.get_logger().info(f"Info: ======移动结束======")


    def mttxf(self,dx,dy):
        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")
        x_target = x - dx
        self.get_logger().info(f"Info: ======横移指定距离,移动{x:.2f}m======")
        self.movex(x_target)
        self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            d = y - dy
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)


    # 移动至寄存器 self.target 所指定的位置
    def mttz(self, dy, dz):

        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        z -= dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y) - dy
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)
    
    #移动至指定世界坐标位置
    def mttpos(self, x, y, z, rz, dy):
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z

        Step["y"] = 0.04
        self.mttz(dy, 0.0)#小范围微调
        self.setrz(rz)
        Step["y"] = 0.02
    
    #移动至指定世界坐标位置，但最后不旋转
    def mttzpos(self, x, y, z, dy):
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z
        Step["z"] = 0.2
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        Step["y"] = 0.02
        Step["z"] = 0.05
    
    #移动至指定世界坐标位置，以比赛开始位置为坐标
    def mttpos_amend(self, x, y, z, rz, dy):
        self.start_pos.target_inbase.vector.x = x
        self.start_pos.target_inbase.vector.y = y
        self.start_pos.target_inbase.vector.z = z
        self.start_pos.target_inbase.vector.rz = rz
        self.start_pos.target_inbase.vector.rx = self.start_pos.target_inbase.vector.ry= 0.0
        self.start_pos.base2world()
        self.target["x"] = self.start_pos.target_inworld.vector.x
        self.target["y"] = self.start_pos.target_inworld.vector.y
        self.target["z"] = self.start_pos.target_inworld.vector.z
        self.target["rz"] = self.start_pos.target_inworld.vector.rz
        
        self.get_logger().info(
            f"x: {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
              
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        self.setrz(rz+self.start_pos.base.vector.rz)
        Step["y"] = 0.02
    
    #移动至指定世界坐标位置，以比赛开始位置为坐标
    def mttzpos_amend(self, x, y, z, dy):
        self.start_pos.target_inbase.vector.x = x
        self.start_pos.target_inbase.vector.y = y
        self.start_pos.target_inbase.vector.z = z
        self.start_pos.target_inbase.vector.rx = self.start_pos.target_inbase.vector.ry= 0.0
        self.start_pos.base2world()
        self.target["x"] = self.start_pos.target_inworld.vector.x
        self.target["y"] = self.start_pos.target_inworld.vector.y
        self.target["z"] = self.start_pos.target_inworld.vector.z
        Step["z"] = 0.2
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        Step["y"] = 0.02
        Step["z"] = 0.05
    
    # 搜寻目标
    def search(self, name, cam):
        # 定位目标
        # 等待服务段上线
        wait = True
        while rclpy.ok() and self.detect_request_client.wait_for_service(0.1) == False:
            if wait:
                wait = False
                self.get_logger().info("Info:等待服务端上线....")
        self.get_logger().info("Info:服务端已启动")

        request = DetectRequest.Request()
        request.stero = cam
        request.target = name
        responce = None

        pos_list = []
        fail_cnt = 0

        image = False

        while True:
            if cam == "front" and self.front_cam_Image_data != None:
                request.imagein = self.front_cam_Image_data
                image = True
            if cam == "down" and self.down_cam_Image_data != None:
                request.imagein = self.down_cam_Image_data
                image = True

            if image == True:
                responce = self.detect_request_client.call(request)
                if responce.s == 1:
                    if cam == "front":
                        self.front_cam.target_inbase.vector.x = responce.x
                        self.front_cam.target_inbase.vector.y = responce.y
                        self.front_cam.target_inbase.vector.z = responce.z
                        #相机坐标系到机器人坐标系
                        self.front_cam.base2world()

                        self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                        self.robot.base2world()

                    if cam == "down":
                        self.down_cam.target_inbase.vector.x = responce.x
                        self.down_cam.target_inbase.vector.y = responce.y
                        self.down_cam.target_inbase.vector.z = responce.z
                        self.down_cam.base2world()

                        self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                        self.robot.base2world()

                    # self.get_logger().info(
                    #     f"Info:目标在机器人坐标系中的位置: x: {self.robot.target_inbase.vector.x: .3f} y: {self.robot.target_inbase.vector.y: .3f} z: {self.robot.target_inbase.vector.z: .3f}")
                    self.get_logger().info(
                        f"Info:目标在相机坐标系中的位置: x: {responce.x: .3f} y: {responce.y: .3f} z: {responce.z: .3f}")

                    pos_list.append([self.robot.target_inworld.vector.x,
                                    self.robot.target_inworld.vector.y, self.robot.target_inworld.vector.z])

                    if len(pos_list) >= 5:
                        break
                else:
                    fail_cnt += 1
                    time
                    if fail_cnt >= 1000 & len(pos_list) < 5:
                        self.get_logger().info(f"确认无目标，退出函数")
                        return responce.s

            else:
                self.get_logger().info("无图像传入")

            image = False
        x = y = z = 0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)

        self.robot.base2world()
        self.target["name"] = name
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z

        self.get_logger().info(
            f"目标位置: x : {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
        return responce.s

    def search2(self, name, cam,dy,dz,z_target,times):
        # 定位目标
        # 等待服务段上线
        wait = True
        while rclpy.ok() and self.detect_request_client.wait_for_service(0.1) == False:
            if wait:
                wait = False
                self.get_logger().info("Info:等待服务端上线....")
        self.get_logger().info("Info:服务端已启动")

        request = DetectRequest.Request()
        request.stero = cam
        request.target = name

        pos_list = []

        image = False
        times_none = 0 #
        flag_to_next = 0 #

        while True:
            if cam == "front" and self.front_cam_Image_data != None:
                request.imagein = self.front_cam_Image_data
                image = True
            if cam == "down" and self.down_cam_Image_data != None:
                request.imagein = self.down_cam_Image_data
                image = True

            if image == True:
                responce = self.detect_request_client.call(request)
                if responce.s == 1:
                    if cam == "front":
                        self.front_cam.target_inbase.vector.x = responce.x
                        self.front_cam.target_inbase.vector.y = responce.y
                        self.front_cam.target_inbase.vector.z = responce.z
                        #相机坐标系到机器人坐标系
                        self.front_cam.base2world()

                        self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                        self.robot.base2world()

                    if cam == "down":
                        self.down_cam.target_inbase.vector.x = responce.x
                        self.down_cam.target_inbase.vector.y = responce.y
                        self.down_cam.target_inbase.vector.z = responce.z
                        self.down_cam.base2world()

                        self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                        self.robot.base2world()

                    self.get_logger().info(
                        f"Info:目标在世界坐标系中的位置: x: {self.robot.target_inworld.vector.x: .3f} y: {self.robot.target_inworld.vector.y: .3f} z: {self.robot.target_inworld.vector.z: .3f}")

                    pos_list.append([self.robot.target_inworld.vector.x,
                                    self.robot.target_inworld.vector.y, self.robot.target_inworld.vector.z])

                    if len(pos_list) >= 100:
                        break
                else:
                    if (times > 0):
                        times_none += 1
                        self.get_logger().info(f"第{times_none}次无目标")
                        if (times_none >= 50) & (len(pos_list) < 10):
                            flag_to_next = 1
                            self.get_logger().info(f"确认无目标，进行下一步")
                            break
            else:
                self.get_logger().info("无图像传入")

            image = False

        times += 1
        if flag_to_next == 0:
            x = y = z = 0
            for i in pos_list:
                x += i[0]
                y += i[1]
                z += i[2]
            x /= len(pos_list)
            y /= len(pos_list)
            z /= len(pos_list)

            self.robot.base2world()
            self.target["name"] = name
            self.target["x"] = x
            self.target["y"] = y
            self.target["z"] = z

            self.get_logger().info(
                f"目标位置: x : {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
            
            self.mttz(dy,dz)
            self.setz(z_target)
            self.get_logger().info(
                f"开始第{times}次搜查是否抓球成功")            
            self.search2(self, name, cam,dy,dz,z_target,times)
    
    def search4(self, name1, name2,dx,dy,dz,z_target,rz_target,times,distance):#1为圈，2为T插
       
        times_none = 0
        flag_to_next = 0
        
        T_cnt = 0
        while True:
            
            s = self.search(self, "scaffolding", "front")
            if s == 0:
                self.get_logger().info("======无目标======")
                self.led(0, 0)
                self.get_logger().info("======旋转寻找目标目标======")
                self.moverz(40)
                T_cnt += 1
            else :
                self.get_logger().info("======发现基架======")  
                self.target["y"] -= 0.50  
                self.mttz(dy,dz)
                self.setrz(rz_target)
                break
            if T_cnt > 10:
                self.get_logger().info("======未找到目标======")
                break
        
        """
        计算法线方向
        """
        # 解包坐标
        x1, y1, z1 = self.cam2robot(2, 4,"front")
        x2, y2, z2 = self.cam2robot(2, 4,"front")
        x3, y3, z3 = self.cam2robot(2, 4,"front")
            
            
        # 计算向量AC的分量
        a = x1 - x3
        b = y1 - y3
            
        # 计算向量模长的平方
        length_squared = a**2 + b**2
            
            
        # 计算u和v的可能值
        if  abs(b) >= 0.001:
            # 一般情况
            factor = distance * abs(b) / (length_squared ** 0.5)
            u1 = factor
            v1 = -a * u1 / b
                
            u2 = -factor
            v2 = -a * u2 / b
        else:
            # b为0的特殊情况（AC垂直于x轴）
            u1 = 0
            v1 = distance
                
            u2 = 0
            v2 = -distance
            
            # 计算点D的坐标
        d1 = (x2 + u1, y2 + v1, z3)
        d2 = (x2 + u2, y2 + v2, z3)
            
        real_d = min(d1, d2)    
             
        
              
    # 机械爪控制
    def pow(self, s):
        servo = ServoSet()
        servo.num = 0
        if s == 1:
            servo.angle = 0.35
            self.servo_control_pub.publish(servo)
        if s == 0:
            servo.angle = 0.92#推球，夹T插
            self.servo_control_pub.publish(servo)
        time.sleep(0.1)


    # 任务启动
    def start(self):
        time.sleep(5)
        #  载入当前目标值
        tpos = TargetPosDown()
        tpos.cs = 0
        self.start_pos.base.vector.x = tpos.pos.x = self.MotionController.pos.x
        self.start_pos.base.vector.y = tpos.pos.y = self.MotionController.pos.y
        tpos.pos.z = self.MotionController.pos.z
        self.start_pos.base.vector.z = 0.0
        self.start_pos.base.vector.rz = tpos.pos.rz = self.MotionController.pos.rz
        self.start_pos.base.vector.ry = self.start_pos.base.vector.rx = tpos.pos.rx = tpos.pos.ry =  0.0
        self.start_pos.base.extract()
        self.get_logger().info(f"载入当前世界坐标 x:{tpos.pos.x:.3f} y:{tpos.pos.y:.3f} z:{tpos.pos.z:.3f} rz:{tpos.pos.rz:.3f}")
        self.led(1,0)#绿灯
        time.sleep(3.0)
        self.led(0,1)#黄灯
        time.sleep(3.0)
        self.led(1,1)#红灯
        time.sleep(3.0)
        self.led(0,0)
        self.target_pos_down_pub.publish(tpos)
        # 机械爪加紧T插
        self.pow(0) 
        
        # 开启PID控制器
        pid = PidControllersState()
        pid.x = pid.y = pid.z = pid.rz = 1
        pid.rx = pid.ry = 0
        self.pid_controllers_set_pub.publish(pid)
        time.sleep(0.1)

    # 任务结束
    def end(self):
        # 关闭PID控制器
        pid = PidControllersState()
        pid.x = pid.y = pid.z = pid.rz = 0
        pid.rx = pid.ry = 0
        self.pid_controllers_set_pub.publish(pid)
        time.sleep(0.1)

    def run(self, task: dict):
        if task["name"] == "movexyz":
            self.movexyz(task["params"]["x"], task["params"]
                         ["y"], task["params"]["z"])

        elif task["name"] == "throw_golf":
            self.throw_golf(task["params"]["dy"],
                            task["params"]["depth"])
            
        elif task["name"] == "movexy":
            self.movexy(task["params"]["x"], task["params"]["y"])

            
        elif task["name"] == "movex":
            self.movex(task["params"]["x"])

        elif task["name"] == "movey":
            self.movey(task["params"]["y"])

        elif task["name"] == "movez":
            self.movez(task["params"]["z"])

        elif task["name"] == "moverz":
            self.moverz(task["params"]["rz"])

        elif task["name"] == "setz":
            self.setz(task["params"]["z"])

        elif task["name"] == "setrz":
            self.setrz(task["params"]["rz"])

        elif task["name"] == "search":
            self.search(task["params"]["name"], task["params"]["cam"])

        elif task["name"] == "mtty":
            self.mtty(task["params"]["y"], task["params"]["z"])
        elif task["name"] == "mttxf":
            self.mttxf(task["params"]["dx"],task["params"]["dy"])
        elif task["name"] == "mttz":
            self.mttz(task["params"]["y"], task["params"]["z"])
        elif task["name"] == "mttzxy":
            self.mttzxy(task["params"]["dz"], task["params"]["dx"], task["params"]["dy"])
        elif task["name"] == "setp":
            self.setp()

        elif task["name"] == "back":
            self.back()
            
        elif task["name"] == "backy":
            self.backy()
            
        elif task["name"] == "pow":
            self.pow(task["params"])
        
        elif task["name"] == "line":
            self.line(task["params"]["ys_dep"])

        elif task["name"] == "graball":
            self.graball(task["params"]["color"], task["params"]["depth"], task["params"]["timeout"],task["params"]["pr"],task["params"]["k"],task["params"]["step_time"])

        elif task["name"] == "thrball":
            self.thrball(task["params"]["pr"], task["params"]["timeout"],task["params"]["k"],task["params"]["step_time"])
        
        elif task["name"] == "pass_door":
            self.pass_door(task["params"]["num"])

        elif task["name"] == "mttpos":
            self.mttpos(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["rz"], task["params"]["dy"])
            
        elif task["name"] == "mttzpos_amend":
            self.mttzpos_amend(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["dy"])
        
        elif task["name"] == "mttpos_amend":
            self.mttpos_amend(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["rz"], task["params"]["dy"])
            
        elif task["name"] == "mttzpos_":
            self.mttzpos(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["dy"])
        
        elif task["name"] == "delay":
            self.delay(task["params"])

        elif task["name"] == "led":
            self.led(task["params"]["led0"],
                     task["params"]["led1"])

        elif task["name"] == "grab_golf":
            self.grab_golf(task["params"]["kind"],
                           task["params"]["dx"],
                           task["params"]["dy"],
                           task["params"]["down_depth"],
                           task["params"]["up_depth"])
        
        elif task["name"] == "put_t":
            self.put_t(task["params"]["num"],
                           task["params"]["dy"],
                           task["params"]["dz"])
        
        elif task["name"] == "strike_ball":
            self.strike_ball(task["params"]["num"])
        
        elif task["name"] == "strike_ball3":
            self.strike_ball3(task["params"]["num1"],
                       task["params"]["num2"],
                       task["params"]["num3"],)
        
        elif task["name"] == "line_qd":
            # 无参数，直接调用line_qd方法
            self.line_qd()
            
        elif task["name"] == "endfloat":
            # 无参数，直接调用line_qd方法
            self.endfloat()

        else:
            self.get_logger().info("Info:非法任务名:  " + task["name"])
    
    def pid_update(self, error):
        self.dt = self.dt + 1 if abs(error-self.previous_error) < 2 else 1
        p_value = self.pid_parameters.p * error
        self.i_error += error * self.dt
        i_value = self.pid_parameters.i * self.i_error
        d_value = self.pid_parameters.d * (error - self.previous_error) / self.dt
        self.previous_error = error
        output = p_value + i_value + d_value
        if output > self.pid_parameters.output_limit:
            output = self.pid_parameters.output_limit
        elif output < -self.pid_parameters.output_limit:
            output = -self.pid_parameters.output_limit
        return output
    

    def cam2robot(self, clas, timeout,cam):
        pos_list = []
        start_time = time.time()

        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # 检查超时
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                return 0.0, 0.0, 0.0
            if cam == "down":
                if self.yolov8_data_down.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.z != 0:
                    self.down_cam.target_inbase.vector.x = self.yolov8_data_down.targets[clas].tpos_inworld.x
                    self.down_cam.target_inbase.vector.y = self.yolov8_data_down.targets[clas].tpos_inworld.y
                    self.down_cam.target_inbase.vector.z = self.yolov8_data_down.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.down_cam.base2world()

                    t_x = self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                    t_z =  self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                    self.robot.base2world()
                    time.sleep(0.015)
                                    # 检查返回的坐标是否为 0
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if cam == "front":
                if self.yolov8_data_front.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.z != 0:
                    self.front_cam.target_inbase.vector.x = self.yolov8_data_front.targets[clas].tpos_inworld.x
                    self.front_cam.target_inbase.vector.y = self.yolov8_data_front.targets[clas].tpos_inworld.y
                    self.front_cam.target_inbase.vector.z = self.yolov8_data_front.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.front_cam.base2world()
                    t_x = self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                    t_z = self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                    self.robot.base2world()
                    time.sleep(0.015)
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")

            if len(pos_list) >= 80:
                break
        x = y = z = 0.0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)
        self.get_logger().info(
            f"目标在机器人坐标系下的位置: x : {x:.2f} y: {y:.2f} z: {z:.2f}")

        return x, y, z
    

    def cam2robot_fast(self, clas, timeout,cam):
        pos_list = []
        start_time = time.time()

        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # 检查超时
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                return 0.0, 0.0, 0.0
            if cam == "down":
                if self.yolov8_data_down.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.z != 0:
                    self.down_cam.target_inbase.vector.x = self.yolov8_data_down.targets[clas].tpos_inworld.x
                    self.down_cam.target_inbase.vector.y = self.yolov8_data_down.targets[clas].tpos_inworld.y
                    self.down_cam.target_inbase.vector.z = self.yolov8_data_down.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.down_cam.base2world()

                    t_x = self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                    t_z =  self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                    self.robot.base2world()
                                    # 检查返回的坐标是否为 0
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if cam == "front":
                if self.yolov8_data_front.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.z != 0:
                    self.front_cam.target_inbase.vector.x = self.yolov8_data_front.targets[clas].tpos_inworld.x
                    self.front_cam.target_inbase.vector.y = self.yolov8_data_front.targets[clas].tpos_inworld.y
                    self.front_cam.target_inbase.vector.z = self.yolov8_data_front.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.front_cam.base2world()
                    t_x = self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                    t_z = self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                    self.robot.base2world()
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if len(pos_list) >= 50:
                break
        x = y = z = 0.0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)
        self.get_logger().info(
            f"目标在机器人坐标系下的位置: x : {x:.2f} y: {y:.2f} z: {z:.2f}")

        return x, y, z
    
    #抓球 pr为百分比距离
    def graball(self,color,depth,timeout,pr,k,step_time):
        led = LedControllers()
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                break
            if all(x==0 for x in self.yolov8_data_down.state):
                self.led(0,0)
                self.get_logger().info(
                f"没有找到任何物体")
            elif self.yolov8_data_down.state[5] == 1 and self.yolov8_data_down.state[4] == 1: #5是黄色，4是pink
                self.led(1,0)
                self.get_logger().info(
                f"发现高尔夫球")
                if color == "pink":
                    a, b, c = self.cam2robot(4, 5,"down")
                    self.movex(a)
                    self.movey(b-0.175)
                    self.movez(depth)
                    self.movez(-depth)
                    break
                elif color == "yellow":
                    a, b, c = self.cam2robot(5, 5,"down")
                    self.movex(a)
                    self.movey(b-0.175)
                    self.movez(depth)
                    self.movez(-depth)
                    break
            elif self.yolov8_data_down.state[6] == 1:
                led.led0 = 0
                led.led1 = 1
                r = sqrt((self.yolov8_data_down.targets[6].tpos_inpic.y -  480)**2 + (self.yolov8_data_down.targets[6].tpos_inpic.x -  640)**2)/sqrt(480**2+640**2)
                a, b, c = self.cam2robot_fast(6, 5,"down")
                if r >= pr:
                    self.led_controllers_pub.publish(led)
                    self.get_logger().info(
                    f"只发现陈列框")
                    vx = k*a
                    vy = k*b
                    if abs(vx) < 0.01:
                        vx = 0.01 if vx >= 0 else -0.01
                    if abs(vy) < 0.01:
                        vy = 0.01 if vy >= 0 else -0.01
                    if abs(vx) > 0.04:
                        vx = 0.04 if vx >= 0 else -0.04
                    if abs(vy) > 0.04:
                        vy = 0.04 if vy >= 0 else -0.04
                    self.fast_movex(vx)
                    self.fast_movey(vy)
                    time.sleep(step_time)
                else:
                    self.get_logger().info(
                    f"陈列框已经进入视野中心")
            else:
                self.led(1,1)
                self.get_logger().info(
                f"检测到非必要物体")       
        self.led(0,0)
    #投球
    def thrball(self,pr,timeout,k,step_time):
        led = LedControllers()
        bridge = CvBridge()
        img = bridge.imgmsg_to_cv2(self.down_cam_Image_data,"bgr8")
        row_index = img.shape[0] // 2
        column_index = img.shape[1] // 4
        self.get_logger().info(f"row: {row_index} , column: {column_index}")
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                break
            if all(x==0 for x in self.yolov8_data_down.state):
                led.led0 = 0
                led.led1 = 0
                self.led_controllers_pub.publish(led)
                self.get_logger().info(
                f"没有找到任何物体")
            elif self.yolov8_data_down.state[5] == 1:
                r = sqrt((self.yolov8_data_down.targets[5].tpos_inpic.y -  row_index)**2 + (self.yolov8_data_down.targets[5].tpos_inpic.x -  column_index)**2)/sqrt(480**2+640**2)
                led.led0 = 1
                led.led1 = 0
                a, b, c = self.cam2robot_fast(5, 5,"down")
                if r >= pr:
                    self.led_controllers_pub.publish(led)
                    self.get_logger().info(
                                            f"发现收集框")
                    vx = k*a
                    vy = k*b
                    if abs(vx) < 0.01:
                        vx = 0.01 if vx >= 0 else -0.01
                    if abs(vy) < 0.01:
                        vy = 0.01 if vy >= 0 else -0.01
                    if abs(vx) > 0.04:
                        vx = 0.04 if vx >= 0 else -0.04
                    if abs(vy) > 0.04:
                        vy = 0.04 if vy >= 0 else -0.04
                    self.fast_movex(vx)
                    self.fast_movey(vy)
                    time.sleep(step_time)
                else:
                    self.get_logger().info(f"收集框已进入视野中心")
                    break
            else:
                led.led0 = 1
                led.led1 = 1
                self.led_controllers_pub.publish(led)
                self.get_logger().info(
                f"检测到非必要物体")
        a, b, c = self.cam2robot(5, 5,"down")
        led.led0 = 1
        led.led1 = 0
        self.led_controllers_pub.publish(led)
        self.movex(a)
        self.movey(b-0.175)   
        self.pow(0) 
        time.sleep(1)      
        led.led0 = 0
        led.led1 = 0
        self.led_controllers_pub.publish(led)

    def pass_door(self,num):
        self.setz(0.5)
        #self.setrz(0)
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= 30:
                self.get_logger().info("超时,采用planB")
                self.movey(1.0)
                break
            if self.yolov8_data_front.state[num] == 1:
                self.get_logger().info(f"检测到资格门")
                time.sleep(2)
                a, b, c = self.cam2robot_fast(num, 5,"front")
                b = b 
                rz = atan2(b, a)*RAD2DEG - 90
                self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
                self.moverz(rz)
                cnt = 0
                cnt2 = 0
                cnt3 = 0
                cnt4 = 0
                cmd = TargetPosDown()
                cmd.cs = 2
                cmd.pos.rx = 0.0
                cmd.pos.ry = 0.0
                cmd.pos.x = 0.0
                cmd.pos.y = 0.01
                cmd.pos.z = 0.0
                cmd.pos.rz = 0.0
                time.sleep(0.5)
                while True:
                    cnt+=1
                    if self.yolov8_data_front.state[num] == 0 or cnt > 300:
                        cnt4 += 1
                        time.sleep(0.1)
                        if self.yolov8_data_front.state[num] == 0 or cnt > 300:
                            cnt4 += 1#0.1秒后再进行一次检测
                    if cnt4 > 20 or cnt > 300:    
                        while True:
                            cnt3+=1
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(0.08)
                            if cnt3 > 60 :
                                break              
                        break
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(0.1)
                break

        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        time.sleep(1.0)
        if num == 5:#红，顺时针
            self.get_logger().info("开始旋转")
            cmd.pos.rz = 0.55
            while True:
                cnt2+=1
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.025)
                if cnt2 > 680:
                    break
            
        elif num == 11:#蓝
            self.get_logger().info("开始旋转")
            cmd.pos.rz = -0.55
            while True:
                cnt2+=1
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.025)
                if cnt2 > 680:
                    break
        #self.movey(0.5)
        time.sleep(1.5)
        self.movey(0.5)
        self.get_logger().info(f"过门任务完成")

    def led(self, led0, led1):
        led = LedControllers()
        led.led0 = led0
        led.led1 = led1
        self.led_controllers_pub.publish(led)
    
    def delay(self, t):
        time.sleep(t)
    
    def grab_golf(self, kind, dx, dy, down_depth, up_depth):
        
        num = 0
        
        if kind == "blue_golf":
            num = 4
        if kind == "red_golf":
            num = 3

        
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.1
        
        sample_flag = 0
        golf_cnt = 0
        
        self.pow(1)
        self.led(0, 0)
        s = 1
        while True:
            if all(x == 0 for x in self.yolov8_data_front.state) and \
               all(y == 0 for y in self.yolov8_data_down.state):
                # pass
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                golf_cnt+=1
                
            else:
                if self.yolov8_data_front.state[6]!= 0 :
                    self.get_logger().info("前视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"front")
                    a = a + 0.1
                    b = b - 0.1                    
                    self.movex(a)
                    self.movey(b)
                    self.setz(0.2)
                    time.sleep(2)
                    break
                elif self.yolov8_data_down.state[6]!= 0 :
                    self.get_logger().info("下视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"down")
                    a = a + 0.1
                    b = b - 0.1                      
                    self.movex(a)
                    self.movey(b)
                    self.setz(0.2)
                    time.sleep(2)
                    break
                else:
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(0.01)
                    golf_cnt+=1 
            if  golf_cnt>4000 :
                self.get_logger().info("任务失败")
                self.get_logger().info("======上浮======")
                self.setz(-0.5)
                return
                     
        '''s = self.search(kind, "down")
        if s == 0:
            self.get_logger().info("======下无目标======")
            self.get_logger().info("======第一次平移寻找目标目标======")
            self.movex(0.2)
            self.movey(0.2)
            s = self.search( kind, "down")
            if s == 0:
                self.get_logger().info("======下无目标======")
                self.get_logger().info("======第二次平移寻找目标目标======")
                self.movey(-0.4)
                s = self.search( kind, "down")
                if s == 0:
                    self.get_logger().info("======下无目标======")
                    self.get_logger().info("======第三次平移寻找目标目标======")
                    self.movex(-0.4)
                    s = self.search( kind, "down")
                    if s == 0:
                        self.get_logger().info("======下无目标======")
                        self.get_logger().info("======第四次平移寻找目标目标======")
                        self.movey(0.4)
                        s = self.search(kind, "down")
                        if s == 0:
                            self.get_logger().info("======下无目标======")
                            self.get_logger().info("======任务失败======")
                            return
        if s != 0 :
            self.get_logger().info("======发现球======")  
            self.get_logger().info("======正在移向球======")   
            self.mttxf(0,0) '''
        golf_cnt = 0
        while True: 
            if all(x == 0 for x in self.yolov8_data_front.state) and \
               all(y == 0 for y in self.yolov8_data_down.state):
                golf_cnt+=1
                time.sleep(0.01)
                if golf_cnt>2000:
                    self.get_logger().info("======确认无目标======")
                    self.get_logger().info("======上浮======")
                    self.setz(-0.5)
                    time.sleep(5.0)
                    self.get_logger().info("=====上浮结束======")
                    return                  
            elif self.yolov8_data_down.state[num] !=0:
                self.get_logger().info("======发现目标球=====")
                a, b, c = self.cam2robot(num, 5,"down")
                a = a - dx
                b = b - dy 
                self.movex(a)
                self.movey(b)

                self.delay(1)
                self.led(1, 0)
                self.movez(down_depth)
                self.get_logger().info("=====抓球结束，开始上浮======")
                self.setz(0.15)
                time.sleep(8.0)
                self.led(0, 0)
                if self.yolov8_data_down.state[6]!= 0 :
                    self.get_logger().info("下视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"down")
                    a = a + 0.1
                    b = b - 0.1                      
                    self.movex(a)
                    self.movey(b)
                    time.sleep(2)
                    break
                self.setz(-0.5)
                time.sleep(8.0)
                self.get_logger().info("=====上浮结束======")
                return
            else:
                golf_cnt+=1
                time.sleep(0.01)
                if golf_cnt>2000:
                    self.get_logger().info("======确认无目标======")
                    self.get_logger().info("======上浮======")
                    self.setz(-0.5)
                    time.sleep(5)
                    self.get_logger().info("=====上浮结束======")
                    return  
    
    
    def put_t(self, num,dy,dz):
        T_cnt = 0
        T_cnt2 = 0
        T_cnt3 = 0
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.01

        while True:
            if self.yolov8_data_front.state[num] == 0: 
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.001)
                T_cnt+=1
                

            elif  self.yolov8_data_front.state[num] != 0:
                time.sleep(2)
                T_cnt = 0
                self.get_logger().info("发现目标")
                a, b, c = self.cam2robot(num, 5,"front")
                a=a-dy
                c=c-dz
                self.movex(a)
                self.movez(c)
                time.sleep(1)
                cmd.pos.rz = 0.0
                while True:
                    T_cnt2+=1
                    if self.yolov8_data_front.state[num] != 0 and T_cnt2 % 600 == 0: 
                        time.sleep(2)
                        a, b, c = self.cam2robot(num, 5,"front")
                        a=a-dy
                        c=c-dz
                        if (abs(a) > 0.03 or abs(c) > 0.03) and b > 0.25:
                            self.get_logger().info("======目标偏移======")
                            cmd.pos.x = float(a)
                            cmd.pos.z = float(c)
                            cmd.pos.y = 0.0
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(2)
                        else:
                            cmd.pos.y = 0.001
                            cmd.pos.x = 0.0
                            cmd.pos.z = 0.0
                            self.target_pos_down_pub.publish(cmd)
                            self.get_logger().info("======正在前进======")
                            T_cnt+=1
                            time.sleep(0.01)

                    else:
                        cmd.pos.y = 0.001
                        cmd.pos.x = 0.0
                        cmd.pos.z = 0.0
                        self.target_pos_down_pub.publish(cmd)
                        T_cnt+=1
                        time.sleep(0.01)
                    if T_cnt > 1000*(b+0.7):
                            self.pow(1)
                            self.get_logger().info("======任务完成======")
                            return
            if T_cnt>4000:
                self.get_logger().info("======未发现目标 任务失败======")            
                
    def endfloat(self):
   
        num = 5
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.2
        plate_cnt = 0
        while True:
            if self.yolov8_data_front.state[num] ==0 and \
               self.yolov8_data_down.state[num] ==0 :
                # pass
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                golf_cnt+=1
                
            else:
                if self.yolov8_data_front.state[num] ==1:
                    self.get_logger().info("前视发现目标")
                    time.sleep(2)
                    a, b, c = self.cam2robot(num, 5,"front")
                    a = a - 0.3
                    b = b - 0.5                    
                    self.movex(a)
                    self.movey(b)
                    time.sleep(1)
                    self.setz(-0.1)
                    self.get_logger().info("任务成功")
                    break
                else:
                    self.get_logger().info("下视发现目标")
                    a, b, c = self.cam2robot(num, 5,"down")
                    a = a - 0.3
                    b = b - 0.5                    
                    self.movex(a)
                    self.movey(b)
                    time.sleep(1)
                    self.setz(-0.1)
                    self.get_logger().info("任务成功")
                    break
            if  plate_cnt>2000 :
                self.get_logger().info("任务失败")
                return


    def throw_golf(self, dy, depth):
        self.get_logger().info("======开始投球======")
        self.led(0, 1)
        self.search('col_basket', 'down')
        self.led(1, 1)
        self.mttxf(0, dy)
        self.movez(depth)
        self.led(1, 0)
        self.pow(0)
        self.delay(1)
        self.led(0, 0)
        self.get_logger().info("======投球结束======")
        
    def strike_ball(self,num):
        
        ball_cnt = 0
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.05

        while True:
            if self.yolov8_data_front.state[num] == 0: 
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                ball_cnt+=1
            elif  self.yolov8_data_front.state[num] != 0:
                time.sleep(2)
                ball_cnt = 0
                self.get_logger().info("发现目标")
                a, b, c = self.cam2robot(num, 5,"front")
                #a = a 
                c = c - 0.32
                b = b - 0.2
                self.fast_movez(c)
                time.sleep(1)
                self.movexy(a,b)
                time.sleep(1)
                self.get_logger().info("======任务完成 正在返回======")
                self.fast_movey(-b)
                self.move_wait()
                time.sleep(4)
                self.get_logger().info("======返回完成======")
                               
                return
            if ball_cnt>75000:
                self.get_logger().info("======未发现目标 任务失败======")
                return
                
    def strike_ball3(self,num1,num2,num3):
        self.get_logger().info("======撞球任务开始======")
        #self.setp()
        self.get_logger().info("======撞第一个球======")
        self.strike_ball(num1)
        #self.fast_moverz(180.0)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        #time.sleep(4)
        self.get_logger().info("======撞第二个球======")
        self.strike_ball(num2)
        #self.fast_moverz(180.0)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        #time.sleep(4)
        self.get_logger().info("======撞第三个球======")
        self.strike_ball(num3)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        
    def line_qd(self):
        
            
        self.led(0,0)
        
        self.pid_parameters.p = 0.0009
        self.pid_parameters.i = 0.0
        self.pid_parameters.d = 0.08
        self.pid_parameters.output_limit = 5.0

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        drz = 0.0

        timesleep = 0.025
        
        self.task_lock = [0,0,0]
        
        magnet = MagnetController()
        led = LedControllers()
        bridge = CvBridge()
    
        window_size = 3  # 滑动窗口的大小
        last_positions = []  # 使用列表来存储最近的位置
        cnt = 0
        cnt_1 = 0
        #等待准备就绪
        time.sleep(1.0)
        while True:
            #try:
            # 转化为opencv图像
            img1 = bridge.imgmsg_to_cv2(self.down_cam_Image_data, "mono8")
            img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
            if img is None:
                self.get_logger().error("bridge.imgmsg_to_cv2 returned None")
                return
            img = cv2.flip(img, -1)

            row_index = img.shape[0] // 3
            row_index1 = img.shape[0] // 2
            column_index = img.shape[1] // 2
            row = img[row_index, :]
            white_pixels = np.where(row == 255)[0]

            # 计算白点的平均位置作为线的中心
            if white_pixels.size > 0:
                line_center = np.mean(white_pixels).astype(int)
                last_positions.append(line_center)
                if len(last_positions) > window_size:  # 如果列表长度超过窗口大小，删除最旧的元素
                    last_positions.pop(0)
            else:
                if last_positions:
                    line_center = last_positions[-1]  # 如果没有检测到新的，则使用上一个

            # 计算滑动平均
            if len(last_positions) > 1:
                smoothed_center = int(np.mean(last_positions))
                cv2.circle(img, (smoothed_center, row_index), 10, (0, 0, 0), -1)  # 标记平滑后的中心点
            else:
                smoothed_center = img.shape[1] // 2
                cv2.circle(img, (smoothed_center, row_index), 10, (0, 0, 0), -1)

            # 在图像上添加文字
            cv2.putText(img, "output: {:.2f}".format(drz), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)

            img_msg = bridge.cv2_to_imgmsg(img, "mono8")
            self.line_patrol_img_pub.publish(img_msg)

            angle_error = smoothed_center - column_index
            drz = self.pid_update(angle_error)

            if all(x==0 for x in self.yolov8_data_down.state):
                # pass
                cmd.pos.x = 0.0
                cmd.pos.y = 0.002
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt_1 += 1
                
            elif not all(x==0 for x in self.yolov8_data_down.state):
                if  self.yolov8_data_down.state[0] != 0 and  self.yolov8_data_down.targets[0].tpos_inpic.y > row_index1 :
                    if self.task_lock[0] == 0 :
                        self.get_logger().info("Info:检测A，开始执行任务") 
                        #self.setp()
                        #a, b, c = self.cam2robot(1, 5,"down")
                        #self.movex(a)
                        #self.movey(b)
                    
                        # 保存任务结束时的图片
                        task1_end_img_path = f"A.png"
                        cv2.imwrite(task1_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task1_end_img_path}")

                        self.get_logger().info("Info:任务执行完毕")
                        #self.back()
                        self.task_lock[0] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[1] != 0 and self.yolov8_data_down.targets[1].tpos_inpic.y > row_index1:
                    if self.task_lock[1] == 0 :
                        self.get_logger().info("Info:检测B，开始执行任务")
                        #self.setp()
                        #a, b, c = self.cam2robot(2, 4,"down")
                        #self.movex(a)
                        #self.movey(b)
                        
                        # 保存任务结束时的图片
                        task2_end_img_path = f"B.png"
                        cv2.imwrite(task2_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task2_end_img_path}")

                        #self.back()
                        self.get_logger().info("Info:任务执行完毕")
                        self.task_lock[1] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[2] != 0 and self.yolov8_data_down.targets[2].tpos_inpic.y > row_index1:
                    if self.task_lock[2] == 0 :
                        self.get_logger().info("Info:检测C，开始执行任务") 
                        #self.setp()
                        #a, b, c = self.cam2robot(0, 4,"down")
                        #self.movex(a)
                       # self.movey(b)
                        # 保存任务结束时的图片
                        task3_end_img_path = f"C.png"
                        cv2.imwrite(task3_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task3_end_img_path}")

                        self.get_logger().info("Info:任务执行完毕")
                        self.task_lock[2] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)

                else:
                    #pass
                    cmd.pos.x = 0.0
                    cmd.pos.y = 0.002
                    cmd.pos.z = 0.0
                    cmd.pos.rz = drz
                    self.target_pos_down_pub.publish(cmd)
                    cnt_1 += 1
                    time.sleep(timesleep)
            if cnt_1 > 1200:
                self.get_logger().info("Info:任务全部执行完毕")
                return
            if all(x == 1 for x in self.task_lock):
                cmd.pos.x = 0.0
                cmd.pos.y = 0.004
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt+=1
                if cnt > 200:
                    self.get_logger().info("Info:任务全部执行完毕")
                    return

          
    #巡线
    def line(self, ys_dep):
        self.led(0, 0)
        
        self.pid_parameters.p = 0.0009
        self.pid_parameters.i = 0.0
        self.pid_parameters.d = 0.08
        self.pid_parameters.output_limit = 5.0

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        drz = 0.0
        depth = ys_dep
        timesleep = 0.025
        
        self.task_lock = [0, 0, 0]
        
        magnet = MagnetController()
        bridge = CvBridge()
        
        # 初始化1D卡尔曼滤波器（仅跟踪位置）
        kf = KalmanFilter(dim_x=1, dim_z=1)
        kf.x = np.array([320.])  # 初始位置（图像中心附近）
        kf.F = np.array([[1.]])  # 状态转移矩阵（简单恒速模型）
        kf.H = np.array([[1.]])  # 观测矩阵
        kf.P *= 100.  # 初始协方差
        kf.R = 3.0    # 观测噪声
        kf.Q = np.array([[1.0]])  # 过程噪声
        
        # 图像状态跟踪变量
        last_valid_image_time = None
        has_valid_image = False
        last_filtered_center = 320  # 初始中心位置
        img_shape = (480, 640)  # 预设图像尺寸，根据实际情况调整
        row_index = img_shape[0] // 3  # 预设行索引
        row_index1 = img_shape[0] // 2  # 预设任务检测行索引
        column_index = img_shape[1] // 2  # 预设列中心
        
        # 新增：图像初始化等待机制
        init_wait_time = 0.1  # 初始化等待0.1秒
        start_time = time.time()
        self.get_logger().info(f"等待图像初始化，最多等待{init_wait_time}秒...")
        
        # 等待图像或超时
        while not has_valid_image and (time.time() - start_time) < init_wait_time:
            try:
                if self.segment_img is not None:
                    img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
                    img_shape = img.shape
                    row_index = img_shape[0] // 3
                    row_index1 = img_shape[0] // 2
                    column_index = img_shape[1] // 2
                    has_valid_image = True
                    last_valid_image_time = time.time()
                    self.get_logger().info("成功获取初始图像")
            except Exception as e:
                self.get_logger().debug(f"初始化阶段图像获取失败: {str(e)}")
            time.sleep(0.1)  # 短时间等待后重试
        
        if not has_valid_image:
            self.get_logger().warn(f"初始化超时，未获取到图像，将使用默认参数运行")
            
        cnt = 0
        cnt_1 = 0
        while True:
            cnt_1 = cnt_1 + 1
            if cnt_1 > 2000:
                self.get_logger().warn(f"时间结束自动退出")
                return
                
            # 尝试获取和处理图像
            try:
                if self.segment_img is not None:
                    img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
                    img = cv2.flip(img, -1)
                    img_shape = img.shape
                    row_index = img_shape[0] // 3
                    row_index1 = img_shape[0] // 2
                    column_index = img_shape[1] // 2
                    last_valid_image_time = time.time()
                    has_valid_image = True
                    
                    # 处理图像获取线中心
                    row = img[row_index, :]
                    white_pixels = np.where(row == 255)[0]

                    # 卡尔曼滤波处理
                    kf.predict()
                    
                    # 有观测值时更新
                    if white_pixels.size > 0:
                        line_center = np.mean(white_pixels).astype(int)
                        kf.update(line_center)
                    
                    # 使用滤波后的值
                    filtered_center = int(kf.x[0])
                    last_filtered_center = filtered_center
                    
                    # 绘制标记并发布图像
                    cv2.circle(img, (filtered_center, row_index), 10, (0, 0, 0), -1)
                    cv2.putText(img, "output: {:.2f}".format(drz), (50, 50), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)
                    img_msg = bridge.cv2_to_imgmsg(img, "mono8")
                    self.line_patrol_img_pub.publish(img_msg)
                    

                        
            except Exception as e:
                # 图像处理失败时的处理
                self.get_logger().warn(f"无分割图像: {str(e)}")
                
                # 仅使用预测
                kf.predict()
                filtered_center = int(kf.x[0])
                last_filtered_center = filtered_center
                
                # 状态判断与警示
                if not has_valid_image:
                    self.get_logger().warn("持续未接收到图像，使用默认控制策略")
                elif (time.time() - last_valid_image_time) > 1.0:
                    self.get_logger().warn("图像已丢失超过1秒，使用预测值控制")
    
            
            # 计算控制量
            angle_error = filtered_center - column_index
            # 无图像时减小控制增益，采用更保守的控制
            if not has_valid_image:
                drz = self.pid_update(angle_error) * 0.5  # 降低控制强度
                dy = 0.004  # 降低前进速度
            else:
                drz = self.pid_update(angle_error)
                dy = 0.005 - 0.0004 * abs(drz)
            
            # 控制逻辑
            if all(x == 0 for x in self.yolov8_data_down.state):
                cmd.pos.x = 0.0
                cmd.pos.y = dy
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                
            elif not all(x == 0 for x in self.yolov8_data_down.state):
                if self.yolov8_data_down.state[1] != 0 and self.yolov8_data_down.targets[1].tpos_inpic.y > row_index1:
                        if self.task_lock[0] == 0:
                            self.get_logger().info("检测到黑色方块，开始执行任务")
                            time.sleep(2)
                            magnet.state = 0
                            self.magnet_controller_pub.publish(magnet)
                            self.led(1, 1)
                            time.sleep(1)
                            self.get_logger().info("任务执行完毕")
                            self.task_lock[0] = 1
                        else:
                            cmd.pos.x = 0.0
                            cmd.pos.y = dy
                            cmd.pos.z = 0.0
                            cmd.pos.rz = drz
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(timesleep)
                elif self.yolov8_data_down.state[2] != 0 and self.yolov8_data_down.targets[2].tpos_inpic.y > row_index1:
                    if self.task_lock[1] == 0:
                        self.get_logger().info("检测到绿色圆形，开始执行任务")
                        time.sleep(2)
                        a, b, c = self.cam2robot(2, 4, "down")
                        b = b - 0.4
                        self.movex(a)
                        self.movey(b)
                        self.movez(depth)
                        self.led(1,0)
                        self.movez(-depth)
                        self.led(0,0)
                        self.get_logger().info("任务执行完毕")
                        self.task_lock[1] = 1
                    else:
                        cmd.pos.x = 0.0
                        cmd.pos.y = dy
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[0] != 0 and self.yolov8_data_down.targets[0].tpos_inpic.y > row_index1:
                    if self.task_lock[2] == 0:
                        self.get_logger().info("检测到黄色三角，开始执行任务")
                        time.sleep(2)
                        self.moverz(179.9)
                        time.sleep(1)
                        self.moverz(179.9)
                        time.sleep(1)
                        self.get_logger().info("任务执行完毕")
                        self.task_lock[2] = 1
                    else:
                        cmd.pos.x = 0.0
                        cmd.pos.y = dy
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        time.sleep(timesleep)
                else:
                    cmd.pos.x = 0.0
                    cmd.pos.y = dy
                    cmd.pos.z = 0.0
                    cmd.pos.rz = drz
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(timesleep)
                    
            if all(x == 1 for x in self.task_lock):
                cmd.pos.x = 0.0
                cmd.pos.y = dy
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt += 1
                if cnt > 190:
                    return
    

            # except Exception as e:
            #     self.get_logger().error(f"图像处理过程中出现错误 {e}")
            #     break
                # except Exception as e:
                #     self.get_logger().error(f"图像处理过程中出现错误 {e}")
                #     break
 


# 从命令行获取任务
def get_act():
    command = input("请输入任务: \n")
    parts = command.split()
    if parts[0] == 'movexyz':
        args = parts[1:]
        if len(args) == 3:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dic = {
                "name": "movexyz",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'throw_golf':
        args = parts[1:]
        if len(args) == 2:
            dy = float(args[0])
            depth = float(args[1])
            dic = {
                "name": "throw_golf",
                "params": {
                    "dy": dy,
                    "depth": depth,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'movexy':
        args = parts[1:]
        if len(args) == 2:
            x = float(args[0])
            y = float(args[1])
            dic = {
                "name": "movexy",
                "params": {
                    "x": x,
                    "y": y,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movex':
        args = parts[1:]
        if len(args) == 1:
            x = float(args[0])
            dic = {
                "name": "movex",
                "params": {
                    "x": x,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movey':
        args = parts[1:]
        if len(args) == 1:
            y = float(args[0])
            dic = {
                "name": "movey",
                "params": {
                    "y": y,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movez':
        args = parts[1:]
        if len(args) == 1:
            z = float(args[0])
            dic = {
                "name": "movez",
                "params": {
                    "z": z,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'moverz':
        args = parts[1:]
        if len(args) == 1:
            rz = float(args[0])
            dic = {
                "name": "moverz",
                "params": {
                    "rz": rz,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'setz':
        args = parts[1:]
        if len(args) == 1:
            z = float(args[0])
            dic = {
                "name": "setz",
                "params": {
                    "z": z,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'setrz':
        args = parts[1:]
        if len(args) == 1:
            rz = float(args[0])
            dic = {
                "name": "setrz",
                "params": {
                    "rz": rz,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'pow':
        args = parts[1:]
        if len(args) == 1:
            a = int(args[0])
            dic = {
                "name": "pow",
                "params": a
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mtty':
        args = parts[1:]
        if len(args) == 2:
            y = float(args[0])
            z = float(args[1])
            dic = {
                "name": "mtty",
                "params": {
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttxf':
        args = parts[1:]
        if len(args) == 2:
            dx = float(args[0])
            dy = float(args[1])
            dic = {
                "name": "mttxf",
                "params": {
                    "dx": dx,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttz':
        args = parts[1:]
        if len(args) == 2:
            y = float(args[0])
            z = float(args[1])
            dic = {
                "name": "mttz",
                "params": {
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttzxy':
        args = parts[1:]
        if len(args) == 3:
            dz = float(args[0])
            dx = float(args[1])
            dy = float(args[2])
            dic = {
                "name": "mttzxy",
                "params": {
                    "dz": dz,
                    "dx": dx,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
    elif parts[0] == 'setp':
        if len(parts) == 1:
            dic = {
                "name": "setp",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'back':
        if len(parts) == 1:
            dic = {
                "name": "back",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'backy':
        if len(parts) == 1:
            dic = {
                "name": "backy",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'search':
        args = parts[1:]
        if len(args) == 2:
            name = args[0]
            cam = args[1]
            dic = {
                "name": "search",
                "params": {
                    "name": name,
                    "cam": cam
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'line':
        args = parts[1:]
        if len(args) == 1:
            ys_dep = float(args[0])
            dic = {
                "name": "line",
                "params": {
                    "ys_dep": ys_dep
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None 
        
    elif parts[0] == 'mttpos':
        args = parts[1:]
        if len(args) == 5:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            rz = float(args[3])
            dy = float(args[4])
            dic = {
                "name": "mttpos",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "rz": rz,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'mttzpos':
        args = parts[1:]
        if len(args) == 4:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dy = float(args[3])
            dic = {
                "name": "mttzpos",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'mttpos_amend':
        args = parts[1:]
        if len(args) == 5:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            rz = float(args[3])
            dy = float(args[4])
            dic = {
                "name": "mttpos_amend",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "rz": rz,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'mttzpos_amend':
        args = parts[1:]
        if len(args) == 4:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dy = float(args[3])
            dic = {
                "name": "mttzpos_amend",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'graball':
        args = parts[1:]
        if len(args) == 6:
            color       =   str(args[0])
            depth       =   float(args[1])
            timeout     =   float(args[2])
            pr          =   float(args[3])
            k           =   float(args[4])
            step_time   =   float(args[5])           
            dic = {
                "name": "graball",
                "params": {
                    "color": color,
                    "depth": depth,
                    "timeout": timeout,
                    "pr": pr,
                    "k" : k,
                    "step_time":step_time
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'thrball':
        args = parts[1:]
        if len(args) == 4:
            pr        =   float(args[0])
            timeout   =   float(args[1])
            k         =   float(args[2])
            step_time =   float(args[3])  
            dic = {
                "name": "thrball",
                "params": {
                    "pr": pr,
                    "timeout": timeout,
                    "k" : k,
                    "step_time":step_time
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None  
    elif parts[0] == 'pass_door':
        args = parts[1:]
        if len(args) == 1:
            num       =   int(args[0])
            dic = {
                "name": "pass_door",
                "params": {
                    "num":num
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'led':
        args = parts[1:]
        if len(args) == 2:
            led0 = int(args[0])
            led1 = int(args[1])
            dic = {
                "name": "led",
                "params": {
                    "led0": led0,
                    "led1": led1
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'delay':
        args = parts[1:]
        if len(args) == 1:
            t = float(args[0])
            dic = {
                "name": "delay",
                "params": t
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'grab_golf':
        args = parts[1:]
        if len(args) == 5:
            kind = str(args[0])
            dx = float(args[1])
            dy = float(args[2])
            down_depth = float(args[3])
            up_depth = float(args[4])
            dic = {
                "name": "grab_golf",
                "params": {
                    "kind": kind,
                    "dx": dx,
                    "dy": dy,
                    "down_depth": down_depth,
                    "up_depth": up_depth
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'line_qd':
        args = parts[1:]
        if len(args) == 0:
            dic = {
                "name": "line_qd",
                "params": {}  # 无参数时为空字典
            }
            return dic
        else:
            print("指令格式不正确，line_qd不需要参数")
            return None 
        
    elif parts[0] == 'endfloat':
        args = parts[1:]
        if len(args) == 0:
            dic = {
                "name": "endfloat",
                "params": {}  # 无参数时为空字典
            }
            return dic
        else:
            print("指令格式不正确，line_qd不需要参数")
            return None 
    
    elif parts[0] == 'put_t':
        args = parts[1:]
        if len(args) == 3:
            num = int(args[0])
            dy = float(args[1])
            dz = float(args[2])
            dic = {
                "name": "put_t",
                "params": {
                    "num": num,
                    "dy": dy,
                    "dz": dz
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'strike_ball':
        args = parts[1:]
        if len(args) == 1:
            num = int(args[0])
            dic = {
                "name": "strike_ball",
                "params": {
                    "num": num
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'strike_ball3':
        args = parts[1:]
        if len(args) == 3:
            num1 = int(args[0])
            num2 = int(args[1])
            num3 = int(args[2])
            dic = {
                "name": "strike_ball3",
                "params": {
                    "num1": num1,
                    "num2": num2,
                    "num3": num3
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    else:
        print("无效指令")
        return None
    
    


# 读取并从文件中加载任务队列
def load_actions(path):
    with open(path, 'r', encoding='utf-8') as f:
        dic = json.load(f)
    return dic

# 保存任务队列


def save_actions(dic, path):
    print("所保存的任务:\n"+str(dic)+"\n")
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(dic, f)

# 普通模式


def commom_loop(node, opt):
    list = load_actions(opt.data_path[0]+"uv_tasks.json")

    node.start()
    num = 0

    for act in list["tasks"]:
        node.get_logger().info(
            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
        node.run(act)
        node.get_logger().info(
            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
        num += 1
    
    node.end()

# 调试模式


def debug_loop(node: CoreNode, opt):
    node.get_logger().info("Info:进入调试模式")

    tasklist = load_actions(opt.data_path[0]+"uv_tasks.json")
     
    help_txt = ""
    with open(opt.data_path[0]+"help.txt", 'r', encoding='utf-8') as f:
        s = f.read()
        help_txt = s

    node.start()

    while True:
        node.get_logger().info(f"Info:等待指令输入")
        command = input("请输入调试指令: \n")
        parts = command.split()
        if parts[0] == 'help':
            print(help_txt)
        elif parts[0] == 'act':
            act = get_act()

            if act == None:
                node.get_logger().info(f"Warn:非法任务")
            else:
                node.get_logger().info(
                    f"Info:=========执行任务: " + act["name"] + "=========")
                node.run(act)
                node.get_logger().info(
                    f"Info:=========完成任务: " + act["name"] + "=========")
        elif parts[0] == "task":
            if parts[1] == "run":
                if len(parts[1:]) == 1:
                    num = 0
                    for act in tasklist["tasks"]:
                        node.get_logger().info(
                            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
                        node.run(act)
                        node.get_logger().info(
                            f"Info:=========完成第 {num:d} 步任务: " + act["name"] + "=========")
                        num += 1
                elif len(parts[1:]) == 2:
                    num = int(parts[parts.index('run') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        n = num
                        for act in tasklist["tasks"][num:]:
                            node.get_logger().info(
                                f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
                            node.run(act)
                            node.get_logger().info(
                                f"Info:=========完成第 {num:d} 步任务: " + act["name"] + "=========")
                            n += 1
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "runonly":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('runonly') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = tasklist["tasks"][num]
                        node.get_logger().info(
                            "Info:=========执行任务: " + act["name"] + "=========")
                        node.run(act)
                        node.get_logger().info(
                            "Info:=========完成任务: " + act["name"] + "=========")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "add":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('add') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = get_act()
                        if act == None:
                            node.get_logger().info("非法任务")
                        else:
                            tasklist["tasks"].insert(num, act)
                            save_actions(
                                tasklist, opt.data_path[0]+"uv_tasks.json")
                elif len(parts[1:]) == 1:
                    act = get_act()
                    if act == None:
                        node.get_logger().info("非法任务")
                    else:
                        tasklist["tasks"].append(act)
                        save_actions(
                            tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "del":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('del') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        tasklist["tasks"].pop(num)
                        save_actions(
                            tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "clear":
                tasklist["tasks"] = []
                save_actions(tasklist, opt.data_path[0]+"uv_tasks.json")
            elif parts[1] == "list":
                node.get_logger().info("Info: 打印任务列表")
                num = 0
                for i in tasklist["tasks"]:
                    print("编号:   " + str(num))
                    print("任务名: "+i["name"])
                    print("参数:   " + str(i["params"]))
                    num += 1
            elif parts[1] == "mod":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('mod') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = get_act()
                        if act == None:
                            node.get_logger().info("非法任务")
                        else:
                            tasklist["tasks"][num] = act
                            save_actions(
                                tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            else:
                node.get_logger().info("Warn:非法指令")


def main(args=None):

    # 加载参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--front-topic', nargs='+', type=str, default=[
                        'front_cam/rectified'], help='前视摄像头')
    parser.add_argument('--down-topic', nargs='+', type=str, default=[
                        'down_cam/rectified'], help='下视摄像头')
    parser.add_argument('--data-path', nargs='+', type=str, default=[
                        '/home/nvidia/Workspace/Cruise/datas/'], help='PID参数路径')
    parser.add_argument('--debug', nargs='+', type=bool,
                        default=False, help='PID参数路径')

    opt = parser.parse_args()

    rclpy.init(args=args)  # 初始化rclpy

    if opt.debug:
        node = CoreNode("uv_automaton_debug", opt)  # 新建一个节点
        thread_debug = threading.Thread(
            target=debug_loop, args=(node, opt))  # 创建调度线程
        thread_debug.start()
    else:
        node = CoreNode("uv_automaton", opt)  # 新建一个节点
        thread_common = threading.Thread(
            target=commom_loop, args=(node, opt))    # 创建调度线程
        thread_common.start()

    node.get_logger().info("节点与调度线程成功启动")

    rclpy.spin(node)  # 保持节点运行，检测是否收到退出指令（Ctrl+Z）
    rclpy.shutdown()  # 关闭rclpy

===== .\uv_ai\uv_ai\uv_automaton_legacy.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import time
import os
import termios
import struct
import threading
import json
import argparse
from uv_control_py import Pid
from uv_control_py.CoordinateSystem import CoordinateSystems, MotionState, Cs_Back, Cs_Move, AngleCorrect

from uv_msgs.msg import RobotDeviceManager  # 机器人设备管理器
from uv_msgs.msg import RobotMotionController  # 机器人运动控制器

from uv_msgs.msg import PidControllersState
from uv_msgs.msg import PidParams#巡线的pid参数

from uv_msgs.msg import RobotAxis
from uv_msgs.msg import ServoSet
from uv_msgs.msg import TargetPosDown
from uv_msgs.msg import Yolov8
from uv_msgs.msg import LedControllers
from uv_msgs.msg import MagnetController

from sensor_msgs.msg import Image
from uv_msgs.srv import DetectRequest
import cv2
import numpy as np
from cv_bridge import CvBridge
from filterpy.kalman import KalmanFilter


from math import sin, cos, atan2, sqrt

PI = 3.141592653589793
DEG2RAD = PI/180
RAD2DEG = 180/PI

Step = {  # 领航点拖曳速度(10hz)
    "x": 0.01,
    "y": 0.01,
    "z": 0.05,
    "rz": 5.0
}

AllowedError = {  # 位置容许误差
    "x": 0.02,
    "y": 0.02,
    "z": 0.02,
    "rz": 1.3
}


class CoreNode(Node):
    def __init__(self, name, opt):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)
        self.opt = opt

        self.robot = CoordinateSystems()

        self.MotionController = RobotMotionController()
        #pid参数初始化
        self.pid_parameters = PidParams()
        # self.pid_parameters.p = 0.0
        # self.pid_parameters.i = 0.0
        # self.pid_parameters.d = 0.0

        self.previous_error = 0.0
        self.i_error = 0.0
        self.dt = 1

        self.task_lock = True
        self.yolov8_data_down = Yolov8()
        self.yolov8_data_front = Yolov8()
        self.magnet = MagnetController()

        self.target = {
            "name": "none",
            "x": 0.0,
            "y": 0.0,
            "z": 0.0
        }

        self.backpoint = {
            "x": 0.0,
            "y": 0.0,
            "z": 0.0,
            "rz": 0.0
        }

        self.front_cam = CoordinateSystems()
        self.down_cam = CoordinateSystems()
        #前视相机坐标偏置
        self.front_cam.base.vector.x = 107.6/1000
        self.front_cam.base.vector.y = 320.0/1000
        self.front_cam.base.vector.z = 65.0/1000
        self.front_cam.base.vector.rx = -90.0
        self.front_cam.base.extract()
        #下视相机坐标偏置
        self.down_cam.base.vector.x = 0.0/1000
        self.down_cam.base.vector.y = 170.0/1000
        self.down_cam.base.vector.z = 42.7/1000
        self.down_cam.base.vector.rz = 0.0
        self.down_cam.base.extract()

        self.get_logger().info(
            f"前置摄像机偏置: x: {self.front_cam.base.vector.x:.2f} y: { self.front_cam.base.vector.y : .2f} z: {self.front_cam.base.vector.z : .2f}")
        self.get_logger().info(
            f"          : rx: {self.front_cam.base.vector.rx:.2f} ry: { self.front_cam.base.vector.ry : .2f} rz: {self.front_cam.base.vector.rz : .2f}")
        self.get_logger().info(
            f"下置摄像机偏置: x: {self.down_cam.base.vector.x:.2f} y: { self.down_cam.base.vector.y : .2f} z: {self.down_cam.base.vector.z : .2f}")
        self.get_logger().info(
            f"          : rx: {self.down_cam.base.vector.rx:.2f} ry: { self.down_cam.base.vector.ry : .2f} rz: {self.down_cam.base.vector.rz : .2f}")
        
        self.start_pos = CoordinateSystems()
        
        self.front_cam_Image_data = None
        self.down_cam_Image_data = None
        self.front_cam_left_Image_data = None
        self.segment_img = None

        # 话题发布
        # 创建话题发布 target_pos_down ，定义其中的消息类型为 TargetPosDown
        self.target_pos_down_pub = self.create_publisher(
            TargetPosDown, "target_pos_down", 10)
        # 创建话题发布 servo_control ，定义其中的消息类型为 ServoSet
        self.servo_control_pub = self.create_publisher(
            ServoSet, "servo_control", 10)
        #创建话题发布  led_controllers, 定义其中的消息类型为 LedControllers
        self.led_controllers_pub = self.create_publisher(
            LedControllers, 'led_controllers', 10)
        # 创建话题发布 magnet_controller ，定义其中的消息类型为 MagnetController
        self.magnet_controller_pub = self.create_publisher(
            MagnetController, "magnet_controller", 10)
        # 创建话题发布 pid_controllers_set ，定义其中的消息类型为 PidControllersState
        self.pid_controllers_set_pub = self.create_publisher(
            PidControllersState, 'pid_controllers_set', 10)
        #创建话题发布 line_patrol_img , 定义消息类型为Image
        self.line_patrol_img_pub = self.create_publisher(
            Image, 'line_patrol_img', 10)

        self.openthrust_data_pub = self.create_publisher(
            RobotAxis, 'openloop_thrust', 10)

        # 话题接收
        # 创建话题接收 motion_controller ，定义其中的消息类型为 RobotMotionController
        self.create_subscription(
            RobotMotionController, 'motion_controller', self.motion_controller_callback, 10)
        # 创建话题接收 front_cam/rectified ，定义其中的消息类型为 Image
        self.create_subscription(
            Image, opt.front_topic[0], self.front_cam_callback, 10)
        # 创建话题接收 down_cam/rectified ，定义其中的消息类型为 Image
        self.create_subscription(
            Image, opt.down_topic[0], self.down_cam_callback, 10)
        #创建话题接收 front_cam/rectified/left,定义其中的消息类型为 Image
        self.create_subscription(
            Image, 'front_cam/rectified/left', self.front_cam_left_callback, 10)
        self.create_subscription(
            PidParams, 'track_pid_parameter', self.track_pid_parameter_callback, 10)
        # 创建话题接收 uv_detect ，定义其中的消息类型为 Yolov8
        self.create_subscription(
            Yolov8, 'uv_detect_down', self.yolov8_down_callback, 10)
        
        self.create_subscription(
            Yolov8, 'uv_detect_front', self.yolov8_front_callback, 10)
        
        #创建话题接收 binary_segment_img , 定义消息类型为Image，用于接收二值化后的分割结果
        self.create_subscription(
            Image, 'binary_segment_img', self.segment_img_callback, 10)

        # 服务请求
        # 创建服务请求 detect_request_client ，定义其中的消息类型为 RobotAxis , 请求服务 uv_detect_srv
        self.detect_request_client = self.create_client(
            DetectRequest, "uv_detect_srv")

        self.magnet.state = 1
        self.magnet_controller_pub.publish(self.magnet)

        self.get_logger().info("节点初始化完成")

    def track_pid_parameter_callback(self, data):
        pass
        # self.pid_parameters = data
    
    # 更新摄像头图像
    def front_cam_callback(self, data):
        self.front_cam_Image_data = data

    def down_cam_callback(self, data):
        self.down_cam_Image_data = data

    def front_cam_left_callback(self, data):
        self.front_cam_left_Image_data = data
    # 更新巡线图像
    def segment_img_callback(self, data):
        self.segment_img = data

    #更新目标检测结果
    def yolov8_down_callback(self, data):
        self.yolov8_data_down = data
    
    def yolov8_front_callback(self, data):
        self.yolov8_data_front = data
    
    # 更新机器人位置数据
    def motion_controller_callback(self, data):
        self.MotionController = data

        self.robot.base.vector.x = self.MotionController.pos.x
        self.robot.base.vector.y = self.MotionController.pos.y
        self.robot.base.vector.z = self.MotionController.pos.z
        self.robot.base.vector.rx = self.MotionController.pos.rx
        self.robot.base.vector.ry = self.MotionController.pos.ry
        self.robot.base.vector.rz = self.MotionController.pos.rz
        self.robot.base.extract()

    # 等待移动至指定位置
    def move_wait(self):
        cnt = 0
        time.sleep(0.5)
        while True:
            judge = 0
            if abs(self.MotionController.tpos_inbase.x) > AllowedError["x"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.y) > AllowedError["y"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.z) > AllowedError["z"]:
                judge += 1
            if abs(self.MotionController.tpos_inbase.rz) > AllowedError["rz"]:
                judge += 1

            if judge == 0:  # 进入容许范围
                return True

            if cnt > 200:  # 超时退出
                return False

            cnt += 1
            time.sleep(0.05)

    def movez(self, z):
         # 校验
        if self.robot.base.vector.z + z < -1.0:
            self.get_logger().info("Warn: 深度设置超出范围")
            z = -self.robot.base.vector.z

        self.get_logger().info("======开始移动======")

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        # 调整深度
        step_cnt = int(abs(z)/Step["z"]) + 1
        #self.get_logger().info(f"Info: 开始调整深度, 需要调整 {step_cnt:d} 次")
        cnt = 0
        while True:
            cnt += 1
            self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整深度")
            if abs(z) <= Step["z"]:
                self.get_logger().info("Info: 最终深度调整开始")
                cmd.pos.z = z
                cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
                self.target_pos_down_pub.publish(cmd)
                re = self.move_wait()
                if re:
                    self.get_logger().info("Info: 最终深度调整完成")
                else:
                    self.get_logger().info("Warn: 最终深度调整超时！")
                break
            else:
                if z > 0:
                    z -= Step["z"]
                    cmd.pos.z = Step["z"]
                else:
                    z += Step["z"]
                    cmd.pos.z = -Step["z"]
                cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
                self.target_pos_down_pub.publish(cmd)
                #self.get_logger().info(f"Info: 第 {cnt:d} 次深度调整完成")
                time.sleep(0.2)

        self.get_logger().info("======移动结束======")
    
        # 移动 z 的相对位移
    def fast_movez(self, z):
        # 直接调整
        if self.robot.base.vector.z + z < 0:
            self.get_logger().info("Warn: 深度设置超出范围")
        else:
            self.get_logger().info("======开始移动======")
            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0
            self.get_logger().info("Info: 深度快速微调开始")
            cmd.pos.z = z
            cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
            self.target_pos_down_pub.publish(cmd)
            self.get_logger().info("======移动结束======")

        # 渐进调整
        # # 校验
        # if self.robot.base.vector.z + z < 0.2:
        #     self.get_logger().info("Warn: 深度设置超出范围")
        # else:
        #     self.get_logger().info("======开始移动======")

        #     cmd = TargetPosDown()
        #     cmd.cs = 2
        #     cmd.pos.rx = 0.0
        #     cmd.pos.ry = 0.0

        #     # 调整深度
        #     step_cnt = int(abs(z)/Step["z"]) + 1
        #     self.get_logger().info(f"Info: 开始调整深度, 需要调整 {step_cnt:d} 次")
        #     cnt = 0
        #     while True:
        #         cnt += 1
        #         self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整深度")
        #         if abs(z) <= Step["z"]:
        #             self.get_logger().info("Info: 最终深度调整开始")
        #             cmd.pos.z = z
        #             cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
        #             self.target_pos_down_pub.publish(cmd)
        #             re = self.move_wait()
        #             if re:
        #                 self.get_logger().info("Info: 最终深度调整完成")
        #             else:
        #                 self.get_logger().info("Warn: 最终深度调整超时！")
        #             break
        #         else:
        #             if z > 0:
        #                 z -= Step["z"]
        #                 cmd.pos.z = Step["z"]
        #             else:
        #                 z += Step["z"]
        #                 cmd.pos.z = -Step["z"]
        #             cmd.pos.x = cmd.pos.y = cmd.pos.rz = 0.0
        #             self.target_pos_down_pub.publish(cmd)
        #             self.get_logger().info(f"Info: 第 {cnt:d} 次深度调整完成")
        #             time.sleep(0.2)

        #     self.get_logger().info("======移动结束======")

    # 移动 x 的相对位移
    def movex(self, x):
        if x > 10:
            self.get_logger().info("Warn: 横向位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0

            # 调整横向位置
            step_cnt = int(abs(x)/Step["x"]) + 1
            self.get_logger().info(f"Info: 开始调整横向位置, 需要调整 {step_cnt:d} 次")
            cnt = 0
            while True:
                cnt += 1
                #self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整横向位置")
                if abs(x) <= Step["x"]:
                    self.get_logger().info("Info: 最终横向位置调整开始")
                    cmd.pos.x = x
                    cmd.pos.y = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    s = self.move_wait()
                    if s:
                        self.get_logger().info("Info: 最终横向位置调整完成")
                    else:
                        self.get_logger().info("Warn: 最终横向位置调整超时！")
                    break
                else:
                    if x > 0:
                        x -= Step["x"]
                        cmd.pos.x = Step["x"]
                    else:
                        x += Step["x"]
                        cmd.pos.x = -Step["x"]
                    cmd.pos.y = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    #self.get_logger().info(f"Info: 第 {cnt:d} 次横向位置调整完成")
                    time.sleep(0.1)
            self.get_logger().info("======移动结束======")

    # 移动 x 的相对位移
    def fast_movex(self, x):
        if x > 10:
            self.get_logger().info("Warn: 横向位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0
            self.get_logger().info("Info: 横向位置快速微调开始")
            cmd.pos.x = x
            cmd.pos.y = cmd.pos.z = cmd.pos.rz = 0.0
            self.target_pos_down_pub.publish(cmd)
            self.get_logger().info("======移动结束======")
    


    # 移动 y 的相对位移
    def movey(self, y):
        if y > 10:
            self.get_logger().info("Warn: 前后位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0

            # 调整
            step_cnt = int(abs(y)/Step["y"]) + 1
            self.get_logger().info(f"Info: 开始调整前后位置, 需要调整 {step_cnt:d} 次")
            cnt = 0
            while True:
                cnt += 1
                #self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整前后位置")
                if abs(y) <= Step["y"]:
                    self.get_logger().info("Info: 最终前后位置调整开始")
                    cmd.pos.y = y
                    cmd.pos.x = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    s = self.move_wait()
                    if s:
                        self.get_logger().info("Info: 最终前后位置调整完成")
                    else:
                        self.get_logger().info("Warn: 最终前后位置调整超时！")
                    break
                else:
                    if y > 0:
                        y -= Step["y"]
                        cmd.pos.y = Step["y"]
                    else:
                        y += Step["y"]
                        cmd.pos.y = -Step["y"]
                    cmd.pos.x = cmd.pos.z = cmd.pos.rz = 0.0
                    self.target_pos_down_pub.publish(cmd)
                    #self.get_logger().info(f"Info: 第 {cnt:d} 次前后位置调整完成")
                    time.sleep(0.1)
            self.get_logger().info("======移动结束======")

                # 移动 y 的相对位移
    def fast_movey(self, y):
        if y > 10:
            self.get_logger().info("Warn: 前后位置设置超出范围！")
        else:
            self.get_logger().info("======开始移动======")

            cmd = TargetPosDown()
            cmd.cs = 2
            cmd.pos.rx = 0.0
            cmd.pos.ry = 0.0
            self.get_logger().info("Info: 前后位置快速微整开始")
            cmd.pos.y = y
            cmd.pos.x = cmd.pos.z = cmd.pos.rz = 0.0
            self.target_pos_down_pub.publish(cmd)
            self.get_logger().info("======移动结束======")

    # 移动 rz 的相对位移
    def moverz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始旋转======")

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        # 调整
        step_cnt = int(abs(rz)/Step["rz"]) + 1
        self.get_logger().info(f"Info: 开始调整角度, 需要调整 {step_cnt:d} 次")
        cnt = 0
        while True:
            cnt += 1
            #self.get_logger().info(f"Info: 开始第 {cnt:d} 次调整角度")
            if abs(rz) <= Step["rz"]:
                self.get_logger().info("Info: 最终角度调整开始")
                cmd.pos.rz = rz
                cmd.pos.x = cmd.pos.z = cmd.pos.y = 0.0
                self.target_pos_down_pub.publish(cmd)
                s = self.move_wait()
                if s:
                    self.get_logger().info("Info: 最终角度调整完成")
                else:
                    self.get_logger().info("Warn: 最终角度调整超时！")
                break
            else:
                if rz > 0:
                    rz -= Step["rz"]
                    cmd.pos.rz = Step["rz"]
                else:
                    rz += Step["rz"]
                    cmd.pos.rz = -Step["rz"]
                cmd.pos.x = cmd.pos.z = cmd.pos.y = 0.0
                self.target_pos_down_pub.publish(cmd)
                #self.get_logger().info(f"Info: 第 {cnt:d} 次角度调整完成")
                time.sleep(0.1)
        self.get_logger().info("======旋转结束======")
        
        
    def fast_moverz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始旋转======")

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        self.get_logger().info("Info: 前后位置快速微整开始")
        cmd.pos.rz = rz
        cmd.pos.x = cmd.pos.z = cmd.pos.y = 0.0
        self.target_pos_down_pub.publish(cmd)
        self.get_logger().info("======移动结束======")

    # 移动x,y相对位移
    def movexy(self, x, y):
        if x == 0 and y == 0:
            self.get_logger().info("Warn: 未设置合法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")
            time.sleep(0.1)
            #self.get_logger().info(f"Info: ======朝向回正,旋转{-rz:.2f}°======")
            #self.moverz(-rz)
            #self.get_logger().info("Info: ======转向结束======")

    # 移动x,y,z相对位移
    def movexyz(self, x, y, z):
        if z == 0:
            self.get_logger().info("Warn: 未设置合法深度位移！")
        else:
            self.movez(z)
        time.sleep(0.1)
        self.movexy(x, y)

    # 设置 z
    def setz(self, z):
        if z >= -1.0:
            self.get_logger().info("======开始调整深度======")
            cmd = TargetPosDown()
            cmd.cs = 0
            cmd.pos.rx = self.MotionController.pos.rx
            cmd.pos.ry = self.MotionController.pos.ry
            cmd.pos.x = self.MotionController.pos.x
            cmd.pos.y = self.MotionController.pos.y
            cmd.pos.rz = self.MotionController.pos.rz
            cmd.pos.z = z
            self.target_pos_down_pub.publish(cmd)
            s = self.move_wait()
            if s:
                self.get_logger().info("Info: 深度调整完成")
            else:
                self.get_logger().info("Warn: 深度调整超时！")
            self.get_logger().info("======移动结束======")
        else:
            self.get_logger().info("Warn: 深度设置错误！")

    # 设置rz
    def setrz(self, rz):
        if rz > 180 or rz < -180:
            self.get_logger().info("Warn: 角度设置超出范围！")
            rz = AngleCorrect(rz)
            self.get_logger().info(f"Info: 角度等效为 {rz:.2f}°")

        self.get_logger().info("======开始调整角度======")
        cmd = TargetPosDown()
        cmd.cs = 0
        cmd.pos.rx = self.MotionController.pos.rx
        cmd.pos.ry = self.MotionController.pos.ry
        cmd.pos.x = self.MotionController.pos.x
        cmd.pos.y = self.MotionController.pos.y
        cmd.pos.z = self.MotionController.pos.z
        cmd.pos.rz = rz
        self.target_pos_down_pub.publish(cmd)
        s = self.move_wait()
        if s:
            self.get_logger().info("Info: 角度调整完成")
        else:
            self.get_logger().info("Warn: 角度调整超时！")
        self.get_logger().info("======移动结束======")

    # 设置路径点
    def setp(self):
        self.backpoint["x"] = self.MotionController.pos.x
        self.backpoint["y"] = self.MotionController.pos.y
        self.backpoint["z"] = self.MotionController.pos.z
        self.backpoint["rz"] = self.MotionController.pos.rz
        self.get_logger().info(
            f'Info:已保存当前位置 x: {self.backpoint["x"]:.2f} y: {self.backpoint["y"]:.2f} z: {self.backpoint["z"]:.2f} rz : {self.backpoint["rz"]:.2f}')

    # 回到路径点
    def back(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(-d)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz-rz_)
            self.get_logger().info("Info: ======转向结束======")
            
    def fast_back(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.fast_movez(z)
        time.sleep(2)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.fast_moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.fast_moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(5.0)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.fast_movey(-d)
            time.sleep(5.0)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.fast_moverz(rz-rz_)
            time.sleep(2.0)
            self.get_logger().info("Info: ======转向结束======")
            
    # 回到路径点
    def backy(self):
        self.robot.target_inworld.vector.x = self.backpoint["x"]
        self.robot.target_inworld.vector.y = self.backpoint["y"]
        self.robot.target_inworld.vector.z = self.backpoint["z"]
        self.robot.target_inworld.vector.rz = self.backpoint["rz"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z
        rz = self.robot.target_inbase.vector.rz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f} rz : {rz:.2f}")


        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
        else:
            rz_ = atan2(y, x)*RAD2DEG - 270
            d = sqrt(x*x + y*y)
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz_:.2f}°======")
            self.moverz(rz_)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(-d)
            self.get_logger().info("Info: ======移动结束======")
            self.get_logger().info(f"Info: ======调整姿态,旋转{rz_:.2f}°======")
            self.moverz(rz-rz_)
            self.get_logger().info("Info: ======转向结束======")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

    # 移动至寄存器 self.target 所指定的位置
    def mtty(self, dy, dz):

        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        z -= dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y) - dy
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")

    def mttzxy(self, dz, dx, dy):
        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        x += dx
        y += dy
        z += dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")
        
        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.get_logger().info(f"Info: ======深度移动指定距离,移动{z:.2f}m======")
            self.movez(z)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if x == 0:
            self.get_logger().info("Warn: 水平位移非法！")
        else:
            self.get_logger().info(f"Info: ======横移指定距离,移动{x:.2f}m======")
            self.movex(x)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if y == 0:
            self.get_logger().info("Warn: 前后位移非法！")
        else:
            self.get_logger().info(f"Info: ======前后指定距离,移动{y:.2f}m======")
            self.movey(y)
        time.sleep(0.1)

        self.get_logger().info(f"Info: ======移动结束======")


    def mttxf(self,dx,dy):
        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")
        x_target = x - dx
        self.get_logger().info(f"Info: ======横移指定距离,移动{x:.2f}m======")
        self.movex(x_target)
        self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)

        if y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            d = y - dy
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{d:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")
        time.sleep(0.1)


    # 移动至寄存器 self.target 所指定的位置
    def mttz(self, dy, dz):

        self.robot.target_inworld.vector.x = self.target["x"]
        self.robot.target_inworld.vector.y = self.target["y"]
        self.robot.target_inworld.vector.z = self.target["z"]
        self.robot.world2base()

        x = self.robot.target_inbase.vector.x
        y = self.robot.target_inbase.vector.y
        z = self.robot.target_inbase.vector.z

        z -= dz

        self.get_logger().info(
            f"Info:需要调整的位移 x: {x:.2f} y: {y:.2f} z: {z:.2f}")

        if x == 0 and y == 0:
            self.get_logger().info("Warn: 非法位移！")
        else:
            rz = atan2(y, x)*RAD2DEG - 90
            d = sqrt(x*x + y*y) - dy
            self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
            self.moverz(rz)
            self.get_logger().info("Info: ======转向结束======")
            time.sleep(0.1)
            self.get_logger().info(f"Info: ======移动指定距离,移动{rz:.2f}m======")
            self.movey(d)
            self.get_logger().info("Info: ======移动结束======")

        if z == 0:
            self.get_logger().info("Warn: 深度位移非法！")
        else:
            self.movez(z)
        time.sleep(0.1)
    
    #移动至指定世界坐标位置
    def mttpos(self, x, y, z, rz, dy):
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z

        Step["y"] = 0.04
        self.mttz(dy, 0.0)#小范围微调
        self.setrz(rz)
        Step["y"] = 0.02
    
    #移动至指定世界坐标位置，但最后不旋转
    def mttzpos(self, x, y, z, dy):
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z
        Step["z"] = 0.2
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        Step["y"] = 0.02
        Step["z"] = 0.05
    
    #移动至指定世界坐标位置，以比赛开始位置为坐标
    def mttpos_amend(self, x, y, z, rz, dy):
        self.start_pos.target_inbase.vector.x = x
        self.start_pos.target_inbase.vector.y = y
        self.start_pos.target_inbase.vector.z = z
        self.start_pos.target_inbase.vector.rz = rz
        self.start_pos.target_inbase.vector.rx = self.start_pos.target_inbase.vector.ry= 0.0
        self.start_pos.base2world()
        self.target["x"] = self.start_pos.target_inworld.vector.x
        self.target["y"] = self.start_pos.target_inworld.vector.y
        self.target["z"] = self.start_pos.target_inworld.vector.z
        self.target["rz"] = self.start_pos.target_inworld.vector.rz
        
        self.get_logger().info(
            f"x: {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
              
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        self.setrz(rz+self.start_pos.base.vector.rz)
        Step["y"] = 0.02
    
    #移动至指定世界坐标位置，以比赛开始位置为坐标
    def mttzpos_amend(self, x, y, z, dy):
        self.start_pos.target_inbase.vector.x = x
        self.start_pos.target_inbase.vector.y = y
        self.start_pos.target_inbase.vector.z = z
        self.start_pos.target_inbase.vector.rx = self.start_pos.target_inbase.vector.ry= 0.0
        self.start_pos.base2world()
        self.target["x"] = self.start_pos.target_inworld.vector.x
        self.target["y"] = self.start_pos.target_inworld.vector.y
        self.target["z"] = self.start_pos.target_inworld.vector.z
        Step["z"] = 0.2
        Step["y"] = 0.04
        self.mttz(dy, 0.0)
        Step["y"] = 0.02
        Step["z"] = 0.05
    
    # 搜寻目标
    def search(self, name, cam):
        # 定位目标
        # 等待服务段上线
        wait = True
        while rclpy.ok() and self.detect_request_client.wait_for_service(0.1) == False:
            if wait:
                wait = False
                self.get_logger().info("Info:等待服务端上线....")
        self.get_logger().info("Info:服务端已启动")

        request = DetectRequest.Request()
        request.stero = cam
        request.target = name
        responce = None

        pos_list = []
        fail_cnt = 0

        image = False

        while True:
            if cam == "front" and self.front_cam_Image_data != None:
                request.imagein = self.front_cam_Image_data
                image = True
            if cam == "down" and self.down_cam_Image_data != None:
                request.imagein = self.down_cam_Image_data
                image = True

            if image == True:
                responce = self.detect_request_client.call(request)
                if responce.s == 1:
                    if cam == "front":
                        self.front_cam.target_inbase.vector.x = responce.x
                        self.front_cam.target_inbase.vector.y = responce.y
                        self.front_cam.target_inbase.vector.z = responce.z
                        #相机坐标系到机器人坐标系
                        self.front_cam.base2world()

                        self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                        self.robot.base2world()

                    if cam == "down":
                        self.down_cam.target_inbase.vector.x = responce.x
                        self.down_cam.target_inbase.vector.y = responce.y
                        self.down_cam.target_inbase.vector.z = responce.z
                        self.down_cam.base2world()

                        self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                        self.robot.base2world()

                    # self.get_logger().info(
                    #     f"Info:目标在机器人坐标系中的位置: x: {self.robot.target_inbase.vector.x: .3f} y: {self.robot.target_inbase.vector.y: .3f} z: {self.robot.target_inbase.vector.z: .3f}")
                    self.get_logger().info(
                        f"Info:目标在相机坐标系中的位置: x: {responce.x: .3f} y: {responce.y: .3f} z: {responce.z: .3f}")

                    pos_list.append([self.robot.target_inworld.vector.x,
                                    self.robot.target_inworld.vector.y, self.robot.target_inworld.vector.z])

                    if len(pos_list) >= 5:
                        break
                else:
                    fail_cnt += 1
                    time
                    if fail_cnt >= 1000 & len(pos_list) < 5:
                        self.get_logger().info(f"确认无目标，退出函数")
                        return responce.s

            else:
                self.get_logger().info("无图像传入")

            image = False
        x = y = z = 0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)

        self.robot.base2world()
        self.target["name"] = name
        self.target["x"] = x
        self.target["y"] = y
        self.target["z"] = z

        self.get_logger().info(
            f"目标位置: x : {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
        return responce.s

    def search2(self, name, cam,dy,dz,z_target,times):
        # 定位目标
        # 等待服务段上线
        wait = True
        while rclpy.ok() and self.detect_request_client.wait_for_service(0.1) == False:
            if wait:
                wait = False
                self.get_logger().info("Info:等待服务端上线....")
        self.get_logger().info("Info:服务端已启动")

        request = DetectRequest.Request()
        request.stero = cam
        request.target = name

        pos_list = []

        image = False
        times_none = 0 #
        flag_to_next = 0 #

        while True:
            if cam == "front" and self.front_cam_Image_data != None:
                request.imagein = self.front_cam_Image_data
                image = True
            if cam == "down" and self.down_cam_Image_data != None:
                request.imagein = self.down_cam_Image_data
                image = True

            if image == True:
                responce = self.detect_request_client.call(request)
                if responce.s == 1:
                    if cam == "front":
                        self.front_cam.target_inbase.vector.x = responce.x
                        self.front_cam.target_inbase.vector.y = responce.y
                        self.front_cam.target_inbase.vector.z = responce.z
                        #相机坐标系到机器人坐标系
                        self.front_cam.base2world()

                        self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                        self.robot.base2world()

                    if cam == "down":
                        self.down_cam.target_inbase.vector.x = responce.x
                        self.down_cam.target_inbase.vector.y = responce.y
                        self.down_cam.target_inbase.vector.z = responce.z
                        self.down_cam.base2world()

                        self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                        self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                        self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                        self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                        self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                        self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                        self.robot.base2world()

                    self.get_logger().info(
                        f"Info:目标在世界坐标系中的位置: x: {self.robot.target_inworld.vector.x: .3f} y: {self.robot.target_inworld.vector.y: .3f} z: {self.robot.target_inworld.vector.z: .3f}")

                    pos_list.append([self.robot.target_inworld.vector.x,
                                    self.robot.target_inworld.vector.y, self.robot.target_inworld.vector.z])

                    if len(pos_list) >= 100:
                        break
                else:
                    if (times > 0):
                        times_none += 1
                        self.get_logger().info(f"第{times_none}次无目标")
                        if (times_none >= 50) & (len(pos_list) < 10):
                            flag_to_next = 1
                            self.get_logger().info(f"确认无目标，进行下一步")
                            break
            else:
                self.get_logger().info("无图像传入")

            image = False

        times += 1
        if flag_to_next == 0:
            x = y = z = 0
            for i in pos_list:
                x += i[0]
                y += i[1]
                z += i[2]
            x /= len(pos_list)
            y /= len(pos_list)
            z /= len(pos_list)

            self.robot.base2world()
            self.target["name"] = name
            self.target["x"] = x
            self.target["y"] = y
            self.target["z"] = z

            self.get_logger().info(
                f"目标位置: x : {self.target['x']:.2f} y: {self.target['y']:.2f} z: {self.target['z']:.2f}")
            
            self.mttz(dy,dz)
            self.setz(z_target)
            self.get_logger().info(
                f"开始第{times}次搜查是否抓球成功")            
            self.search2(self, name, cam,dy,dz,z_target,times)
    
    def search4(self, name1, name2,dx,dy,dz,z_target,rz_target,times,distance):#1为圈，2为T插
       
        times_none = 0
        flag_to_next = 0
        
        T_cnt = 0
        while True:
            
            s = self.search(self, "scaffolding", "front")
            if s == 0:
                self.get_logger().info("======无目标======")
                self.led(0, 0)
                self.get_logger().info("======旋转寻找目标目标======")
                self.moverz(40)
                T_cnt += 1
            else :
                self.get_logger().info("======发现基架======")  
                self.target["y"] -= 0.50  
                self.mttz(dy,dz)
                self.setrz(rz_target)
                break
            if T_cnt > 10:
                self.get_logger().info("======未找到目标======")
                break
        
        """
        计算法线方向
        """
        # 解包坐标
        x1, y1, z1 = self.cam2robot(2, 4,"front")
        x2, y2, z2 = self.cam2robot(2, 4,"front")
        x3, y3, z3 = self.cam2robot(2, 4,"front")
            
            
        # 计算向量AC的分量
        a = x1 - x3
        b = y1 - y3
            
        # 计算向量模长的平方
        length_squared = a**2 + b**2
            
            
        # 计算u和v的可能值
        if  abs(b) >= 0.001:
            # 一般情况
            factor = distance * abs(b) / (length_squared ** 0.5)
            u1 = factor
            v1 = -a * u1 / b
                
            u2 = -factor
            v2 = -a * u2 / b
        else:
            # b为0的特殊情况（AC垂直于x轴）
            u1 = 0
            v1 = distance
                
            u2 = 0
            v2 = -distance
            
            # 计算点D的坐标
        d1 = (x2 + u1, y2 + v1, z3)
        d2 = (x2 + u2, y2 + v2, z3)
            
        real_d = min(d1, d2)    
             
        
              
    # 机械爪控制
    def pow(self, s):
        servo = ServoSet()
        servo.num = 0
        if s == 1:
            servo.angle = 0.35
            self.servo_control_pub.publish(servo)
        if s == 0:
            servo.angle = 0.92#推球，夹T插
            self.servo_control_pub.publish(servo)
        time.sleep(0.1)


    # 任务启动
    def start(self):
        time.sleep(5)
        #  载入当前目标值
        tpos = TargetPosDown()
        tpos.cs = 0
        self.start_pos.base.vector.x = tpos.pos.x = self.MotionController.pos.x
        self.start_pos.base.vector.y = tpos.pos.y = self.MotionController.pos.y
        tpos.pos.z = self.MotionController.pos.z
        self.start_pos.base.vector.z = 0.0
        self.start_pos.base.vector.rz = tpos.pos.rz = self.MotionController.pos.rz
        self.start_pos.base.vector.ry = self.start_pos.base.vector.rx = tpos.pos.rx = tpos.pos.ry =  0.0
        self.start_pos.base.extract()
        self.get_logger().info(f"载入当前世界坐标 x:{tpos.pos.x:.3f} y:{tpos.pos.y:.3f} z:{tpos.pos.z:.3f} rz:{tpos.pos.rz:.3f}")
        self.led(1,0)#绿灯
        time.sleep(3.0)
        self.led(0,1)#黄灯
        time.sleep(3.0)
        self.led(1,1)#红灯
        time.sleep(3.0)
        self.led(0,0)
        self.target_pos_down_pub.publish(tpos)
        # 机械爪加紧T插
        self.pow(0) 
        
        # 开启PID控制器
        pid = PidControllersState()
        pid.x = pid.y = pid.z = pid.rz = 1
        pid.rx = pid.ry = 0
        self.pid_controllers_set_pub.publish(pid)
        time.sleep(0.1)

    # 任务结束
    def end(self):
        # 关闭PID控制器
        pid = PidControllersState()
        pid.x = pid.y = pid.z = pid.rz = 0
        pid.rx = pid.ry = 0
        self.pid_controllers_set_pub.publish(pid)
        time.sleep(0.1)

    def run(self, task: dict):
        if task["name"] == "movexyz":
            self.movexyz(task["params"]["x"], task["params"]
                         ["y"], task["params"]["z"])

        elif task["name"] == "throw_golf":
            self.throw_golf(task["params"]["dy"],
                            task["params"]["depth"])
            
        elif task["name"] == "movexy":
            self.movexy(task["params"]["x"], task["params"]["y"])

            
        elif task["name"] == "movex":
            self.movex(task["params"]["x"])

        elif task["name"] == "movey":
            self.movey(task["params"]["y"])

        elif task["name"] == "movez":
            self.movez(task["params"]["z"])

        elif task["name"] == "moverz":
            self.moverz(task["params"]["rz"])

        elif task["name"] == "setz":
            self.setz(task["params"]["z"])

        elif task["name"] == "setrz":
            self.setrz(task["params"]["rz"])

        elif task["name"] == "search":
            self.search(task["params"]["name"], task["params"]["cam"])

        elif task["name"] == "mtty":
            self.mtty(task["params"]["y"], task["params"]["z"])
        elif task["name"] == "mttxf":
            self.mttxf(task["params"]["dx"],task["params"]["dy"])
        elif task["name"] == "mttz":
            self.mttz(task["params"]["y"], task["params"]["z"])
        elif task["name"] == "mttzxy":
            self.mttzxy(task["params"]["dz"], task["params"]["dx"], task["params"]["dy"])
        elif task["name"] == "setp":
            self.setp()

        elif task["name"] == "back":
            self.back()
            
        elif task["name"] == "backy":
            self.backy()
            
        elif task["name"] == "pow":
            self.pow(task["params"])
        
        elif task["name"] == "line":
            self.line(task["params"]["ys_dep"])

        elif task["name"] == "graball":
            self.graball(task["params"]["color"], task["params"]["depth"], task["params"]["timeout"],task["params"]["pr"],task["params"]["k"],task["params"]["step_time"])

        elif task["name"] == "thrball":
            self.thrball(task["params"]["pr"], task["params"]["timeout"],task["params"]["k"],task["params"]["step_time"])
        
        elif task["name"] == "pass_door":
            self.pass_door(task["params"]["num"])

        elif task["name"] == "mttpos":
            self.mttpos(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["rz"], task["params"]["dy"])
            
        elif task["name"] == "mttzpos_amend":
            self.mttzpos_amend(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["dy"])
        
        elif task["name"] == "mttpos_amend":
            self.mttpos_amend(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["rz"], task["params"]["dy"])
            
        elif task["name"] == "mttzpos_":
            self.mttzpos(task["params"]["x"], task["params"]["y"], task["params"]["z"], task["params"]["dy"])
        
        elif task["name"] == "delay":
            self.delay(task["params"])

        elif task["name"] == "led":
            self.led(task["params"]["led0"],
                     task["params"]["led1"])

        elif task["name"] == "grab_golf":
            self.grab_golf(task["params"]["kind"],
                           task["params"]["dx"],
                           task["params"]["dy"],
                           task["params"]["down_depth"],
                           task["params"]["up_depth"])
        
        elif task["name"] == "put_t":
            self.put_t(task["params"]["num"],
                           task["params"]["dy"],
                           task["params"]["dz"])
        
        elif task["name"] == "strike_ball":
            self.strike_ball(task["params"]["num"])
        
        elif task["name"] == "strike_ball3":
            self.strike_ball3(task["params"]["num1"],
                       task["params"]["num2"],
                       task["params"]["num3"],)
        
        elif task["name"] == "line_qd":
            # 无参数，直接调用line_qd方法
            self.line_qd()
            
        elif task["name"] == "endfloat":
            # 无参数，直接调用line_qd方法
            self.endfloat()

        else:
            self.get_logger().info("Info:非法任务名:  " + task["name"])
    
    def pid_update(self, error):
        self.dt = self.dt + 1 if abs(error-self.previous_error) < 2 else 1
        p_value = self.pid_parameters.p * error
        self.i_error += error * self.dt
        i_value = self.pid_parameters.i * self.i_error
        d_value = self.pid_parameters.d * (error - self.previous_error) / self.dt
        self.previous_error = error
        output = p_value + i_value + d_value
        if output > self.pid_parameters.output_limit:
            output = self.pid_parameters.output_limit
        elif output < -self.pid_parameters.output_limit:
            output = -self.pid_parameters.output_limit
        return output
    

    def cam2robot(self, clas, timeout,cam):
        pos_list = []
        start_time = time.time()

        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # 检查超时
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                return 0.0, 0.0, 0.0
            if cam == "down":
                if self.yolov8_data_down.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.z != 0:
                    self.down_cam.target_inbase.vector.x = self.yolov8_data_down.targets[clas].tpos_inworld.x
                    self.down_cam.target_inbase.vector.y = self.yolov8_data_down.targets[clas].tpos_inworld.y
                    self.down_cam.target_inbase.vector.z = self.yolov8_data_down.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.down_cam.base2world()

                    t_x = self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                    t_z =  self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                    self.robot.base2world()
                    time.sleep(0.015)
                                    # 检查返回的坐标是否为 0
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if cam == "front":
                if self.yolov8_data_front.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.z != 0:
                    self.front_cam.target_inbase.vector.x = self.yolov8_data_front.targets[clas].tpos_inworld.x
                    self.front_cam.target_inbase.vector.y = self.yolov8_data_front.targets[clas].tpos_inworld.y
                    self.front_cam.target_inbase.vector.z = self.yolov8_data_front.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.front_cam.base2world()
                    t_x = self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                    t_z = self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                    self.robot.base2world()
                    time.sleep(0.015)
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")

            if len(pos_list) >= 80:
                break
        x = y = z = 0.0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)
        self.get_logger().info(
            f"目标在机器人坐标系下的位置: x : {x:.2f} y: {y:.2f} z: {z:.2f}")

        return x, y, z
    

    def cam2robot_fast(self, clas, timeout,cam):
        pos_list = []
        start_time = time.time()

        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # 检查超时
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                return 0.0, 0.0, 0.0
            if cam == "down":
                if self.yolov8_data_down.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_down.targets[clas].tpos_inworld.z != 0:
                    self.down_cam.target_inbase.vector.x = self.yolov8_data_down.targets[clas].tpos_inworld.x
                    self.down_cam.target_inbase.vector.y = self.yolov8_data_down.targets[clas].tpos_inworld.y
                    self.down_cam.target_inbase.vector.z = self.yolov8_data_down.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.down_cam.base2world()

                    t_x = self.robot.target_inbase.vector.x = self.down_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.down_cam.target_inworld.vector.y
                    t_z =  self.robot.target_inbase.vector.z = self.down_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.down_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.down_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.down_cam.target_inworld.vector.rz
                    self.robot.base2world()
                                    # 检查返回的坐标是否为 0
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if cam == "front":
                if self.yolov8_data_front.targets[clas].tpos_inworld.x != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.y != 0 or self.yolov8_data_front.targets[clas].tpos_inworld.z != 0:
                    self.front_cam.target_inbase.vector.x = self.yolov8_data_front.targets[clas].tpos_inworld.x
                    self.front_cam.target_inbase.vector.y = self.yolov8_data_front.targets[clas].tpos_inworld.y
                    self.front_cam.target_inbase.vector.z = self.yolov8_data_front.targets[clas].tpos_inworld.z
                    #相机坐标系到机器人坐标系
                    self.front_cam.base2world()
                    t_x = self.robot.target_inbase.vector.x = self.front_cam.target_inworld.vector.x
                    t_y = self.robot.target_inbase.vector.y = self.front_cam.target_inworld.vector.y
                    t_z = self.robot.target_inbase.vector.z = self.front_cam.target_inworld.vector.z
                    t_rx = self.robot.target_inbase.vector.rx = self.front_cam.target_inworld.vector.rx
                    t_ry = self.robot.target_inbase.vector.ry = self.front_cam.target_inworld.vector.ry
                    t_rz = self.robot.target_inbase.vector.rz = self.front_cam.target_inworld.vector.rz
                        #机器人坐标系到世界坐标系
                    self.robot.base2world()
                    if t_x != 0 or t_y != 0 or t_z != 0:
                        pos_list.append([t_x, t_y, t_z])
                        self.get_logger().info(f"t_x : {t_x:.2f} t_y: {t_y:.2f} t_z: {t_z:.2f}")
            if len(pos_list) >= 50:
                break
        x = y = z = 0.0
        for i in pos_list:
            x += i[0]
            y += i[1]
            z += i[2]
        x /= len(pos_list)
        y /= len(pos_list)
        z /= len(pos_list)
        self.get_logger().info(
            f"目标在机器人坐标系下的位置: x : {x:.2f} y: {y:.2f} z: {z:.2f}")

        return x, y, z
    
    #抓球 pr为百分比距离
    def graball(self,color,depth,timeout,pr,k,step_time):
        led = LedControllers()
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                break
            if all(x==0 for x in self.yolov8_data_down.state):
                self.led(0,0)
                self.get_logger().info(
                f"没有找到任何物体")
            elif self.yolov8_data_down.state[5] == 1 and self.yolov8_data_down.state[4] == 1: #5是黄色，4是pink
                self.led(1,0)
                self.get_logger().info(
                f"发现高尔夫球")
                if color == "pink":
                    a, b, c = self.cam2robot(4, 5,"down")
                    self.movex(a)
                    self.movey(b-0.175)
                    self.movez(depth)
                    self.movez(-depth)
                    break
                elif color == "yellow":
                    a, b, c = self.cam2robot(5, 5,"down")
                    self.movex(a)
                    self.movey(b-0.175)
                    self.movez(depth)
                    self.movez(-depth)
                    break
            elif self.yolov8_data_down.state[6] == 1:
                led.led0 = 0
                led.led1 = 1
                r = sqrt((self.yolov8_data_down.targets[6].tpos_inpic.y -  480)**2 + (self.yolov8_data_down.targets[6].tpos_inpic.x -  640)**2)/sqrt(480**2+640**2)
                a, b, c = self.cam2robot_fast(6, 5,"down")
                if r >= pr:
                    self.led_controllers_pub.publish(led)
                    self.get_logger().info(
                    f"只发现陈列框")
                    vx = k*a
                    vy = k*b
                    if abs(vx) < 0.01:
                        vx = 0.01 if vx >= 0 else -0.01
                    if abs(vy) < 0.01:
                        vy = 0.01 if vy >= 0 else -0.01
                    if abs(vx) > 0.04:
                        vx = 0.04 if vx >= 0 else -0.04
                    if abs(vy) > 0.04:
                        vy = 0.04 if vy >= 0 else -0.04
                    self.fast_movex(vx)
                    self.fast_movey(vy)
                    time.sleep(step_time)
                else:
                    self.get_logger().info(
                    f"陈列框已经进入视野中心")
            else:
                self.led(1,1)
                self.get_logger().info(
                f"检测到非必要物体")       
        self.led(0,0)
    #投球
    def thrball(self,pr,timeout,k,step_time):
        led = LedControllers()
        bridge = CvBridge()
        img = bridge.imgmsg_to_cv2(self.down_cam_Image_data,"bgr8")
        row_index = img.shape[0] // 2
        column_index = img.shape[1] // 4
        self.get_logger().info(f"row: {row_index} , column: {column_index}")
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= timeout:
                self.get_logger().info("超时退出")
                break
            if all(x==0 for x in self.yolov8_data_down.state):
                led.led0 = 0
                led.led1 = 0
                self.led_controllers_pub.publish(led)
                self.get_logger().info(
                f"没有找到任何物体")
            elif self.yolov8_data_down.state[5] == 1:
                r = sqrt((self.yolov8_data_down.targets[5].tpos_inpic.y -  row_index)**2 + (self.yolov8_data_down.targets[5].tpos_inpic.x -  column_index)**2)/sqrt(480**2+640**2)
                led.led0 = 1
                led.led1 = 0
                a, b, c = self.cam2robot_fast(5, 5,"down")
                if r >= pr:
                    self.led_controllers_pub.publish(led)
                    self.get_logger().info(
                                            f"发现收集框")
                    vx = k*a
                    vy = k*b
                    if abs(vx) < 0.01:
                        vx = 0.01 if vx >= 0 else -0.01
                    if abs(vy) < 0.01:
                        vy = 0.01 if vy >= 0 else -0.01
                    if abs(vx) > 0.04:
                        vx = 0.04 if vx >= 0 else -0.04
                    if abs(vy) > 0.04:
                        vy = 0.04 if vy >= 0 else -0.04
                    self.fast_movex(vx)
                    self.fast_movey(vy)
                    time.sleep(step_time)
                else:
                    self.get_logger().info(f"收集框已进入视野中心")
                    break
            else:
                led.led0 = 1
                led.led1 = 1
                self.led_controllers_pub.publish(led)
                self.get_logger().info(
                f"检测到非必要物体")
        a, b, c = self.cam2robot(5, 5,"down")
        led.led0 = 1
        led.led1 = 0
        self.led_controllers_pub.publish(led)
        self.movex(a)
        self.movey(b-0.175)   
        self.pow(0) 
        time.sleep(1)      
        led.led0 = 0
        led.led1 = 0
        self.led_controllers_pub.publish(led)

    def pass_door(self,num):
        self.setz(0.5)
        #self.setrz(0)
        start_time = time.time()
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= 30:
                self.get_logger().info("超时,采用planB")
                self.movey(1.0)
                break
            if self.yolov8_data_front.state[num] == 1:
                self.get_logger().info(f"检测到资格门")
                time.sleep(2)
                a, b, c = self.cam2robot_fast(num, 5,"front")
                b = b 
                rz = atan2(b, a)*RAD2DEG - 90
                self.get_logger().info(f"Info: ======转向目标点,旋转{rz:.2f}°======")
                self.moverz(rz)
                cnt = 0
                cnt2 = 0
                cnt3 = 0
                cnt4 = 0
                cmd = TargetPosDown()
                cmd.cs = 2
                cmd.pos.rx = 0.0
                cmd.pos.ry = 0.0
                cmd.pos.x = 0.0
                cmd.pos.y = 0.01
                cmd.pos.z = 0.0
                cmd.pos.rz = 0.0
                time.sleep(0.5)
                while True:
                    cnt+=1
                    if self.yolov8_data_front.state[num] == 0 or cnt > 300:
                        cnt4 += 1
                        time.sleep(0.1)
                        if self.yolov8_data_front.state[num] == 0 or cnt > 300:
                            cnt4 += 1#0.1秒后再进行一次检测
                    if cnt4 > 20 or cnt > 300:    
                        while True:
                            cnt3+=1
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(0.08)
                            if cnt3 > 60 :
                                break              
                        break
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(0.1)
                break

        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        time.sleep(1.0)
        if num == 5:#红，顺时针
            self.get_logger().info("开始旋转")
            cmd.pos.rz = 0.55
            while True:
                cnt2+=1
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.025)
                if cnt2 > 680:
                    break
            
        elif num == 11:#蓝
            self.get_logger().info("开始旋转")
            cmd.pos.rz = -0.55
            while True:
                cnt2+=1
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.025)
                if cnt2 > 680:
                    break
        #self.movey(0.5)
        time.sleep(1.5)
        self.movey(0.5)
        self.get_logger().info(f"过门任务完成")

    def led(self, led0, led1):
        led = LedControllers()
        led.led0 = led0
        led.led1 = led1
        self.led_controllers_pub.publish(led)
    
    def delay(self, t):
        time.sleep(t)
    
    def grab_golf(self, kind, dx, dy, down_depth, up_depth):
        
        num = 0
        
        if kind == "blue_golf":
            num = 4
        if kind == "red_golf":
            num = 3

        
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.1
        
        sample_flag = 0
        golf_cnt = 0
        
        self.pow(1)
        self.led(0, 0)
        s = 1
        while True:
            if all(x == 0 for x in self.yolov8_data_front.state) and \
               all(y == 0 for y in self.yolov8_data_down.state):
                # pass
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                golf_cnt+=1
                
            else:
                if self.yolov8_data_front.state[6]!= 0 :
                    self.get_logger().info("前视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"front")
                    a = a + 0.1
                    b = b - 0.1                    
                    self.movex(a)
                    self.movey(b)
                    self.setz(0.2)
                    time.sleep(2)
                    break
                elif self.yolov8_data_down.state[6]!= 0 :
                    self.get_logger().info("下视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"down")
                    a = a + 0.1
                    b = b - 0.1                      
                    self.movex(a)
                    self.movey(b)
                    self.setz(0.2)
                    time.sleep(2)
                    break
                else:
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(0.01)
                    golf_cnt+=1 
            if  golf_cnt>4000 :
                self.get_logger().info("任务失败")
                self.get_logger().info("======上浮======")
                self.setz(-0.5)
                return
                     
        '''s = self.search(kind, "down")
        if s == 0:
            self.get_logger().info("======下无目标======")
            self.get_logger().info("======第一次平移寻找目标目标======")
            self.movex(0.2)
            self.movey(0.2)
            s = self.search( kind, "down")
            if s == 0:
                self.get_logger().info("======下无目标======")
                self.get_logger().info("======第二次平移寻找目标目标======")
                self.movey(-0.4)
                s = self.search( kind, "down")
                if s == 0:
                    self.get_logger().info("======下无目标======")
                    self.get_logger().info("======第三次平移寻找目标目标======")
                    self.movex(-0.4)
                    s = self.search( kind, "down")
                    if s == 0:
                        self.get_logger().info("======下无目标======")
                        self.get_logger().info("======第四次平移寻找目标目标======")
                        self.movey(0.4)
                        s = self.search(kind, "down")
                        if s == 0:
                            self.get_logger().info("======下无目标======")
                            self.get_logger().info("======任务失败======")
                            return
        if s != 0 :
            self.get_logger().info("======发现球======")  
            self.get_logger().info("======正在移向球======")   
            self.mttxf(0,0) '''
        golf_cnt = 0
        while True: 
            if all(x == 0 for x in self.yolov8_data_front.state) and \
               all(y == 0 for y in self.yolov8_data_down.state):
                golf_cnt+=1
                time.sleep(0.01)
                if golf_cnt>2000:
                    self.get_logger().info("======确认无目标======")
                    self.get_logger().info("======上浮======")
                    self.setz(-0.5)
                    time.sleep(5.0)
                    self.get_logger().info("=====上浮结束======")
                    return                  
            elif self.yolov8_data_down.state[num] !=0:
                self.get_logger().info("======发现目标球=====")
                a, b, c = self.cam2robot(num, 5,"down")
                a = a - dx
                b = b - dy 
                self.movex(a)
                self.movey(b)

                self.delay(1)
                self.led(1, 0)
                self.movez(down_depth)
                self.get_logger().info("=====抓球结束，开始上浮======")
                self.setz(0.15)
                time.sleep(8.0)
                self.led(0, 0)
                if self.yolov8_data_down.state[6]!= 0 :
                    self.get_logger().info("下视发现置物台")
                    time.sleep(2)
                    a, b, c = self.cam2robot(6, 5,"down")
                    a = a + 0.1
                    b = b - 0.1                      
                    self.movex(a)
                    self.movey(b)
                    time.sleep(2)
                    break
                self.setz(-0.5)
                time.sleep(8.0)
                self.get_logger().info("=====上浮结束======")
                return
            else:
                golf_cnt+=1
                time.sleep(0.01)
                if golf_cnt>2000:
                    self.get_logger().info("======确认无目标======")
                    self.get_logger().info("======上浮======")
                    self.setz(-0.5)
                    time.sleep(5)
                    self.get_logger().info("=====上浮结束======")
                    return  
    
    
    def put_t(self, num,dy,dz):
        T_cnt = 0
        T_cnt2 = 0
        T_cnt3 = 0
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.01

        while True:
            if self.yolov8_data_front.state[num] == 0: 
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.001)
                T_cnt+=1
                

            elif  self.yolov8_data_front.state[num] != 0:
                time.sleep(2)
                T_cnt = 0
                self.get_logger().info("发现目标")
                a, b, c = self.cam2robot(num, 5,"front")
                a=a-dy
                c=c-dz
                self.movex(a)
                self.movez(c)
                time.sleep(1)
                cmd.pos.rz = 0.0
                while True:
                    T_cnt2+=1
                    if self.yolov8_data_front.state[num] != 0 and T_cnt2 % 600 == 0: 
                        time.sleep(2)
                        a, b, c = self.cam2robot(num, 5,"front")
                        a=a-dy
                        c=c-dz
                        if (abs(a) > 0.03 or abs(c) > 0.03) and b > 0.25:
                            self.get_logger().info("======目标偏移======")
                            cmd.pos.x = float(a)
                            cmd.pos.z = float(c)
                            cmd.pos.y = 0.0
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(2)
                        else:
                            cmd.pos.y = 0.001
                            cmd.pos.x = 0.0
                            cmd.pos.z = 0.0
                            self.target_pos_down_pub.publish(cmd)
                            self.get_logger().info("======正在前进======")
                            T_cnt+=1
                            time.sleep(0.01)

                    else:
                        cmd.pos.y = 0.001
                        cmd.pos.x = 0.0
                        cmd.pos.z = 0.0
                        self.target_pos_down_pub.publish(cmd)
                        T_cnt+=1
                        time.sleep(0.01)
                    if T_cnt > 1000*(b+0.7):
                            self.pow(1)
                            self.get_logger().info("======任务完成======")
                            return
            if T_cnt>4000:
                self.get_logger().info("======未发现目标 任务失败======")            
                
    def endfloat(self):
   
        num = 5
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.2
        plate_cnt = 0
        while True:
            if self.yolov8_data_front.state[num] ==0 and \
               self.yolov8_data_down.state[num] ==0 :
                # pass
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                golf_cnt+=1
                
            else:
                if self.yolov8_data_front.state[num] ==1:
                    self.get_logger().info("前视发现目标")
                    time.sleep(2)
                    a, b, c = self.cam2robot(num, 5,"front")
                    a = a - 0.3
                    b = b - 0.5                    
                    self.movex(a)
                    self.movey(b)
                    time.sleep(1)
                    self.setz(-0.1)
                    self.get_logger().info("任务成功")
                    break
                else:
                    self.get_logger().info("下视发现目标")
                    a, b, c = self.cam2robot(num, 5,"down")
                    a = a - 0.3
                    b = b - 0.5                    
                    self.movex(a)
                    self.movey(b)
                    time.sleep(1)
                    self.setz(-0.1)
                    self.get_logger().info("任务成功")
                    break
            if  plate_cnt>2000 :
                self.get_logger().info("任务失败")
                return


    def throw_golf(self, dy, depth):
        self.get_logger().info("======开始投球======")
        self.led(0, 1)
        self.search('col_basket', 'down')
        self.led(1, 1)
        self.mttxf(0, dy)
        self.movez(depth)
        self.led(1, 0)
        self.pow(0)
        self.delay(1)
        self.led(0, 0)
        self.get_logger().info("======投球结束======")
        
    def strike_ball(self,num):
        
        ball_cnt = 0
        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0
        cmd.pos.x = 0.0
        cmd.pos.y = 0.0
        cmd.pos.z = 0.0
        cmd.pos.rz = 0.05

        while True:
            if self.yolov8_data_front.state[num] == 0: 
                self.target_pos_down_pub.publish(cmd)
                time.sleep(0.01)
                ball_cnt+=1
            elif  self.yolov8_data_front.state[num] != 0:
                time.sleep(2)
                ball_cnt = 0
                self.get_logger().info("发现目标")
                a, b, c = self.cam2robot(num, 5,"front")
                #a = a 
                c = c - 0.32
                b = b - 0.2
                self.fast_movez(c)
                time.sleep(1)
                self.movexy(a,b)
                time.sleep(1)
                self.get_logger().info("======任务完成 正在返回======")
                self.fast_movey(-b)
                self.move_wait()
                time.sleep(4)
                self.get_logger().info("======返回完成======")
                               
                return
            if ball_cnt>75000:
                self.get_logger().info("======未发现目标 任务失败======")
                return
                
    def strike_ball3(self,num1,num2,num3):
        self.get_logger().info("======撞球任务开始======")
        #self.setp()
        self.get_logger().info("======撞第一个球======")
        self.strike_ball(num1)
        #self.fast_moverz(180.0)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        #time.sleep(4)
        self.get_logger().info("======撞第二个球======")
        self.strike_ball(num2)
        #self.fast_moverz(180.0)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        #time.sleep(4)
        self.get_logger().info("======撞第三个球======")
        self.strike_ball(num3)
        #self.get_logger().info("======正在返回======")
        #self.fast_back()
        
    def line_qd(self):
        
            
        self.led(0,0)
        
        self.pid_parameters.p = 0.0009
        self.pid_parameters.i = 0.0
        self.pid_parameters.d = 0.08
        self.pid_parameters.output_limit = 5.0

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        drz = 0.0

        timesleep = 0.025
        
        self.task_lock = [0,0,0]
        
        magnet = MagnetController()
        led = LedControllers()
        bridge = CvBridge()
    
        window_size = 3  # 滑动窗口的大小
        last_positions = []  # 使用列表来存储最近的位置
        cnt = 0
        cnt_1 = 0
        #等待准备就绪
        time.sleep(1.0)
        while True:
            #try:
            # 转化为opencv图像
            img1 = bridge.imgmsg_to_cv2(self.down_cam_Image_data, "mono8")
            img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
            if img is None:
                self.get_logger().error("bridge.imgmsg_to_cv2 returned None")
                return
            img = cv2.flip(img, -1)

            row_index = img.shape[0] // 3
            row_index1 = img.shape[0] // 2
            column_index = img.shape[1] // 2
            row = img[row_index, :]
            white_pixels = np.where(row == 255)[0]

            # 计算白点的平均位置作为线的中心
            if white_pixels.size > 0:
                line_center = np.mean(white_pixels).astype(int)
                last_positions.append(line_center)
                if len(last_positions) > window_size:  # 如果列表长度超过窗口大小，删除最旧的元素
                    last_positions.pop(0)
            else:
                if last_positions:
                    line_center = last_positions[-1]  # 如果没有检测到新的，则使用上一个

            # 计算滑动平均
            if len(last_positions) > 1:
                smoothed_center = int(np.mean(last_positions))
                cv2.circle(img, (smoothed_center, row_index), 10, (0, 0, 0), -1)  # 标记平滑后的中心点
            else:
                smoothed_center = img.shape[1] // 2
                cv2.circle(img, (smoothed_center, row_index), 10, (0, 0, 0), -1)

            # 在图像上添加文字
            cv2.putText(img, "output: {:.2f}".format(drz), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)

            img_msg = bridge.cv2_to_imgmsg(img, "mono8")
            self.line_patrol_img_pub.publish(img_msg)

            angle_error = smoothed_center - column_index
            drz = self.pid_update(angle_error)

            if all(x==0 for x in self.yolov8_data_down.state):
                # pass
                cmd.pos.x = 0.0
                cmd.pos.y = 0.002
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt_1 += 1
                
            elif not all(x==0 for x in self.yolov8_data_down.state):
                if  self.yolov8_data_down.state[0] != 0 and  self.yolov8_data_down.targets[0].tpos_inpic.y > row_index1 :
                    if self.task_lock[0] == 0 :
                        self.get_logger().info("Info:检测A，开始执行任务") 
                        #self.setp()
                        #a, b, c = self.cam2robot(1, 5,"down")
                        #self.movex(a)
                        #self.movey(b)
                    
                        # 保存任务结束时的图片
                        task1_end_img_path = f"A.png"
                        cv2.imwrite(task1_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task1_end_img_path}")

                        self.get_logger().info("Info:任务执行完毕")
                        #self.back()
                        self.task_lock[0] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[1] != 0 and self.yolov8_data_down.targets[1].tpos_inpic.y > row_index1:
                    if self.task_lock[1] == 0 :
                        self.get_logger().info("Info:检测B，开始执行任务")
                        #self.setp()
                        #a, b, c = self.cam2robot(2, 4,"down")
                        #self.movex(a)
                        #self.movey(b)
                        
                        # 保存任务结束时的图片
                        task2_end_img_path = f"B.png"
                        cv2.imwrite(task2_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task2_end_img_path}")

                        #self.back()
                        self.get_logger().info("Info:任务执行完毕")
                        self.task_lock[1] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[2] != 0 and self.yolov8_data_down.targets[2].tpos_inpic.y > row_index1:
                    if self.task_lock[2] == 0 :
                        self.get_logger().info("Info:检测C，开始执行任务") 
                        #self.setp()
                        #a, b, c = self.cam2robot(0, 4,"down")
                        #self.movex(a)
                       # self.movey(b)
                        # 保存任务结束时的图片
                        task3_end_img_path = f"C.png"
                        cv2.imwrite(task3_end_img_path, img1)
                        self.get_logger().info(f"Info:保存图片 {task3_end_img_path}")

                        self.get_logger().info("Info:任务执行完毕")
                        self.task_lock[2] = 1
                    else:
                        #pass
                        cmd.pos.x = 0.0
                        cmd.pos.y = 0.002
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        cnt_1 += 1
                        time.sleep(timesleep)

                else:
                    #pass
                    cmd.pos.x = 0.0
                    cmd.pos.y = 0.002
                    cmd.pos.z = 0.0
                    cmd.pos.rz = drz
                    self.target_pos_down_pub.publish(cmd)
                    cnt_1 += 1
                    time.sleep(timesleep)
            if cnt_1 > 1200:
                self.get_logger().info("Info:任务全部执行完毕")
                return
            if all(x == 1 for x in self.task_lock):
                cmd.pos.x = 0.0
                cmd.pos.y = 0.004
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt+=1
                if cnt > 200:
                    self.get_logger().info("Info:任务全部执行完毕")
                    return

          
    #巡线
    def line(self, ys_dep):
        self.led(0, 0)
        
        self.pid_parameters.p = 0.0009
        self.pid_parameters.i = 0.0
        self.pid_parameters.d = 0.08
        self.pid_parameters.output_limit = 5.0

        cmd = TargetPosDown()
        cmd.cs = 2
        cmd.pos.rx = 0.0
        cmd.pos.ry = 0.0

        drz = 0.0
        depth = ys_dep
        timesleep = 0.025
        
        self.task_lock = [0, 0, 0]
        
        magnet = MagnetController()
        bridge = CvBridge()
        
        # 初始化1D卡尔曼滤波器（仅跟踪位置）
        kf = KalmanFilter(dim_x=1, dim_z=1)
        kf.x = np.array([320.])  # 初始位置（图像中心附近）
        kf.F = np.array([[1.]])  # 状态转移矩阵（简单恒速模型）
        kf.H = np.array([[1.]])  # 观测矩阵
        kf.P *= 100.  # 初始协方差
        kf.R = 3.0    # 观测噪声
        kf.Q = np.array([[1.0]])  # 过程噪声
        
        # 图像状态跟踪变量
        last_valid_image_time = None
        has_valid_image = False
        last_filtered_center = 320  # 初始中心位置
        img_shape = (480, 640)  # 预设图像尺寸，根据实际情况调整
        row_index = img_shape[0] // 3  # 预设行索引
        row_index1 = img_shape[0] // 2  # 预设任务检测行索引
        column_index = img_shape[1] // 2  # 预设列中心
        
        # 新增：图像初始化等待机制
        init_wait_time = 0.1  # 初始化等待0.1秒
        start_time = time.time()
        self.get_logger().info(f"等待图像初始化，最多等待{init_wait_time}秒...")
        
        # 等待图像或超时
        while not has_valid_image and (time.time() - start_time) < init_wait_time:
            try:
                if self.segment_img is not None:
                    img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
                    img_shape = img.shape
                    row_index = img_shape[0] // 3
                    row_index1 = img_shape[0] // 2
                    column_index = img_shape[1] // 2
                    has_valid_image = True
                    last_valid_image_time = time.time()
                    self.get_logger().info("成功获取初始图像")
            except Exception as e:
                self.get_logger().debug(f"初始化阶段图像获取失败: {str(e)}")
            time.sleep(0.1)  # 短时间等待后重试
        
        if not has_valid_image:
            self.get_logger().warn(f"初始化超时，未获取到图像，将使用默认参数运行")
            
        cnt = 0
        cnt_1 = 0
        while True:
            cnt_1 = cnt_1 + 1
            if cnt_1 > 2000:
                self.get_logger().warn(f"时间结束自动退出")
                return
                
            # 尝试获取和处理图像
            try:
                if self.segment_img is not None:
                    img = bridge.imgmsg_to_cv2(self.segment_img, "mono8")
                    img = cv2.flip(img, -1)
                    img_shape = img.shape
                    row_index = img_shape[0] // 3
                    row_index1 = img_shape[0] // 2
                    column_index = img_shape[1] // 2
                    last_valid_image_time = time.time()
                    has_valid_image = True
                    
                    # 处理图像获取线中心
                    row = img[row_index, :]
                    white_pixels = np.where(row == 255)[0]

                    # 卡尔曼滤波处理
                    kf.predict()
                    
                    # 有观测值时更新
                    if white_pixels.size > 0:
                        line_center = np.mean(white_pixels).astype(int)
                        kf.update(line_center)
                    
                    # 使用滤波后的值
                    filtered_center = int(kf.x[0])
                    last_filtered_center = filtered_center
                    
                    # 绘制标记并发布图像
                    cv2.circle(img, (filtered_center, row_index), 10, (0, 0, 0), -1)
                    cv2.putText(img, "output: {:.2f}".format(drz), (50, 50), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)
                    img_msg = bridge.cv2_to_imgmsg(img, "mono8")
                    self.line_patrol_img_pub.publish(img_msg)
                    

                        
            except Exception as e:
                # 图像处理失败时的处理
                self.get_logger().warn(f"无分割图像: {str(e)}")
                
                # 仅使用预测
                kf.predict()
                filtered_center = int(kf.x[0])
                last_filtered_center = filtered_center
                
                # 状态判断与警示
                if not has_valid_image:
                    self.get_logger().warn("持续未接收到图像，使用默认控制策略")
                elif (time.time() - last_valid_image_time) > 1.0:
                    self.get_logger().warn("图像已丢失超过1秒，使用预测值控制")
    
            
            # 计算控制量
            angle_error = filtered_center - column_index
            # 无图像时减小控制增益，采用更保守的控制
            if not has_valid_image:
                drz = self.pid_update(angle_error) * 0.5  # 降低控制强度
                dy = 0.004  # 降低前进速度
            else:
                drz = self.pid_update(angle_error)
                dy = 0.005 - 0.0004 * abs(drz)
            
            # 控制逻辑
            if all(x == 0 for x in self.yolov8_data_down.state):
                cmd.pos.x = 0.0
                cmd.pos.y = dy
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                
            elif not all(x == 0 for x in self.yolov8_data_down.state):
                if self.yolov8_data_down.state[1] != 0 and self.yolov8_data_down.targets[1].tpos_inpic.y > row_index1:
                        if self.task_lock[0] == 0:
                            self.get_logger().info("检测到黑色方块，开始执行任务")
                            time.sleep(2)
                            magnet.state = 0
                            self.magnet_controller_pub.publish(magnet)
                            self.led(1, 1)
                            time.sleep(1)
                            self.get_logger().info("任务执行完毕")
                            self.task_lock[0] = 1
                        else:
                            cmd.pos.x = 0.0
                            cmd.pos.y = dy
                            cmd.pos.z = 0.0
                            cmd.pos.rz = drz
                            self.target_pos_down_pub.publish(cmd)
                            time.sleep(timesleep)
                elif self.yolov8_data_down.state[2] != 0 and self.yolov8_data_down.targets[2].tpos_inpic.y > row_index1:
                    if self.task_lock[1] == 0:
                        self.get_logger().info("检测到绿色圆形，开始执行任务")
                        time.sleep(2)
                        a, b, c = self.cam2robot(2, 4, "down")
                        b = b - 0.4
                        self.movex(a)
                        self.movey(b)
                        self.movez(depth)
                        self.led(1,0)
                        self.movez(-depth)
                        self.led(0,0)
                        self.get_logger().info("任务执行完毕")
                        self.task_lock[1] = 1
                    else:
                        cmd.pos.x = 0.0
                        cmd.pos.y = dy
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        time.sleep(timesleep)
                elif self.yolov8_data_down.state[0] != 0 and self.yolov8_data_down.targets[0].tpos_inpic.y > row_index1:
                    if self.task_lock[2] == 0:
                        self.get_logger().info("检测到黄色三角，开始执行任务")
                        time.sleep(2)
                        self.moverz(179.9)
                        time.sleep(1)
                        self.moverz(179.9)
                        time.sleep(1)
                        self.get_logger().info("任务执行完毕")
                        self.task_lock[2] = 1
                    else:
                        cmd.pos.x = 0.0
                        cmd.pos.y = dy
                        cmd.pos.z = 0.0
                        cmd.pos.rz = drz
                        self.target_pos_down_pub.publish(cmd)
                        time.sleep(timesleep)
                else:
                    cmd.pos.x = 0.0
                    cmd.pos.y = dy
                    cmd.pos.z = 0.0
                    cmd.pos.rz = drz
                    self.target_pos_down_pub.publish(cmd)
                    time.sleep(timesleep)
                    
            if all(x == 1 for x in self.task_lock):
                cmd.pos.x = 0.0
                cmd.pos.y = dy
                cmd.pos.z = 0.0
                cmd.pos.rz = drz
                self.target_pos_down_pub.publish(cmd)
                time.sleep(timesleep)
                cnt += 1
                if cnt > 190:
                    return
    

            # except Exception as e:
            #     self.get_logger().error(f"图像处理过程中出现错误 {e}")
            #     break
                # except Exception as e:
                #     self.get_logger().error(f"图像处理过程中出现错误 {e}")
                #     break
 


# 从命令行获取任务
def get_act():
    command = input("请输入任务: \n")
    parts = command.split()
    if parts[0] == 'movexyz':
        args = parts[1:]
        if len(args) == 3:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dic = {
                "name": "movexyz",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'throw_golf':
        args = parts[1:]
        if len(args) == 2:
            dy = float(args[0])
            depth = float(args[1])
            dic = {
                "name": "throw_golf",
                "params": {
                    "dy": dy,
                    "depth": depth,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'movexy':
        args = parts[1:]
        if len(args) == 2:
            x = float(args[0])
            y = float(args[1])
            dic = {
                "name": "movexy",
                "params": {
                    "x": x,
                    "y": y,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movex':
        args = parts[1:]
        if len(args) == 1:
            x = float(args[0])
            dic = {
                "name": "movex",
                "params": {
                    "x": x,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movey':
        args = parts[1:]
        if len(args) == 1:
            y = float(args[0])
            dic = {
                "name": "movey",
                "params": {
                    "y": y,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'movez':
        args = parts[1:]
        if len(args) == 1:
            z = float(args[0])
            dic = {
                "name": "movez",
                "params": {
                    "z": z,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'moverz':
        args = parts[1:]
        if len(args) == 1:
            rz = float(args[0])
            dic = {
                "name": "moverz",
                "params": {
                    "rz": rz,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'setz':
        args = parts[1:]
        if len(args) == 1:
            z = float(args[0])
            dic = {
                "name": "setz",
                "params": {
                    "z": z,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'setrz':
        args = parts[1:]
        if len(args) == 1:
            rz = float(args[0])
            dic = {
                "name": "setrz",
                "params": {
                    "rz": rz,
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'pow':
        args = parts[1:]
        if len(args) == 1:
            a = int(args[0])
            dic = {
                "name": "pow",
                "params": a
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mtty':
        args = parts[1:]
        if len(args) == 2:
            y = float(args[0])
            z = float(args[1])
            dic = {
                "name": "mtty",
                "params": {
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttxf':
        args = parts[1:]
        if len(args) == 2:
            dx = float(args[0])
            dy = float(args[1])
            dic = {
                "name": "mttxf",
                "params": {
                    "dx": dx,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttz':
        args = parts[1:]
        if len(args) == 2:
            y = float(args[0])
            z = float(args[1])
            dic = {
                "name": "mttz",
                "params": {
                    "y": y,
                    "z": z
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'mttzxy':
        args = parts[1:]
        if len(args) == 3:
            dz = float(args[0])
            dx = float(args[1])
            dy = float(args[2])
            dic = {
                "name": "mttzxy",
                "params": {
                    "dz": dz,
                    "dx": dx,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
    elif parts[0] == 'setp':
        if len(parts) == 1:
            dic = {
                "name": "setp",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'back':
        if len(parts) == 1:
            dic = {
                "name": "back",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'backy':
        if len(parts) == 1:
            dic = {
                "name": "backy",
                "params": {}
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'search':
        args = parts[1:]
        if len(args) == 2:
            name = args[0]
            cam = args[1]
            dic = {
                "name": "search",
                "params": {
                    "name": name,
                    "cam": cam
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'line':
        args = parts[1:]
        if len(args) == 1:
            ys_dep = float(args[0])
            dic = {
                "name": "line",
                "params": {
                    "ys_dep": ys_dep
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None 
        
    elif parts[0] == 'mttpos':
        args = parts[1:]
        if len(args) == 5:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            rz = float(args[3])
            dy = float(args[4])
            dic = {
                "name": "mttpos",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "rz": rz,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'mttzpos':
        args = parts[1:]
        if len(args) == 4:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dy = float(args[3])
            dic = {
                "name": "mttzpos",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'mttpos_amend':
        args = parts[1:]
        if len(args) == 5:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            rz = float(args[3])
            dy = float(args[4])
            dic = {
                "name": "mttpos_amend",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "rz": rz,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'mttzpos_amend':
        args = parts[1:]
        if len(args) == 4:
            x = float(args[0])
            y = float(args[1])
            z = float(args[2])
            dy = float(args[3])
            dic = {
                "name": "mttzpos_amend",
                "params": {
                    "x": x,
                    "y": y,
                    "z": z,
                    "dy": dy
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'graball':
        args = parts[1:]
        if len(args) == 6:
            color       =   str(args[0])
            depth       =   float(args[1])
            timeout     =   float(args[2])
            pr          =   float(args[3])
            k           =   float(args[4])
            step_time   =   float(args[5])           
            dic = {
                "name": "graball",
                "params": {
                    "color": color,
                    "depth": depth,
                    "timeout": timeout,
                    "pr": pr,
                    "k" : k,
                    "step_time":step_time
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'thrball':
        args = parts[1:]
        if len(args) == 4:
            pr        =   float(args[0])
            timeout   =   float(args[1])
            k         =   float(args[2])
            step_time =   float(args[3])  
            dic = {
                "name": "thrball",
                "params": {
                    "pr": pr,
                    "timeout": timeout,
                    "k" : k,
                    "step_time":step_time
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None  
    elif parts[0] == 'pass_door':
        args = parts[1:]
        if len(args) == 1:
            num       =   int(args[0])
            dic = {
                "name": "pass_door",
                "params": {
                    "num":num
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    elif parts[0] == 'led':
        args = parts[1:]
        if len(args) == 2:
            led0 = int(args[0])
            led1 = int(args[1])
            dic = {
                "name": "led",
                "params": {
                    "led0": led0,
                    "led1": led1
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'delay':
        args = parts[1:]
        if len(args) == 1:
            t = float(args[0])
            dic = {
                "name": "delay",
                "params": t
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    elif parts[0] == 'grab_golf':
        args = parts[1:]
        if len(args) == 5:
            kind = str(args[0])
            dx = float(args[1])
            dy = float(args[2])
            down_depth = float(args[3])
            up_depth = float(args[4])
            dic = {
                "name": "grab_golf",
                "params": {
                    "kind": kind,
                    "dx": dx,
                    "dy": dy,
                    "down_depth": down_depth,
                    "up_depth": up_depth
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'line_qd':
        args = parts[1:]
        if len(args) == 0:
            dic = {
                "name": "line_qd",
                "params": {}  # 无参数时为空字典
            }
            return dic
        else:
            print("指令格式不正确，line_qd不需要参数")
            return None 
        
    elif parts[0] == 'endfloat':
        args = parts[1:]
        if len(args) == 0:
            dic = {
                "name": "endfloat",
                "params": {}  # 无参数时为空字典
            }
            return dic
        else:
            print("指令格式不正确，line_qd不需要参数")
            return None 
    
    elif parts[0] == 'put_t':
        args = parts[1:]
        if len(args) == 3:
            num = int(args[0])
            dy = float(args[1])
            dz = float(args[2])
            dic = {
                "name": "put_t",
                "params": {
                    "num": num,
                    "dy": dy,
                    "dz": dz
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
        
    elif parts[0] == 'strike_ball':
        args = parts[1:]
        if len(args) == 1:
            num = int(args[0])
            dic = {
                "name": "strike_ball",
                "params": {
                    "num": num
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None
    
    elif parts[0] == 'strike_ball3':
        args = parts[1:]
        if len(args) == 3:
            num1 = int(args[0])
            num2 = int(args[1])
            num3 = int(args[2])
            dic = {
                "name": "strike_ball3",
                "params": {
                    "num1": num1,
                    "num2": num2,
                    "num3": num3
                }
            }
            return dic
        else:
            print("指令格式不正确")
            return None

    else:
        print("无效指令")
        return None
    
    


# 读取并从文件中加载任务队列
def load_actions(path):
    with open(path, 'r', encoding='utf-8') as f:
        dic = json.load(f)
    return dic

# 保存任务队列


def save_actions(dic, path):
    print("所保存的任务:\n"+str(dic)+"\n")
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(dic, f)

# 普通模式


def commom_loop(node, opt):
    list = load_actions(opt.data_path[0]+"uv_tasks.json")

    node.start()
    num = 0

    for act in list["tasks"]:
        node.get_logger().info(
            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
        node.run(act)
        node.get_logger().info(
            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
        num += 1
    
    node.end()

# 调试模式


def debug_loop(node: CoreNode, opt):
    node.get_logger().info("Info:进入调试模式")

    tasklist = load_actions(opt.data_path[0]+"uv_tasks.json")
     
    help_txt = ""
    with open(opt.data_path[0]+"help.txt", 'r', encoding='utf-8') as f:
        s = f.read()
        help_txt = s

    node.start()

    while True:
        node.get_logger().info(f"Info:等待指令输入")
        command = input("请输入调试指令: \n")
        parts = command.split()
        if parts[0] == 'help':
            print(help_txt)
        elif parts[0] == 'act':
            act = get_act()

            if act == None:
                node.get_logger().info(f"Warn:非法任务")
            else:
                node.get_logger().info(
                    f"Info:=========执行任务: " + act["name"] + "=========")
                node.run(act)
                node.get_logger().info(
                    f"Info:=========完成任务: " + act["name"] + "=========")
        elif parts[0] == "task":
            if parts[1] == "run":
                if len(parts[1:]) == 1:
                    num = 0
                    for act in tasklist["tasks"]:
                        node.get_logger().info(
                            f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
                        node.run(act)
                        node.get_logger().info(
                            f"Info:=========完成第 {num:d} 步任务: " + act["name"] + "=========")
                        num += 1
                elif len(parts[1:]) == 2:
                    num = int(parts[parts.index('run') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        n = num
                        for act in tasklist["tasks"][num:]:
                            node.get_logger().info(
                                f"Info:=========执行第 {num:d} 步任务: " + act["name"] + "=========")
                            node.run(act)
                            node.get_logger().info(
                                f"Info:=========完成第 {num:d} 步任务: " + act["name"] + "=========")
                            n += 1
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "runonly":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('runonly') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = tasklist["tasks"][num]
                        node.get_logger().info(
                            "Info:=========执行任务: " + act["name"] + "=========")
                        node.run(act)
                        node.get_logger().info(
                            "Info:=========完成任务: " + act["name"] + "=========")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "add":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('add') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = get_act()
                        if act == None:
                            node.get_logger().info("非法任务")
                        else:
                            tasklist["tasks"].insert(num, act)
                            save_actions(
                                tasklist, opt.data_path[0]+"uv_tasks.json")
                elif len(parts[1:]) == 1:
                    act = get_act()
                    if act == None:
                        node.get_logger().info("非法任务")
                    else:
                        tasklist["tasks"].append(act)
                        save_actions(
                            tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "del":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('del') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        tasklist["tasks"].pop(num)
                        save_actions(
                            tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            elif parts[1] == "clear":
                tasklist["tasks"] = []
                save_actions(tasklist, opt.data_path[0]+"uv_tasks.json")
            elif parts[1] == "list":
                node.get_logger().info("Info: 打印任务列表")
                num = 0
                for i in tasklist["tasks"]:
                    print("编号:   " + str(num))
                    print("任务名: "+i["name"])
                    print("参数:   " + str(i["params"]))
                    num += 1
            elif parts[1] == "mod":
                if len(parts[1:]) == 2:
                    num = int(parts[parts.index('mod') + 1])
                    if num > len(tasklist["tasks"]) - 1 or num < 0:
                        node.get_logger().info("Warn: 所请求任务不在列表范围内！")
                    else:
                        act = get_act()
                        if act == None:
                            node.get_logger().info("非法任务")
                        else:
                            tasklist["tasks"][num] = act
                            save_actions(
                                tasklist, opt.data_path[0]+"uv_tasks.json")
                else:
                    node.get_logger().info("Warn:非法指令")
            else:
                node.get_logger().info("Warn:非法指令")


def main(args=None):

    # 加载参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--front-topic', nargs='+', type=str, default=[
                        'front_cam/rectified'], help='前视摄像头')
    parser.add_argument('--down-topic', nargs='+', type=str, default=[
                        'down_cam/rectified'], help='下视摄像头')
    parser.add_argument('--data-path', nargs='+', type=str, default=[
                        '/home/nvidia/Workspace/Cruise/datas/'], help='PID参数路径')
    parser.add_argument('--debug', nargs='+', type=bool,
                        default=False, help='PID参数路径')

    opt = parser.parse_args()

    rclpy.init(args=args)  # 初始化rclpy

    if opt.debug:
        node = CoreNode("uv_automaton_debug", opt)  # 新建一个节点
        thread_debug = threading.Thread(
            target=debug_loop, args=(node, opt))  # 创建调度线程
        thread_debug.start()
    else:
        node = CoreNode("uv_automaton", opt)  # 新建一个节点
        thread_common = threading.Thread(
            target=commom_loop, args=(node, opt))    # 创建调度线程
        thread_common.start()

    node.get_logger().info("节点与调度线程成功启动")

    rclpy.spin(node)  # 保持节点运行，检测是否收到退出指令（Ctrl+Z）
    rclpy.shutdown()  # 关闭rclpy

===== .\uv_ai\uv_ai\uv_detect_demo.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import subprocess
from multiprocessing import Process,Pipe
import threading

from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image
import time
import cv2
from pathlib import Path
import numpy as np
import torch
import torch.backends.cudnn as cudnn
from numpy import random
import argparse
import torch
import torch.nn as nn
from ultralytics import YOLO

from sensor_msgs.msg import Image
from uv_msgs.srv import DetectRequest
from uv_msgs.msg import Yolov8
from typing import Dict, Tuple, Union, List

from uv_vision.stereocam import StereoCamera

# 养了一只猫猫，路过的人可以摸一摸
# 　／l、
# （ﾟ､ 。 ７
# 　l、 ~ヽ
# 　じしf_, )ノ


class AiNode(Node):
    def __init__(self, name, opt, pipe_1, pipe_2):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)
        self.opt = opt
        self.bridge = CvBridge()  # 图像格式转换器

        # 是否正在处理图像
        self.processing = False
        self.front_cam_Image_data = None
        self.down_cam_Image_data = None
        self.pipe_front   =  pipe_1
        self.pipe_down    =  pipe_2
        #话题发布
        #创建话题发布detectedimg，定义其消息类型为Image，用于发布检测结果图像
        self.detectedimg_down_pub = self.create_publisher(
            Image, "detectedimg_down", 10)
                #创建话题发布detectedimg，定义其消息类型为Image，用于发布检测结果图像
        self.detectedimg_front_pub = self.create_publisher(
            Image, "detectedimg_front", 10)
        
        #创建话题发布detectedimg，定义其消息类型为Image，用于发布检测结果图像
        self.detectserveimg_pub = self.create_publisher(
            Image, "detect_server_img", 10)
        
        # 创建话题发布 uv_detect，定义其消息类型为Yolov8，用于发布检测结果
        self.detect_result_pub_down = self.create_publisher(
            Yolov8, 'uv_detect_down', 10)
        
        self.detect_result_pub_front = self.create_publisher(
            Yolov8, 'uv_detect_front', 10) 

        #话题接收
        #创建话题接收down_cam/rectified,定义其消息类型为Image
        self.create_subscription(
            Image, 'down_cam/rectified', self.down_cam_callback, 10)
        
        self.create_subscription(
            Image, 'front_cam/rectified', self.front_cam_callback, 10   
        )
        #初始化服务端
        #服务类型为DetectRequest，服务 uv_detect_srv , 回调函数为self.detectrequest_callback
        self.detect_srv = self.create_service(
            DetectRequest, 'uv_detect_srv', self.detectrequest_callback)

        # # 初始化相机参数
        fsc = StereoCamera()
        dsc = StereoCamera()
        self.stereocams = {"front": fsc, "down": dsc}
        self.stereocams["front"].cal_parameters_init(opt.front_params[0])
        self.stereocams["down"].cal_parameters_init(opt.down_params[0])

        # 初始化
        #set_logging()
        self.device = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
        # 加载模型
        self.model = YOLO(opt.weights2)
        self.model.to(self.device)

        self.names = self.model.names if hasattr(self.model, 'names') else self.model.module.names


    # 下置摄像头回调函数
    def down_cam_callback(self, data):
        self.down_cam_Image_data = data
        self.process_image_down()

    def front_cam_callback(self, data):
        self.front_cam_Image_data = data
        self.process_image_front()
    
    def process_image_down(self):
        if self.down_cam_Image_data is not None and not self.processing:
            self.processing = True
            img0 = self.bridge.imgmsg_to_cv2(self.down_cam_Image_data, 'bgr8')
            img0 = cv2.flip(img0, -1)
            self.pipe_down.send((img0,"down"))
            self.get_logger().info("下视图像已发送到检测进程")
            results_down, img_msg_down = self.pipe_down.recv()
            self.get_logger().info(f"接收到下视检测结果！")
            self.detectedimg_down_pub.publish(img_msg_down)
            self.detect_result_pub_down.publish(results_down)
            self.processing = False

    def process_image_front(self):
        if self.front_cam_Image_data is not None and not self.processing: 
            self.processing = True      
            img1 = self.bridge.imgmsg_to_cv2(self.front_cam_Image_data, 'bgr8')
            img1 = cv2.flip(img1, -1)
            self.pipe_front.send((img1,"front"))
            self.get_logger().info("前视图像已发送到检测进程")
            results_front, img_msg_front = self.pipe_front.recv()
            self.get_logger().info(f"接收到前视检测结果！")
            self.detectedimg_front_pub.publish(img_msg_front)
            self.detect_result_pub_front.publish(results_front)
            self.processing = False
        
            
    #检测结果预处理
    def img_process(self, results):
        try:
            clas = results.boxes.cls.tolist()
            conf = results.boxes.conf.tolist()
            point = results.boxes.xyxy.tolist()
            combined = list(zip(clas, conf, point))
            # 过滤掉置信度低于0.9的检测结果，并将结果格式化为 (clas, conf, center)
            filtered = [(item[0], item[1], ((item[2][0] + item[2][2]) / 2, (item[2][1] + item[2][3]) / 2)) for item in combined if item[1] >= 0.65]

            return filtered
        except Exception as e:
            self.get_logger().error(f"图像处理错误: {e}")
            return []

    # 服务回调函数
    def detectrequest_callback(self, request, response):
        img0 = self.bridge.imgmsg_to_cv2(request.imagein, 'bgr8')
        img0 = cv2.flip(img0, -1)
        askedtarget = request.target
        response.s = 0
        _, width, _ = img0.shape
        half_width = width // 2

        #把图像分为左右两部分
        img_l = img0[:, :half_width]
        img_r = img0[:, half_width:]

        t0 = time.time()
        #模型预测
        results_l = self.model.predict(source=img_l)[0]
        filtered_l = self.img_process(results_l)
        self.get_logger().info(f"server:左目完成图像预测,检测到 {len(filtered_l)} 个目标")

        results_r = self.model.predict(source=img_r)[0]
        filtered_r = self.img_process(results_r)
        self.get_logger().info(f"server:右目完成图像预测,检测到 {len(filtered_r)} 个目标")
        #合并检测结果
        targets_dict: Dict[Union[str, int], Tuple[float, Tuple[float], Tuple[float]]] = {}
        for clas, conf, center_l in filtered_l:
                targets_dict[clas] = (conf, center_l, None)
        for clas, conf, center_r in filtered_r:
            if clas in targets_dict:
                targets_dict[clas] = (targets_dict[clas][0] , targets_dict[clas][1], center_r)

        #遍历字典，计算每个目标物的三维坐标
        for clas in targets_dict:
            left_pt = None
            right_pt = None
            if self.names[int(clas)] == askedtarget:
                    left_pt = targets_dict[clas][1]
                    right_pt = targets_dict[clas][2]

            if left_pt is not None and right_pt is not None:
                # 使用左右两点纵坐标的平均值作为新的纵坐标
                avg_y = (left_pt[1] + right_pt[1]) / 2
                left_pt = np.array([left_pt[0], avg_y], dtype=np.float32).reshape(2, 1)
                right_pt = np.array([right_pt[0], avg_y], dtype=np.float32).reshape(2, 1)      
                
                pt = cv2.triangulatePoints(self.stereocams[request.stero].P1, self.stereocams[request.stero].P2, left_pt, right_pt)
                pt = pt / pt[3][0]  # 标准化为笛卡尔坐标
                x, y, z = -float(pt[0][0]), -float(pt[1][0]), float(pt[2][0])  # 转换为浮点数确保正确的数据类型

                response.s = 1
                response.x, response.y, response.z = x, y, z

        img_l = results_l.plot()
        img_r = results_r.plot()
        img0 = np.hstack((img_l, img_r))
        img0 = np.array(img0)
        data = self.bridge.cv2_to_imgmsg(img0, encoding="bgr8")
        self.detectserveimg_pub.publish(data)

        if response.s == 1:
            self.get_logger().info("已检测到目标，用时: %.3fs" % (time.time() - t0))
        else:
            self.get_logger().info("未检测到目标，用时: %.3fs" % (time.time() - t0))

        return response

        

def detect_process(pipe, opt):

    # 初始化相机参数
    fsc = StereoCamera()
    dsc = StereoCamera()
    stereocams = {"front": fsc, "down": dsc}
    stereocams["front"].cal_parameters_init(opt.front_params[0])
    stereocams["down"].cal_parameters_init(opt.down_params[0])
    
    model1 = YOLO(opt.weights)
    device1 = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
    model1.to(device1)

    while True:
        img0 ,cam_type = pipe.recv()
        tar = Yolov8()

        try:
            print("detect_process:开始处理图像")
            _, width, _ = img0.shape
            half_width = width // 2
            img_l = img0[:, :half_width]
            img_r = img0[:, half_width:]
            # 模型预测
            #results = model1.predict(source=img0)[0]

            print("detect_process:完成图像预测...")
            results_l = model1.predict(source=img_l)[0]
            clas_l = results_l.boxes.cls.tolist()
            conf_l = results_l.boxes.conf.tolist()
            point_l = results_l.boxes.xyxy.tolist()
            combined_l = list(zip(clas_l, conf_l, point_l))
            # 过滤掉置信度低于0.9的检测结果，并将结果格式化为 (clas, conf, center)
            filtered_l = [(item[0], item[1], ((item[2][0] + item[2][2]) / 2, (item[2][1] + item[2][3]) / 2)) for item in combined_l if item[1] >= 0.50]
            print(f"process:左目完成图像预测,检测到 {len(filtered_l)} 个目标")

            results_r = model1.predict(source=img_r)[0]
            clas_r = results_r.boxes.cls.tolist()
            conf_r = results_r.boxes.conf.tolist()
            point_r = results_r.boxes.xyxy.tolist()
            combined_r = list(zip(clas_r, conf_r, point_r))
            # 过滤掉置信度低于0.9的检测结果，并将结果格式化为 (clas, conf, center)
            filtered_r = [(item[0], item[1], ((item[2][0] + item[2][2]) / 2, (item[2][1] + item[2][3]) / 2)) for item in combined_r if item[1] >= 0.50]
            print(f"process:右目完成图像预测,检测到 {len(filtered_r)} 个目标")
            
            targets_dict: Dict[Union[str, int], Tuple[float, Tuple[float], Tuple[float]]] = {}
            for clas, conf, center_l in filtered_l:
                targets_dict[clas] = (conf, center_l, None)
            for clas, conf, center_r in filtered_r:
                if clas in targets_dict:
                    targets_dict[clas] = (targets_dict[clas][0] , targets_dict[clas][1], center_r)
            
            tar.state = [0.0 for _ in range(13)]

            for clas in targets_dict: 
                if targets_dict[clas][1] is not None or targets_dict[clas][2] is not None:
                    tar.state[int(clas)] += 1

                left_pt = targets_dict[clas][1]
                right_pt = targets_dict[clas][2]

                if left_pt is not None and right_pt is not None:
                    # left_pt = np.array(left_pt, dtype=np.float32).reshape(2, 1)
                    # right_pt = np.array(right_pt, dtype=np.float32).reshape(2, 1)

                    # 使用左右两点纵坐标的平均值作为新的纵坐标
                    avg_y = (left_pt[1] + right_pt[1]) / 2
                    left_pt = np.array([left_pt[0], avg_y], dtype=np.float32).reshape(2, 1)
                    right_pt = np.array([right_pt[0], avg_y], dtype=np.float32).reshape(2, 1)      

                    pt = cv2.triangulatePoints(stereocams[cam_type].P1, stereocams[cam_type].P2, left_pt, right_pt)
                    pt = pt / pt[3][0]  # 标准化为笛卡尔坐标
                    x, y, z = -float(pt[0][0]), -float(pt[1][0]), float(pt[2][0])  # 转换为浮点数确保正确的数据类型

                    tar.targets[int(clas)].tpos_inpic.x = round(targets_dict[clas][1][0])
                    tar.targets[int(clas)].tpos_inpic.y = round(targets_dict[clas][1][1])
                    tar.targets[int(clas)].tpos_inworld.x = x
                    tar.targets[int(clas)].tpos_inworld.y = y
                    tar.targets[int(clas)].tpos_inworld.z = z
            img_l = results_l.plot()
            img_r = results_r.plot()
            img0 = np.hstack((img_l, img_r)) #图像二合一
            img0 = np.array(img0)    
            img_msg = CvBridge().cv2_to_imgmsg(img0, encoding="bgr8")

            pipe.send((tar, img_msg))

            print("detect_process:图像处理完成")
        except CvBridgeError as e:
            print(f"detect_process:图像转换错误: {e}")
        except Exception as e:
            print(f"detect_process:目标检测错误: {e}")



import rclpy
from rclpy.node import Node
import argparse
from multiprocessing import Pipe, Process  # 补充缺失的导入（根据实际代码调整）
import sys  # 需导入sys模块处理命令行参数

def main(args=None):
    # 过滤ROS 2自动添加的参数（关键步骤）
    # 从命令行参数中移除ROS相关参数（如--ros-args），只保留自定义参数
    ros_args = rclpy.utilities.remove_ros_args(sys.argv)
    
    #  解析自定义参数（使用过滤后的参数列表）
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str,
                        default='/home/nvidia/Workspace/Cruise/datas/AUV2025V1.pt', help='model.pt path(s)')
    parser.add_argument('--weights2', nargs='+', type=str,
                        default='/home/nvidia/Workspace/Cruise/datas/AUV2025V1.pt', help='model.pt path(s)')
    parser.add_argument('--show-img', type=bool,
                        default=True, help='是否展示图像')
    parser.add_argument('--front-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/front.npz'], help='前置摄像头参数存储路径')
    parser.add_argument('--down-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/down.npz'], help='下置摄像头参数存储路径')

    # 注意：解析时跳过脚本名本身（ros_args[0]是脚本名）
    opt = parser.parse_args(ros_args[1:])

    # 初始化ROS 2节点
    rclpy.init(args=args)

    parent_conn_1, child_conn_1 = Pipe()
    parent_conn_2, child_conn_2 = Pipe()
    p_1 = Process(target=detect_process, args=(child_conn_1, opt))
    p_2 = Process(target=detect_process, args=(child_conn_2, opt))
    p_1.start()
    p_2.start()

    node = AiNode("uv_detect_demo", opt, parent_conn_1, parent_conn_2)
    rclpy.spin(node)
    rclpy.shutdown()

    # 进程清理（避免僵尸进程
    p_1.join()
    p_2.join()

===== .\uv_ai\uv_ai\uv_detect_demo_enumerated.txt =====
功能: 代码摘录
001: import rclpy
002: from rclpy.node import Node
003: import subprocess
004: from multiprocessing import Process,Pipe
005: import threading
006: 
007: from cv_bridge import CvBridge, CvBridgeError
008: from sensor_msgs.msg import Image
009: import time
010: import cv2
011: from pathlib import Path
012: import numpy as np
013: import torch
014: import torch.backends.cudnn as cudnn
015: from numpy import random
016: import argparse
017: import torch
018: import torch.nn as nn
019: from ultralytics import YOLO
020: 
021: from sensor_msgs.msg import Image
022: from uv_msgs.srv import DetectRequest
023: from uv_msgs.msg import Yolov8
024: from typing import Dict, Tuple, Union, List
025: 
026: from uv_vision.stereocam import StereoCamera
027: 
028: # 养了一只猫猫，路过的人可以摸一摸
029: # 　／l、
030: # （ﾟ､ 。 ７
031: # 　l、 ~ヽ
032: # 　じしf_, )ノ
033: 
034: 
035: class AiNode(Node):
036:     def __init__(self, name, opt, pipe_1, pipe_2):
037:         super().__init__(name)
038:         self.get_logger().info("大家好，我是%s!" % name)
039:         self.opt = opt
040:         self.bridge = CvBridge()  # 图像格式转换器
041: 
042:         # 是否正在处理图像
043:         self.processing = False
044:         self.front_cam_Image_data = None
045:         self.down_cam_Image_data = None
046:         self.pipe_front   =  pipe_1
047:         self.pipe_down    =  pipe_2
048:         #话题发布
049:         #创建话题发布detectedimg，定义其消息类型为Image，用于发布检测结果图像
050:         self.detectedimg_down_pub = self.create_publisher(
051:             Image, "detectedimg_down", 10)
052:                 #创建话题发布detectedimg，定义其消息类型为Image，用于发布检测结果图像
053:         self.detectedimg_front_pub = self.create_publisher(
054:             Image, "detectedimg_front", 10)
055:         
056:         #创建话题发布detectedimg，定义其消息类型为Image，用于发布检测结果图像
057:         self.detectserveimg_pub = self.create_publisher(
058:             Image, "detect_server_img", 10)
059:         
060:         # 创建话题发布 uv_detect，定义其消息类型为Yolov8，用于发布检测结果
061:         self.detect_result_pub_down = self.create_publisher(
062:             Yolov8, 'uv_detect_down', 10)
063:         
064:         self.detect_result_pub_front = self.create_publisher(
065:             Yolov8, 'uv_detect_front', 10) 
066: 
067:         #话题接收
068:         #创建话题接收down_cam/rectified,定义其消息类型为Image
069:         self.create_subscription(
070:             Image, 'down_cam/rectified', self.down_cam_callback, 10)
071:         
072:         self.create_subscription(
073:             Image, 'front_cam/rectified', self.front_cam_callback, 10   
074:         )
075:         #初始化服务端
076:         #服务类型为DetectRequest，服务 uv_detect_srv , 回调函数为self.detectrequest_callback
077:         self.detect_srv = self.create_service(
078:             DetectRequest, 'uv_detect_srv', self.detectrequest_callback)
079: 
080:         # # 初始化相机参数
081:         fsc = StereoCamera()
082:         dsc = StereoCamera()
083:         self.stereocams = {"front": fsc, "down": dsc}
084:         self.stereocams["front"].cal_parameters_init(opt.front_params[0])
085:         self.stereocams["down"].cal_parameters_init(opt.down_params[0])
086: 
087:         # 初始化
088:         #set_logging()
089:         self.device = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
090:         # 加载模型
091:         self.model = YOLO(opt.weights2)
092:         self.model.to(self.device)
093: 
094:         self.names = self.model.names if hasattr(self.model, 'names') else self.model.module.names
095: 
096: 
097:     # 下置摄像头回调函数
098:     def down_cam_callback(self, data):
099:         self.down_cam_Image_data = data
100:         self.process_image_down()
101: 
102:     def front_cam_callback(self, data):
103:         self.front_cam_Image_data = data
104:         self.process_image_front()
105:     
106:     def process_image_down(self):
107:         if self.down_cam_Image_data is not None and not self.processing:
108:             self.processing = True
109:             img0 = self.bridge.imgmsg_to_cv2(self.down_cam_Image_data, 'bgr8')
110:             img0 = cv2.flip(img0, -1)
111:             self.pipe_down.send((img0,"down"))
112:             self.get_logger().info("下视图像已发送到检测进程")
113:             results_down, img_msg_down = self.pipe_down.recv()
114:             self.get_logger().info(f"接收到下视检测结果！")
115:             self.detectedimg_down_pub.publish(img_msg_down)
116:             self.detect_result_pub_down.publish(results_down)
117:             self.processing = False
118: 
119:     def process_image_front(self):
120:         if self.front_cam_Image_data is not None and not self.processing: 
121:             self.processing = True      
122:             img1 = self.bridge.imgmsg_to_cv2(self.front_cam_Image_data, 'bgr8')
123:             img1 = cv2.flip(img1, -1)
124:             self.pipe_front.send((img1,"front"))
125:             self.get_logger().info("前视图像已发送到检测进程")
126:             results_front, img_msg_front = self.pipe_front.recv()
127:             self.get_logger().info(f"接收到前视检测结果！")
128:             self.detectedimg_front_pub.publish(img_msg_front)
129:             self.detect_result_pub_front.publish(results_front)
130:             self.processing = False
131:         
132:             
133:     #检测结果预处理
134:     def img_process(self, results):
135:         try:
136:             clas = results.boxes.cls.tolist()
137:             conf = results.boxes.conf.tolist()
138:             point = results.boxes.xyxy.tolist()
139:             combined = list(zip(clas, conf, point))
140:             # 过滤掉置信度低于0.9的检测结果，并将结果格式化为 (clas, conf, center)
141:             filtered = [(item[0], item[1], ((item[2][0] + item[2][2]) / 2, (item[2][1] + item[2][3]) / 2)) for item in combined if item[1] >= 0.65]
142: 
143:             return filtered
144:         except Exception as e:
145:             self.get_logger().error(f"图像处理错误: {e}")
146:             return []
147: 
148:     # 服务回调函数
149:     def detectrequest_callback(self, request, response):
150:         img0 = self.bridge.imgmsg_to_cv2(request.imagein, 'bgr8')
151:         img0 = cv2.flip(img0, -1)
152:         askedtarget = request.target
153:         response.s = 0
154:         _, width, _ = img0.shape
155:         half_width = width // 2
156: 
157:         #把图像分为左右两部分
158:         img_l = img0[:, :half_width]
159:         img_r = img0[:, half_width:]
160: 
161:         t0 = time.time()
162:         #模型预测
163:         results_l = self.model.predict(source=img_l)[0]
164:         filtered_l = self.img_process(results_l)
165:         self.get_logger().info(f"server:左目完成图像预测,检测到 {len(filtered_l)} 个目标")
166: 
167:         results_r = self.model.predict(source=img_r)[0]
168:         filtered_r = self.img_process(results_r)
169:         self.get_logger().info(f"server:右目完成图像预测,检测到 {len(filtered_r)} 个目标")
170:         #合并检测结果
171:         targets_dict: Dict[Union[str, int], Tuple[float, Tuple[float], Tuple[float]]] = {}
172:         for clas, conf, center_l in filtered_l:
173:                 targets_dict[clas] = (conf, center_l, None)
174:         for clas, conf, center_r in filtered_r:
175:             if clas in targets_dict:
176:                 targets_dict[clas] = (targets_dict[clas][0] , targets_dict[clas][1], center_r)
177: 
178:         #遍历字典，计算每个目标物的三维坐标
179:         for clas in targets_dict:
180:             left_pt = None
181:             right_pt = None
182:             if self.names[int(clas)] == askedtarget:
183:                     left_pt = targets_dict[clas][1]
184:                     right_pt = targets_dict[clas][2]
185: 
186:             if left_pt is not None and right_pt is not None:
187:                 # 使用左右两点纵坐标的平均值作为新的纵坐标
188:                 avg_y = (left_pt[1] + right_pt[1]) / 2
189:                 left_pt = np.array([left_pt[0], avg_y], dtype=np.float32).reshape(2, 1)
190:                 right_pt = np.array([right_pt[0], avg_y], dtype=np.float32).reshape(2, 1)      
191:                 
192:                 pt = cv2.triangulatePoints(self.stereocams[request.stero].P1, self.stereocams[request.stero].P2, left_pt, right_pt)
193:                 pt = pt / pt[3][0]  # 标准化为笛卡尔坐标
194:                 x, y, z = -float(pt[0][0]), -float(pt[1][0]), float(pt[2][0])  # 转换为浮点数确保正确的数据类型
195: 
196:                 response.s = 1
197:                 response.x, response.y, response.z = x, y, z
198: 
199:         img_l = results_l.plot()
200:         img_r = results_r.plot()
201:         img0 = np.hstack((img_l, img_r))
202:         img0 = np.array(img0)
203:         data = self.bridge.cv2_to_imgmsg(img0, encoding="bgr8")
204:         self.detectserveimg_pub.publish(data)
205: 
206:         if response.s == 1:
207:             self.get_logger().info("已检测到目标，用时: %.3fs" % (time.time() - t0))
208:         else:
209:             self.get_logger().info("未检测到目标，用时: %.3fs" % (time.time() - t0))
210: 
211:         return response
212: 
213:         
214: 
215: def detect_process(pipe, opt):
216: 
217:     # 初始化相机参数
218:     fsc = StereoCamera()
219:     dsc = StereoCamera()
220:     stereocams = {"front": fsc, "down": dsc}
221:     stereocams["front"].cal_parameters_init(opt.front_params[0])
222:     stereocams["down"].cal_parameters_init(opt.down_params[0])
223:     
224:     model1 = YOLO(opt.weights)
225:     device1 = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
226:     model1.to(device1)
227: 
228:     while True:
229:         img0 ,cam_type = pipe.recv()
230:         tar = Yolov8()
231: 
232:         try:
233:             print("detect_process:开始处理图像")
234:             _, width, _ = img0.shape
235:             half_width = width // 2
236:             img_l = img0[:, :half_width]
237:             img_r = img0[:, half_width:]
238:             # 模型预测
239:             #results = model1.predict(source=img0)[0]
240: 
241:             print("detect_process:完成图像预测...")
242:             results_l = model1.predict(source=img_l)[0]
243:             clas_l = results_l.boxes.cls.tolist()
244:             conf_l = results_l.boxes.conf.tolist()
245:             point_l = results_l.boxes.xyxy.tolist()
246:             combined_l = list(zip(clas_l, conf_l, point_l))
247:             # 过滤掉置信度低于0.9的检测结果，并将结果格式化为 (clas, conf, center)
248:             filtered_l = [(item[0], item[1], ((item[2][0] + item[2][2]) / 2, (item[2][1] + item[2][3]) / 2)) for item in combined_l if item[1] >= 0.50]
249:             print(f"process:左目完成图像预测,检测到 {len(filtered_l)} 个目标")
250: 
251:             results_r = model1.predict(source=img_r)[0]
252:             clas_r = results_r.boxes.cls.tolist()
253:             conf_r = results_r.boxes.conf.tolist()
254:             point_r = results_r.boxes.xyxy.tolist()
255:             combined_r = list(zip(clas_r, conf_r, point_r))
256:             # 过滤掉置信度低于0.9的检测结果，并将结果格式化为 (clas, conf, center)
257:             filtered_r = [(item[0], item[1], ((item[2][0] + item[2][2]) / 2, (item[2][1] + item[2][3]) / 2)) for item in combined_r if item[1] >= 0.50]
258:             print(f"process:右目完成图像预测,检测到 {len(filtered_r)} 个目标")
259:             
260:             targets_dict: Dict[Union[str, int], Tuple[float, Tuple[float], Tuple[float]]] = {}
261:             for clas, conf, center_l in filtered_l:
262:                 targets_dict[clas] = (conf, center_l, None)
263:             for clas, conf, center_r in filtered_r:
264:                 if clas in targets_dict:
265:                     targets_dict[clas] = (targets_dict[clas][0] , targets_dict[clas][1], center_r)
266:             
267:             tar.state = [0.0 for _ in range(13)]
268: 
269:             for clas in targets_dict: 
270:                 if targets_dict[clas][1] is not None or targets_dict[clas][2] is not None:
271:                     tar.state[int(clas)] += 1
272: 
273:                 left_pt = targets_dict[clas][1]
274:                 right_pt = targets_dict[clas][2]
275: 
276:                 if left_pt is not None and right_pt is not None:
277:                     # left_pt = np.array(left_pt, dtype=np.float32).reshape(2, 1)
278:                     # right_pt = np.array(right_pt, dtype=np.float32).reshape(2, 1)
279: 
280:                     # 使用左右两点纵坐标的平均值作为新的纵坐标
281:                     avg_y = (left_pt[1] + right_pt[1]) / 2
282:                     left_pt = np.array([left_pt[0], avg_y], dtype=np.float32).reshape(2, 1)
283:                     right_pt = np.array([right_pt[0], avg_y], dtype=np.float32).reshape(2, 1)      
284: 
285:                     pt = cv2.triangulatePoints(stereocams[cam_type].P1, stereocams[cam_type].P2, left_pt, right_pt)
286:                     pt = pt / pt[3][0]  # 标准化为笛卡尔坐标
287:                     x, y, z = -float(pt[0][0]), -float(pt[1][0]), float(pt[2][0])  # 转换为浮点数确保正确的数据类型
288: 
289:                     tar.targets[int(clas)].tpos_inpic.x = round(targets_dict[clas][1][0])
290:                     tar.targets[int(clas)].tpos_inpic.y = round(targets_dict[clas][1][1])
291:                     tar.targets[int(clas)].tpos_inworld.x = x
292:                     tar.targets[int(clas)].tpos_inworld.y = y
293:                     tar.targets[int(clas)].tpos_inworld.z = z
294:             img_l = results_l.plot()
295:             img_r = results_r.plot()
296:             img0 = np.hstack((img_l, img_r)) #图像二合一
297:             img0 = np.array(img0)    
298:             img_msg = CvBridge().cv2_to_imgmsg(img0, encoding="bgr8")
299: 
300:             pipe.send((tar, img_msg))
301: 
302:             print("detect_process:图像处理完成")
303:         except CvBridgeError as e:
304:             print(f"detect_process:图像转换错误: {e}")
305:         except Exception as e:
306:             print(f"detect_process:目标检测错误: {e}")
307: 
308: 
309: 
310: import rclpy
311: from rclpy.node import Node
312: import argparse
313: from multiprocessing import Pipe, Process  # 补充缺失的导入（根据实际代码调整）
314: import sys  # 需导入sys模块处理命令行参数
315: 
316: def main(args=None):
317:     # 过滤ROS 2自动添加的参数（关键步骤）
318:     # 从命令行参数中移除ROS相关参数（如--ros-args），只保留自定义参数
319:     ros_args = rclpy.utilities.remove_ros_args(sys.argv)
320:     
321:     #  解析自定义参数（使用过滤后的参数列表）
322:     parser = argparse.ArgumentParser()
323:     parser.add_argument('--weights', nargs='+', type=str,
324:                         default='/home/nvidia/Workspace/Cruise/datas/AUV2025V1.pt', help='model.pt path(s)')
325:     parser.add_argument('--weights2', nargs='+', type=str,
326:                         default='/home/nvidia/Workspace/Cruise/datas/AUV2025V1.pt', help='model.pt path(s)')
327:     parser.add_argument('--show-img', type=bool,
328:                         default=True, help='是否展示图像')
329:     parser.add_argument('--front-params', nargs='+', type=str,
330:                         default=['/home/nvidia/Workspace/Cruise/datas/front.npz'], help='前置摄像头参数存储路径')
331:     parser.add_argument('--down-params', nargs='+', type=str,
332:                         default=['/home/nvidia/Workspace/Cruise/datas/down.npz'], help='下置摄像头参数存储路径')
333: 
334:     # 注意：解析时跳过脚本名本身（ros_args[0]是脚本名）
335:     opt = parser.parse_args(ros_args[1:])
336: 
337:     # 初始化ROS 2节点
338:     rclpy.init(args=args)
339: 
340:     parent_conn_1, child_conn_1 = Pipe()
341:     parent_conn_2, child_conn_2 = Pipe()
342:     p_1 = Process(target=detect_process, args=(child_conn_1, opt))
343:     p_2 = Process(target=detect_process, args=(child_conn_2, opt))
344:     p_1.start()
345:     p_2.start()
346: 
347:     node = AiNode("uv_detect_demo", opt, parent_conn_1, parent_conn_2)
348:     rclpy.spin(node)
349:     rclpy.shutdown()
350: 
351:     # 进程清理（避免僵尸进程
352:     p_1.join()
353:     p_2.join()

===== .\uv_ai\uv_ai\uv_detect_lightglue_test1.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import subprocess
from multiprocessing import Process, Pipe
import threading

from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image
import time
import cv2
from pathlib import Path
import numpy as np
import torch
import torch.backends.cudnn as cudnn
from numpy import random
import argparse
import torch
import torch.nn as nn
from ultralytics import YOLO

from sensor_msgs.msg import Image
from uv_msgs.srv import DetectRequest
from uv_msgs.msg import Yolov8
from typing import Dict, Tuple, Union, List

from uv_vision.stereocam import StereoCamera

# ============ 新增导入：LightGlue相关 ============
from lightglue import LightGlue, SuperPoint
from lightglue.utils import load_image, rbd


# 养了一只猫猫，路过的人可以摸一摸
# 　／l、
# （ﾟ､ 。 ７
# 　l、 ~ヽ
# 　じしf_, )ノ


class AiNode(Node):
    def __init__(self, name, opt, pipe_1, pipe_2):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)
        self.opt = opt
        self.bridge = CvBridge()  # 图像格式转换器

        # 是否正在处理图像
        self.processing = False
        self.front_cam_Image_data = None
        self.down_cam_Image_data = None
        self.pipe_front = pipe_1
        self.pipe_down = pipe_2
        
        # 话题发布
        # 创建话题发布detectedimg，定义其消息类型为Image，用于发布检测结果图像
        self.detectedimg_down_pub = self.create_publisher(
            Image, "detectedimg_down", 10)
        # 创建话题发布detectedimg，定义其消息类型为Image，用于发布检测结果图像
        self.detectedimg_front_pub = self.create_publisher(
            Image, "detectedimg_front", 10)
        
        # 创建话题发布detectedimg，定义其消息类型为Image，用于发布检测结果图像
        self.detectserveimg_pub = self.create_publisher(
            Image, "detect_server_img", 10)
        
        # 创建话题发布 uv_detect，定义其消息类型为Yolov8，用于发布检测结果
        self.detect_result_pub_down = self.create_publisher(
            Yolov8, 'uv_detect_down', 10)
        
        self.detect_result_pub_front = self.create_publisher(
            Yolov8, 'uv_detect_front', 10) 

        # 话题接收
        # 创建话题接收down_cam/rectified,定义其消息类型为Image
        self.create_subscription(
            Image, 'down_cam/rectified', self.down_cam_callback, 10)
        
        self.create_subscription(
            Image, 'front_cam/rectified', self.front_cam_callback, 10   
        )
        
        # 初始化服务端
        # 服务类型为DetectRequest，服务 uv_detect_srv , 回调函数为self.detectrequest_callback
        self.detect_srv = self.create_service(
            DetectRequest, 'uv_detect_srv', self.detectrequest_callback)

        # 初始化相机参数
        fsc = StereoCamera()
        dsc = StereoCamera()
        self.stereocams = {"front": fsc, "down": dsc}
        self.stereocams["front"].cal_parameters_init(opt.front_params[0])
        self.stereocams["down"].cal_parameters_init(opt.down_params[0])

        # 初始化AI模型
        self.device = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
        
        # ============ 修改：加载分割模型（从检测模型切换为分割模型）============
        self.model = YOLO(opt.weights2)  # 这里需要使用seg模型，如yolov8n-seg.pt
        self.model.to(self.device)
        self.names = self.model.names if hasattr(self.model, 'names') else self.model.module.names

        # ============ 新增：加载LightGlue模型（用于服务回调）============
        self.get_logger().info("正在加载LightGlue模型...")
        self.extractor = SuperPoint(max_num_keypoints=512).eval().to(self.device)
        self.matcher = LightGlue(features='superpoint').eval().to(self.device)
        self.get_logger().info("LightGlue模型加载完成！")


    # 下置摄像头回调函数（保持不变）
    def down_cam_callback(self, data):
        self.down_cam_Image_data = data
        self.process_image_down()

    # 前置摄像头回调函数（保持不变）
    def front_cam_callback(self, data):
        self.front_cam_Image_data = data
        self.process_image_front()
    
    # 下视图像处理（保持不变）
    def process_image_down(self):
        if self.down_cam_Image_data is not None and not self.processing:
            self.processing = True
            img0 = self.bridge.imgmsg_to_cv2(self.down_cam_Image_data, 'bgr8')
            img0 = cv2.flip(img0, -1)
            self.pipe_down.send((img0, "down"))
            self.get_logger().info("下视图像已发送到检测进程")
            results_down, img_msg_down = self.pipe_down.recv()
            self.get_logger().info(f"接收到下视检测结果！")
            self.detectedimg_down_pub.publish(img_msg_down)
            self.detect_result_pub_down.publish(results_down)
            self.processing = False

    # 前视图像处理（保持不变）
    def process_image_front(self):
        if self.front_cam_Image_data is not None and not self.processing: 
            self.processing = True      
            img1 = self.bridge.imgmsg_to_cv2(self.front_cam_Image_data, 'bgr8')
            img1 = cv2.flip(img1, -1)
            self.pipe_front.send((img1, "front"))
            self.get_logger().info("前视图像已发送到检测进程")
            results_front, img_msg_front = self.pipe_front.recv()
            self.get_logger().info(f"接收到前视检测结果！")
            self.detectedimg_front_pub.publish(img_msg_front)
            self.detect_result_pub_front.publish(results_front)
            self.processing = False
        
    # ============ 修改：检测结果预处理（增加mask提取）============
    def img_process(self, results):
        """
        处理YOLO分割结果，提取类别、置信度、中心点和mask
        
        Args:
            results: YOLOv8-seg的检测结果对象
            
        Returns:
            filtered: 列表，每个元素为(类别ID, 置信度, 中心点坐标, mask二值图)
        """
        try:
            clas = results.boxes.cls.tolist()  # 类别ID列表
            conf = results.boxes.conf.tolist()  # 置信度列表
            point = results.boxes.xyxy.tolist()  # 边界框坐标列表 [x1,y1,x2,y2]
            
            # ============ 新增：提取分割mask ============
            masks = []
            if results.masks is not None:
                # masks.data是张量 [N, H, W]，需要转为numpy数组
                for mask_tensor in results.masks.data:
                    # 将mask转为numpy数组并调整到原图尺寸
                    mask_np = mask_tensor.cpu().numpy()
                    # 如果mask尺寸不是原图尺寸，需要resize
                    if mask_np.shape != results.orig_shape[:2]:
                        mask_np = cv2.resize(mask_np, 
                                            (results.orig_shape[1], results.orig_shape[0]),
                                            interpolation=cv2.INTER_NEAREST)
                    masks.append(mask_np)
            else:
                # 如果没有mask（使用检测模型），用bbox生成伪mask
                self.get_logger().warn("未检测到分割mask，将使用bbox生成伪mask")
                for bbox in point:
                    mask_np = np.zeros(results.orig_shape[:2], dtype=np.uint8)
                    x1, y1, x2, y2 = map(int, bbox)
                    mask_np[y1:y2, x1:x2] = 1
                    masks.append(mask_np)
            
            # 组合数据
            combined = list(zip(clas, conf, point, masks))
            
            # ============ 修改：过滤条件保持不变，但增加mask信息 ============
            # 过滤掉置信度低于0.65的检测结果，并将结果格式化为 (clas, conf, center, mask)
            filtered = []
            for item in combined:
                if item[1] >= 0.65:  # 置信度阈值
                    # 计算中心点
                    center_x = (item[2][0] + item[2][2]) / 2
                    center_y = (item[2][1] + item[2][3]) / 2
                    center = (center_x, center_y)
                    # 添加：(类别, 置信度, 中心点, mask)
                    filtered.append((item[0], item[1], center, item[3]))

            return filtered
            
        except Exception as e:
            self.get_logger().error(f"图像处理错误: {e}")
            return []

    # ============ 修改：服务回调函数（集成LightGlue多点匹配）============
    def detectrequest_callback(self, request, response):
        """
        处理检测服务请求，使用LightGlue进行特征匹配和多点三角测量
        
        Args:
            request: 包含图像和目标名称的请求
            response: 返回3D坐标和状态
        """
        img0 = self.bridge.imgmsg_to_cv2(request.imagein, 'bgr8')
        img0 = cv2.flip(img0, -1)
        askedtarget = request.target  # 请求的目标名称
        response.s = 0  # 初始化状态为未找到
        
        _, width, _ = img0.shape
        half_width = width // 2

        # 把图像分为左右两部分
        img_l = img0[:, :half_width]
        img_r = img0[:, half_width:]

        t0 = time.time()
        
        # ============ YOLO分割检测 ============
        results_l = self.model.predict(source=img_l)[0]
        filtered_l = self.img_process(results_l)
        self.get_logger().info(f"server:左目完成图像预测,检测到 {len(filtered_l)} 个目标")

        results_r = self.model.predict(source=img_r)[0]
        filtered_r = self.img_process(results_r)
        self.get_logger().info(f"server:右目完成图像预测,检测到 {len(filtered_r)} 个目标")
        
        # ============ 匹配左右目标（基于类别）============
        targets_dict: Dict[Union[str, int], Tuple[float, Tuple[float], Tuple[float], np.ndarray, np.ndarray]] = {}
        
        # 格式：{类别ID: (置信度, 左中心, 右中心, 左mask, 右mask)}
        for clas, conf, center_l, mask_l in filtered_l:
            targets_dict[clas] = (conf, center_l, None, mask_l, None)
        
        for clas, conf, center_r, mask_r in filtered_r:
            if clas in targets_dict:
                targets_dict[clas] = (targets_dict[clas][0], 
                                     targets_dict[clas][1], 
                                     center_r, 
                                     targets_dict[clas][3], 
                                     mask_r)

        # ============ 遍历字典，使用LightGlue计算目标物的三维坐标 ============
        for clas in targets_dict:
            if self.names[int(clas)] == askedtarget:
                left_center = targets_dict[clas][1]
                right_center = targets_dict[clas][2]
                left_mask = targets_dict[clas][3]
                right_mask = targets_dict[clas][4]

                # 检查是否左右都检测到
                if left_center is not None and right_center is not None and \
                   left_mask is not None and right_mask is not None:
                    
                    # ============ 使用LightGlue进行多点匹配 ============
                    result_3d = self.multipoint_triangulation_with_lightglue(
                        img_l, img_r, 
                        left_mask, right_mask,
                        self.stereocams[request.stero].P1, 
                        self.stereocams[request.stero].P2
                    )
                    
                    if result_3d is not None:
                        x, y, z = result_3d
                        response.s = 1
                        response.x, response.y, response.z = x, y, z
                        self.get_logger().info(f"目标 {askedtarget} 3D坐标: ({x:.3f}, {y:.3f}, {z:.3f})")
                        break  # 找到目标后退出循环

        # ============ 发布可视化图像（保持不变）============
        img_l_plot = results_l.plot()
        img_r_plot = results_r.plot()
        img0_vis = np.hstack((img_l_plot, img_r_plot))
        img0_vis = np.array(img0_vis)
        data = self.bridge.cv2_to_imgmsg(img0_vis, encoding="bgr8")
        self.detectserveimg_pub.publish(data)

        if response.s == 1:
            self.get_logger().info("已检测到目标，用时: %.3fs" % (time.time() - t0))
        else:
            self.get_logger().info("未检测到目标，用时: %.3fs" % (time.time() - t0))

        return response

    # ============ 新增：使用LightGlue进行多点三角测量的核心函数 ============
    def multipoint_triangulation_with_lightglue(self, img_l, img_r, mask_l, mask_r, P1, P2):
        """
        使用LightGlue在mask区域内进行特征匹配，并通过多点三角测量计算鲁棒的3D坐标
        
        Args:
            img_l: 左目图像 (numpy array, BGR)
            img_r: 右目图像 (numpy array, BGR)
            mask_l: 左目mask (numpy array, 0-1二值图)
            mask_r: 右目mask (numpy array, 0-1二值图)
            P1: 左相机投影矩阵
            P2: 右相机投影矩阵
            
        Returns:
            (x, y, z): 3D坐标，如果失败返回None
        """
        try:
            # ============ Step 1: 预处理mask（腐蚀操作去除边缘噪声）============
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            mask_l_eroded = cv2.erode(mask_l.astype(np.uint8), kernel, iterations=2)
            mask_r_eroded = cv2.erode(mask_r.astype(np.uint8), kernel, iterations=2)
            
            # ============ Step 2: 转换图像格式为灰度图（LightGlue需要）============
            gray_l = cv2.cvtColor(img_l, cv2.COLOR_BGR2GRAY)
            gray_r = cv2.cvtColor(img_r, cv2.COLOR_BGR2GRAY)
            
            # 转换为torch张量 [1, 1, H, W]，归一化到[0,1]
            image_l = torch.from_numpy(gray_l).float()[None, None] / 255.0
            image_r = torch.from_numpy(gray_r).float()[None, None] / 255.0
            image_l = image_l.to(self.device)
            image_r = image_r.to(self.device)
            
            # ============ Step 3: 使用SuperPoint提取特征点 ============
            with torch.no_grad():
                feats_l = self.extractor.extract(image_l)
                feats_r = self.extractor.extract(image_r)
            
            # ============ Step 4: 过滤特征点（只保留mask内的点）============
            # feats包含keypoints [N, 2]和descriptors [N, D]
            kpts_l = feats_l['keypoints'][0].cpu().numpy()  # [N, 2]
            kpts_r = feats_r['keypoints'][0].cpu().numpy()
            
            # 检查哪些特征点在mask内
            valid_l = []
            for i, (x, y) in enumerate(kpts_l):
                if 0 <= int(y) < mask_l_eroded.shape[0] and 0 <= int(x) < mask_l_eroded.shape[1]:
                    if mask_l_eroded[int(y), int(x)] > 0:
                        valid_l.append(i)
            
            valid_r = []
            for i, (x, y) in enumerate(kpts_r):
                if 0 <= int(y) < mask_r_eroded.shape[0] and 0 <= int(x) < mask_r_eroded.shape[1]:
                    if mask_r_eroded[int(y), int(x)] > 0:
                        valid_r.append(i)
            
            if len(valid_l) < 5 or len(valid_r) < 5:
                self.get_logger().warn(f"mask内特征点不足: 左{len(valid_l)}个，右{len(valid_r)}个")
                return None
            
            # 过滤特征
            feats_l['keypoints'] = feats_l['keypoints'][:, valid_l, :]
            feats_l['descriptors'] = feats_l['descriptors'][:, valid_l, :]
            feats_r['keypoints'] = feats_r['keypoints'][:, valid_r, :]
            feats_r['descriptors'] = feats_r['descriptors'][:, valid_r, :]
            
            # ============ Step 5: 使用LightGlue进行匹配 ============
            with torch.no_grad():
                matches01 = self.matcher({'image0': feats_l, 'image1': feats_r})
            
            # 提取匹配结果
            matches = matches01['matches'][0].cpu().numpy()  # [M, 2]，每行是(idx_l, idx_r)
            valid_matches = matches[matches[:, 0] != -1]  # 过滤无效匹配
            
            if len(valid_matches) < 5:
                self.get_logger().warn(f"有效匹配点不足: {len(valid_matches)}个")
                return None
            
            self.get_logger().info(f"LightGlue匹配成功: {len(valid_matches)}个点对")
            
            # ============ Step 6: 提取匹配点坐标 ============
            kpts_l_matched = feats_l['keypoints'][0][valid_matches[:, 0]].cpu().numpy()
            kpts_r_matched = feats_r['keypoints'][0][valid_matches[:, 1]].cpu().numpy()
            
            # ============ Step 7: 多点三角测量 + RANSAC ============
            points_3d = []
            for pt_l, pt_r in zip(kpts_l_matched, kpts_r_matched):
                # 纵坐标对齐（使用平均值）
                avg_y = (pt_l[1] + pt_r[1]) / 2
                pt_l_aligned = np.array([pt_l[0], avg_y], dtype=np.float32).reshape(2, 1)
                pt_r_aligned = np.array([pt_r[0], avg_y], dtype=np.float32).reshape(2, 1)
                
                # 三角测量
                pt_4d = cv2.triangulatePoints(P1, P2, pt_l_aligned, pt_r_aligned)
                pt_3d = pt_4d[:3] / pt_4d[3]  # 归一化为笛卡尔坐标
                points_3d.append(pt_3d.flatten())
            
            points_3d = np.array(points_3d)  # [M, 3]
            
            # ============ Step 8: RANSAC剔除外点（基于深度一致性）============
            z_values = points_3d[:, 2]
            z_median = np.median(z_values)
            z_std = np.std(z_values)
            
            # 内点判定：距离中位数不超过2倍标准差
            inliers = np.abs(z_values - z_median) < 2.0 * z_std
            
            if np.sum(inliers) < 3:
                self.get_logger().warn(f"内点数量不足: {np.sum(inliers)}个")
                return None
            
            # ============ Step 9: 计算加权平均（内点）============
            inlier_points = points_3d[inliers]
            final_point = np.mean(inlier_points, axis=0)
            
            # 转换坐标系（与原代码保持一致）
            x = -float(final_point[0])
            y = -float(final_point[1])
            z = float(final_point[2])
            
            self.get_logger().info(f"多点测量成功: 使用{np.sum(inliers)}/{len(points_3d)}个内点")
            
            return (x, y, z)
            
        except Exception as e:
            self.get_logger().error(f"LightGlue多点三角测量失败: {e}")
            import traceback
            traceback.print_exc()
            return None


# ============ 修改：检测子进程（集成LightGlue）============
def detect_process(pipe, opt):
    """
    独立的检测进程，使用YOLOv8-seg + LightGlue进行目标检测和深度估计
    
    Args:
        pipe: 与主进程通信的管道
        opt: 命令行参数
    """
    # 初始化相机参数
    fsc = StereoCamera()
    dsc = StereoCamera()
    stereocams = {"front": fsc, "down": dsc}
    stereocams["front"].cal_parameters_init(opt.front_params[0])
    stereocams["down"].cal_parameters_init(opt.down_params[0])
    
    # ============ 修改：加载分割模型 ============
    model1 = YOLO(opt.weights)  # 需要使用seg模型
    device1 = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
    model1.to(device1)
    
    # ============ 新增：加载LightGlue模型 ============
    print("detect_process: 正在加载LightGlue模型...")
    extractor = SuperPoint(max_num_keypoints=512).eval().to(device1)
    matcher = LightGlue(features='superpoint').eval().to(device1)
    print("detect_process: LightGlue模型加载完成！")

    while True:
        img0, cam_type = pipe.recv()
        tar = Yolov8()

        try:
            print("detect_process: 开始处理图像")
            _, width, _ = img0.shape
            half_width = width // 2
            img_l = img0[:, :half_width]
            img_r = img0[:, half_width:]
            
            # ============ YOLO分割检测 ============
            print("detect_process: 开始YOLO分割推理...")
            results_l = model1.predict(source=img_l)[0]
            results_r = model1.predict(source=img_r)[0]
            
            # ============ 提取检测结果（包含mask）============
            clas_l = results_l.boxes.cls.tolist()
            conf_l = results_l.boxes.conf.tolist()
            point_l = results_l.boxes.xyxy.tolist()
            
            # 提取mask
            masks_l = []
            if results_l.masks is not None:
                for mask_tensor in results_l.masks.data:
                    mask_np = mask_tensor.cpu().numpy()
                    if mask_np.shape != results_l.orig_shape[:2]:
                        mask_np = cv2.resize(mask_np, 
                                           (results_l.orig_shape[1], results_l.orig_shape[0]),
                                           interpolation=cv2.INTER_NEAREST)
                    masks_l.append(mask_np)
            else:
                print("detect_process: 警告 - 未检测到mask，使用bbox生成")
                for bbox in point_l:
                    mask_np = np.zeros(results_l.orig_shape[:2], dtype=np.uint8)
                    x1, y1, x2, y2 = map(int, bbox)
                    mask_np[y1:y2, x1:x2] = 1
                    masks_l.append(mask_np)
            
            combined_l = list(zip(clas_l, conf_l, point_l, masks_l))
            filtered_l = []
            for item in combined_l:
                if item[1] >= 0.50:  # 置信度阈值
                    center_x = (item[2][0] + item[2][2]) / 2
                    center_y = (item[2][1] + item[2][3]) / 2
                    filtered_l.append((item[0], item[1], (center_x, center_y), item[3]))
            
            print(f"process: 左目完成图像预测，检测到 {len(filtered_l)} 个目标")

            # 右目同样处理
            clas_r = results_r.boxes.cls.tolist()
            conf_r = results_r.boxes.conf.tolist()
            point_r = results_r.boxes.xyxy.tolist()
            
            masks_r = []
            if results_r.masks is not None:
                for mask_tensor in results_r.masks.data:
                    mask_np = mask_tensor.cpu().numpy()
                    if mask_np.shape != results_r.orig_shape[:2]:
                        mask_np = cv2.resize(mask_np, 
                                           (results_r.orig_shape[1], results_r.orig_shape[0]),
                                           interpolation=cv2.INTER_NEAREST)
                    masks_r.append(mask_np)
            else:
                for bbox in point_r:
                    mask_np = np.zeros(results_r.orig_shape[:2], dtype=np.uint8)
                    x1, y1, x2, y2 = map(int, bbox)
                    mask_np[y1:y2, x1:x2] = 1
                    masks_r.append(mask_np)
            
            combined_r = list(zip(clas_r, conf_r, point_r, masks_r))
            filtered_r = []
            for item in combined_r:
                if item[1] >= 0.50:
                    center_x = (item[2][0] + item[2][2]) / 2
                    center_y = (item[2][1] + item[2][3]) / 2
                    filtered_r.append((item[0], item[1], (center_x, center_y), item[3]))
            
            print(f"process: 右目完成图像预测，检测到 {len(filtered_r)} 个目标")
            
            # ============ 匹配左右目标 ============
            targets_dict: Dict[Union[str, int], Tuple[float, Tuple[float], Tuple[float], np.ndarray, np.ndarray]] = {}
            
            for clas, conf, center_l, mask_l in filtered_l:
                targets_dict[clas] = (conf, center_l, None, mask_l, None)
            
            for clas, conf, center_r, mask_r in filtered_r:
                if clas in targets_dict:
                    targets_dict[clas] = (targets_dict[clas][0], 
                                         targets_dict[clas][1], 
                                         center_r, 
                                         targets_dict[clas][3], 
                                         mask_r)
            
            # 初始化状态
            tar.state = [0.0 for _ in range(13)]

            # ============ 遍历每个目标，使用LightGlue计算深度 ============
            for clas in targets_dict: 
                # 统计检测数量
                if targets_dict[clas][1] is not None or targets_dict[clas][2] is not None:
                    tar.state[int(clas)] += 1

                left_center = targets_dict[clas][1]
                right_center = targets_dict[clas][2]
                left_mask = targets_dict[clas][3]
                right_mask = targets_dict[clas][4]

                # 检查左右是否都检测到
                if left_center is not None and right_center is not None and \
                   left_mask is not None and right_mask is not None:
                    
                    # ============ 调用多点三角测量函数 ============
                    result_3d = multipoint_triangulation_lightglue(
                        img_l, img_r,
                        left_mask, right_mask,
                        stereocams[cam_type].P1,
                        stereocams[cam_type].P2,
                        extractor, matcher, device1
                    )
                    
                    if result_3d is not None:
                        x, y, z = result_3d
                        # 填充消息
                        tar.targets[int(clas)].tpos_inpic.x = round(left_center[0])
                        tar.targets[int(clas)].tpos_inpic.y = round(left_center[1])
                        tar.targets[int(clas)].tpos_inworld.x = x
                        tar.targets[int(clas)].tpos_inworld.y = y
                        tar.targets[int(clas)].tpos_inworld.z = z
                        print(f"process: 类别{int(clas)} 3D坐标: ({x:.3f}, {y:.3f}, {z:.3f})")
                    else:
                        print(f"process: 类别{int(clas)} 多点测量失败，跳过")
            
            # ============ 可视化结果 ============
            img_l_vis = results_l.plot()
            img_r_vis = results_r.plot()
            img0_vis = np.hstack((img_l_vis, img_r_vis))  # 图像二合一
            img0_vis = np.array(img0_vis)    
            img_msg = CvBridge().cv2_to_imgmsg(img0_vis, encoding="bgr8")

            pipe.send((tar, img_msg))

            print("detect_process: 图像处理完成")
            
        except CvBridgeError as e:
            print(f"detect_process: 图像转换错误: {e}")
        except Exception as e:
            print(f"detect_process: 目标检测错误: {e}")
            import traceback
            traceback.print_exc()


# ============ 新增：子进程使用的多点三角测量函数 ============
def multipoint_triangulation_lightglue(img_l, img_r, mask_l, mask_r, P1, P2, extractor, matcher, device):
    """
    使用LightGlue进行多点三角测量（子进程版本）
    
    参数和返回值与AiNode中的方法相同
    """
    try:
        # ============ mask预处理 ============
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        mask_l_eroded = cv2.erode(mask_l.astype(np.uint8), kernel, iterations=2)
        mask_r_eroded = cv2.erode(mask_r.astype(np.uint8), kernel, iterations=2)
        
        # ============ 转换为灰度图 ============
        gray_l = cv2.cvtColor(img_l, cv2.COLOR_BGR2GRAY)
        gray_r = cv2.cvtColor(img_r, cv2.COLOR_BGR2GRAY)
        
        # 转为torch张量
        image_l = torch.from_numpy(gray_l).float()[None, None] / 255.0
        image_r = torch.from_numpy(gray_r).float()[None, None] / 255.0
        image_l = image_l.to(device)
        image_r = image_r.to(device)
        
        # ============ 提取特征 ============
        with torch.no_grad():
            feats_l = extractor.extract(image_l)
            feats_r = extractor.extract(image_r)
        
        # ============ 过滤mask内的特征点 ============
        kpts_l = feats_l['keypoints'][0].cpu().numpy()
        kpts_r = feats_r['keypoints'][0].cpu().numpy()
        
        valid_l = []
        for i, (x, y) in enumerate(kpts_l):
            if 0 <= int(y) < mask_l_eroded.shape[0] and 0 <= int(x) < mask_l_eroded.shape[1]:
                if mask_l_eroded[int(y), int(x)] > 0:
                    valid_l.append(i)
        
        valid_r = []
        for i, (x, y) in enumerate(kpts_r):
            if 0 <= int(y) < mask_r_eroded.shape[0] and 0 <= int(x) < mask_r_eroded.shape[1]:
                if mask_r_eroded[int(y), int(x)] > 0:
                    valid_r.append(i)
        
        if len(valid_l) < 5 or len(valid_r) < 5:
            print(f"mask内特征点不足: 左{len(valid_l)}个，右{len(valid_r)}个")
            return None
        
        # 过滤特征
        feats_l['keypoints'] = feats_l['keypoints'][:, valid_l, :]
        feats_l['descriptors'] = feats_l['descriptors'][:, valid_l, :]
        feats_r['keypoints'] = feats_r['keypoints'][:, valid_r, :]
        feats_r['descriptors'] = feats_r['descriptors'][:, valid_r, :]
        
        # ============ LightGlue匹配 ============
        with torch.no_grad():
            matches01 = matcher({'image0': feats_l, 'image1': feats_r})
        
        matches = matches01['matches'][0].cpu().numpy()
        valid_matches = matches[matches[:, 0] != -1]
        
        if len(valid_matches) < 5:
            print(f"有效匹配点不足: {len(valid_matches)}个")
            return None
        
        print(f"LightGlue匹配成功: {len(valid_matches)}个点对")
        
        # ============ 提取匹配点 ============
        kpts_l_matched = feats_l['keypoints'][0][valid_matches[:, 0]].cpu().numpy()
        kpts_r_matched = feats_r['keypoints'][0][valid_matches[:, 1]].cpu().numpy()
        
        # ============ 多点三角测量 ============
        points_3d = []
        for pt_l, pt_r in zip(kpts_l_matched, kpts_r_matched):
            # 纵坐标对齐
            avg_y = (pt_l[1] + pt_r[1]) / 2
            pt_l_aligned = np.array([pt_l[0], avg_y], dtype=np.float32).reshape(2, 1)
            pt_r_aligned = np.array([pt_r[0], avg_y], dtype=np.float32).reshape(2, 1)
            
            # 三角测量
            pt_4d = cv2.triangulatePoints(P1, P2, pt_l_aligned, pt_r_aligned)
            pt_3d = pt_4d[:3] / pt_4d[3]
            points_3d.append(pt_3d.flatten())
        
        points_3d = np.array(points_3d)
        
        # ============ RANSAC剔除外点 ============
        z_values = points_3d[:, 2]
        z_median = np.median(z_values)
        z_std = np.std(z_values)
        inliers = np.abs(z_values - z_median) < 2.0 * z_std
        
        if np.sum(inliers) < 3:
            print(f"内点数量不足: {np.sum(inliers)}个")
            return None
        
        # ============ 加权平均 ============
        inlier_points = points_3d[inliers]
        final_point = np.mean(inlier_points, axis=0)
        
        # 坐标转换
        x = -float(final_point[0])
        y = -float(final_point[1])
        z = float(final_point[2])
        
        print(f"多点测量成功: 使用{np.sum(inliers)}/{len(points_3d)}个内点")
        
        return (x, y, z)
        
    except Exception as e:
        print(f"LightGlue多点三角测量失败: {e}")
        import traceback
        traceback.print_exc()
        return None


# ============ main函数（保持不变）============
import rclpy
from rclpy.node import Node
import argparse
from multiprocessing import Pipe, Process
import sys

def main(args=None):
    # 过滤ROS 2自动添加的参数
    ros_args = rclpy.utilities.remove_ros_args(sys.argv)
    
    # 解析自定义参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str,
                        default='/home/nvidia/Workspace/Cruise/datas/AUV2025V1.pt', 
                        help='子进程检测模型路径（建议使用seg模型）')
    parser.add_argument('--weights2', nargs='+', type=str,
                        default='/home/nvidia/Workspace/Cruise/datas/AUV2025V1.pt', 
                        help='服务检测模型路径（建议使用seg模型）')
    parser.add_argument('--show-img', type=bool,
                        default=True, help='是否展示图像')
    parser.add_argument('--front-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/front.npz'], 
                        help='前置摄像头参数存储路径')
    parser.add_argument('--down-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/down.npz'], 
                        help='下置摄像头参数存储路径')

    opt = parser.parse_args(ros_args[1:])

    # 初始化ROS 2节点
    rclpy.init(args=args)

    # 创建双进程通信管道
    parent_conn_1, child_conn_1 = Pipe()
    parent_conn_2, child_conn_2 = Pipe()
    
    # 启动检测子进程
    p_1 = Process(target=detect_process, args=(child_conn_1, opt))
    p_2 = Process(target=detect_process, args=(child_conn_2, opt))
    p_1.start()
    p_2.start()

    # 启动主节点
    node = AiNode("uv_detect_demo", opt, parent_conn_1, parent_conn_2)
    rclpy.spin(node)
    rclpy.shutdown()

    # 进程清理
    p_1.join()
    p_2.join()

===== .\uv_ai\uv_ai\uv_segment.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image
import torch
from ultralytics import YOLO
import cv2
import numpy as np
import argparse
import sys


class SegmentNode(Node):
    def __init__(self, name, opt):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)

        # 初始化CVBridge
        self.bridge = CvBridge()

        # 初始化模型
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.model = YOLO(opt.weights)
        self.model.to(self.device)

        # 订阅话题
        self.create_subscription(
            Image, 'down_cam/rectified/left', self.img_callback, 10)

        # 创建话题发布器，用于发布分割结果
        self.segment_img_pub = self.create_publisher(
            Image, 'segment_img', 10)

        # 创建话题发布器，用于发布二值化后的分割结果
        self.binary_segment_img_pub = self.create_publisher(
            Image, 'binary_segment_img', 10)

    def img_callback(self, msg):
        self.get_logger().info("接收到下视左相机图像信息。")
        try:
            # 将ROS图像消息转换为OpenCV图像
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            if cv_image is None:
                self.get_logger().error("bridge.imgmsg_to_cv2 returned None")
                return

            # 进行语义分割
            results = self.model(cv_image)[0]

            if results.masks is not None:
                # 创建红色掩码图像
                red_mask = np.zeros_like(cv_image, dtype=np.uint8)
                binary_mask = np.zeros((cv_image.shape[0], cv_image.shape[1]), dtype=np.uint8)

                # 叠加每个掩码
                for mask in results.masks.data.cpu().numpy():
                    mask = cv2.resize(mask, (cv_image.shape[1], cv_image.shape[0]))  # 确保掩码尺寸匹配
                    mask = mask.astype(np.uint8)
                    binary_mask = cv2.bitwise_or(binary_mask, mask)
                    red_overlay = np.zeros_like(cv_image, dtype=np.uint8)
                    red_overlay[:, :, 2] = mask * 255
                    red_mask = cv2.addWeighted(red_mask, 1, red_overlay, 0.5, 0)

                # 将原始图像和红色掩码图像叠加
                overlay_image = cv2.addWeighted(cv_image, 1, red_mask, 0.5, 0)

                # 将二值化后的分割结果转换为ROS图像消息
                binary_image_msg = self.bridge.cv2_to_imgmsg(binary_mask * 255, "mono8")

                # 将带透明红色掩码的图像转换为ROS图像消息
                overlay_image_msg = self.bridge.cv2_to_imgmsg(overlay_image, "bgr8")

                # 发布带透明红色掩码的分割结果
                self.segment_img_pub.publish(overlay_image_msg)

                # 发布二值化后的分割结果
                self.binary_segment_img_pub.publish(binary_image_msg)
                self.get_logger().info("发布分割结果")
            else:
                self.get_logger().info("未检测到对象或分割结果。")

        except CvBridgeError as e:
            self.get_logger().error(f"CvBridge错误: {e}")
        except Exception as e:
            self.get_logger().error(f"错误: {e}")

def main(args=None):

    ros_args = rclpy.utilities.remove_ros_args(sys.argv)
    
    # 解析自定义参数（使用过滤后的参数列表）
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str,
                        default='/home/nvidia/Workspace/Cruise/datas/redline-7-2.pt', help='model.pt路径')

    # 注意：解析时跳过脚本名本身（ros_args[0]是脚本名）
    opt = parser.parse_args(ros_args[1:])

    # 初始化ROS 2节点（保持原逻辑）
    rclpy.init(args=args)
    node = SegmentNode("uv_segment", opt)
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()


===== .\uv_control_py\package.xml =====
功能: 代码摘录
<?xml version="1.0"?>
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
<package format="3">
  <name>uv_control_py</name>
  <version>0.0.0</version>
  <description>TODO: Package description</description>
  <maintainer email="macabaka@todo.todo">macabaka</maintainer>
  <license>TODO: License declaration</license>

  <depend>rclpy</depend>

  <test_depend>ament_copyright</test_depend>
  <test_depend>ament_flake8</test_depend>
  <test_depend>ament_pep257</test_depend>
  <test_depend>python3-pytest</test_depend>

  <export>
    <build_type>ament_python</build_type>
  </export>
</package>

===== .\uv_control_py\setup.cfg =====
功能: 代码摘录
[develop]
script-dir=$base/lib/uv_control_py
[install]
install-scripts=$base/lib/uv_control_py

===== .\uv_control_py\setup.py =====
功能: 代码摘录
from setuptools import setup

package_name = 'uv_control_py'

setup(
    name=package_name,
    version='0.0.0',
    packages=[package_name],
    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),
        ('share/' + package_name, ['package.xml']),
    ],
    install_requires=['setuptools'],
    zip_safe=True,
    maintainer='macabaka',
    maintainer_email='macabaka@todo.todo',
    description='TODO: Package description',
    license='TODO: License declaration',
    tests_require=['pytest'],
    entry_points={
        'console_scripts': [
        ],
    },
)

===== .\uv_control_py\test\test_copyright.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_copyright.main import main
import pytest


@pytest.mark.copyright
@pytest.mark.linter
def test_copyright():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found errors'

===== .\uv_control_py\test\test_flake8.py =====
功能: 代码摘录
# Copyright 2017 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_flake8.main import main_with_errors
import pytest


@pytest.mark.flake8
@pytest.mark.linter
def test_flake8():
    rc, errors = main_with_errors(argv=[])
    assert rc == 0, \
        'Found %d code style errors / warnings:\n' % len(errors) + \
        '\n'.join(errors)

===== .\uv_control_py\test\test_pep257.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_pep257.main import main
import pytest


@pytest.mark.linter
@pytest.mark.pep257
def test_pep257():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found code style errors / warnings'

===== .\uv_control_py\uv_control_py\__init__.py =====
功能: 代码摘录

===== .\uv_control_py\uv_control_py\CoordinateSystem.py =====
功能: 代码摘录
from math import sin,cos,atan2,asin
from uv_msgs.msg import RobotAxis

PI = 3.141592653589793238462643383279502884197169
DEG2RAD = PI/180
RAD2DEG = 180/PI

def AngleCorrect(angle ):
    if angle > 180 :
        cnt = int((angle+180)/ 360)
        angle -= cnt * 360
    if angle < -180 :
        cnt = int((angle - 180)/ 360)
        angle -= cnt * 360
    return angle

def MatrixInverse(input ):
    matrix = [[0.0 for _ in range(8)] for _ in range(4)]
    result = [0]*16
    
    # 初始化增广矩阵
    for i in range(4):
        for  j in range(4):
            matrix[i][j]     = input[i * 4 + j]
            matrix[i][j + 4] =  1.0 if (i == j) else 0.0

    # 消元过程
    for i in range(4):
        # 如果当前行的对角线元素为0，则需要进行行交换
        if matrix[i][i] == 0:
            row = i + 1
            while row < 4 and matrix[row][i] == 0: 
                row += 1

            # 如果找到了非零元素的行，则进行交换
            if row < 4:
                for j in range(8): 
                    temp = matrix[i][j]
                    matrix[i][j] = matrix[row][j]
                    matrix[row][j] = temp

        # 将对角线元素调整为1
        scale = matrix[i][i]
        for j in range(8):  
            matrix[i][j] /= scale

        # 消元
        for j in range(4):  
            if j != i:
                factor = matrix[j][i]
                for k in range(8):  
                    matrix[j][k] -= factor * matrix[i][k]
                    
    # 提取逆矩阵部分
    for i in range(4):
        for j in range(4): 
            result[i * 4 + j] = matrix[i][j + 4]
            
    return result

def MatrixMultiply(m1  ,m2 ):
    if len(m1) != 16 or len(m2) != 16:
            raise ValueError("Input matrices must be represented as 4x4 lists (length 16).")

    result = [0.0]*16

    for i in range(4):
        for j in range(4):
            result[i * 4 + j] = sum(m1[i * 4 + k] * m2[k * 4 + j] for k in range(4))

    return result

class MotionState:
    def __init__(self):
        self.vector = RobotAxis()
        self.h_matrix = [0]*16
        
    def extract(self):
        Sx = sin(self.vector.rx * DEG2RAD)
        Cx = cos(self.vector.rx * DEG2RAD)
        Sy = sin(self.vector.ry * DEG2RAD)
        Cy = cos(self.vector.ry * DEG2RAD)
        Sz = sin(self.vector.rz * DEG2RAD)
        Cz = cos(self.vector.rz * DEG2RAD)
        
        # 矩阵计算
        self.h_matrix[0] = Cy * Cz
        self.h_matrix[1] = Sx * Sy * Cz - Cx * Sz
        self.h_matrix[2] = Cx * Sy * Cz + Sx * Sz
        self.h_matrix[3] = self.vector.x

        self.h_matrix[4] = Cy * Sz
        self.h_matrix[5] = Sx * Sy * Sz + Cx * Cz
        self.h_matrix[6] = Cx * Sy * Sz - Sx * Cz
        self.h_matrix[7] = self.vector.y

        self.h_matrix[8]  = -Sy
        self.h_matrix[9]  = Sx * Cy
        self.h_matrix[10] = Cx * Cy
        self.h_matrix[11] = self.vector.z

        self.h_matrix[12] = 0.0
        self.h_matrix[13] = 0.0
        self.h_matrix[14] = 0.0
        self.h_matrix[15] = 1.0
        
    def r_extract(self):
        self.vector.x = self.h_matrix[3]
        self.vector.y = self.h_matrix[7]
        self.vector.z = self.h_matrix[11]
        
        rx1 = rx2 = 0.0
        ry1 = ry2 = 0.0
        
        if self.h_matrix[8] != 1.0 or self.h_matrix[8] != -1.0: # 若越界，放弃更新
    
            ry1 = -asin(self.h_matrix[8]) 
            ry2 = PI - ry1 

            rx1 = atan2(self.h_matrix[9] / cos(ry1), self.h_matrix[10] / cos(ry1)) 
            rx2 = atan2(self.h_matrix[9] / cos(ry2), self.h_matrix[10] / cos(ry2)) 

            if ry1 < PI / 2 and ry1 > -PI / 2:
                self.vector.ry = ry1 * RAD2DEG
            if ry2 < PI / 2 and ry2 > -PI / 2:
                self.vector.ry = ry2 * RAD2DEG

            if rx1 < PI / 2 and rx1 > -PI / 2:
                self.vector.rx = rx1 * RAD2DEG
            if rx2 < PI / 2 and rx2 > -PI / 2:
                self.vector.rx = rx2 * RAD2DEG

            # if (rz1 < PI and rz1 > -PI)
            self.vector.rz = atan2(self.h_matrix[4] / cos(self.vector.ry * DEG2RAD),
                                   self.h_matrix[0] / cos(self.vector.ry * DEG2RAD)) * RAD2DEG 
            # if (rz2 < PI and rz2 > -PI)
            #     self.vector.rz = rz2 * RAD2DEG 
    
class CoordinateSystems:
    def __init__(self):
        self.base = MotionState()
        self.target_inbase = MotionState()        
        self.target_inworld = MotionState()    
        
    def world2base(self):
        self.base.extract()
        self.target_inworld.extract()
        
        mat =  MatrixInverse(self.base.h_matrix)
        self.target_inbase.h_matrix = MatrixMultiply(mat,self.target_inworld.h_matrix)
        
        self.target_inbase.r_extract()
        
        return self.target_inbase
    
    def base2world(self):
        self.base.extract()
        self.target_inbase.extract()
        
        self.target_inworld.h_matrix = MatrixMultiply(self.base.h_matrix,self.target_inbase.h_matrix)
        
        self.target_inworld.r_extract()
        
        return self.target_inworld
        
def Cs_Move(raw ,move):
    raw.extract()
    move.extract()
    
    result = MotionState()
    
    result.h_matrix = MatrixMultiply(move.h_matrix,raw.h_matrix)
    
    result.r_extract()
    
    return result
    
def Cs_Back(raw ,back):
    raw.extract()
    back.extract()
    
    result = MotionState()
    
    mat = MatrixInverse(back.h_matrix)
    result.h_matrix = MatrixMultiply(mat,raw.h_matrix)
    
    result.r_extract()
    
    return result

===== .\uv_control_py\uv_control_py\Curve.py =====
功能: 代码摘录
import time
import struct
import json

from uv_msgs.msg import ThrustCurve
from uv_msgs.msg import ThrustCurves

from uv_control_py import Serial

# 养了一只猫猫，路过的人可以摸摸她
# 　／l、
# （ﾟ､ 。 ７
# 　l、 ~ヽ
# 　じしf_, )ノ

GET_NAME = [
    "m0",
    "m1",
    "m2",
    "m3",
    "m4",
    "m5"
]

CURVE_DIC_INIT = {
    "m0": {
        "np_mid": 2500.0,
        "np_ini": 3000.0,
        "pp_ini": 3000.0,
        "pp_mid": 3500.0,

        "nt_end": -1500.0,
        "nt_mid": -750.0,
        "pt_mid": 750.0,
        "pt_end": 1500.0,

        "name": "m0",
        "num": 0
    },
    "m1": {
        "np_mid": 2500.0,
        "np_ini": 3000.0,
        "pp_ini": 3000.0,
        "pp_mid": 3500.0,

        "nt_end": -1500.0,
        "nt_mid": -750.0,
        "pt_mid": 750.0,
        "pt_end": 1500.0,

        "name": "m1",
        "num": 1

    },
    "m2": {
        "np_mid": 2500.0,
        "np_ini": 3000.0,
        "pp_ini": 3000.0,
        "pp_mid": 3500.0,

        "nt_end": -1500.0,
        "nt_mid": -750.0,
        "pt_mid": 750.0,
        "pt_end": 1500.0,

        "name": "m2",
        "num": 2

    },
    "m3": {
        "np_mid": 2500.0,
        "np_ini": 3000.0,
        "pp_ini": 3000.0,
        "pp_mid": 3500.0,

        "nt_end": -1500.0,
        "nt_mid": -750.0,
        "pt_mid": 750.0,
        "pt_end": 1500.0,

        "name": "m3",
        "num": 3

    },
    "m4": {
        "np_mid": 2500.0,
        "np_ini": 3000.0,
        "pp_ini": 3000.0,
        "pp_mid": 3500.0,

        "nt_end": -1500.0,
        "nt_mid": -750.0,
        "pt_mid": 750.0,
        "pt_end": 1500.0,

        "name": "m4",
        "num": 4

    },
    "m5": {
        "np_mid": 2500.0,
        "np_ini": 3000.0,
        "pp_ini": 3000.0,
        "pp_mid": 3500.0,

        "nt_end": -1500.0,
        "nt_mid": -750.0,
        "pt_mid": 750.0,
        "pt_end": 1500.0,

        "name": "m5",
        "num": 5
    }
}


class CURVE:
    def __init__(self, tty, save_path):

        self.curves = ThrustCurves()
        self.curves_dic = CURVE_DIC_INIT

        self.curves.m0.num = 0
        self.curves.m1.num = 1
        self.curves.m2.num = 2
        self.curves.m3.num = 3
        self.curves.m4.num = 4
        self.curves.m5.num = 5

        self.path = save_path
        self.tty_writer = tty

        # 读取储存的信息
        self.fileread()

    def dic2class(self):
        self.curves.m0.np_mid = self.curves_dic["m0"]["np_mid"]
        self.curves.m0.np_ini = self.curves_dic["m0"]["np_ini"]
        self.curves.m0.pp_ini = self.curves_dic["m0"]["pp_ini"]
        self.curves.m0.pp_mid = self.curves_dic["m0"]["pp_mid"]
        self.curves.m0.nt_end = self.curves_dic["m0"]["nt_end"]
        self.curves.m0.nt_mid = self.curves_dic["m0"]["nt_mid"]
        self.curves.m0.pt_mid = self.curves_dic["m0"]["pt_mid"]
        self.curves.m0.pt_end = self.curves_dic["m0"]["pt_end"]

        self.curves.m1.np_mid = self.curves_dic["m1"]["np_mid"]
        self.curves.m1.np_ini = self.curves_dic["m1"]["np_ini"]
        self.curves.m1.pp_ini = self.curves_dic["m1"]["pp_ini"]
        self.curves.m1.pp_mid = self.curves_dic["m1"]["pp_mid"]
        self.curves.m1.nt_end = self.curves_dic["m1"]["nt_end"]
        self.curves.m1.nt_mid = self.curves_dic["m1"]["nt_mid"]
        self.curves.m1.pt_mid = self.curves_dic["m1"]["pt_mid"]
        self.curves.m1.pt_end = self.curves_dic["m1"]["pt_end"]

        self.curves.m2.np_mid = self.curves_dic["m2"]["np_mid"]
        self.curves.m2.np_ini = self.curves_dic["m2"]["np_ini"]
        self.curves.m2.pp_ini = self.curves_dic["m2"]["pp_ini"]
        self.curves.m2.pp_mid = self.curves_dic["m2"]["pp_mid"]
        self.curves.m2.nt_end = self.curves_dic["m2"]["nt_end"]
        self.curves.m2.nt_mid = self.curves_dic["m2"]["nt_mid"]
        self.curves.m2.pt_mid = self.curves_dic["m2"]["pt_mid"]
        self.curves.m2.pt_end = self.curves_dic["m2"]["pt_end"]

        self.curves.m3.np_mid = self.curves_dic["m3"]["np_mid"]
        self.curves.m3.np_ini = self.curves_dic["m3"]["np_ini"]
        self.curves.m3.pp_ini = self.curves_dic["m3"]["pp_ini"]
        self.curves.m3.pp_mid = self.curves_dic["m3"]["pp_mid"]
        self.curves.m3.nt_end = self.curves_dic["m3"]["nt_end"]
        self.curves.m3.nt_mid = self.curves_dic["m3"]["nt_mid"]
        self.curves.m3.pt_mid = self.curves_dic["m3"]["pt_mid"]
        self.curves.m3.pt_end = self.curves_dic["m3"]["pt_end"]

        self.curves.m4.np_mid = self.curves_dic["m4"]["np_mid"]
        self.curves.m4.np_ini = self.curves_dic["m4"]["np_ini"]
        self.curves.m4.pp_ini = self.curves_dic["m4"]["pp_ini"]
        self.curves.m4.pp_mid = self.curves_dic["m4"]["pp_mid"]
        self.curves.m4.nt_end = self.curves_dic["m4"]["nt_end"]
        self.curves.m4.nt_mid = self.curves_dic["m4"]["nt_mid"]
        self.curves.m4.pt_mid = self.curves_dic["m4"]["pt_mid"]
        self.curves.m4.pt_end = self.curves_dic["m4"]["pt_end"]

        self.curves.m5.np_mid = self.curves_dic["m5"]["np_mid"]
        self.curves.m5.np_ini = self.curves_dic["m5"]["np_ini"]
        self.curves.m5.pp_ini = self.curves_dic["m5"]["pp_ini"]
        self.curves.m5.pp_mid = self.curves_dic["m5"]["pp_mid"]
        self.curves.m5.nt_end = self.curves_dic["m5"]["nt_end"]
        self.curves.m5.nt_mid = self.curves_dic["m5"]["nt_mid"]
        self.curves.m5.pt_mid = self.curves_dic["m5"]["pt_mid"]
        self.curves.m5.pt_end = self.curves_dic["m5"]["pt_end"]

    def topicrec(self, data):
        self.curves_dic[GET_NAME[data.num]]["np_mid"] = data.np_mid
        self.curves_dic[GET_NAME[data.num]]["np_ini"] = data.np_ini
        self.curves_dic[GET_NAME[data.num]]["pp_ini"] = data.pp_ini
        self.curves_dic[GET_NAME[data.num]]["pp_mid"] = data.pp_mid
        self.curves_dic[GET_NAME[data.num]]["nt_end"] = data.nt_end
        self.curves_dic[GET_NAME[data.num]]["nt_mid"] = data.nt_mid
        self.curves_dic[GET_NAME[data.num]]["pt_mid"] = data.pt_mid
        self.curves_dic[GET_NAME[data.num]]["pt_end"] = data.pt_end
        self.dic2class()
        

    def hwinit(self):
        # M0
        buff = b"\xfa\xaf\x07" \
            + struct.pack("<Bffffffff",self.curves.m0.num ,
                          self.curves.m0.np_mid, self.curves.m0.np_ini,
                          self.curves.m0.pp_ini, self.curves.m0.pp_mid,
                          self.curves.m0.nt_end, self.curves.m0.nt_mid,
                          self.curves.m0.pt_mid, self.curves.m0.pt_end) +b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.05)
        # M1
        buff = b"\xfa\xaf\x07" \
            + struct.pack("<Bffffffff",self.curves.m1.num ,
                          self.curves.m1.np_mid, self.curves.m1.np_ini,
                          self.curves.m1.pp_ini, self.curves.m1.pp_mid,
                          self.curves.m1.nt_end, self.curves.m1.nt_mid,
                          self.curves.m1.pt_mid, self.curves.m1.pt_end) +b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.05)
        # M2
        buff = b"\xfa\xaf\x07" \
            + struct.pack("<Bffffffff",self.curves.m2.num ,
                          self.curves.m2.np_mid, self.curves.m2.np_ini,
                          self.curves.m2.pp_ini, self.curves.m2.pp_mid,
                          self.curves.m2.nt_end, self.curves.m2.nt_mid,
                          self.curves.m2.pt_mid, self.curves.m2.pt_end) +b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.05)
        # M3
        buff = b"\xfa\xaf\x07" \
            + struct.pack("<Bffffffff",self.curves.m3.num ,
                          self.curves.m3.np_mid, self.curves.m3.np_ini,
                          self.curves.m3.pp_ini, self.curves.m3.pp_mid,
                          self.curves.m3.nt_end, self.curves.m3.nt_mid,
                          self.curves.m3.pt_mid, self.curves.m3.pt_end) +b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.05)
        # M4
        buff = b"\xfa\xaf\x07" \
            + struct.pack("<Bffffffff",self.curves.m4.num ,
                          self.curves.m4.np_mid, self.curves.m4.np_ini,
                          self.curves.m4.pp_ini, self.curves.m4.pp_mid,
                          self.curves.m4.nt_end, self.curves.m4.nt_mid,
                          self.curves.m4.pt_mid, self.curves.m4.pt_end) +b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.05)
        # M5
        buff = b"\xfa\xaf\x07" \
            + struct.pack("<Bffffffff",self.curves.m5.num ,
                          self.curves.m5.np_mid, self.curves.m5.np_ini,
                          self.curves.m5.pp_ini, self.curves.m5.pp_mid,
                          self.curves.m5.nt_end, self.curves.m5.nt_mid,
                          self.curves.m5.pt_mid, self.curves.m5.pt_end) +b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.05)


    def fileread(self):
        with open(self.path, 'r', encoding='utf-8') as file:
            self.curves_dic = json.load(file)
            self.dic2class()

    def filesave(self):
        with open(self.path, 'w', encoding='utf-8') as file:
            json.dump(self.curves_dic, file)

===== .\uv_control_py\uv_control_py\Pid.py =====
功能: 代码摘录
import time
import struct
import json

from uv_msgs.msg import PidParams
from uv_msgs.msg import PidControllers

from uv_control_py import Serial

# 养了一只猫猫，路过的人可以摸摸她
# 　／l、
# （ﾟ､ 。 ７
# 　l、 ~ヽ
# 　じしf_, )ノ

PID_DIC_INIT = {
    "x": {
        "p": 0.0,
        "i": 0.0,
        "d": 0.0,
        "i_limit": 0.0,
        "output_limit": 0.0,
        "name": "x"
    },
    "y": {
        "p": 0.0,
        "i": 0.0,
        "d": 0.0,
        "i_limit": 0.0,
        "output_limit": 0.0,
        "name": "y"
    },
    "z": {
        "p": 0.0,
        "i": 0.0,
        "d": 0.0,
        "i_limit": 0.0,
        "output_limit": 0.0,
        "name": "z"
    },
    "rx": {
        "p": 0.0,
        "i": 0.0,
        "d": 0.0,
        "i_limit": 0.0,
        "output_limit": 0.0,
        "name": "rx"
    },
    "ry": {
        "p": 0.0,
        "i": 0.0,
        "d": 0.0,
        "i_limit": 0.0,
        "output_limit": 0.0,
        "name": "ry"
    },
    "rz": {
        "p": 0.0,
        "i": 0.0,
        "d": 0.0,
        "i_limit": 0.0,
        "output_limit": 0.0,
        "name": "rz"
    },
    "vx": {
        "p": 0.0,
        "i": 0.0,
        "d": 0.0,
        "i_limit": 0.0,
        "output_limit": 0.0,
        "name": "vx"
    },
    "vy": {
        "p": 0.0,
        "i": 0.0,
        "d": 0.0,
        "i_limit": 0.0,
        "output_limit": 0.0,
        "name": "vy"
    }
}


class PID:
    def __init__(self, tty, save_path):

        self.pid = PidControllers()

        self.pid.x.name = "x"
        self.pid.y.name = "y"
        self.pid.z.name = "z"
        self.pid.rx.name = "rx"
        self.pid.ry.name = "ry"
        self.pid.rz.name = "rz"
        
        self.pid.ry.name = "vx"
        self.pid.rz.name = "vy"

        self.path = save_path
        self.tty_writer = tty

        self.pid_dic = PID_DIC_INIT
        # 读取储存的信息
        self.fileread()

    def dic2class(self):
        self.pid.x.p = self.pid_dic["x"]["p"]
        self.pid.x.i = self.pid_dic["x"]["i"]
        self.pid.x.d = self.pid_dic["x"]["d"]
        self.pid.x.i_limit = self.pid_dic["x"]["i_limit"]
        self.pid.x.output_limit = self.pid_dic["x"]["output_limit"]

        self.pid.y.p = self.pid_dic["y"]["p"]
        self.pid.y.i = self.pid_dic["y"]["i"]
        self.pid.y.d = self.pid_dic["y"]["d"]
        self.pid.y.i_limit = self.pid_dic["y"]["i_limit"]
        self.pid.y.output_limit = self.pid_dic["y"]["output_limit"]

        self.pid.z.p = self.pid_dic["z"]["p"]
        self.pid.z.i = self.pid_dic["z"]["i"]
        self.pid.z.d = self.pid_dic["z"]["d"]
        self.pid.z.i_limit = self.pid_dic["z"]["i_limit"]
        self.pid.z.output_limit = self.pid_dic["z"]["output_limit"]

        self.pid.rx.p = self.pid_dic["rx"]["p"]
        self.pid.rx.i = self.pid_dic["rx"]["i"]
        self.pid.rx.d = self.pid_dic["rx"]["d"]
        self.pid.rx.i_limit = self.pid_dic["rx"]["i_limit"]
        self.pid.rx.output_limit = self.pid_dic["rx"]["output_limit"]

        self.pid.ry.p = self.pid_dic["ry"]["p"]
        self.pid.ry.i = self.pid_dic["ry"]["i"]
        self.pid.ry.d = self.pid_dic["ry"]["d"]
        self.pid.ry.i_limit = self.pid_dic["ry"]["i_limit"]
        self.pid.ry.output_limit = self.pid_dic["ry"]["output_limit"]

        self.pid.rz.p = self.pid_dic["rz"]["p"]
        self.pid.rz.i = self.pid_dic["rz"]["i"]
        self.pid.rz.d = self.pid_dic["rz"]["d"]
        self.pid.rz.i_limit = self.pid_dic["rz"]["i_limit"]
        self.pid.rz.output_limit = self.pid_dic["rz"]["output_limit"]
        
        self.pid.vx.p = self.pid_dic["vx"]["p"]
        self.pid.vx.i = self.pid_dic["vx"]["i"]
        self.pid.vx.d = self.pid_dic["vx"]["d"]
        self.pid.vx.i_limit = self.pid_dic["vx"]["i_limit"]
        self.pid.vx.output_limit = self.pid_dic["vx"]["output_limit"]

        self.pid.vy.p = self.pid_dic["vy"]["p"]
        self.pid.vy.i = self.pid_dic["vy"]["i"]
        self.pid.vy.d = self.pid_dic["vy"]["d"]
        self.pid.vy.i_limit = self.pid_dic["vy"]["i_limit"]
        self.pid.vy.output_limit = self.pid_dic["vy"]["output_limit"]

    def topicrec(self, data):
        self.pid_dic[data.name]["p"] = data.p
        self.pid_dic[data.name]["i"] = data.i
        self.pid_dic[data.name]["d"] = data.d
        self.pid_dic[data.name]["i_limit"] = data.i_limit
        self.pid_dic[data.name]["output_limit"] = data.output_limit
        self.dic2class()

    def hwinit(self):
        # X
        buff = b"\xfa\xaf\x05\x00" + \
            struct.pack("<fffff", self.pid.x.p,self.pid.x.i, 
                        self.pid.x.d, self.pid.x.i_limit,self.pid.x.output_limit)+b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.05)
        # Y
        buff = b"\xfa\xaf\x05\x01" + \
            struct.pack("<fffff", self.pid.y.p, self.pid.y.i,
                        self.pid.y.d, self.pid.y.i_limit,self.pid.y.output_limit)+b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.01)
        # Z
        buff = b"\xfa\xaf\x05\x02" + \
            struct.pack("<fffff", self.pid.z.p, self.pid.z.i,
                        self.pid.z.d, self.pid.z.i_limit,self.pid.z.output_limit)+b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.01)
        # RX
        buff = b"\xfa\xaf\x05\x03" + \
            struct.pack("<fffff", self.pid.rx.p,
                        self.pid.rx.i, self.pid.rx.d, self.pid.rx.i_limit,self.pid.rx.output_limit)+b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.01)
        # RY
        buff = b"\xfa\xaf\x05\x04" + \
            struct.pack("<fffff", self.pid.ry.p,
                        self.pid.ry.i, self.pid.ry.d, self.pid.ry.i_limit,self.pid.ry.output_limit)+b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.01)
        # RZ
        buff = b"\xfa\xaf\x05\x05" + \
            struct.pack("<fffff", self.pid.rz.p,
                        self.pid.rz.i, self.pid.rz.d, self.pid.rz.i_limit,self.pid.rz.output_limit)+b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.01)       
        # VX
        buff = b"\xfa\xaf\x05\x06" + \
            struct.pack("<fffff", self.pid.vx.p,
                        self.pid.vx.i, self.pid.vx.d, self.pid.vx.i_limit,self.pid.vx.output_limit)+b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.01)

        # VY
        buff = b"\xfa\xaf\x05\x07" + \
            struct.pack("<fffff", self.pid.vy.p,
                        self.pid.vy.i, self.pid.vy.d, self.pid.vy.i_limit,self.pid.vy.output_limit)+b"\xfb\xbf"
        self.tty_writer.write(buff)
        time.sleep(0.01)

    def fileread(self):
        with open(self.path, 'r', encoding='utf-8') as file:
            self.pid_dic = json.load(file)
            self.dic2class()

    def filesave(self):
        with open(self.path, 'w', encoding='utf-8') as file:
            json.dump(self.pid_dic, file)

===== .\uv_control_py\uv_control_py\Serial.py =====
功能: 代码摘录
from rclpy.node import Node
import os
import termios


# magic number for uart
SETTINGS = [
    0, 0, 6322, 0, 4098, 4098,
    [
        b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', 1, 254, b'\x00', b'\x00', b'\x00', b'\x00', b'\x00',
        b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00',
        b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00', b'\x00'
    ]
]

# 养了一只猫猫，路过的人可以摸摸她
# 　／l、
# （ﾟ､ 。 ７
# 　l、 ~ヽ
# 　じしf_, )ノ


class TtyReader:  # 读串口

    def __init__(self, path):
        self.tty_dev = open(path, 'rb')
        termios.tcsetattr(self.tty_dev.fileno(), termios.TCSANOW, SETTINGS)
        self.name = path

    def read(self, length):
        try:
            buff = os.read(self.tty_dev.fileno(), length)
            return True, buff
        except:
            # print("uart read failed")
            return False, b"\x00"

    def close(self):
        try:
            self.tty_dev.close()
        except:
            print("uart has been already closed")

    def __del__(self):
        try:
            self.tty_dev.close()
        except:
            print("uart has been already closed")


class TtyWriter:  # 写串口

    def __init__(self, path):
        self.tty_dev = open(path, 'w')
        termios.tcsetattr(self.tty_dev.fileno(), termios.TCSANOW, SETTINGS)

    def write(self, data):
        try:
            os.write(self.tty_dev.fileno(), data)
            return True
        except:
            # print("uart writed failed")
            return False

    def close(self):
        try:
            self.tty_dev.close()
        except:
            print("uart has been already closed")

    def __del__(self):
        try:
            self.tty_dev.close()
        except:
            print("uart has been already closed")

===== .\uv_hm\package.xml =====
功能: 代码摘录
<?xml version="1.0"?>
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
<package format="3">
  <name>uv_hm</name>
  <version>0.0.0</version>
  <description>TODO: Package description</description>
  <maintainer email="macabaka@todo.todo">macabaka</maintainer>
  <license>TODO: License declaration</license>

  <depend>rclpy</depend>

  <test_depend>ament_copyright</test_depend>
  <test_depend>ament_flake8</test_depend>
  <test_depend>ament_pep257</test_depend>
  <test_depend>python3-pytest</test_depend>

  <export>
    <build_type>ament_python</build_type>
  </export>
</package>

===== .\uv_hm\setup.cfg =====
功能: 代码摘录
[develop]
script_dir=$base/lib/uv_hm
[install]
install_scripts=$base/lib/uv_hm

===== .\uv_hm\setup.py =====
功能: 代码摘录
from setuptools import setup

package_name = 'uv_hm'

setup(
    name=package_name,
    version='0.0.0',
    packages=[package_name],
    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),
        ('share/' + package_name, ['package.xml']),
    ],
    install_requires=['setuptools'],
    zip_safe=True,
    maintainer='macabaka',
    maintainer_email='macabaka@todo.todo',
    description='TODO: Package description',
    license='TODO: License declaration',
    tests_require=['pytest'],
    entry_points={
        'console_scripts': [
            "uv_hmu = uv_hm.uv_hmu:main",
            "uv_web_pannel = uv_hm.uv_web_pannel:main",
        ],
    },
)

===== .\uv_hm\test\test_copyright.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_copyright.main import main
import pytest


# Remove the `skip` decorator once the source file(s) have a copyright header
@pytest.mark.skip(reason='No copyright header has been placed in the generated source file.')
@pytest.mark.copyright
@pytest.mark.linter
def test_copyright():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found errors'

===== .\uv_hm\test\test_flake8.py =====
功能: 代码摘录
# Copyright 2017 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_flake8.main import main_with_errors
import pytest


@pytest.mark.flake8
@pytest.mark.linter
def test_flake8():
    rc, errors = main_with_errors(argv=[])
    assert rc == 0, \
        'Found %d code style errors / warnings:\n' % len(errors) + \
        '\n'.join(errors)

===== .\uv_hm\test\test_pep257.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_pep257.main import main
import pytest


@pytest.mark.linter
@pytest.mark.pep257
def test_pep257():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found code style errors / warnings'

===== .\uv_hm\uv_hm\__init__.py =====
功能: 代码摘录

===== .\uv_hm\uv_hm\uv_hmu.py =====
功能: 代码摘录
# 水下机器人硬件管理单元
# "Underwater Vehicle Hardware Management Unit


import rclpy
from rclpy.node import Node
import time
import os
import termios
import struct
import threading
import json
import argparse
import sys
import threading

from rclpy.utilities import remove_ros_args  # 导入ROS参数过滤工具

from uv_msgs.msg import RobotDeviceManager  # 机器人设备管理器
from uv_msgs.msg import RobotMotionController  # 机器人运动控制器


from uv_msgs.msg import PidParams
from uv_msgs.msg import PidControllers
from uv_msgs.msg import PidControllersState

from uv_msgs.msg import ThrustCurve
from uv_msgs.msg import ThrustCurves

from uv_msgs.msg import RobotAxis
from uv_msgs.msg import ServoSet
from uv_msgs.msg import TargetPosDown
from uv_msgs.msg import ImuData
from uv_msgs.msg import LedControllers
from uv_msgs.msg import MagnetController


from uv_control_py import Pid
from uv_control_py import Curve
from uv_control_py import Serial

#                               _ooOoo_
#                              o8888888o
#                              88" . "88
#                              (| -_- |)
#                               O\ = /O
#                           ____/`---'\____
#                         .   ' \\| |// `.
#                          / \\||| : |||// \
#                        / _||||| -:- |||||- \
#                          | | \\\ - /// | |
#                        | \_| ''\---/'' | |
#                        \ .-\__ `-` ___/-. /
#                    ___`. .' /--.--\ `. . __
#                  ."" '< `.___\_<|>_/___.' >'"".
#                 | | : `- \`.;`\ _ /`;.`/ - ` : | |
#                    \ \ `-. \_ __\ /__ _/ .-` / /
#           ======`-.____`-.___\_____/___.-`____.-'======
#                              `=---='
#
#           .............................................
#                     佛祖保佑             永无BUG


class CoreNode(Node):
    def __init__(self, name, h750tty, f407tty, pid_path, curve_path):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)

        self.MotionController = RobotMotionController()
        self.DeviceManager = RobotDeviceManager()

        # 话题发布
        # 创建话题发布 motion_controller ，定义其中的消息类型为 RobotMotionController
        self.motion_controller_pub = self.create_publisher(
            RobotMotionController, "motion_controller", 10)
        # 创建话题发布 device_manager ，定义其中的消息类型为 ImuData
        self.device_manager_pub = self.create_publisher(
            RobotDeviceManager, "device_manager", 10)

        # 创建话题发布 pid_controllers ，定义其中的消息类型为 PidParameters
        self.pid_controllers_pub = self.create_publisher(
            PidControllers, "pid_controllers", 10)
        # 创建话题发布 pid_controllers ，定义其中的消息类型为 PidParameters
        self.curves_pub = self.create_publisher(
            ThrustCurves, "curves", 10)

        # 话题接收
        # 创建话题接收 openloop_thrust ，定义其中的消息类型为 RobotAxis
        self.create_subscription(
            RobotAxis, 'openloop_thrust', self.openloop_thrust_callback, 10)
        # 创建话题接收 servo_control ，定义其中的消息类型为 ServoSet
        self.create_subscription(
            ServoSet, 'servo_control', self.servo_control_callback, 10)
        # 创建话题接收 pid_param_set ，定义其中的消息类型为 PidParams
        self.create_subscription(
            PidParams, 'pid_params_set', self.pid_params_set_callback, 10)
        # 创建话题接收 pid_controllers_set ，定义其中的消息类型为 PidControllersState
        self.create_subscription(
            PidControllersState, 'pid_controllers_set', self.pid_controllers_set_callback, 10)
        # 创建话题接收 target_pos_down ，定义其中的消息类型为 TargetPosDown
        self.create_subscription(
            TargetPosDown, 'target_pos_down', self.target_pos_down_callback, 10)
        # 创建话题接收 dvl_set ，定义其中的消息类型为 ImuData
        self.create_subscription(
            ImuData, 'dvl_set', self.dvl_set_callback, 10)
        # 创建话题接收 thrust_curve_set ，定义其中的消息类型为 ThrustCurve
        self.create_subscription(
            ThrustCurve, 'thrust_curve_set', self.thrust_curve_set_callback, 10)
        # 创建话题接收 Target_speed_down ，定义其中的消息类型为 TargetPosDown
        self.create_subscription(
            TargetPosDown, 'Target_speed_down', self.target_speed_down_callback, 10)
        #创建话题接收 led_controllers , 定义其中的消息类型为 LedControllers
        self.create_subscription(
            LedControllers, 'led_controllers', self.led_controllers_callback, 10)
        # 创建话题接收 magnet_controller ，定义其中的消息类型为 MagnetController
        self.create_subscription(
            MagnetController, 'magnet_controller', self.magnet_controller_callback, 10)           


        # 对F407读写
        self.usb0_reader = Serial.TtyReader(f407tty)
        self.usb0_writer = Serial.TtyWriter(f407tty)
        # 对H743读写
        self.usb1_reader = Serial.TtyReader(h750tty)
        self.usb1_writer = Serial.TtyWriter(h750tty)
        # pid参数
        self.pid = Pid.PID(self.usb1_writer, pid_path)
        # 推力曲线
        self.curve = Curve.CURVE(self.usb1_writer, curve_path)

    def openloop_thrust_callback(self, data):
        buff = b"\xfa\xaf\x02" + \
            struct.pack("<ffffff", data.x, data.y, data.z,
                        data.rx, data.ry, data.rz)+b"\xfb\xbf"
        self.usb1_writer.write(buff)

    def servo_control_callback(self, data):
        if data.angle > 1:
            data.angle = 1.0
        elif data.angle < 0:
            data.angle = 0.0

        buff = b"\xfa\xaf\x06" + \
            struct.pack("<Bf", data.num, data.angle)+b"\xfb\xbf"
        self.usb0_writer.write(buff)

    def led_controllers_callback(self, data):
        buff = b"\xfa\xaf\x08" + \
            struct.pack("<BB", data.led0, data.led1)+b"\xfb\xbf"
        self.usb1_writer.write(buff)

    def magnet_controller_callback(self, data):
        buff = b"\xfa\xaf\x09" + \
            struct.pack("<B", data.state)+b"\xfb\xbf"
        self.usb0_writer.write(buff)


    def pid_params_set_callback(self, data):  # pid参数设置
        self.pid.topicrec(data)

        # 参数下行
        self.pid.hwinit()
        # 参数保存
        self.pid.filesave()
        self.get_logger().info("已保存PID参数信息")

    def thrust_curve_set_callback(self, data):
        self.curve.topicrec(data)

        # 参数下行
        self.curve.hwinit()
        # 参数保存
        self.curve.filesave()
        self.get_logger().info("已保存推力曲线")

    def target_pos_down_callback(self, data):  # 设置目标位置
        buff = b"\xfa\xaf\x03"+struct.pack("<Bffffff", data.cs, data.pos.x, data.pos.y,
                                           data.pos.z, data.pos.rx, data.pos.ry, data.pos.rz)+b"\xfb\xbf"
        self.usb1_writer.write(buff)

    def pid_controllers_set_callback(self, data):  # 设置PID控制器工作状态
        buff = b"\xfa\xaf\x01" + \
            struct.pack("<BBBBBB", data.x, data.y, data.z,
                        data.rx, data.ry, data.rz)+b"\xfb\xbf"
        self.usb1_writer.write(buff)

    def pid_controllers_set_callback(self, data):  # 设置PID控制器工作状态
        buff = b"\xfa\xaf\x01" + \
            struct.pack("<BBBBBBBB", data.x, data.y, data.z,data.vx, data.vy,
                        data.rz, data.rx, data.ry)+b"\xfb\xbf"
        self.usb1_writer.write(buff)
        
        
        
    def dvl_set_callback(self, data):  # 设置dvl工作状态
        buff = b"\xfa\xaf\x04" + \
            struct.pack("<B", data.dvl,)+b"\xfb\xbf"
        self.usb0_writer.write(buff)
    
    def target_speed_down_callback(self, data): #设置目标速度
        buff =  b"\xfa\xaf\x08"+struct.pack("<ff",  data.pos.x, data.pos.y)+b"\xfb\xbf"
        self.usb1_writer.write(buff)
    
    
    def parameters_init(self):
        # pid控制器硬件初始化
        self.pid.hwinit()
        self.get_logger().info("pid 参数已写入")
        # 推力曲线初始化
        self.curve.hwinit()
        self.get_logger().info("推力曲线已写入")


def TTyRead(tty_reader, node, name):
    node.get_logger().info("%s串口监听已启动" % name)
    while rclpy.ok():
        s, buff = tty_reader.read(1)
        # 校验帧头
        if s and buff == b"\xfa":
            s, buff = tty_reader.read(1)
            if s and buff == b"\xaf":
                count, buff = 0, bytes()
                while rclpy.ok():
                    count += 1
                    s, b = tty_reader.read(1)
                    if s:
                        buff += b
                        # 校验帧尾
                        if len(buff) > 1 and buff[-1] == 0xbf and buff[-2] == 0xfb:
                            # 接收成功后解码
                            # 设备管理器
                            if buff[0] == 0x01 and len(buff[1:-2]) == 22:  # 校验长度
                                node.DeviceManager.leak, node.DeviceManager.vol, node.DeviceManager.tem, \
                                    node.DeviceManager.hum, node.DeviceManager.magnet, node.DeviceManager.angle[0],  node.DeviceManager.angle[1]= struct.unpack(
                                        "<BfffBff", buff[1:-2])
                                node.device_manager_pub.publish(
                                    node.DeviceManager)
                                # node.get_logger().info(name+":接收到设备管理器信息")
                            # 运动控制器
                            elif buff[0] == 0x00 and len(buff[1:-2]) >= 154:  # 校验长度
                                # 机器人位置 1~24
                                node.MotionController.pos.x, node.MotionController.pos.y, node.MotionController.pos.z, \
                                    node.MotionController.pos.rx, node.MotionController.pos.ry, node.MotionController.pos.rz = struct.unpack(
                                        "<ffffff", buff[1:25])
                                # 目标位置(base) 25~48
                                node.MotionController.tpos_inbase.x, node.MotionController.tpos_inbase.y, node.MotionController.tpos_inbase.z, \
                                    node.MotionController.tpos_inbase.rx, node.MotionController.tpos_inbase.ry, node.MotionController.tpos_inbase.rz = struct.unpack(
                                        "<ffffff", buff[25:49])
                                # 目标位置(world) 49~72
                                node.MotionController.tpos_inworld.x, node.MotionController.tpos_inworld.y, node.MotionController.tpos_inworld.z, \
                                    node.MotionController.tpos_inworld.rx, node.MotionController.tpos_inworld.ry, node.MotionController.tpos_inworld.rz = struct.unpack(
                                        "<ffffff", buff[49:73])
                                # PID控制器状态 73~78
                                node.MotionController.pidstate.x, node.MotionController.pidstate.y, node.MotionController.pidstate.z, \
                                    node.MotionController.pidstate.vx, node.MotionController.pidstate.vy, node.MotionController.pidstate.rz, = struct.unpack(
                                        "<BBBBBB", buff[73:79])
                                # IMU数据 79~128
                                node.MotionController.imu.mode, node.MotionController.imu.dvl,\
                                    node.MotionController.imu.pos.x, node.MotionController.imu.pos.y, node.MotionController.imu.pos.z, \
                                    node.MotionController.imu.pos.rx, node.MotionController.imu.pos.ry, node.MotionController.imu.pos.rz, \
                                    node.MotionController.imu.spd.x, node.MotionController.imu.spd.y, node.MotionController.imu.spd.z, \
                                    node.MotionController.imu.spd.rx, node.MotionController.imu.spd.ry, node.MotionController.imu.spd.rz = struct.unpack(
                                        "<BBffffffffffff", buff[79:129])
                                # 推力数据 129~152
                                node.MotionController.thrust.thrust[0], node.MotionController.thrust.thrust[1], node.MotionController.thrust.thrust[2], \
                                    node.MotionController.thrust.thrust[3], node.MotionController.thrust.thrust[4], node.MotionController.thrust.thrust[5], = struct.unpack(
                                        "<ffffff", buff[129:153])
                                node.motion_controller_pub.publish(
                                    node.MotionController)
                                #LED数据 153~154
                                node.DeviceManager.led[0], node.DeviceManager.led[1] = struct.unpack(
                                        "<BB", buff[153:155])
                                node.device_manager_pub.publish(
                                    node.DeviceManager)
                                    
                                # node.get_logger().info(name+":接收到运动控制器信息")

                            # 接收成功后退出
                            buff = bytes()
                            break
                    if count > 200:  # 接收超时后退出
                        buff = bytes()
                        break


def ParameterBroadcast(node):  # 参数广播
    while rclpy.ok():
        node.pid_controllers_pub.publish(node.pid.pid)
        time.sleep(0.05)
        node.curves_pub.publish(node.curve.curves)
        time.sleep(0.05)


def main(args=None):
    
    ros_args = remove_ros_args(sys.argv)
    # 加载参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--pid-path', nargs='+', type=str, default=[
                        '/home/nvidia/Workspace/Cruise/datas/pid_parameters.json'], help='PID参数路径')
    parser.add_argument('--curve-path', nargs='+', type=str, default=[
                        '/home/nvidia/Workspace/Cruise/datas/thrust_cureves.json'], help='推力曲线路径')
    parser.add_argument('--h750-path', nargs='+', type=str,
                        default=['/dev/ttyUSB1'], help='h750路径')
    parser.add_argument('--f407-path', nargs='+', type=str,
                        default=['/dev/ttyUSB0'], help='f407路径')
    opt = parser.parse_args(ros_args[1:])

    rclpy.init(args=args)  # 初始化rclpy
    node = CoreNode("uv_core", opt.h750_path[0],
                    opt.f407_path[0], opt.pid_path[0], opt.curve_path[0])  # 新建一个节点

    node.parameters_init()  # 写入参数

    # 创建串口接收线程
    thread_usb0_read = threading.Thread(
        target=TTyRead, args=(node.usb0_reader, node, "ttyUSB0"))
    thread_usb1_read = threading.Thread(
        target=TTyRead, args=(node.usb1_reader, node, "ttyUSB1"))
    # 创建参数发布线程
    thread_parameter_broadcast = threading.Thread(
        target=ParameterBroadcast, args=(node,))

    # 启动线程
    thread_usb0_read.start()
    thread_usb1_read.start()
    thread_parameter_broadcast.start()

    rclpy.spin(node)  # 保持节点运行，检测是否收到退出指令（Ctrl+Z）
    rclpy.shutdown()  # 关闭rclpy

===== .\uv_hm\uv_hm\uv_web_pannel.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import cv2
from cv_bridge import CvBridge, CvBridgeError
import numpy as np
import time
from sensor_msgs.msg import Image
import argparse
import subprocess
import socket
import json
import threading

from datetime import datetime

from uv_msgs.msg import CabinState
from uv_msgs.msg import PropellerThrust
from uv_msgs.msg import RobotAxis
from uv_msgs.msg import WorkState

COLOR_RED = (0, 0, 255)


class CaptureNode(Node):
    def __init__(self, name, front_cam, host, height, width):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)

        self.size = (int(height), int(width))
        self.height = int(height)
        self.width = int(width)
        self.address = ("", 0)
        self.letterheight = int(16*self.height/720)
        self.letterzoom = 0.5*self.height/720

        self.cabin_state = CabinState()
        self.propeller_thrust = PropellerThrust()
        self.robot_position = RobotAxis()
        self.work_state = WorkState()
        self.robot_speed = RobotAxis()


        # 创建话题接收 cabin_state ，定义其中的消息类型为 CabinState
        self.create_subscription(
            CabinState, 'cabin_state', self.cabin_state_callback, 10)

        # 创建话题接收 propeller_thrust ，定义其中的消息类型为 PropellerThrust
        self.create_subscription(
            PropellerThrust, 'propeller_thrust', self.propeller_thrust_callback, 10)

        # 创建话题接收 robot_position ，定义其中的消息类型为 RobotAxis
        self.create_subscription(
            RobotAxis, 'robot_position', self.robot_position_callback, 10)

        # 创建话题接收 robot_speed ，定义其中的消息类型为 RobotAxis
        self.create_subscription(
            RobotAxis, 'robot_speed', self.robot_speed_callback, 10)

        # 创建话题发布 openloop_thrust ，定义其中的消息类型为 RobotAxis
        self.openloop_thrust_pub = self.create_publisher(
            RobotAxis, "openloop_thrust", 10)

        # 创建话题发布 servo_control ，定义其中的消息类型为 CabinState
        self.servo_control_pub = self.create_publisher(
            CabinState, "servo_control", 10)

        # 创建话题发布 work_state ，定义其中的消息类型为 WorkState
        self.work_state_pub = self.create_publisher(
            WorkState, "work_state", 10)

    def cabin_state_callback(self, data):
        self.cabin_state = data

    def propeller_thrust_callback(self, data):
        self.propeller_thrust = data

    def robot_position_callback(self, data):
        self.robot_position = data

    def robot_speed_callback(self, data):
        self.robot_speed = data


def controller_callback(node, port):
    openloop_thrust = RobotAxis()
    servo_state = CabinState()
    work_state = WorkState()

    server_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    s.connect(("8.8.8.8", 80))
    node.address = (s.getsockname()[0], port)
   
    server_socket.bind(node.address)

    # 获取当前时间，并格式化为文件名
    # current_time = datetime.now()
    # file_name = f"output_{current_time.strftime('%Y%m%d_%H%M%S')}.txt"

    # with open("/home/nvidia/Workspace/Cruise/ctrl_output.txt", 'w') as file:

    while rclpy.ok():
        receive_data, client_address = server_socket.recvfrom(1024)
        data = json.loads(receive_data.decode())

        
        openloop_thrust.x = data["x"]
        openloop_thrust.y = data["y"]
        openloop_thrust.z = data["z"]
        openloop_thrust.rz = data["yaw"]
        openloop_thrust.rx = data["roll"]
        openloop_thrust.ry = data["pitch"]

        # servo_state.servo[0] = data["servo0"]
        # servo_state.servo[1] = data["servo1"]
        
        #work_state.state = data["state"]

        # 将 JSON 对象转换为字符串并写入 .txt 文件
        # json_str = json.dumps(data, indent=None, separators=(',', ':'))
        # file.write(json_str + '\n')  # 每个 JSON 对象后添加换行符

        # node.get_logger().info(json_str)

        node.openloop_thrust_pub.publish(openloop_thrust)
        node.servo_control_pub.publish(servo_state)
        #node.work_state_pub.pubilsh(work_state)
        # node.get_logger().info(str(data))
        
        

def main(args=None):
    # 加载参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--cam', nargs='+', type=str,
                        default=['/dev/video0'], help='前置摄像头')
    parser.add_argument('--host', nargs='+', type=str,
                        default=["127.0.0.1"], help='srs服务器地址')
    parser.add_argument('--height', nargs='+', type=str,
                        default=["1080"], help='图像高度')
    parser.add_argument('--width', nargs='+', type=str,
                        default=["1920"], help='图像宽度')
    parser.add_argument('--port', nargs='+', type=str,
                        default=["10086"], help='远程控制器接入端口')
    opt = parser.parse_args()

    if opt.cam[0] == "none":
        print("No Camera opened")
    else:
        rclpy.init(args=args)  # 初始化rclpy
        node = CaptureNode(
            "uv_web_pannel", opt.cam[0], opt.host[0], opt.height[0], opt.width[0])  # 新建一个节点


        thread_controller = threading.Thread(
            target=controller_callback, args=(node, int(opt.port[0])))
        thread_controller.start()
       

        # 保持节点运行，检测是否收到退出指令（Ctrl+C）
        rclpy.spin(node)
        # 关闭rclpy
        rclpy.shutdown()

===== .\uv_launch_pkg\launch\launch.py =====
功能: 代码摘录
from launch import LaunchDescription
from launch_ros.actions import Node

def generate_launch_description():
    return LaunchDescription([
        Node(
            package='uv_hm',
            executable='uv_hmu',
            output='screen'
        ),
        
        Node(
            package='uv_vision',
            executable='uv_capture',
            output='screen'
        ),
        
        Node(
            package='uv_ai',  # 替换为你的包名
            executable='uv_detect_demo',  # 替换为你的节点可执行文件名
            output='screen', # 输出到终端
        ),
        

        Node(
            package='uv_ai',
            executable='uv_segment',
            output='screen'
        )
        

    ])

===== .\uv_launch_pkg\package.xml =====
功能: 代码摘录
<?xml version="1.0"?>
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
<package format="3">
  <name>uv_launch_pkg</name>
  <version>0.0.0</version>
  <description>Package containing launch files for UV detection system</description>
  <maintainer email="nvidia@example.com">nvidia</maintainer>
  <license>Apache-2.0</license>

  <!-- 构建工具依赖 -->
  <buildtool_depend>ament_python</buildtool_depend>

  <!-- Launch相关编译依赖 -->
  <build_depend>launch</build_depend>
  <build_depend>launch_ros</build_depend>

  <!-- Launch相关运行依赖 -->
  <exec_depend>launch</exec_depend>
  <exec_depend>launch_ros</exec_depend>

  <!-- 测试依赖 -->
  <test_depend>ament_copyright</test_depend>
  <test_depend>ament_flake8</test_depend>
  <test_depend>ament_pep257</test_depend>
  <test_depend>pytest</test_depend>

  <!-- 导出构建类型 -->
  <export>
    <build_type>ament_python</build_type>
  </export>
</package>
    

===== .\uv_launch_pkg\setup.cfg =====
功能: 代码摘录
[develop]
script-dir=$base/lib/uv_launch_pkg
[install]
install-scripts=$base/lib/uv_launch_pkg

===== .\uv_launch_pkg\setup.py =====
功能: 代码摘录
from setuptools import setup
import os
from glob import glob

package_name = 'uv_launch_pkg'  

setup(
    name=package_name,
    version='0.0.0',
    packages=[package_name],  
    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),
        ('share/' + package_name, ['package.xml']),
        (os.path.join('share', package_name, 'launch'), glob('launch/*.py')),
    ],
    install_requires=['setuptools'],
    zip_safe=True,
    maintainer='nvidia',
    maintainer_email='nvidia@example.com',
    description='Package containing launch files',
    license='Apache-2.0',
    tests_require=['pytest'],
    entry_points={
        'console_scripts': [],
    },
)

===== .\uv_launch_pkg\test\test_copyright.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_copyright.main import main
import pytest


@pytest.mark.copyright
@pytest.mark.linter
def test_copyright():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found errors'

===== .\uv_launch_pkg\test\test_flake8.py =====
功能: 代码摘录
# Copyright 2017 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_flake8.main import main_with_errors
import pytest


@pytest.mark.flake8
@pytest.mark.linter
def test_flake8():
    rc, errors = main_with_errors(argv=[])
    assert rc == 0, \
        'Found %d code style errors / warnings:\n' % len(errors) + \
        '\n'.join(errors)

===== .\uv_launch_pkg\test\test_pep257.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_pep257.main import main
import pytest


@pytest.mark.linter
@pytest.mark.pep257
def test_pep257():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found code style errors / warnings'

===== .\uv_launch_pkg\uv_launch_pkg\__init__.py =====
功能: 代码摘录

===== .\uv_msgs\CMakeLists.txt =====
功能: 代码摘录
cmake_minimum_required(VERSION 3.5)
project(uv_msgs)

# Default to C99
if(NOT CMAKE_C_STANDARD)
  set(CMAKE_C_STANDARD 99)
endif()

# Default to C++14
if(NOT CMAKE_CXX_STANDARD)
  set(CMAKE_CXX_STANDARD 14)
endif()

if(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES "Clang")
  add_compile_options(-Wall -Wextra -Wpedantic)
endif()

# find dependencies
find_package(ament_cmake REQUIRED)
find_package(rclcpp REQUIRED)

if(BUILD_TESTING)
  find_package(ament_lint_auto REQUIRED)
  # the following line skips the linter which checks for copyrights
  # uncomment the line when a copyright and license is not present in all source files
  #set(ament_cmake_copyright_FOUND TRUE)
  # the following line skips cpplint (only works in a git repo)
  # uncomment the line when this package is not in a git repo
  #set(ament_cmake_cpplint_FOUND TRUE)
  ament_lint_auto_find_test_dependencies()
endif()

find_package(geometry_msgs REQUIRED)
find_package(rosidl_default_generators REQUIRED)
# find_package(uv_msgs REQUIRED)
find_package(sensor_msgs REQUIRED)
 
rosidl_generate_interfaces(${PROJECT_NAME}
  "msg/RobotDeviceManager.msg" # 机器人设备管理器
  "msg/RobotMotionController.msg" # 机器人运动控制器

  "msg/PidParams.msg"
  "msg/PidControllers.msg"
  "msg/PidControllersState.msg"

  "msg/ThrustCurve.msg"
  "msg/ThrustCurves.msg"

  "msg/RobotAxis.msg"

  "msg/ImuData.msg"
  "msg/MotorThrust.msg"
  "msg/ServoSet.msg"
  "msg/TargetPosDown.msg"
  "msg/CabinState.msg"
  "msg/PropellerThrust.msg"
  "msg/WorkState.msg"
  
  "msg/Yolov8.msg"
  "msg/TargetParams.msg"
  "msg/PixelAxis.msg"
  "msg/TargetAxis.msg"
  "msg/LedControllers.msg"
  "msg/MagnetController.msg"
  
  "srv/DetectRequest.srv"
  DEPENDENCIES  geometry_msgs sensor_msgs # 添加以上自定义依赖的ros包
)


ament_package()



===== .\uv_msgs\msg\CabinState.msg =====
功能: 代码摘录
float32 temp
float32 hum
uint8 leak
float32 voltage
float32[2] servo

===== .\uv_msgs\msg\ImuData.msg =====
功能: 代码摘录
uint8 mode

# mode 当前导航模式
# uint8
# 0x00 待机
# 0x01 粗对准
# 0x02 精对准
# 0x04 SINS/DVL
# 0x05 MRU (无DVL数据时自动进入姿态模式)
# 0xFF 系统故障

uint8 dvl

# dvl 传感器标志位，指示传感器状态
# 0x00 DVL 未上传数据
# 0x01 DVL 数据更新但无效
# 0x02 DVL 数据更新且有效

RobotAxis pos
RobotAxis spd

===== .\uv_msgs\msg\LedControllers.msg =====
功能: 代码摘录
uint8 led0
uint8 led1

===== .\uv_msgs\msg\MagnetController.msg =====
功能: 代码摘录
uint8 state

===== .\uv_msgs\msg\MotorThrust.msg =====
功能: 代码摘录
float32[6] thrust

===== .\uv_msgs\msg\PidControllers.msg =====
功能: 代码摘录
PidParams x
PidParams y
PidParams z
PidParams rx
PidParams ry
PidParams rz
PidParams vx
PidParams vy


===== .\uv_msgs\msg\PidControllersState.msg =====
功能: 代码摘录
uint8 x
uint8 y
uint8 z
uint8 rx
uint8 ry
uint8 rz
uint8 vy
uint8 vx

===== .\uv_msgs\msg\PidParams.msg =====
功能: 代码摘录
string name
float32 p
float32 i
float32 d
float32 i_limit
float32 output_limit

===== .\uv_msgs\msg\PixelAxis.msg =====
功能: 代码摘录
uint32 x
uint32 y

===== .\uv_msgs\msg\PropellerThrust.msg =====
功能: 代码摘录
float32[6] thrust

===== .\uv_msgs\msg\RobotAxis.msg =====
功能: 代码摘录
float32 x
float32 y
float32 z
float32 rx
float32 ry
float32 rz

===== .\uv_msgs\msg\RobotDeviceManager.msg =====
功能: 代码摘录
uint8 leak
float32 tem
float32 hum
float32 vol
uint8 magnet
uint8[2] led
float32[2] angle

===== .\uv_msgs\msg\RobotMotionController.msg =====
功能: 代码摘录
RobotAxis pos
RobotAxis tpos_inbase
RobotAxis tpos_inworld
ImuData imu
MotorThrust thrust
PidControllersState pidstate

===== .\uv_msgs\msg\ServoSet.msg =====
功能: 代码摘录
uint8 num
float32 angle

===== .\uv_msgs\msg\TargetAxis.msg =====
功能: 代码摘录
float32 x
float32 y
float32 z

===== .\uv_msgs\msg\TargetParams.msg =====
功能: 代码摘录
PixelAxis tpos_inpic
TargetAxis tpos_inworld


===== .\uv_msgs\msg\TargetPosDown.msg =====
功能: 代码摘录
uint8 cs
RobotAxis pos

===== .\uv_msgs\msg\ThrustCurve.msg =====
功能: 代码摘录
uint8 num

float32 np_mid
float32 np_ini
float32 pp_ini
float32 pp_mid

float32 nt_end
float32 nt_mid
float32 pt_mid
float32 pt_end

===== .\uv_msgs\msg\ThrustCurves.msg =====
功能: 代码摘录
ThrustCurve m0
ThrustCurve m1
ThrustCurve m2
ThrustCurve m3
ThrustCurve m4
ThrustCurve m5

===== .\uv_msgs\msg\WorkState.msg =====
功能: 代码摘录
uint8 state

===== .\uv_msgs\msg\Yolov8.msg =====
功能: 代码摘录
float32[13] state

TargetParams[13] targets

===== .\uv_msgs\package.xml =====
功能: 代码摘录
<?xml version="1.0"?>
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
<package format="3">
  <name>uv_msgs</name>
  <version>0.0.0</version>
  <description>TODO: Package description</description>
  <maintainer email="macabaka@todo.todo">macabaka</maintainer>
  <license>TODO: License declaration</license>

  <buildtool_depend>ament_cmake</buildtool_depend>
  <buildtool_depend>rosidl_default_generators</buildtool_depend>

  <depend>rclcpp</depend>
  <depend>geometry_msgs</depend>
  <depend>action_msgs</depend>
  
  <build_depend>rosidl_default_generators</build_depend>

  <test_depend>ament_lint_auto</test_depend>
  <test_depend>ament_lint_common</test_depend>
  
  <exec_depend>rosidl_default_runtime</exec_depend>
  <exec_depend>tutorial_interfaces</exec_depend>

  <member_of_group>rosidl_interface_packages</member_of_group>

  <export>
    <build_type>ament_cmake</build_type>
  </export>
</package>

===== .\uv_msgs\srv\DetectRequest.srv =====
功能: 代码摘录
sensor_msgs/Image imagein
string target
string stero
---
uint8 s
float32 x
float32 y
float32 z

===== .\uv_vision\package.xml =====
功能: 代码摘录
<?xml version="1.0"?>
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>
<package format="3">
  <name>uv_vision</name>
  <version>0.0.0</version>
  <description>TODO: Package description</description>
  <maintainer email="macabaka@todo.todo">macabaka</maintainer>
  <license>TODO: License declaration</license>

  <depend>rclpy</depend>

  <test_depend>ament_copyright</test_depend>
  <test_depend>ament_flake8</test_depend>
  <test_depend>ament_pep257</test_depend>
  <test_depend>python3-pytest</test_depend>

  <export>
    <build_type>ament_python</build_type>
  </export>
</package>

===== .\uv_vision\setup.cfg =====
功能: 代码摘录
[develop]
script-dir=$base/lib/uv_vision
[install]
install-scripts=$base/lib/uv_vision

===== .\uv_vision\setup.py =====
功能: 代码摘录
from setuptools import setup

package_name = 'uv_vision'

setup(
    name=package_name,
    version='0.0.0',
    packages=[package_name],
    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),
        ('share/' + package_name, ['package.xml']),
    ],
    install_requires=['setuptools'],
    zip_safe=True,
    maintainer='macabaka',
    maintainer_email='macabaka@todo.todo',
    description='TODO: Package description',
    license='TODO: License declaration',
    tests_require=['pytest'],
    entry_points={
        'console_scripts': [
            "uv_capture = uv_vision.uv_capture:main",
            "uv_virtualwebcam = uv_vision.uv_virtualwebcam:main",
            "uv_srs = uv_vision.uv_srs:main",
            "uv_depthimg = uv_vision.uv_depthimg:main",
        ],
    },
)

===== .\uv_vision\test\test_copyright.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_copyright.main import main
import pytest


@pytest.mark.copyright
@pytest.mark.linter
def test_copyright():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found errors'

===== .\uv_vision\test\test_flake8.py =====
功能: 代码摘录
# Copyright 2017 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_flake8.main import main_with_errors
import pytest


@pytest.mark.flake8
@pytest.mark.linter
def test_flake8():
    rc, errors = main_with_errors(argv=[])
    assert rc == 0, \
        'Found %d code style errors / warnings:\n' % len(errors) + \
        '\n'.join(errors)

===== .\uv_vision\test\test_pep257.py =====
功能: 代码摘录
# Copyright 2015 Open Source Robotics Foundation, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from ament_pep257.main import main
import pytest


@pytest.mark.linter
@pytest.mark.pep257
def test_pep257():
    rc = main(argv=['.', 'test'])
    assert rc == 0, 'Found code style errors / warnings'

===== .\uv_vision\uv_vision\__init__.py =====
功能: 代码摘录

===== .\uv_vision\uv_vision\stereocam.py =====
功能: 代码摘录
import numpy as np
import cv2
import os


def stereoMatchSGBM(left_image, right_image, down_scale=False):
    # 视差计算

    # SGBM匹配参数设置
    if left_image.ndim == 2:
        img_channels = 1
    else:
        img_channels = 3
    blockSize = 3
    paraml = {'minDisparity': 0,  # Minimum possible disparity value
              'numDisparities': 128,  # Maximum disparity minus minimum disparity
              'blockSize': blockSize,  # Matched block size
              # The first parameter controlling the disparity smoothness
              'P1': 8 * img_channels * blockSize ** 2,
              # The second parameter controlling the disparity smoothness
              'P2': 32 * img_channels * blockSize ** 2,
              'disp12MaxDiff': 1,    # 左右视差检查中允许的最大差异(以整数像素为单位)
              'preFilterCap': 63,    # 预滤波图像像素的截断值
              'uniquenessRatio': 15,  # 通常,5-15范围内的值就足够了
              'speckleWindowSize': 0,  # 平滑视差区域的最大尺寸,以考虑其噪声斑点和无效。将其设置为0可禁用斑点过滤。否则,将其设置在50-200的范围内
              'speckleRange': 1,         # 每个连接组件内的最大视差变化。
              'mode': cv2.STEREO_SGBM_MODE_SGBM_3WAY  #
              }

    # 构建SGBM对象
    left_matcher = cv2.StereoSGBM_create(**paraml)
    paramr = paraml
    paramr['minDisparity'] = -paraml['numDisparities']
    right_matcher = cv2.StereoSGBM_create(**paramr)

    # 计算视差图
    size = (left_image.shape[1], left_image.shape[0])
    if down_scale == False:
        disparity_left = left_matcher.compute(left_image, right_image)
        disparity_right = right_matcher.compute(right_image, left_image)

    else:
        # 实现高斯金字塔中的下采样,抛弃偶数行和偶数列
        left_image_down = cv2.pyrDown(left_image)
        right_image_down = cv2.pyrDown(right_image)
        factor = left_image.shape[1] / left_image_down.shape[1]

        disparity_left_half = left_matcher.compute(
            left_image_down, right_image_down)
        disparity_right_half = right_matcher.compute(
            right_image_down, left_image_down)
        disparity_left = cv2.resize(
            disparity_left_half, size, interpolation=cv2.INTER_AREA)
        disparity_right = cv2.resize(
            disparity_right_half, size, interpolation=cv2.INTER_AREA)
        disparity_left = factor * disparity_left
        disparity_right = factor * disparity_right

    # 真实视差(因为SGBM算法得到的视差是x16的)
    trueDisp_left = disparity_left.astype(np.float32) / 16
    trueDisp_right = disparity_right.astype(np.float32) / 16

    return trueDisp_left, trueDisp_right


def getDepthMap(disparityMap: np.ndarray, config) -> np.array:
    """
    :param disparityMap:输入视差图
    :return:
    """

    # 得到视差图后,就可以计算像素深度
    # 利用opencv函数计算深度图

    # cv2.reprojectImageTo3D将像素坐标转换为三维坐标,该函数会返回一个3通道的矩阵,分别存储X、Y、Z坐标(左摄像机坐标下)
    fb = config.camera_matrix_left[0, 0] * (-config.T[0])
    doffs = config.doffs
    depthMap = np.divide(fb, disparityMap + doffs)
    reset_index = np.where(np.logical_or(depthMap < 0.0, depthMap > 50000.0))
    depthMap[reset_index] = 0
    reset_index2 = np.where(disparityMap < 0.0)
    depthMap[reset_index2] = 0
    return depthMap.astype(np.float32)


class StereoCamera(object):
    def __init__(self):

        self.cap = None

        self.camera_matrix_left = None  # 左相机内参
        self.camera_matrix_right = None  # 右相机内参

        self.dist_coeffs_left = None  # 左相机畸变系数
        self.dist_coeffs_right = None  # 右相机畸变系数

        self.R = None  # 左相机至右相机的旋转矩阵
        self.T = None  # 左相机至右相机的平移矩阵

        # 主点列坐标的差
        self.doffs = 0.0

        # 指示上述内外参是否为经过立体校正后的结果
        self.isRectified = False

        # 相机矩阵
        self.R1 = None
        self.R2 = None
        self.P1 = None
        self.P2 = None
        self.Q = None

        self.map1_left = None
        self.map2_left = None
        self.map1_right = None
        self.map2_right = None

        # 图像大小
        self.half_size = (1280, 960)
        self.size = (self.half_size[0]*2, self.half_size[1])

        # 主点列坐标的差
        self.doffs = 0.0

    def cal_parameters_init(self, path):
        calib_file = np.load(path)

        self.camera_matrix_left = calib_file["camera_matrix_left"]
        self.dist_coeffs_left = calib_file["dist_coeffs_left"]
        self.camera_matrix_right = calib_file["camera_matrix_right"]
        self.dist_coeffs_right = calib_file["dist_coeffs_right"]

        self.R1 = calib_file["R1"]
        self.R2 = calib_file["R2"]

        self.P1 = calib_file["P1"]
        self.P2 = calib_file["P2"]

        self.R = calib_file["R"]
        self.T = calib_file["T"]

        self.Q = calib_file["Q"]

    def device_parameter_config(self, device=0, stream_format=cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), size=(2560, 960), fps=30):
        """
        @param stream_format:视频流格式
        @param size: 设置图像大小
        @param fps: 设置帧率
        """
        self.cap = cv2.VideoCapture(device)

        self.size = size
        self.half_size = (size[0]//2, size[1])

        self.cap.set(6, stream_format)  # 视频流格式
        self.cap.set(5, fps)  # 帧率
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, size[0])  # 设置宽度
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, size[1])  # 设置高度

    def cam_init(self):
        """
        向摄像头发送捕获指令,使摄像头开启
        """

        for i in range(30):
            self.cap.read()

    def capture(self):
        """
        @return s:是否捕获成功
        @return f:捕获图像
        """

        for i in range(10):
            s, f = self.cap.read()
            if s:
                f = cv2.flip(f, -1)
                return s, f
        return s, f

    def get_halfsize(self, image):
        """
        @param image:输入图像
        @return size:图像大小
        """

        height, width, channels = image.shape
        size = (width//2, height)
        return size

    def get_fullimg(self, img1, img2):
        """
        合并图像
        @param image_left:输入左侧图像
        @param image_right:输入右侧图像
        """
        result = cv2.hconcat([img1, img2])
        return result

    def get_halfimg(self, image):
        """
        @param image:输入图像
        @return image_left:左侧图像
        @return image_right:右侧图像
        """

        height, width, channels = image.shape
        image_left = image[:, 0:width//2, :]
        image_right = image[:, width//2:width, :]
        return image_left, image_right

    def rectification_init(self):
        """
        计算摄像机转换映射
        """

        # self.R1, self.R2, self.P1, self.P2, self.Q, _, _ = cv2.stereoRectify(
        #     self.camera_matrix_left, self.dist_coeffs_left, self.camera_matrix_right, self.dist_coeffs_right, self.half_size, self.R, self.T, alpha=1)

        # 计算左右摄像机的转换映射
        self.map1_left, self.map2_left = cv2.initUndistortRectifyMap(
            self.camera_matrix_left, self.dist_coeffs_left, self.R1, self.P1, self.half_size, cv2.CV_32FC1)
        self.map1_right, self.map2_right = cv2.initUndistortRectifyMap(
            self.camera_matrix_right, self.dist_coeffs_right, self.R2, self.P2, self.half_size, cv2.CV_32FC1)

    def preprocess(self, image_left, image_right):
        """
        图像预处理,用于减小光照影响
        @param image_left:输入左侧图像
        @param image_right:输入右侧图像
        """
        if (image_left.ndim == 3):
            # 通过opencv加载的图像通道顺序是BGR
            image_left = cv2.cvtColor(image_left, cv2.COLOR_BGR2GRAY)
        if (image_right.ndim == 3):
            image_right = cv2.cvtColor(image_right, cv2.COLOR_BGR2GRAY)

        # 直方图均衡
        image_left = cv2.equalizeHist(image_left)
        image_right = cv2.equalizeHist(image_right)

        return image_left, image_right

    def rectifyImage(self, image_left, image_right):
        """
        校正图像
        @param image_left:输入左侧图像
        @param image_right:输入右侧图像
        """
        rectified_left = cv2.remap(
            image_left, self.map1_left, self.map2_left, cv2.INTER_AREA)
        rectified_right = cv2.remap(
            image_right, self.map1_right, self.map2_right, cv2.INTER_AREA)
        return rectified_left, rectified_right

    def getdepth(self, rectified_left, rectified_right):
        """
        获取深度
        @param image_left:输入左侧图像(已校正)
        @param image_right:输入右侧图像(已校正)
        @return depthMap:深度图(基于已校正的右侧图像)
        """

        # 获取两幅图像的视差值
        disp, _ = stereoMatchSGBM(rectified_left, rectified_right, False)

        # 计算深度图
        depthMap = getDepthMap(disp, self)

        return depthMap

    def depth2img(self, depthMap):
        """
        将深度信息可视化
        @param depthMap:深度图
        @return depth_image:深度图(可视化)
        """
        depthMap = -depthMap

        minDepth = np.min(depthMap)
        maxDepth = np.max(depthMap)

        depthMapVis = (255.0 * (depthMap - minDepth)) / (maxDepth - minDepth)
        depth_image = depthMapVis.astype(np.uint8)
        depth = -depthMap[self.half_size[1]//2,
                          self.half_size[0]//2] / 0.025 / 2

        return depth, depth_image

===== .\uv_vision\uv_vision\uv_capture - 保存图像版.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import cv2
from cv_bridge import CvBridge, CvBridgeError
import numpy as np
import time
from sensor_msgs.msg import Image
import argparse
from datetime import datetime
from uv_vision import stereocam
import os
import sys
from rclpy.utilities import remove_ros_args  # 导入ROS参数过滤工具

cnt_down = 0
cnt_front = 0

def image_publish(frame, img_bridge, image_pub):
    # 转为numpy.array
    frame = np.array(frame)
    # 转换为ros2消息类型，且解码方式为b(blue)、g(green)、r(red)
    data = img_bridge.cv2_to_imgmsg(frame, encoding="bgr8")
    # 发布 转换好的 图像类型消息
    image_pub.publish(data)
        # 如果提供了保存路径，则保存图像

class CaptureNode(Node):
    def __init__(self, name, opt):
        super().__init__(name)
        self.bridge = CvBridge()

        self.get_logger().info("大家好，我是%s!" % name)

        if opt.front_cam[0] != "none":
            # 前置摄像头
            self.frontcam_rawleft_pub = self.create_publisher(
                Image, "front_cam/raw/left", 10)
            self.frontcam_rawright_pub = self.create_publisher(
                Image, "front_cam/raw/right", 10)
            self.frontcam_raw_pub = self.create_publisher(
                Image, "front_cam/raw", 10)
            
            if opt.front_params[0] != "none":
                self.frontcam_rectifiedleft_pub = self.create_publisher(
                    Image, "front_cam/rectified/left", 10)
                self.frontcam_rectifiedright_pub = self.create_publisher(
                    Image, "front_cam/rectified/right", 10)
                self.frontcam_rectified_pub = self.create_publisher(
                    Image, "front_cam/rectified", 10)

            self.front_cam_timer = self.create_timer(
                0.01, self.front_cam_timer_callback)

            self.front_sc = stereocam.StereoCamera()
            self.front_sc.device_parameter_config(device=opt.front_cam[0])
            if opt.front_params[0] != "none":
                self.front_sc.cal_parameters_init(opt.front_params[0])
                self.front_sc.rectification_init()

        if opt.down_cam[0] != "none":
            # 后置摄像头
            self.backcam_rawleft_pub = self.create_publisher(
                Image, "down_cam/raw/left", 10)
            self.backcam_rawright_pub = self.create_publisher(
                Image, "down_cam/raw/right", 10)
            self.backcam_raw_pub = self.create_publisher(
                Image, "down_cam/raw", 10)
            
            if opt.down_params[0] != "none":
                self.backcam_rectifiedleft_pub = self.create_publisher(
                    Image, "down_cam/rectified/left", 10)
                self.backcam_rectifiedright_pub = self.create_publisher(
                    Image, "down_cam/rectified/right", 10)
                self.backcam_rectified_pub = self.create_publisher(
                    Image, "down_cam/rectified", 10)
            
            self.down_cam_timer = self.create_timer(
                0.01, self.back_cam_timer_callback)

            self.down_sc = stereocam.StereoCamera()
            self.down_sc.device_parameter_config(device=opt.down_cam[0])
            if opt.down_params[0] != "none":
                self.down_sc.cal_parameters_init(opt.down_params[0])
                self.down_sc.rectification_init()

        self.opt =opt   

    def front_cam_timer_callback(self):

        s, f = self.front_sc.capture()

        if s:
            img_l, img_r = self.front_sc.get_halfimg(f)
            
            image_publish(f, self.bridge, self.frontcam_raw_pub)
            image_publish(img_l, self.bridge, self.frontcam_rawleft_pub)
            image_publish(img_r, self.bridge, self.frontcam_rawright_pub)
            
            if self.opt.down_params[0] != "none":
                r_l,r_r = self.front_sc.rectifyImage(img_l, img_r)
                full = self.front_sc.get_fullimg(r_l,r_r)
                global cnt_front
                cnt_front = cnt_front+1
                if cnt_front == 2:
                    now = datetime.now()
                    timestamp = now.strftime("%Y%m%d_%H%M%S%f")
                    filename = os.path.join("/home/nvidia/Workspace/Cruise/img/front", f"{timestamp}.jpg")
                    cv2.imwrite(filename, full)
                    cnt_front = 0
                image_publish(full, self.bridge, self.frontcam_rectified_pub)
                image_publish(r_l, self.bridge, self.frontcam_rectifiedleft_pub)
                image_publish(r_r, self.bridge, self.frontcam_rectifiedright_pub)

            self.get_logger().info('发布了前视图像')
        else:
            self.get_logger().info('图像获取失败')

    def back_cam_timer_callback(self):

        s, f = self.down_sc.capture()

        if s:
            img_l, img_r = self.down_sc.get_halfimg(f)
            
            image_publish(f, self.bridge, self.backcam_raw_pub)
            image_publish(img_l, self.bridge, self.backcam_rawleft_pub)
            image_publish(img_r, self.bridge, self.backcam_rawright_pub)
            
            if self.opt.down_params[0] != "none":
                r_l,r_r = self.down_sc.rectifyImage(img_l, img_r)
                full = self.down_sc.get_fullimg(r_l,r_r)
                global cnt_down
                cnt_down = cnt_down+1
                if cnt_down == 2:
                    now = datetime.now()
                    timestamp = now.strftime("%Y%m%d_%H%M%S%f")
                    filename = os.path.join("/home/nvidia/Workspace/Cruise/img/down", f"{timestamp}.jpg")
                    cv2.imwrite(filename, full)
                    cnt_down = 0
                image_publish(full, self.bridge, self.backcam_rectified_pub)
                image_publish(r_l, self.bridge, self.backcam_rectifiedleft_pub)
                image_publish(r_r, self.bridge, self.backcam_rectifiedright_pub)

            self.get_logger().info('发布了下视图像')
        else:
            self.get_logger().info('图像获取失败')

 

def main(args=None):
    # 1. 过滤ROS 2自动添加的参数（关键步骤）
    # 移除--ros-args等ROS相关参数，只保留自定义参数
    ros_args = remove_ros_args(sys.argv)
    
    # 2. 解析自定义参数（使用过滤后的参数列表）
    parser = argparse.ArgumentParser()
    parser.add_argument('--front-cam', nargs='+', type=str,
                        default=['/dev/video0'], help='前置摄像头')
    parser.add_argument('--down-cam', nargs='+', type=str,
                        default=['/dev/video2'], help='下置摄像头')
    parser.add_argument('--front-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/front.npz'], help='前置摄像头参数存储路径')
    parser.add_argument('--down-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/down.npz'], help='下置摄像头参数存储路径')
    
    # 解析时跳过脚本文件名（ros_args[0]），只处理自定义参数
    opt = parser.parse_args(ros_args[1:])

    # 3. 原有逻辑保持不变
    # 注意：原代码中判断条件使用了opt.back_cam，但未定义该参数，此处保留原逻辑，若实际有back-cam参数需补充
    if opt.front_cam[0] == "none" and opt.down_cam[0] == "none":  # 假设原代码中back_cam是笔误，改为down_cam
        print("No Camera opened")
    else:
        rclpy.init(args=args)
        node = CaptureNode("uv_capture", opt)
        rclpy.spin(node)
        rclpy.shutdown()
        

===== .\uv_vision\uv_vision\uv_capture - 不保存图像版.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import cv2
from cv_bridge import CvBridge, CvBridgeError
import numpy as np
import time
from sensor_msgs.msg import Image
import argparse
from datetime import datetime
from uv_vision import stereocam
import os
import sys
from rclpy.utilities import remove_ros_args  # 导入ROS参数过滤工具

cnt_down = 0
cnt_front = 0

def image_publish(frame, img_bridge, image_pub):
    # 转为numpy.array
    frame = np.array(frame)
    # 转换为ros2消息类型，且解码方式为b(blue)、g(green)、r(red)
    data = img_bridge.cv2_to_imgmsg(frame, encoding="bgr8")
    # 发布 转换好的 图像类型消息
    image_pub.publish(data)
        # 如果提供了保存路径，则保存图像

class CaptureNode(Node):
    def __init__(self, name, opt):
        super().__init__(name)
        self.bridge = CvBridge()

        self.get_logger().info("大家好，我是%s!" % name)

        if opt.front_cam[0] != "none":
            # 前置摄像头
            self.frontcam_rawleft_pub = self.create_publisher(
                Image, "front_cam/raw/left", 10)
            self.frontcam_rawright_pub = self.create_publisher(
                Image, "front_cam/raw/right", 10)
            self.frontcam_raw_pub = self.create_publisher(
                Image, "front_cam/raw", 10)
            
            if opt.front_params[0] != "none":
                self.frontcam_rectifiedleft_pub = self.create_publisher(
                    Image, "front_cam/rectified/left", 10)
                self.frontcam_rectifiedright_pub = self.create_publisher(
                    Image, "front_cam/rectified/right", 10)
                self.frontcam_rectified_pub = self.create_publisher(
                    Image, "front_cam/rectified", 10)

            self.front_cam_timer = self.create_timer(
                0.01, self.front_cam_timer_callback)

            self.front_sc = stereocam.StereoCamera()
            self.front_sc.device_parameter_config(device=opt.front_cam[0])
            if opt.front_params[0] != "none":
                self.front_sc.cal_parameters_init(opt.front_params[0])
                self.front_sc.rectification_init()

        if opt.down_cam[0] != "none":
            # 后置摄像头
            self.backcam_rawleft_pub = self.create_publisher(
                Image, "down_cam/raw/left", 10)
            self.backcam_rawright_pub = self.create_publisher(
                Image, "down_cam/raw/right", 10)
            self.backcam_raw_pub = self.create_publisher(
                Image, "down_cam/raw", 10)
            
            if opt.down_params[0] != "none":
                self.backcam_rectifiedleft_pub = self.create_publisher(
                    Image, "down_cam/rectified/left", 10)
                self.backcam_rectifiedright_pub = self.create_publisher(
                    Image, "down_cam/rectified/right", 10)
                self.backcam_rectified_pub = self.create_publisher(
                    Image, "down_cam/rectified", 10)
            
            self.down_cam_timer = self.create_timer(
                0.01, self.back_cam_timer_callback)

            self.down_sc = stereocam.StereoCamera()
            self.down_sc.device_parameter_config(device=opt.down_cam[0])
            if opt.down_params[0] != "none":
                self.down_sc.cal_parameters_init(opt.down_params[0])
                self.down_sc.rectification_init()

        self.opt =opt   

    def front_cam_timer_callback(self):

        s, f = self.front_sc.capture()

        if s:
            img_l, img_r = self.front_sc.get_halfimg(f)
            
            image_publish(f, self.bridge, self.frontcam_raw_pub)
            image_publish(img_l, self.bridge, self.frontcam_rawleft_pub)
            image_publish(img_r, self.bridge, self.frontcam_rawright_pub)
            
            if self.opt.down_params[0] != "none":
                r_l,r_r = self.front_sc.rectifyImage(img_l, img_r)
                full = self.front_sc.get_fullimg(r_l,r_r)
                """global cnt_front
                cnt_front = cnt_front+1
                if cnt_front == 2:
                    now = datetime.now()
                    timestamp = now.strftime("%Y%m%d_%H%M%S%f")
                    filename = os.path.join("/home/nvidia/Workspace/Cruise/img/front", f"{timestamp}.jpg")
                    cv2.imwrite(filename, full)
                    cnt_front = 0"""
                image_publish(full, self.bridge, self.frontcam_rectified_pub)
                image_publish(r_l, self.bridge, self.frontcam_rectifiedleft_pub)
                image_publish(r_r, self.bridge, self.frontcam_rectifiedright_pub)

            self.get_logger().info('发布了前视图像')
        else:
            self.get_logger().info('图像获取失败')

    def back_cam_timer_callback(self):

        s, f = self.down_sc.capture()

        if s:
            img_l, img_r = self.down_sc.get_halfimg(f)
            
            image_publish(f, self.bridge, self.backcam_raw_pub)
            image_publish(img_l, self.bridge, self.backcam_rawleft_pub)
            image_publish(img_r, self.bridge, self.backcam_rawright_pub)
            
            if self.opt.down_params[0] != "none":
                r_l,r_r = self.down_sc.rectifyImage(img_l, img_r)
                full = self.down_sc.get_fullimg(r_l,r_r)
                """global cnt_down
                cnt_down = cnt_down+1
                if cnt_down == 2:
                    now = datetime.now()
                    timestamp = now.strftime("%Y%m%d_%H%M%S%f")
                    filename = os.path.join("/home/nvidia/Workspace/Cruise/img/down", f"{timestamp}.jpg")
                    cv2.imwrite(filename, full)
                    cnt_down = 0"""
                image_publish(full, self.bridge, self.backcam_rectified_pub)
                image_publish(r_l, self.bridge, self.backcam_rectifiedleft_pub)
                image_publish(r_r, self.bridge, self.backcam_rectifiedright_pub)

            self.get_logger().info('发布了下视图像')
        else:
            self.get_logger().info('图像获取失败')

 

def main(args=None):
    # 1. 过滤ROS 2自动添加的参数（关键步骤）
    # 移除--ros-args等ROS相关参数，只保留自定义参数
    ros_args = remove_ros_args(sys.argv)
    
    # 2. 解析自定义参数（使用过滤后的参数列表）
    parser = argparse.ArgumentParser()
    parser.add_argument('--front-cam', nargs='+', type=str,
                        default=['/dev/video0'], help='前置摄像头')
    parser.add_argument('--down-cam', nargs='+', type=str,
                        default=['/dev/video2'], help='下置摄像头')
    parser.add_argument('--front-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/front.npz'], help='前置摄像头参数存储路径')
    parser.add_argument('--down-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/down.npz'], help='下置摄像头参数存储路径')
    
    # 解析时跳过脚本文件名（ros_args[0]），只处理自定义参数
    opt = parser.parse_args(ros_args[1:])

    # 3. 原有逻辑保持不变
    # 注意：原代码中判断条件使用了opt.back_cam，但未定义该参数，此处保留原逻辑，若实际有back-cam参数需补充
    if opt.front_cam[0] == "none" and opt.down_cam[0] == "none":  # 假设原代码中back_cam是笔误，改为down_cam
        print("No Camera opened")
    else:
        rclpy.init(args=args)
        node = CaptureNode("uv_capture", opt)
        rclpy.spin(node)
        rclpy.shutdown()
        

===== .\uv_vision\uv_vision\uv_capture.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import cv2
from cv_bridge import CvBridge, CvBridgeError
import numpy as np
import time
from sensor_msgs.msg import Image
import argparse
from datetime import datetime
from uv_vision import stereocam
import os
import sys
from rclpy.utilities import remove_ros_args  # 导入ROS参数过滤工具

cnt_down = 0
cnt_front = 0

def image_publish(frame, img_bridge, image_pub):
    frame = np.array(frame)  # 转为numpy.array
    data = img_bridge.cv2_to_imgmsg(frame, encoding="bgr8")  # 转换为ROS2消息类型
    image_pub.publish(data)  # 发布图像消息


class CaptureNode(Node):
    def __init__(self, name, opt):
        super().__init__(name)
        self.bridge = CvBridge()

        self.get_logger().info("大家好，我是%s!" % name)

        if opt.front_cam[0] != "none":
            # 前置摄像头
            self.frontcam_rawleft_pub = self.create_publisher(
                Image, "front_cam/raw/left", 10)
            self.frontcam_rawright_pub = self.create_publisher(
                Image, "front_cam/raw/right", 10)
            self.frontcam_raw_pub = self.create_publisher(
                Image, "front_cam/raw", 10)
            
            if opt.front_params[0] != "none":
                self.frontcam_rectifiedleft_pub = self.create_publisher(
                    Image, "front_cam/rectified/left", 10)
                self.frontcam_rectifiedright_pub = self.create_publisher(
                    Image, "front_cam/rectified/right", 10)
                self.frontcam_rectified_pub = self.create_publisher(
                    Image, "front_cam/rectified", 10)

            self.front_cam_timer = self.create_timer(
                0.01, self.front_cam_timer_callback)

            self.front_sc = stereocam.StereoCamera()
            self.front_sc.device_parameter_config(device=opt.front_cam[0])
            if opt.front_params[0] != "none":
                self.front_sc.cal_parameters_init(opt.front_params[0])
                self.front_sc.rectification_init()

        if opt.down_cam[0] != "none":
            # 后置摄像头
            self.backcam_rawleft_pub = self.create_publisher(
                Image, "down_cam/raw/left", 10)
            self.backcam_rawright_pub = self.create_publisher(
                Image, "down_cam/raw/right", 10)
            self.backcam_raw_pub = self.create_publisher(
                Image, "down_cam/raw", 10)
            
            if opt.down_params[0] != "none":
                self.backcam_rectifiedleft_pub = self.create_publisher(
                    Image, "down_cam/rectified/left", 10)
                self.backcam_rectifiedright_pub = self.create_publisher(
                    Image, "down_cam/rectified/right", 10)
                self.backcam_rectified_pub = self.create_publisher(
                    Image, "down_cam/rectified", 10)
            
            self.down_cam_timer = self.create_timer(
                0.01, self.back_cam_timer_callback)

            self.down_sc = stereocam.StereoCamera()
            self.down_sc.device_parameter_config(device=opt.down_cam[0])
            if opt.down_params[0] != "none":
                self.down_sc.cal_parameters_init(opt.down_params[0])
                self.down_sc.rectification_init()

        self.opt =opt   

    def front_cam_timer_callback(self):

        s, f = self.front_sc.capture()

        if s:
            img_l, img_r = self.front_sc.get_halfimg(f)
            
            image_publish(f, self.bridge, self.frontcam_raw_pub)
            image_publish(img_l, self.bridge, self.frontcam_rawleft_pub)
            image_publish(img_r, self.bridge, self.frontcam_rawright_pub)
            
            if self.opt.front_params[0] != "none":
                r_l,r_r = self.front_sc.rectifyImage(img_l, img_r)
                full = self.front_sc.get_fullimg(r_l,r_r)
                global cnt_front
                cnt_front = cnt_front+1
                if cnt_front == 2:
                    now = datetime.now()
                    timestamp = now.strftime("%Y%m%d_%H%M%S%f")
                    filename = os.path.join("/home/nvidia/Workspace/Cruise/img/front", f"{timestamp}.jpg")
                    cv2.imwrite(filename, full)
                    cnt_front = 0
                image_publish(full, self.bridge, self.frontcam_rectified_pub)
                image_publish(r_l, self.bridge, self.frontcam_rectifiedleft_pub)
                image_publish(r_r, self.bridge, self.frontcam_rectifiedright_pub)

            self.get_logger().info('发布了前视图像')
        else:
            self.get_logger().info('图像获取失败')

    def back_cam_timer_callback(self):

        s, f = self.down_sc.capture()

        if s:
            img_l, img_r = self.down_sc.get_halfimg(f)
            
            image_publish(f, self.bridge, self.backcam_raw_pub)
            image_publish(img_l, self.bridge, self.backcam_rawleft_pub)
            image_publish(img_r, self.bridge, self.backcam_rawright_pub)
            
            if self.opt.down_params[0] != "none":
                r_l,r_r = self.down_sc.rectifyImage(img_l, img_r)
                full = self.down_sc.get_fullimg(r_l,r_r)
                global cnt_down
                cnt_down = cnt_down+1
                if cnt_down == 2:
                    now = datetime.now()
                    timestamp = now.strftime("%Y%m%d_%H%M%S%f")
                    filename = os.path.join("/home/nvidia/Workspace/Cruise/img/down", f"{timestamp}.jpg")
                    cv2.imwrite(filename, full)
                    cnt_down = 0
                image_publish(full, self.bridge, self.backcam_rectified_pub)
                image_publish(r_l, self.bridge, self.backcam_rectifiedleft_pub)
                image_publish(r_r, self.bridge, self.backcam_rectifiedright_pub)

            self.get_logger().info('发布了下视图像')
        else:
            self.get_logger().info('图像获取失败')

 

def main(args=None):
    # 1. 过滤ROS 2自动添加的参数（关键步骤）
    # 移除--ros-args等ROS相关参数，只保留自定义参数
    ros_args = remove_ros_args(sys.argv)
    
    # 2. 解析自定义参数（使用过滤后的参数列表）
    parser = argparse.ArgumentParser()
    parser.add_argument('--front-cam', nargs='+', type=str,
                        default=['/dev/video0'], help='前置摄像头')
    parser.add_argument('--down-cam', nargs='+', type=str,
                        default=['/dev/video2'], help='下置摄像头')
    parser.add_argument('--front-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/front.npz'], help='前置摄像头参数存储路径')
    parser.add_argument('--down-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/down.npz'], help='下置摄像头参数存储路径')
    
    # 解析时跳过脚本文件名（ros_args[0]），只处理自定义参数
    opt = parser.parse_args(ros_args[1:])

    # 3. 原有逻辑保持不变
    # 注意：原代码中判断条件使用了opt.back_cam，但未定义该参数，此处保留原逻辑，若实际有back-cam参数需补充
    if opt.front_cam[0] == "none" and opt.down_cam[0] == "none":  # 假设原代码中back_cam是笔误，改为down_cam
        print("No Camera opened")
    else:
        rclpy.init(args=args)
        node = CaptureNode("uv_capture", opt)
         
        rclpy.shutdown()
        

===== .\uv_vision\uv_vision\uv_capture_commented.py =====
功能: 代码摘录
# 导入ROS2的Python客户端库，用于创建ROS节点和通信
import rclpy
# 从rclpy.node导入Node类，这是所有ROS2节点的基础类
from rclpy.node import Node
# 导入OpenCV库，用于图像处理和计算机视觉操作
import cv2
# 导入CvBridge和相关异常，用于ROS图像消息和OpenCV图像格式之间的转换
from cv_bridge import CvBridge, CvBridgeError
# 导入NumPy库，用于数值计算和数组操作
import numpy as np
# 导入时间模块，虽然在本代码中未直接使用，但可能用于时间相关操作
import time
# 导入ROS2的Image消息类型，用于发布图像数据
from sensor_msgs.msg import Image
# 导入argparse模块，用于解析命令行参数
import argparse
# 导入datetime模块，用于生成时间戳
from datetime import datetime
# 导入自定义的立体相机模块
from uv_vision import stereocam
# 导入操作系统接口模块，用于文件路径操作
import os
# 导入系统模块，用于访问命令行参数
import sys
# 导入ROS2的参数过滤工具，用于移除ROS自动添加的命令行参数
from rclpy.utilities import remove_ros_args

# 全局计数器，用于控制下视图像保存频率（每2帧保存一次）
cnt_down = 0
# 全局计数器，用于控制前视图像保存频率（每2帧保存一次）
cnt_front = 0

def image_publish(frame, img_bridge, image_pub):
    """
    图像发布函数：将OpenCV图像转换为ROS消息并发布
    
    参数:
    frame: 要发布的图像帧（OpenCV格式）
    img_bridge: CvBridge对象，用于格式转换
    image_pub: ROS发布器对象
    """
    # 将输入图像转换为NumPy数组格式（确保数据类型正确）
    frame = np.array(frame)
    # 使用CvBridge将OpenCV图像（BGR8编码）转换为ROS Image消息格式
    data = img_bridge.cv2_to_imgmsg(frame, encoding="bgr8")
    # 通过指定的发布器将转换后的图像消息发布到ROS话题
    image_pub.publish(data)
    # 注释：如果提供了保存路径，则保存图像（原代码中的注释，但未实现）

class CaptureNode(Node):
    """
    图像采集节点类：继承自ROS2 Node，负责从立体摄像头采集图像并发布
    """
    
    def __init__(self, name, opt):
        """
        初始化图像采集节点
        
        参数:
        name: 节点名称
        opt: 包含配置选项的对象（摄像头设备路径、参数文件路径等）
        """
        # 调用父类Node的初始化方法，设置节点名称
        super().__init__(name)
        # 创建CvBridge对象，用于OpenCV和ROS图像格式转换
        self.bridge = CvBridge()

        # 在ROS日志中输出节点启动信息
        self.get_logger().info("大家好，我是%s!" % name)

        # 检查是否启用了前视摄像头（"none"表示禁用）
        if opt.front_cam[0] != "none":
            # 创建前视摄像头原始完整图像发布器，话题名为"front_cam/raw"
            self.frontcam_raw_pub = self.create_publisher(
                Image, "front_cam/raw", 10)
            # 创建前视摄像头原始左目图像发布器，话题名为"front_cam/raw/left"
            self.frontcam_rawleft_pub = self.create_publisher(
                Image, "front_cam/raw/left", 10)
            # 创建前视摄像头原始右目图像发布器，话题名为"front_cam/raw/right"
            self.frontcam_rawright_pub = self.create_publisher(
                Image, "front_cam/raw/right", 10)
            
            # 检查是否提供了前视摄像头的标定参数文件
            if opt.front_params[0] != "none":
                # 创建前视摄像头校正后完整图像发布器，话题名为"front_cam/rectified"
                self.frontcam_rectified_pub = self.create_publisher(
                    Image, "front_cam/rectified", 10)
                # 创建前视摄像头校正后左目图像发布器，话题名为"front_cam/rectified/left"
                self.frontcam_rectifiedleft_pub = self.create_publisher(
                    Image, "front_cam/rectified/left", 10)
                # 创建前视摄像头校正后右目图像发布器，话题名为"front_cam/rectified/right"
                self.frontcam_rectifiedright_pub = self.create_publisher(
                    Image, "front_cam/rectified/right", 10)

            # 创建前视摄像头定时器，每0.01秒触发一次（100Hz频率）
            self.front_cam_timer = self.create_timer(
                0.01, self.front_cam_timer_callback)

            # 创建前视立体相机对象
            self.front_sc = stereocam.StereoCamera()
            # 配置前视摄像头的设备参数（设备路径、分辨率、帧率等）
            self.front_sc.device_parameter_config(device=opt.front_cam[0])
            # 如果提供了标定参数文件，则加载相机标定参数
            if opt.front_params[0] != "none":
                # 从.npz文件中加载相机内外参数、畸变系数等标定数据
                self.front_sc.cal_parameters_init(opt.front_params[0])
                # 初始化立体校正映射，用于后续的图像校正处理
                self.front_sc.rectification_init()

        # 检查是否启用了下视摄像头（"none"表示禁用）
        if opt.down_cam[0] != "none":
            # 创建下视摄像头原始完整图像发布器，话题名为"down_cam/raw"
            self.backcam_raw_pub = self.create_publisher(
                Image, "down_cam/raw", 10)
            # 创建下视摄像头原始左目图像发布器，话题名为"down_cam/raw/left"
            self.backcam_rawleft_pub = self.create_publisher(
                Image, "down_cam/raw/left", 10)
            # 创建下视摄像头原始右目图像发布器，话题名为"down_cam/raw/right"
            self.backcam_rawright_pub = self.create_publisher(
                Image, "down_cam/raw/right", 10)
            
            # 检查是否提供了下视摄像头的标定参数文件
            if opt.down_params[0] != "none":
                # 创建下视摄像头校正后完整图像发布器，话题名为"down_cam/rectified"
                self.backcam_rectified_pub = self.create_publisher(
                    Image, "down_cam/rectified", 10)
                # 创建下视摄像头校正后左目图像发布器，话题名为"down_cam/rectified/left"
                self.backcam_rectifiedleft_pub = self.create_publisher(
                    Image, "down_cam/rectified/left", 10)
                # 创建下视摄像头校正后右目图像发布器，话题名为"down_cam/rectified/right"
                self.backcam_rectifiedright_pub = self.create_publisher(
                    Image, "down_cam/rectified/right", 10)
            
            # 创建下视摄像头定时器，每0.01秒触发一次（100Hz频率）
            self.down_cam_timer = self.create_timer(
                0.01, self.back_cam_timer_callback)

            # 创建下视立体相机对象
            self.down_sc = stereocam.StereoCamera()
            # 配置下视摄像头的设备参数（设备路径、分辨率、帧率等）
            self.down_sc.device_parameter_config(device=opt.down_cam[0])
            # 如果提供了标定参数文件，则加载相机标定参数
            if opt.down_params[0] != "none":
                # 从.npz文件中加载相机内外参数、畸变系数等标定数据
                self.down_sc.cal_parameters_init(opt.down_params[0])
                # 初始化立体校正映射，用于后续的图像校正处理
                self.down_sc.rectification_init()

        # 将配置选项对象保存为实例变量，供其他方法使用
        self.opt = opt   

    def front_cam_timer_callback(self):
        """
        前视摄像头定时器回调函数：每0.01秒被调用一次，负责采集和处理前视图像
        """
        # 从立体摄像头捕获一帧图像，s表示成功状态，f表示图像帧
        s, f = self.front_sc.capture()

        # 检查图像捕获是否成功
        if s:
            # 将捕获的立体图像分割为左目和右目图像
            img_l, img_r = self.front_sc.get_halfimg(f)
            
            # 发布前视摄像头的原始完整图像
            image_publish(f, self.bridge, self.frontcam_raw_pub)
            # 发布前视摄像头的原始左目图像
            image_publish(img_l, self.bridge, self.frontcam_rawleft_pub)
            # 发布前视摄像头的原始右目图像
            image_publish(img_r, self.bridge, self.frontcam_rawright_pub)
            
            # 检查是否提供了下视摄像头的标定参数（这里应该是前视参数，可能是代码错误）
            if self.opt.down_params[0] != "none":
                # 对左右目图像进行立体校正，消除镜头畸变和立体视差
                r_l, r_r = self.front_sc.rectifyImage(img_l, img_r)
                # 将校正后的左右目图像合并为完整的立体图像
                full = self.front_sc.get_fullimg(r_l, r_r)
                # 声明使用全局计数器变量cnt_front
                global cnt_front
                # 增加前视图像计数器
                cnt_front = cnt_front + 1
                # 检查是否达到保存条件（每2帧保存一次）
                if cnt_front == 2:
                    # 获取当前时间
                    now = datetime.now()
                    # 生成带微秒精度的时间戳字符串
                    timestamp = now.strftime("%Y%m%d_%H%M%S%f")
                    # 构建图像保存的完整路径
                    filename = os.path.join("/home/nvidia/Workspace/Cruise/img/front", f"{timestamp}.jpg")
                    # 将校正后的完整图像保存为JPG文件
                    cv2.imwrite(filename, full)
                    # 重置计数器为0
                    cnt_front = 0
                # 发布前视摄像头的校正后完整图像
                image_publish(full, self.bridge, self.frontcam_rectified_pub)
                # 发布前视摄像头的校正后左目图像
                image_publish(r_l, self.bridge, self.frontcam_rectifiedleft_pub)
                # 发布前视摄像头的校正后右目图像
                image_publish(r_r, self.bridge, self.frontcam_rectifiedright_pub)

            # 在ROS日志中输出前视图像发布成功的消息
            self.get_logger().info('发布了前视图像')
        else:
            # 如果图像捕获失败，在ROS日志中输出错误消息
            self.get_logger().info('图像获取失败')

    def back_cam_timer_callback(self):
        """
        下视摄像头定时器回调函数：每0.01秒被调用一次，负责采集和处理下视图像
        """
        # 从立体摄像头捕获一帧图像，s表示成功状态，f表示图像帧
        s, f = self.down_sc.capture()

        # 检查图像捕获是否成功
        if s:
            # 将捕获的立体图像分割为左目和右目图像
            img_l, img_r = self.down_sc.get_halfimg(f)
            
            # 发布下视摄像头的原始完整图像
            image_publish(f, self.bridge, self.backcam_raw_pub)
            # 发布下视摄像头的原始左目图像
            image_publish(img_l, self.bridge, self.backcam_rawleft_pub)
            # 发布下视摄像头的原始右目图像
            image_publish(img_r, self.bridge, self.backcam_rawright_pub)
            
            # 检查是否提供了下视摄像头的标定参数
            if self.opt.down_params[0] != "none":
                # 对左右目图像进行立体校正，消除镜头畸变和立体视差
                r_l, r_r = self.down_sc.rectifyImage(img_l, img_r)
                # 将校正后的左右目图像合并为完整的立体图像
                full = self.down_sc.get_fullimg(r_l, r_r)
                # 声明使用全局计数器变量cnt_down
                global cnt_down
                # 增加下视图像计数器
                cnt_down = cnt_down + 1
                # 检查是否达到保存条件（每2帧保存一次）
                if cnt_down == 2:
                    # 获取当前时间
                    now = datetime.now()
                    # 生成带微秒精度的时间戳字符串
                    timestamp = now.strftime("%Y%m%d_%H%M%S%f")
                    # 构建图像保存的完整路径
                    filename = os.path.join("/home/nvidia/Workspace/Cruise/img/down", f"{timestamp}.jpg")
                    # 将校正后的完整图像保存为JPG文件
                    cv2.imwrite(filename, full)
                    # 重置计数器为0
                    cnt_down = 0
                # 发布下视摄像头的校正后完整图像
                image_publish(full, self.bridge, self.backcam_rectified_pub)
                # 发布下视摄像头的校正后左目图像
                image_publish(r_l, self.bridge, self.backcam_rectifiedleft_pub)
                # 发布下视摄像头的校正后右目图像
                image_publish(r_r, self.bridge, self.backcam_rectifiedright_pub)

            # 在ROS日志中输出下视图像发布成功的消息
            self.get_logger().info('发布了下视图像')
        else:
            # 如果图像捕获失败，在ROS日志中输出错误消息
            self.get_logger().info('图像获取失败')

def main(args=None):
    """
    主函数：程序的入口点，负责参数解析、节点初始化和运行
    """
    # 步骤1：过滤ROS 2自动添加的命令行参数（关键步骤）
    # 移除--ros-args等ROS相关参数，只保留用户自定义的参数
    ros_args = remove_ros_args(sys.argv)
    
    # 步骤2：解析自定义命令行参数（使用过滤后的参数列表）
    # 创建参数解析器对象
    parser = argparse.ArgumentParser()
    # 添加前视摄像头设备路径参数，默认为/dev/video0
    parser.add_argument('--front-cam', nargs='+', type=str,
                        default=['/dev/video0'], help='前置摄像头')
    # 添加下视摄像头设备路径参数，默认为/dev/video2
    parser.add_argument('--down-cam', nargs='+', type=str,
                        default=['/dev/video2'], help='下置摄像头')
    # 添加前视摄像头标定参数文件路径，默认为front.npz
    parser.add_argument('--front-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/front.npz'], help='前置摄像头参数存储路径')
    # 添加下视摄像头标定参数文件路径，默认为down.npz
    parser.add_argument('--down-params', nargs='+', type=str,
                        default=['/home/nvidia/Workspace/Cruise/datas/down.npz'], help='下置摄像头参数存储路径')
    
    # 解析命令行参数，跳过脚本文件名（ros_args[0]），只处理自定义参数
    opt = parser.parse_args(ros_args[1:])

    # 步骤3：检查摄像头配置并初始化ROS2节点
    # 检查是否所有摄像头都被禁用
    if opt.front_cam[0] == "none" and opt.down_cam[0] == "none":
        # 如果没有启用任何摄像头，输出提示信息并退出
        print("No Camera opened")
    else:
        # 初始化ROS2通信系统
        rclpy.init(args=args)
        # 创建图像采集节点实例，传入节点名称和配置参数
        node = CaptureNode("uv_capture", opt)
        # 启动节点的事件循环，使节点开始处理回调和定时器
        rclpy.spin(node)
        # 关闭ROS2通信系统，清理资源
        rclpy.shutdown()
        
# 如果此脚本被直接执行（而不是被导入），则调用主函数
if __name__ == '__main__':
    main()

===== .\uv_vision\uv_vision\uv_depthimg.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import cv2
from cv_bridge import CvBridge, CvBridgeError
import numpy as np
import time
from sensor_msgs.msg import Image
import argparse

from uv_vision import stereocam


def image_publish(frame, img_bridge, image_pub):
    # 转为numpy.array
    frame = np.array(frame)
    # 转换为ros2消息类型，且解码方式为b(blue)、g(green)、r(red)
    data = img_bridge.cv2_to_imgmsg(frame, encoding="bgr8")
    # 发布 转换好的 图像类型消息
    image_pub.publish(data)


class CaptureNode(Node):
    def __init__(self, name, front_cam, path):
        super().__init__(name)
        self.bridge = CvBridge()

        self.get_logger().info("大家好，我是%s!" % name)

        if front_cam != "none":
            # 前置摄像头
            self.depthmap_pub = self.create_publisher(
                Image, "depthmap", 10)

            self.front_cam_timer = self.create_timer(
                0.01, self.front_cam_timer_callback)

            self.front_sc = stereocam.StereoCamera()
            self.front_sc.cal_parameters_init(path)
            self.front_sc.device_parameter_config(device=front_cam)
            self.front_sc.rectification_init()

    def front_cam_timer_callback(self):

        s, f = self.front_sc.capture()

        if s:
            img_l, img_r = self.front_sc.get_halfimg(f)

            img_l, img_r = self.front_sc.rectifyImage(img_l, img_r)
            
            depth_map = self.front_sc.getdepth(img_l, img_r)
            
            depth,depth_image = self.front_sc.depth2img(depth_map)
            
            depth_image = cv2.cvtColor(depth_image, cv2.COLOR_GRAY2BGR)

            image_publish(depth_image,self.bridge,self.depthmap_pub)
            
            self.get_logger().info('发布了图像')
        else:
            self.get_logger().info('图像获取失败')


def main(args=None):
    # 加载参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--front-cam', nargs='+', type=str,
                        default=['none'], help='前置摄像头')
    parser.add_argument('--param-path', nargs='+', type=str,
                        default=['datas/stereo_calib.npz'], help='摄像头参数')
    opt = parser.parse_args()

    if opt.front_cam[0] == "none" :
        print("No Camera opened")
    else:
        rclpy.init(args=args)  # 初始化rclpy
        node = CaptureNode(
            "uv_depthimg", opt.front_cam[0],opt.param_path[0])  # 新建一个节点
        rclpy.spin(node)  # 保持节点运行，检测是否收到退出指令（Ctrl+C）
        rclpy.shutdown()  # 关闭rclpy
        

===== .\uv_vision\uv_vision\uv_srs.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import cv2
from cv_bridge import CvBridge, CvBridgeError
import numpy as np
import time
from sensor_msgs.msg import Image
import argparse
import subprocess


class CaptureNode(Node):
    def __init__(self, name, srs_path):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)
        self.path = srs_path

    def run(self):
        subprocess.run(["bash " + self.path], shell=True)


def main(args=None):
    # 加载参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--path', nargs='+', type=str,
                        default=['~/Workspace/Rosws/scripts/run/srs_start.sh'], help='启动文件路径')
    opt = parser.parse_args()

    # # ./objs/srs -c conf/rtc2rtmp.conf

    rclpy.init(args=args)  # 初始化rclpy
    node = CaptureNode(
        "uv_srsserver", opt.path[0])  # 新建一个节点

    node.run()

    # 保持节点运行，检测是否收到退出指令（Ctrl+C）
    rclpy.spin(node)
    # 关闭rclpy
    rclpy.shutdown()

===== .\uv_vision\uv_vision\uv_virtualwebcam.py =====
功能: 代码摘录
import rclpy
from rclpy.node import Node
import cv2
from cv_bridge import CvBridge, CvBridgeError
import numpy as np
import time
from sensor_msgs.msg import Image
import argparse
import subprocess
import socket
import json
import threading




class CaptureNode(Node):
    def __init__(self, name, opt):
        super().__init__(name)
        self.get_logger().info("大家好，我是%s!" % name)

        self.size = (int(opt.width[0]),int(opt.height[0]) )
        self.bridge = CvBridge()

        # 创建一个话题接收指定图像信息
        self.create_subscription(
            Image, opt.topic[0], self.img_rec_callback, 10)

        # 设置推流的参数
        self.web_command = ['ffmpeg',
                            '-y',
                            '-f', 'rawvideo',
                            '-vcodec', 'rawvideo',
                            '-pix_fmt', 'bgr24',
                            '-s', opt.width[0]+'*' +
                            opt.height[0],  # 根据输入视频尺寸填写
                            '-r', '25',
                            '-i', '-',
                            '-c:v', 'h264',
                            '-pix_fmt', 'yuv420p',
                            '-preset', 'ultrafast',
                            "-tune", "zerolatency",
                            "-start_time_realtime", "0",
                            '-f', 'flv',
                            "rtmp://"+opt.host[0]+"/"+opt.suffix[0]
                            ]
        # 创建、管理子进程
        self.web_pipe = subprocess.Popen(
            self.web_command, stdin=subprocess.PIPE)

    def img_rec_callback(self, data):
        try:
            frame = self.bridge.imgmsg_to_cv2(data, "bgr8")

            frame_compressed = cv2.resize(
                frame, self.size, interpolation=cv2.INTER_AREA)

            # 读取尺寸、推流
            img = cv2.resize(frame_compressed, self.size)
            self.web_pipe.stdin.write(img.tobytes())

        except:
            self.get_logger().info('图像获取失败')



def main(args=None):
    # 加载参数
    parser = argparse.ArgumentParser()
    parser.add_argument('--topic', nargs='+', type=str,
                        default=['none'], help='订阅话题')
    parser.add_argument('--host', nargs='+', type=str,
                        default=["192.168.16.108"], help='srs服务器地址')
    parser.add_argument('--suffix', nargs='+', type=str,
                        default=['/cam/front'], help='url后缀')
    parser.add_argument('--height', nargs='+', type=str,
                        default=["360"], help='图像高度')
    parser.add_argument('--width', nargs='+', type=str,
                        default=["640"], help='图像宽度')
    opt = parser.parse_args()

    if opt.topic[0] == "none":
        print("...")
    else:
        rclpy.init(args=args)  # 初始化rclpy
        node = CaptureNode("uv_virtualwebcam", opt)  # 新建一个节点

        # 保持节点运行，检测是否收到退出指令（Ctrl+C）
        rclpy.spin(node)
        # 关闭rclpy
        rclpy.shutdown()
